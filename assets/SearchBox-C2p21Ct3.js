import{h as f,i as C,w as x,j as R,t as M,u as L,k as F,o as u,c as m,l as N,v as _,b as y,n as b,m as w,F as G,p as I,f as E,q as v,x as U}from"./app-BpAZDfdM.js";import{_ as B}from"./plugin-vue_export-helper-DlAUqK2U.js";const O=[{path:"/",title:"Home",pathLocale:"/",contents:[]},{path:"/AI/CS50%20Introduction%20to%20Artificial%20Intelligence%20with%20Python.html",title:"CS50’s Introduction to Artificial Intelligence with Python",pathLocale:"/",contents:[{header:"CS50’s Introduction to Artificial Intelligence with Python",slug:"cs50-s-introduction-to-artificial-intelligence-with-python",content:"课程地址"},{header:"Search",slug:"search",content:`Slides Search problems involve an agent that is given an initial state and a goal state, and it returns a solution of how to get from the former to the latter. A navigator app uses a typical search process, where the agent (the thinking part of the program) receives as input your current location and your desired destination, and, based on a search algorithm, returns a suggested path. However, there are many other forms of search problems, like puzzles or mazes. Finding a solution to a 15 puzzle would require the use of a search algorithm. Agent: An entity that perceives its environment and acts upon that environment. In a navigator app, for example, the agent would be a representation of a car that needs to decide on which actions to take to arrive at the destination.
State: A configuration of an agent in its environment. For example, in a 15 puzzle, a state is any one way that all the numbers are arranged on the board. Initial State: The state from which the search algorithm starts. In a navigator app, that would be the current location. Actions: Choices that can be made in a state. More precisely, actions can be defined as a function. Upon receiving state s as input, Actions(s) returns as output the set of actions that can be executed in state s. For example, in a 15 puzzle, the actions of a given state are the ways you can slide squares in the current configuration (4 if the empty square is in the middle, 3 if next to a side, 2 if in the corner
Transition Model: A description of what state results from performing any applicable action in any state. More precisely, the transition model can be defined as a function. Upon receiving state s and action a as input, Results(s, a) returns the state resulting from performing action a in state s. For example, given a certain configuration of a 15 puzzle (state s), moving a square in any direction (action a) will bring to a new configuration of the puzzle (the new state).
State Space: The set of all states reachable from the initial state by any sequence of actions.
Goal Test: Way to determine whether a given state is a goal state.
Path Cost: Numerical cost associated with a given path.`}]},{path:"/Animation/note.html",title:"Note",pathLocale:"/",contents:[{header:"Note",slug:"note",content:`动画压缩
https://docs.unrealengine.com/4.27/zh-CN/AnimatingObjects/SkeletalMeshAnimation/Sequences/
专业动画压缩
https://github.com/nfrechette Blink System : Humanoids and creatures can blink and have automatic eyes movements that can be tweaked https://www.youtube.com/watch?v=Q7J84TGiKxs
https://www.youtube.com/watch?v=5FpGtI0S-Xo Knock Down : Physical animation system where a creature or humanoid can be knocked down and get up to return in idle naturally (using more or less procedural system) Hit react : Procedural hit react system`}]},{path:"/Basic/Clean%20Code%20Notes.html",title:"Clean Code Notes",pathLocale:"/",contents:[{header:"Clean Code Notes",slug:"clean-code-notes",content:""},{header:"Table of contents",slug:"table-of-contents",content:`Chapter 1 - Clean Code
Chapter 2 - Meaningful Names
Chapter 3 - Functions
Chapter 4 - Comments
Chapter 5 - Formatting
Chapter 6 - Objects and Data Structures
Chapter 7 - Error Handling
Chapter 8 - Boundaries
Chapter 9 - Unit Tests
Chapter 10 - Classes
Chapter 11 - Systems
Chapter 12 - Emergence
Chapter 13 - Concurrency
Chapter 14 - Successive Refinement
Chapter 15 - JUnit Internals
Chapter 16 - Refactoring SerialDate
Chapter 17 - Smells and Heuristics`},{header:"Chapter 1 - Clean Code",content:`This Book is about good programming. It's about how to write good code, and how to transform bad code into good code.
The code represents the detail of the requirements and the details cannot be ignored or abstracted. We may create languages that are closer to the requirements. We can create tools that help us parse and assemble those requirements into formal structures. But we will never eliminate necessary precision.`},{header:"Why write bad code?",slug:"why-write-bad-code",content:`Are you in a rush?
Do you try to go "fast"?
Do not you have time to do a good job?
Are you tired of work in the same program/module?
Does your Boss push you to finish soon? The previous arguments could create a swamp of senseless code.
If you say "I will back to fix it later" you could fall in the LeBlanc's law "Later equals never"
You are a professional and the code is your responsibility. Let's analyze the following anecdote: What if you were a doctor and had a patient who demanded that you stop all the silly hand-washing in preparation for surgery because it was taking too much time? Clearly the patient is the boss; and yet the doctor should absolutely refuse to comply. Why? Because the doctor knows more than the patient about the risks of disease and infection. It would be unprofessional (never mind criminal) for the doctor to comply with the patient. So too it is unprofessional for programmers to bend to the will of managers who don’t understand the risks of making messes.
Maybe sometime you think in go fast to make the deadline. The only way to go fast is to keep the code as clean as possible at all times.`},{header:"What is Clean Code?",slug:"what-is-clean-code",content:`Each experienced programmer has his/her own definition of clean code, but something is clear, a clean code is a code that you can read easily. The clean code is code that has been taken care of.
In his book Uncle Bob says the next: Consider this book a description of the Object Mentor School of Clean Code. The techniques and teachings within are the way that we practice our art. We are willing to claim that if you follow these teachings, you will enjoy the benefits that we have enjoyed, and you will learn to write code that is clean and professional. But don’t make the mistake of thinking that we are somehow “right” in any absolute sense. There are other schools and other masters that have just as much claim to professionalism as we. It would behoove you to learn from them as well.`},{header:"The boy Scout Rule",slug:"the-boy-scout-rule",content:`It’s not enough to write the code well. The code has to be kept clean over time. We have all seen code rot and degrade as time passes. So we must take an active role in preventing this degradation.
It's a good practice apply the Boy Scout Rule Always leave the campground cleaner than you found it.`},{header:"Chapter 2 - Meaningful Names",content:"Names are everywhere in software. Files, directories, variables functions, etc. Because we do so much of it. We have better do it well."},{header:"Use Intention-Revealing Names",slug:"use-intention-revealing-names",content:`It is easy to say that names reveal intent. Choosing good names takes time, but saves more than it takes. So take care with your names and change them when you find better ones.
The name of a variable, function or class, should answer all the big questions. It should tell you why it exists, what it does, and how is used. If a name requires a comment, then the name does not reveals its intent. Does not reveals intention
Reveals intention int d; // elapsed time in days
int elapsedTimeInDays Choosing names that reveal intent can make much easier to understand and change code. Example:
public List<int[]> getThem() { List<int[]> list1 = new ArrayList<int[]>(); for (int[] x : theList) if (x[0] == 4) list1.add(x); return list1;
} This code is simple, but create many questions: What is the content of theList?
What is the significance of the item x[0] in the list?.
Why we compare x[0] vs 4?
How would i use the returned list? The answers to these questions are not present in the code sample, but they could have been. Say that we’re working in a mine sweeper game. We can refactor the previous code as follows:
public List<int[]> getFlaggedCells() { List<int[]> flaggedCells = new ArrayList<int[]>(); for (int[] cell : gameBoard) if (cell[STATUS_VALUE] == FLAGGED) flaggedCells.add(cell); return flaggedCells;
} Now we know the next information: theList represents the gameBoard
x[0] represents a cell in the board and 4 represents a flagged cell
The returned list represents the flaggedCells Notice that the simplicity of the code has not changed. It still has exactly the same number of operators and constants, with exactly the same number of nesting levels. But the code has become much more explicit.
We can improve the code writing a simple class for cells instead of using an array of ints. It can include an intention-revealing function (called it isFlagged) to hide the magic numbers. It results in a new function of the function.
public List<Cell> getFlaggedCells() { List<Cell> flaggedCells = new ArrayList<Cell>(); for (Cell cell : gameBoard) if (cell.isFlagged()) flaggedCells.add(cell); return flaggedCells;
}`},{header:"Avoid Disinformation",slug:"avoid-disinformation",content:`Programmers must avoid leaving false clues that obscure the meaning of code. We should avoid words whose entrenched meaning vary from our intended meaning.
Do not refer to a grouping of accounts as an accountList unless it's actually a List. The word List means something specific to programmers. If the container holding the accounts is not actually a List, it may lead to false conclusions. So accountGroup or bunchOfAccounts or just plain accounts would be better.
Beware of using names which vary in small ways. How long does it take to spot the subtle difference between a XYZControllerForEfficientHandlingOfStrings in one module and, somewhere a little more distant, XYZControllerForEfficientStorageOfStrings? The words have frightfully similar shapes`},{header:"Make Meaningful Distinctions",slug:"make-meaningful-distinctions",content:`Programmers create problems for themselves when they write code solely to satisfy a compiler or interpreter. For example because you can't use the same name to refer two different things in the same scope, you might be tempted to change one name in an arbitrary way. Sometimes this is done by misspelling one, leading to the surprising situation where correcting spelling errors leads to an inability to compile. Example, you create the variable klassbecause the name class was used for something else.
In the next function, the arguments are noninformative, a1 and a2 doesn't provide clues to the author intention.
public static void copyChars(char a1[], char a2[]) { for (int i = 0; i < a1.length; i++) { a2[i] = a1[i]; }
} We can improve the code selecting more explicit argument names:
public static void copyChars(char source[], char destination[]) { for (int i = 0; i < source.length; i++) { destination[i] = source[i]; }
} Noise words are another meaningless distinction. Imagine that you have a Product class. If you have another called ProductInfo or ProductData, you have made the names different without making them mean anything different. Info and Data are indistinct noise words like a, an, and the.
Noise words are redundant. The word variable should never appear in a variable name. The word table should never appear in a table name.`},{header:"Use Pronounceable Names",slug:"use-pronounceable-names",content:`Imagine you have the variable genymdhms (Generation date, year, month, day, hour, minute and second) and imagine a conversation where you need talk about this variable calling it "gen why emm dee aich emm ess". You can consider convert a class like this:
class DtaRcrd102 { private Date genymdhms; private Date modymdhms; private final String pszqint = "102"; /* ... */
}; To
class Customer { private Date generationTimestamp; private Date modificationTimestamp;; private final String recordId = "102"; /* ... */
};`},{header:"Use Searchable Names",slug:"use-searchable-names",content:"Single-letter names and numeric constants have a particular problem in that they are not easy to locate across a body of text."},{header:"Avoid Encoding",slug:"avoid-encoding",content:"We have enough encodings to deal with without adding more to our burden. Encoding type or scope information into names simply adds an extra burden of deciphering. Encoded names are seldom pronounceable and are easy to mis-type. An example of this, is the use of the Hungarian Notation or the use of member prefixes."},{header:"Interfaces and Implementations",slug:"interfaces-and-implementations",content:"These are sometimes a special case for encodings. For example, say you are building an ABSTRACT FACTORY for the creation of shapes. This factory will be an interface and will be implemented by a concrete class. What should you name them? IShapeFactory and ShapeFactory? Is preferable to leave interfaces unadorned.I don’t want my users knowing that I’m handing them an interface. I just want them to know that it’s a ShapeFactory. So if I must encode either the interface or the implementation, I choose the implementation. Calling it ShapeFactoryImp, or even the hideous CShapeFactory, is preferable to encoding the interface."},{header:"Avoid Mental Mapping",slug:"avoid-mental-mapping",content:`Readers shouldn't have to mentally translate your names into other names they already know.
One difference between a smart programmer and a professional programmer is that the professional understands that clarity is king. Professionals use their powers for good and write code that others can understand.`},{header:"Class Names",slug:"class-names",content:"Classes and objects should have noun or noun phrase names like Customer, WikiPage, Account, and AddressParser. Avoid words like Manager,Processor, Data, or Info in the name of a class. A class name should not be a verb."},{header:"Method Names",slug:"method-names",content:`Methods should have verb or verb phrase names like postPayment, deletePage or save. Accessors, mutators, and predicates should be named for their value and prefixed with get, set, and is according to the javabean standard.
When constructors are overloaded, use static factory methods with names that describe the arguments. For example:
Complex fulcrumPoint = Complex.FromRealNumber(23.0); Is generally better than
Complex fulcrumPoint = new Complex(23.0); Consider enforcing their use by making the corresponding constructors private.`},{header:"Don't Be Cute",slug:"don-t-be-cute",content:`Cute name
Clean name holyHandGranade
deleteItems whack
kill eatMyShorts
abort`},{header:"Pick one word per concept",slug:"pick-one-word-per-concept",content:"Pick one word for one abstract concept and stick with it. For instance, it’s confusing to have fetch, retrieve, and get as equivalent methods of different classes."},{header:"Don’t Pun",slug:"don-t-pun",content:`Avoid using the same word for two purposes. Using the same term for two different ideas is essentially a pun.
Example: in a class use add for create a new value by adding or concatenating two existing values and in another class use add for put a simple parameter in a collection, it's a better options use a name like insert or append instead.`},{header:"Use Solution Domain Names",slug:"use-solution-domain-names",content:"Remember that the people who read your code will be programmers. So go ahead and use computer science (CS) terms, algorithm names, pattern names, math terms, and so forth."},{header:"Use Problem Domain Names",slug:"use-problem-domain-names",content:"When there is no “programmer-eese” for what you’re doing, use the name from the problem domain. At least the programmer who maintains your code can ask a domain expert what it means."},{header:"Add Meaningful context",slug:"add-meaningful-context",content:`There are a few names which are meaningful in and of themselves—most are not. Instead, you need to place names in context for your reader by enclosing them in well-named classes, functions, or namespaces. When all else fails, then prefixing the name may be necessary as a last resort
Variables like: firstName, lastName, street, city, state. Taken together it's pretty clear that they form an address, but, what if you saw the variable state being used alone in a method?, you could add context using prefixes like: addrState at least readers will understand that the variable is part of a large structure. Of course, a better solution is to create a class named Address then even the compiler knows that the variables belong to a bigger concept`},{header:"Don’t Add Gratuitous Context",slug:"don-t-add-gratuitous-context",content:`In an imaginary application called “Gas Station Deluxe,” it is a bad idea to prefix every class with GSD. Example: GSDAccountAddress
Shorter names are generally better than longer ones, so long as they are clear. Add no more context to a name than is necessary.`},{header:"Chapter 3 - Functions",content:"Functions are the first line of organization in any topic."},{header:"Small!!",slug:"small",content:"The first rule of functions is that they should be small. The second rule of functions is that they should be smaller than that."},{header:"Blocks and Indenting",slug:"blocks-and-indenting",content:`This implies that the blocks within if statements, else statements, while statements, and so on should be one line long. Probably that line should be a function call. Not only does this keep the enclosing function small, but also adds documentary value because the function called within the block can have a nicely descriptive name.
This also implies that functions should not be large enough to hold nested structures. Therefore, the indent level of a function should not be greater than one or two. This, of course, makes the functions easy to read and understand.`},{header:"Do One Thing",slug:"do-one-thing",content:"FUNCTIONS SHOULD DO ONE THING. THEY SHOULD DO IT WELL. THEY SHOULD DO IT ONLY."},{header:"Sections within Functions",slug:"sections-within-functions",content:"If you have a function divided in sections like declarations, initialization etc, it's a obvious symptom of the function is doing more than one thing. Functions that do one thing cannot be reasonably divided into sections."},{header:"One Level of Abstraction per Function",slug:"one-level-of-abstraction-per-function",content:'In order to make sure our functions are doing "one thing", we need to make sure that the statements within our function are all at the same level of abstraction.'},{header:"Reading Code from Top to Bottom: The Stepdown Rule",slug:"reading-code-from-top-to-bottom-the-stepdown-rule",content:`We want the code to read like a top-down narrative. 5 We want every function to be followed by those at the next level of abstraction so that we can read the program, descending one level of abstraction at a time as we read down the list of functions.
To say this differently, we want to be able to read the program as though it were a set
of TO paragraphs, each of which is describing the current level of abstraction and referencing subsequent TO paragraphs at the next level down.
- To include the setups and teardowns, we include setups, then we include the test page content, and then we include the teardowns.
- To include the setups, we include the suite setup if this is a suite, then we include the regular setup.
- To include the suite setup, we search the parent hierarchy for the “SuiteSetUp” page and add an include statement with the path of that page.
- To search the parent... It turns out to be very difficult for programmers to learn to follow this rule and write functions that stay at a single level of abstraction. But learning this trick is also very important. It is the key to keeping functions short and making sure they do “one thing.” Making the code read like a top-down set of TO paragraphs is an effective technique for keeping the abstraction level consistent.`},{header:"Switch Statements",slug:"switch-statements",content:"It’s hard to make a small switch statement. 6 Even a switch statement with only two cases is larger than I’d like a single block or function to be. It’s also hard to make a switch statement that does one thing. By their nature, switch statements always do N things. Unfortunately we can’t always avoid switch statements, but we can make sure that each switch statement is buried in a low-level class and is never repeated. We do this, of course, with polymorphism."},{header:"Use Descriptive Names",slug:"use-descriptive-names",content:`You know you are working on clean code when each routine turns out to be pretty much what you expected Half the battle to achieving that principle is choosing good names for small functions that do one thing. The smaller and more focused a function is, the easier it is to choose a descriptive name.
Don’t be afraid to make a name long. A long descriptive name is better than a short enigmatic name. A long descriptive name is better than a long descriptive comment. Use a naming convention that allows multiple words to be easily read in the function names, and then make use of those multiple words to give the function a name that says what it does.
Choosing descriptive names will clarify the design of the module in your mind and help you to improve it. It is not at all uncommon that hunting for a good name results in a favorable restructuring of the code.`},{header:"Function arguments",slug:"function-arguments",content:`The ideal number of arguments for a function is zero (niladic). Next comes one (monadic), followed closely by two (dyadic). Three arguments (triadic) should be avoided where possible. More than three (polyadic) requires very special justification—and then shouldn’t be used anyway.
Arguments are even harder from a testing point of view. Imagine the difficulty of writing all the test cases to ensure that all the various combinations of arguments work properly. If there are no arguments, this is trivial. If there’s one argument, it’s not too hard. With two arguments the problem gets a bit more challenging. With more than two arguments, testing every combination of appropriate values can be daunting.
Output arguments are harder to understand than input arguments. When we read a function, we are used to the idea of information going in to the function through arguments and out through the return value. We don’t usually expect information to be going out through the arguments. So output arguments often cause us to do a double-take.`},{header:"Common Monadic Forms",slug:"common-monadic-forms",content:"There are two very common reasons to pass a single argument into a function. You may be asking a question about that argument, as in boolean fileExists(“MyFile”) . Or you may be operating on that argument, transforming it into something else and returning it. For example, InputStream fileOpen(“MyFile”) transforms a file name String into an InputStream return value. These two uses are what readers expect when they see a function. You should choose names that make the distinction clear, and always use the two forms in a consistent context."},{header:"Flag Arguments",slug:"flag-arguments",content:"Flag arguments are ugly. Passing a boolean into a function is a truly terrible practice. It immediately complicates the signature of the method, loudly proclaiming that this function does more than one thing. It does one thing if the flag is true and another if the flag is false!"},{header:"Dyadic Functions",slug:"dyadic-functions",content:`A function with two arguments is harder to understand than a monadic function. For example, writeField(name) is easier to understand than writeField(output-Stream, name)
There are times, of course, where two arguments are appropriate. For example, Point p = new Point(0,0); is perfectly reasonable. Cartesian points naturally take two arguments.
Even obvious dyadic functions like assertEquals(expected, actual) are problematic. How many times have you put the actual where the expected should be? The two arguments have no natural ordering. The expected, actual ordering is a convention that requires practice to learn.
Dyads aren’t evil, and you will certainly have to write them. However, you should be aware that they come at a cost and should take advantage of what mechanims may be available to you to convert them into monads. For example, you might make the writeField method a member of outputStream so that you can say outputStream. writeField(name) . Or you might make the outputStream a member variable of the current class so that you don’t have to pass it. Or you might extract a new class like FieldWriter that takes the outputStream in its constructor and has a write method.`},{header:"Triads",slug:"triads",content:"Functions that take three arguments are significantly harder to understand than dyads. The issues of ordering, pausing, and ignoring are more than doubled. I suggest you think very carefully before creating a triad."},{header:"Argument Objects",slug:"argument-objects",content:`Compare:
Circle makeCircle(double x, double y, double radius); vs
Circle makeCircle(Point center, double radius);`},{header:"Verbs and Keywords",slug:"verbs-and-keywords",content:`Choosing good names for a function can go a long way toward explaining the intent of the function and the order and intent of the arguments. In the case of a monad, the function and argument should form a very nice verb/noun pair. For example, write(name) is very evocative. Whatever this “name” thing is, it is being “written.” An even better name might be writeField(name) , which tells us that the "name" thing is a "field".
This last is an example of the keyword form of a function name. Using this form we encode the names of the arguments into the function name. For example, assertEquals might be better written as assertExpectedEqualsActual(expected, actual). This strongly mitigates the problem of having to remember the ordering of the arguments.`},{header:"Output Arguments",slug:"output-arguments",content:"In general output arguments should be avoided. If your function must change the state of something, have it change the state of its owning object."},{header:"Command Query Separation",slug:"command-query-separation",content:"Functions should either do something or answer something, but not both. Either your function should change the state of an object, or it should return some information about that object. Doing both often leads to confusion."},{header:"Prefer Exceptions to Returning Error Codes",slug:"prefer-exceptions-to-returning-error-codes",content:"Returning error codes from command functions is a subtle violation of command query separation."},{header:"Don't Repeat Yourself",slug:"don-t-repeat-yourself",content:"Duplication may be the root of all evil in software. Many principles and practices have been created for the purpose of controlling or eliminating it."},{header:"Structured Programming",slug:"structured-programming",content:`Some programmers follow Edsger Dijkstra’s rules of structured programming. Dijkstra said that every function, and every block within a function, should have one entry and one exit. Following these rules means that there should only be one return statement in a function, no break or continue statements in a loop, and never, ever, any goto statements.
While we are sympathetic to the goals and disciplines of structured programming, those rules serve little benefit when functions are very small. It is only in larger functions that such rules provide significant benefit.
So if you keep your functions small, then the occasional multiple return , break , or continue statement does no harm and can sometimes even be more expressive than the single-entry, single-exit rule. On the other hand, goto only makes sense in large functions, so it should be avoided`},{header:"Chapter 4 - Comments",content:`Nothing can be quite so helpful as a well-placed comment. Nothing can clutter up a module more than frivolous dogmatic comments. Nothing can be quite so damaging as an old comment that propagates lies and misinformation.
If our programming languages were expressive enough, or if we had the talent to subtly wield those languages to express our intent, we would not need comments very much—perhaps not at all.`},{header:"Comments Do Not Make Up for Bad Code",slug:"comments-do-not-make-up-for-bad-code",content:"Clear and expressive code with few comments is far superior to cluttered and complex code with lots of comments. Rather than spend your time writing the comments that explain the mess you’ve made, spend it cleaning that mess."},{header:"Explain Yourself in Code",slug:"explain-yourself-in-code",content:`// Check to see if the employee is eligible for full benefits
if ((employee.flags & HOURLY_FLAG) && (employee.age > 65)) vs
if (employee.isEligibleForFullBenefits())`},{header:"Good Comments",slug:"good-comments",content:"Some comments are necessary or beneficial. However the only truly good comment is the comment you found a way not to write."},{header:"Legal Comments",slug:"legal-comments",content:"Sometimes our corporate coding standards force us to write certain comments for legal reasons. For example, copyright and authorship statements are necessary and reasonable things to put into a comment at the start of each source file."},{header:"Informative Comments",slug:"informative-comments",content:`It is sometimes useful to provide basic information with a comment. For example, consider this comment that explains the return value of an abstract method:
// Returns an instance of the Responder being tested.
protected abstract Responder responderInstance(); A comment like this can sometimes be useful, but it is better to use the name of the function to convey the information where possible. For example, in this case the comment could be made redundant by renaming the function: responderBeingTested.`},{header:"Explanation of Intent",slug:"explanation-of-intent",content:`Sometimes a comment goes beyond just useful information about the implementation and provides the intent behind a decision. Example:
public int compareTo(Object o)
{ if(o instanceof WikiPagePath) { WikiPagePath p = (WikiPagePath) o; String compressedName = StringUtil.join(names, ""); String compressedArgumentName = StringUtil.join(p.names, ""); return compressedName.compareTo(compressedArgumentName); } return 1; // we are greater because we are the right type.
}`},{header:"Clarification",slug:"clarification",content:"Sometimes it is just helpful to translate the meaning of some obscure argument or return value into something that's readable. In general it is better to find a way to make that argument or return value clear in its own right; but when its part of the standard library, or in code that you cannot alter, then a helpful clarifying comment can be useful."},{header:"Warning of concequences",slug:"warning-of-concequences",content:`Sometimes it is useful to warn other programmers about certain consequences.
// Don't run unless you
// have some time to kill.
public void _testWithReallyBigFile() { writeLinesToFile(10000000); response.setBody(testFile); response.readyToSend(this); String responseString = output.toString(); assertSubString("Content-Length: 1000000000", responseString); assertTrue(bytesSent > 1000000000);
}`},{header:"TODO Comments",slug:"todo-comments",content:`It is sometimes reasonable to leave “To do” notes in the form of //TODO comments. In the
following case, the TODO comment explains why the function has a degenerate implementation and what that function's future should be.
//TODO-MdM these are not needed
// We expect this to go away when we do the checkout model
protected VersionInfo makeVersion() throws Exception { return null;
} TODOs are jobs that the programmer thinks should be done, but for some reason can’t do at the moment. It might be a reminder to delete a deprecated feature or a plea for someone else to look at a problem. It might be a request for someone else to think of a better name or a reminder to make a change that is dependent on a planned event. Whatever else a TODO might be, it is not an excuse to leave bad code in the system.`},{header:"Amplification",slug:"amplification",content:`A comment may be used to amplify the importance of something that may otherwise seem inconsequential.
String listItemContent = match.group(3).trim();
// the trim is real important. It removes the starting
// spaces that could cause the item to be recognized
// as another list.
new ListItemWidget(this, listItemContent, this.level + 1);
return buildList(text.substring(match.end()));`},{header:"Javadocs in Public APIs",slug:"javadocs-in-public-apis",content:"There is nothing quite so helpful and satisfying as a well-described public API. The javadocs for the standard Java library are a case in point. It would be difficult, at best, to write Java programs without them."},{header:"Bad Comments",slug:"bad-comments",content:"Most comments fall into this category. Usually they are crutches or excuses for poor code or justifications for insufficient decisions, amounting to little more than the programmer talking to himself."},{header:"Mumbling",slug:"mumbling",content:`Plopping in a comment just because you feel you should or because the process requires it, is a hack. If you decide to write a comment, then spend the time necessary to make sure it is the best comment you can write. Example:
public void loadProperties() { try { String propertiesPath = propertiesLocation + "/" + PROPERTIES_FILE; FileInputStream propertiesStream = new FileInputStream(propertiesPath); loadedProperties.load(propertiesStream); } catch(IOException e) { // No properties files means all defaults are loaded }
} What does that comment in the catch block mean? Clearly meant something to the author, but the meaning not come though all that well. Apparently, if we get an IOException, it means that there was no properties file; and in that case all the defaults are loaded. But who loads all the defaults?`},{header:"Redundant Comments",slug:"redundant-comments",content:`// Utility method that returns when this.closed is true. Throws an exception
// if the timeout is reached.
public synchronized void waitForClose(final long timeoutMillis) throws Exception { if(!closed) { wait(timeoutMillis); if(!closed) throw new Exception("MockResponseSender could not be closed"); }
} What purpose does this comment serve? It’s certainly not more informative than the code. It does not justify the code, or provide intent or rationale. It is not easier to read than the code. Indeed, it is less precise than the code and entices the reader to accept that lack of precision in lieu of true understanding.`},{header:"Misleading comments",slug:"misleading-comments",content:"Sometimes, with all the best intentions, a programmer makes a statement in his comments that isn't precise enough to be accurate. Consider for another moment the example of the previous section. The method does not return when this.closed becomes true. It returns if this.closed is true; otherwise, it waits for a blind time-out and then throws an exception if this.closed is still not true."},{header:"Mandated Comments",slug:"mandated-comments",content:`It is just plain silly to have a rule that says that every function must have a javadoc, or every variable must have a comment. Comments like this just clutter up the code, propagate lies, and lend to general confusion and disorganization.
/**
*
* @param title The title of the CD
* @param author The author of the CD
* @param tracks The number of tracks on the CD
* @param durationInMinutes The duration of the CD in minutes
*/
public void addCD(String title, String author, int tracks, int durationInMinutes) { CD cd = new CD(); cd.title = title; cd.author = author; cd.tracks = tracks; cd.duration = duration; cdList.add(cd);
}`},{header:"Journal Comments",slug:"journal-comments",content:`Sometimes people add a comment to the start of a module every time they edit it. Example:
* Changes (from 11-Oct-2001)
* --------------------------
* 11-Oct-2001 : Re-organised the class and moved it to new package com.jrefinery.date (DG);
* 05-Nov-2001 : Added a getDescription() method, and eliminated NotableDate class (DG);
* 12-Nov-2001 : IBD requires setDescription() method, now that NotableDate class is gone (DG); Changed getPreviousDayOfWeek(),
getFollowingDayOfWeek() and getNearestDayOfWeek() to correct bugs (DG);
* 05-Dec-2001 : Fixed bug in SpreadsheetDate class (DG); Today we have source code control systems, we don't need this type of logs.`},{header:"Noise Comments",slug:"noise-comments",content:`The comments in the follow examples doesn't provides new information.
/**
* Default constructor.
*/
protected AnnualDateRule() {
} /** The day of the month. */
private int dayOfMonth; Javadocs comments could enter in this category. Many times they are just redundant noisy comments written out of some misplaced desire to provide documentation.`},{header:"Don’t Use a Comment When You Can Use a Function or a Variable",slug:"don-t-use-a-comment-when-you-can-use-a-function-or-a-variable",content:`Example:
// does the module from the global list <mod> depend on the
// subsystem we are part of?
if (smodule.getDependSubsystems().contains(subSysMod.getSubSystem())) vs
ArrayList moduleDependees = smodule.getDependSubsystems();
String ourSubSystem = subSysMod.getSubSystem();
if (moduleDependees.contains(ourSubSystem))`},{header:"Position Markers",slug:"position-markers",content:`This type of comments are noising
// Actions //////////////////////////////////`},{header:"Closing Brace Comments",slug:"closing-brace-comments",content:`Example:
public class wc { public static void main(String[] args) { BufferedReader in = new BufferedReader(new InputStreamReader(System.in)); String line; int lineCount = 0; int charCount = 0; int wordCount = 0; try { while ((line = in.readLine()) != null) { lineCount++; charCount += line.length(); String words[] = line.split("\\\\W"); wordCount += words.length; } //while System.out.println("wordCount = " + wordCount); System.out.println("lineCount = " + lineCount); System.out.println("charCount = " + charCount); } // try catch (IOException e) { System.err.println("Error:" + e.getMessage()); } //catch } //main You could break the code in small functions instead to use this type of comments.`},{header:"Attributions and Bylines",slug:"attributions-and-bylines",content:`Example:
/* Added by Rick */
The VCS can manage this information instead.`},{header:"Commented-Out Code",slug:"commented-out-code",content:`InputStreamResponse response = new InputStreamResponse();
response.setBody(formatter.getResultStream(), formatter.getByteCount());
// InputStream resultsStream = formatter.getResultStream();
// StreamReader reader = new StreamReader(resultsStream);
// response.setContent(reader.read(formatter.getByteCount())); If you don't need anymore, please delete it, you can back later with your VCS if you need it again.`},{header:"HTML Comments",slug:"html-comments",content:`HTML in source code comments is an abomination, as you can tell by reading the code below.
/**
* Task to run fit tests.
* This task runs fitnesse tests and publishes the results.
* <p/>
* <pre>
* Usage:
* &lt;taskdef name=&quot;execute-fitnesse-tests&quot;
* classname=&quot;fitnesse.ant.ExecuteFitnesseTestsTask&quot;
* classpathref=&quot;classpath&quot; /&gt;
* OR
* &lt;taskdef classpathref=&quot;classpath&quot;
* resource=&quot;tasks.properties&quot; /&gt;
* <p/>
* &lt;execute-fitnesse-tests
* suitepage=&quot;FitNesse.SuiteAcceptanceTests&quot;
* fitnesseport=&quot;8082&quot;
* resultsdir=&quot;\${results.dir}&quot;
* resultshtmlpage=&quot;fit-results.html&quot;
* classpathref=&quot;classpath&quot; /&gt;
* </pre>
*/`},{header:"Nonlocal Information",slug:"nonlocal-information",content:"If you must write a comment, then make sure it describes the code it appears near. Don't offer systemwide information in the context of a local comment."},{header:"Too Much Information",slug:"too-much-information",content:"Don't put interesting historical discussions or irrelevant descriptions of details into your comments."},{header:"Inobvious Connection",slug:"inobvious-connection",content:"The connection between a comment and the code it describes should be obvious. If you are going to the trouble to write a comment, then at least you'd like the reader to be able to look at the comment and the code and understand what the comment is talking about"},{header:"Function Headers",slug:"function-headers",content:"Short functions don’t need much description. A well-chosen name for a small function that does one thing is usually better than a comment header."},{header:"Javadocs in Nonpublic Code",slug:"javadocs-in-nonpublic-code",content:"Javadocs are for public APIs, in nonpublic code could be a distraction more than a help."},{header:"Chapter 5 - Formatting",content:"Code formatting is important. It is too important to ignore and it is too important to treat religiously. Code formatting is about communication, and communication is the professional developer’s first order of business."},{header:"Vertical Formatting",slug:"vertical-formatting",content:""},{header:"Vertical Openness Between Concepts",slug:"vertical-openness-between-concepts",content:`This concept consist in how to you separate concepts in your code, In the next example we can appreciate it.
package fitnesse.wikitext.widgets; import java.util.regex.*; public class BoldWidget extends ParentWidget { public static final String REGEXP = "'''.+?'''"; private static final Pattern pattern = Pattern.compile("'''(.+?)'''", Pattern.MULTILINE + Pattern.DOTALL ); public BoldWidget(ParentWidget parent, String text) throws Exception { super(parent); Matcher match = pattern.matcher(text); match.find(); addChildWidgets(match.group(1)); } public String render() throws Exception { StringBuffer html = new StringBuffer("<b>"); html.append(childHtml()).append("</b>"); return html.toString(); }
} package fitnesse.wikitext.widgets;
import java.util.regex.*;
public class BoldWidget extends ParentWidget { public static final String REGEXP = "'''.+?'''"; private static final Pattern pattern = Pattern.compile("'''(.+?)'''", Pattern.MULTILINE + Pattern.DOTALL); public BoldWidget(ParentWidget parent, String text) throws Exception { super(parent); Matcher match = pattern.matcher(text); match.find(); addChildWidgets(match.group(1)); } public String render() throws Exception { StringBuffer html = new StringBuffer("<b>"); html.append(childHtml()).append("</b>"); return html.toString(); }
} As you can see, the readability of the first example is greater than that of the second.`},{header:"Vertical Density",slug:"vertical-density",content:`The vertical density implies close association. So lines of code that are tightly related should appear vertically dense. Check the follow example:
public class ReporterConfig { /** * The class name of the reporter listener */ private String m_className; /** * The properties of the reporter listener */ private List<Property> m_properties = new ArrayList<Property>(); public void addProperty(Property property) { m_properties.add(property); } public class ReporterConfig { private String m_className; private List<Property> m_properties = new ArrayList<Property>(); public void addProperty(Property property) { m_properties.add(property); }
} The second code it's much easier to read. It fits in an "eye-full".`},{header:"Vertical Distance",slug:"vertical-distance",content:`Variable Declarations. Variables should be declared as close to their usage as possible. Because our functions are very short, local variables should appear at the top of each function,
Instance variables, on the other hand, should be declared at the top of the class. This should not increase the vertical distance of these variables, because in a well-designed class, they are used by many, if not all, of the methods of the class.
There have been many debates over where instance variables should go. In C++ we commonly practiced the so-called scissors rule, which put all the instance variables at the bottom. The common convention in Java, however, is to put them all at the top of the class. I see no reason to follow any other convention. The important thing is for the instance variables to be declared in one well-known place. Everybody should know where to go to see the declarations.
Dependent Functions. If one function calls another, they should be vertically close, and the caller should be above the callee, if at all possible. This gives the program a natural flow. If the convention is followed reliably, readers will be able to trust that function definitions will follow shortly after their use.
Conceptual Affinity. Certain bits of code want to be near other bits. They have a certain conceptual affinity. The stronger that affinity, the less vertical distance there should be between them.`},{header:"Vertical Ordering",slug:"vertical-ordering",content:"In general we want function call dependencies to point in the downward direction. That is, a function that is called should be below a function that does the calling. This creates a nice flow down the source code module from high level to low level. (This is the exact opposite of languages like Pascal, C, and C++ that enforce functions to be defined, or at least declared, before they are used)"},{header:"Horizontal Formatting",slug:"horizontal-formatting",content:""},{header:"Horizontal Openness and Density",slug:"horizontal-openness-and-density",content:`We use horizontal white space to associate things that are strongly related and disassociate things that are more weakly related. Example:
private void measureLine(String line) { lineCount++; int lineSize = line.length(); totalChars += lineSize; lineWidthHistogram.addLine(lineSize, lineCount); recordWidestLine(lineSize);
} Assignment statements have two distinct and major elements: the left side and the right side. The spaces make that separation obvious.`},{header:"Horizontal Alignment",slug:"horizontal-alignment",content:`public class Example implements Base
{ private Socket socket; private inputStream input; protected long requestProgress; public Expediter(Socket s, inputStream input) { this.socket = s; this.input = input; }
} In modern languages this type of alignment is not useful. The alignment seems to emphasize the wrong things and leads my eye away from the true intent.
public class Example implements Base
{ private Socket socket; private inputStream input; protected longrequestProgress; public Expediter(Socket s, inputStream input) { this.socket = s; this.input = input; }
} This is a better approach.`},{header:"Indentation",slug:"indentation",content:"The indentation it's important because help us to have a visible hierarchy and well defined blocks."},{header:"Team Rules",slug:"team-rules",content:`Every programmer has his own favorite formatting rules, but if he works in a team, then the team rules.
A team of developers should agree upon a single formatting style, and then every member of that team should use that style. We want the software to have a consistent style. We don't want it to appear to have been written by a bunch of disagreeing individuals.`},{header:"Chapter 6 - Objects and Data Structures",content:""},{header:"Data Abstraction",slug:"data-abstraction",content:"Hiding implementation is not just a matter of putting a layer of functions between the variables. Hiding implementation is about abstractions! A class does not simply push its variables out through getters and setters. Rather it exposes abstract interfaces that allow its users to manipulate the essence of the data, without having to know its implementation."},{header:"Data/Object Anti-Symmetry",slug:"data-object-anti-symmetry",content:`These two examples show the difference between objects and data structures. Objects hide their data behind abstractions and expose functions that operate on that data. Data structure expose their data and have no meaningful functions.
Procedural Shape
public class Square { public Point topLeft; public double side;
} public class Rectangle { public Point topLeft; public double height; public double width;
} public class Circle { public Point center; public double radius;
} public class Geometry { public final double PI = 3.141592653589793; public double area(Object shape) throws NoSuchShapeException { if (shape instanceof Square) { Square s = (Square)shape; return s.side * s.side; } else if (shape instanceof Rectangle) { Rectangle r = (Rectangle)shape; return r.height * r.width; } else if (shape instanceof Circle) { Circle c = (Circle)shape; return PI * c.radius * c.radius; } throw new NoSuchShapeException(); }
} Polymorphic Shape
public class Square implements Shape { private Point topLeft; private double side; public double area() { return side*side; }
} public class Rectangle implements Shape { private Point topLeft; private double height; private double width; public double area() { return height * width; }
} public class Circle implements Shape { private Point center; private double radius; public final double PI = 3.141592653589793; public double area() { return PI * radius * radius; }
} Again, we see the complimentary nature of these two definitions; they are virtual opposites! This exposes the fundamental dichotomy between objects and data structures: Procedural code (code using data structures) makes it easy to add new functions without changing the existing data structures. OO code, on the other hand, makes it easy to add new classes without changing existing functions. The complement is also true: Procedural code makes it hard to add new data structures because all the functions must change. OO code makes it hard to add new functions because all the classes must change. Mature programmers know that the idea that everything is an object is a myth. Sometimes you really do want simple data structures with procedures operating on them.`},{header:"The Law of Demeter",slug:"the-law-of-demeter",content:`There is a well-known heuristic called the Law of Demeter that says a module should not know about the innards of the objects it manipulates.
More precisely, the Law of Demeter says that a method f of a class C should only call the methods of these: C
An object created by f
An object passed as an argument to f
An object held in an instance variable of C The method should not invoke methods on objects that are returned by any of the allowed functions. In other words, talk to friends, not to strangers.`},{header:"Data Transfer Objects",slug:"data-transfer-objects",content:"The quintessential form of a data structure is a class with public variables and no functions. This is sometimes called a data transfer object, or DTO. DTOs are very useful structures, especially when communicating with databases or parsing messages from sockets, and so on. They often become the first in a series of translation stages that convert raw data in a database into objects in the application code."},{header:"Chapter 7 - Error Handling",content:"Many code bases are completely dominated by error handling. When I say dominated, I don't mean that error handling is all that they do. I mean that it is nearly impossible to see what the code does because of all of the scattered error handling. Error handling is important, but if it obscures logic, it's wrong."},{header:"Use Exceptions Rather Than Return Codes",slug:"use-exceptions-rather-than-return-codes",content:"Back in the distant past there were many languages that didn't have exceptions. In those languages the techniques for handling and reporting errors were limited. You either set an error flag or returned an error code that the caller could check"},{header:"Write Your Try-Catch-Finally Statement First",slug:"write-your-try-catch-finally-statement-first",content:"In a way, try blocks are like transactions. Your catch has to leave your program in a consistent state, no matter what happens in the try. For this reason it is good practice to start with a try-catch-finally statement when you are writing code that could throw exceptions. This helps you define what the user of that code should expect, no matter what goes wrong with the code that is executed in the try."},{header:"Provide Context with Exceptions",slug:"provide-context-with-exceptions",content:`Each exception that you throw should provide enough context to determine the source and location of an error.
Create informative error messages and pass them along with your exceptions. Mention the operation that failed and the type of failure. If you are logging in your application, pass along enough information to be able to log the error in your catch.`},{header:"Don't Return Null",slug:"don-t-return-null",content:"If you are tempted to return null from a method, consider throwing an exception or returning a SPECIAL CASE object instead. If you are calling a null-returning method from a third-party API, consider wrapping that method with a method that either throws an exception or returns a special case object."},{header:"Don't Pass Null",slug:"don-t-pass-null",content:"Returning null from methods is bad, but passing null into methods is worse. Unless you are working with an API which expects you to pass null, you should avoid passing null in your code whenever possible."},{header:"Chapter 8 - Boundaries",content:"We seldom control all the software in our systems. Sometimes we buy third-party pack- ages or use open source. Other times we depend on teams in our own company to produce components or subsystems for us. Somehow we must cleanly integrate this foreign code with our own."},{header:"Using Third-Party Code",slug:"using-third-party-code",content:`There is a natural tension between the provider of an interface and the user of an interface. Providers of third-party packages and frameworks strive for broad applicability so they can work in many environments and appeal to a wide audience. Users, on the other hand, want an interface that is focused on their particular needs. This tension can cause problems at the boundaries of our systems. Example:
Map sensors = new HashMap();
Sensor s = (Sensor)sensors.get(sensorId); VS
public class Sensors { private Map sensors = new HashMap(); public Sensor getById(String id) { return (Sensor) sensors.get(id); } //snip
} The first code exposes the casting in the Map, while the second is able to evolve with very little impact on the rest of the application. The casting and type management is handled inside the Sensors class.
The interface is also tailored and constrained to meet the needs of the application. It results in code that is easier to understand and harder to misuse. The Sensors class can enforce design and business rules.`},{header:"Exploring and Learning Boundaries",slug:"exploring-and-learning-boundaries",content:`Third-party code helps us get more functionality delivered in less time. Where do we start when we want to utilize some third-party package? It’s not our job to test the third-party code, but it may be in our best interest to write tests for the third-party code we use.
It's a good idea write some test for learn and understand how to use a third-party code. Newkirk calls such tests learning tests.`},{header:"Learning Tests Are Better Than Free",slug:"learning-tests-are-better-than-free",content:`The learning tests end up costing nothing. We had to learn the API anyway, and writing those tests was an easy and isolated way to get that knowledge. The learning tests were precise experiments that helped increase our understanding.
Not only are learning tests free, they have a positive return on investment. When there are new releases of the third-party package, we run the learning tests to see whether there are behavioral differences.`},{header:"Using Code That Does Not Yet Exist",slug:"using-code-that-does-not-yet-exist",content:"Some times it's necessary work in a module that will be connected to another module under develop, and we have no idea about how to send the information, because the API had not been designed yet. In this cases it's recommendable create an interface for encapsulate the communication with the pending module. In this way we maintain the control over our module and we can test although the second module isn't available yet."},{header:"Clean Boundaries",slug:"clean-boundaries",content:"Interesting things happen at boundaries. Change is one of those things. Good software designs accommodate change without huge investments and rework. When we use code that is out of our control, special care must be taken to protect our investment and make sure future change is not too costly."},{header:"Chapter 9 - Unit Tests",content:`Test
Driven
Development`},{header:"The Three Laws of TDD",slug:"the-three-laws-of-tdd",content:`First Law You may not write production code until you have written a failing unit test.
Second Law You may not write more of a unit tests than is sufficient to fail, and not comipling is failing.
Third Law You may not write more production code than is sufficient to pass the currently failing tests.`},{header:"Clean Tests",slug:"clean-tests",content:`If you don't keep your tests clean, you will lose them.
The readability it's very important to keep clean your tests.`},{header:"One Assert per test",slug:"one-assert-per-test",content:"It's recomendable maintain only one asserts per tests, because this helps to maintain each tests easy to understand."},{header:"Single concept per Test",slug:"single-concept-per-test",content:"This rule will help you to keep short functions. Write one test per each concept that you need to verify"},{header:"F.I.R.S.T",slug:"f-i-r-s-t",content:`Fast Test should be fast.
Independient Test should not depend on each other.
Repeatable Test Should be repeatable in any environment.
Self-Validating Test should have a boolean output. either they pass or fail.
Timely Unit tests should be written just before the production code that makes them pass. If you write tests after the production code, then you may find the production code to be hard to test.`},{header:"Chapter 10 - Classes",content:""},{header:"Class Organization",slug:"class-organization",content:""},{header:"Encapsulation",slug:"encapsulation",content:"We like to keep our variables and utility functions small, but we're not fanatic about it. Sometimes we need to make a variable or utility function protected so that it can be accessed by a test."},{header:"Classes Should be Small",slug:"classes-should-be-small",content:`First Rule: Classes should be small
Second Rule: Classes should be smaller than the first rule`},{header:"The Single Responsibility Principle",slug:"the-single-responsibility-principle",content:`Classes should have one responsibility - one reason to change
SRP is one of the more important concept in OO design. It's also one of the simple concepts to understand and adhere to.`},{header:"Cohesion",slug:"cohesion",content:"Classes Should have a small number of instance variables. Each of the methods of a class should manipulate one or more of those variables. In general the more variables a method manipulates the more cohesive that method is to its class. A class in which each variable is used by each method is maximally cohesive."},{header:"Maintaining Cohesion Results in Many Small Classes",slug:"maintaining-cohesion-results-in-many-small-classes",content:"Just the act of breaking large functions into smaller functions causes a proliferation of classes."},{header:"Organizing for change",slug:"organizing-for-change",content:"For most systems, change is continual. Every change subjects us to the risk that the remainder of the system no longer works as intended. In a clean system we organize our classes so as to reduce the risk of change."},{header:"Isolating from Change",slug:"isolating-from-change",content:"Needs will change, therefore code will change. We learned in OO 101 that there are concrete classes, which contain implementation details (code), and abstract classes, which represent concepts only. A client class depending upon concrete details is at risk when those details change. We can introduce intefaces and abstract classes to help isolate the impact of those details."},{header:"Chapter 11 - Systems",content:""},{header:"Separate Constructing a System from using It",slug:"separate-constructing-a-system-from-using-it",content:'Software Systems should separate the startup process, when the application objects are constructed and the dependencies are "wired" together, from the runtime logic that takes over after startup'},{header:"Separation from main",slug:"separation-from-main",content:`One way to separate construction from use is simply to move all aspects of construction to main, or modules called by main, and to design the rest of the system assuming that all objects have been created constructed and wired up appropriately.
The Abstract Factory Pattern is an option for this kind of approach.`},{header:"Dependency Injection",slug:"dependency-injection",content:`A powerful mechanism for separating construction from use is Dependency Injection (DI), the application of Inversion of control (IoC) to dependency management. Inversion of control moves secondary responsibilities from an object to other objects that are dedicated to the purpose, thereby supporting the Single Responsibility Principle. In context of dependency management, an object should not take responsibility for instantiating dependencies itself. Instead, it, should pass this responsibility to another "authoritative" mechanism, thereby inverting the control. Because setup is a global concern, this authoritative mechanism will usually be either the "main"
routine or a special-purpose container.`},{header:"Chapter 12 - Emergence",content:`According to Kent Beck, a design is "simple" if it follows these rules Run all tests
Contains no duplication
Expresses the intent of programmers
Minimizes the number of classes and methods`},{header:"Chapter 13 - Concurrency",content:`Concurrence is a decoupling strategy. It helps us decouple what gets fone from when it gets done. In single-threaded applications what and when are so strongly coupled that the state of the entire application can often be determined by looking at the stack backtrace. A programmer who debugs such a system can set a breakpoint, or a sequence of breakpoints, and know the state of the system by which breakpoints are hit.
Decoupling what from when can dramatically improve both the throughput and structures of an application. From a structural point of view the application looks like many lit- tle collaborating computers rather than one big main loop. This can make the system easier to understand and offers some powerful ways to separate concerns.`},{header:"Myths and Misconceptions",slug:"myths-and-misconceptions",content:`Concurrency always improves performance.
Concurrency can sometimes improve performance, but only when there is a lot of wait time that can be shared between multiple threads or multiple processors. Neither situ- ation is trivial.
Design does not change when writing concurrent programs.
In fact, the design of a concurrent algorithm can be remarkably different from the design of a single-threaded system. The decoupling of what from when usually has a huge effect on the structure of the system.
Understanding concurrency issues is not important when working with a container such as a Web or EJB container.
In fact, you’d better know just what your container is doing and how to guard against the issues of concurrent update and deadlock described later in this chapter.
Here are a few more balanced sound bites regarding writing concurrent software:
Concurrency incurs some overhead, both in performance as well as writing additional code.
Correct concurrency is complex, even for simple problems.
Concurrency bugs aren’t usually repeatable, so they are often ignored as one-offs instead of the true defects they are.
Concurrency often requires a fundamental change in design strategy.`},{header:"Chapter 14 - Successive Refinement",content:"This chapter is a study case. It's recommendable to completely read it to understand more."},{header:"Chapter 15 - JUnit Internals",content:"This chapter analize the JUnit tool. It's recommendable to completely read it to understand more."},{header:"Chapter 16 - Refactoring SerialDate",content:"This chapter is a study case. It's recommendable to completely read it to understand more."},{header:"Chapter 17 - Smells and Heuristics",content:`A reference of code smells from Martin Fowler's Refactoring and Robert C Martin's Clean Code.
While clean code comes from discipline and not a list or value system, here is a starting point.`},{header:"Comments",slug:"comments",content:""},{header:"C1: Inappropriate Information",slug:"c1-inappropriate-information",content:"Reserve comments for technical notes referring to code and design."},{header:"C2: Obsolete Comment",slug:"c2-obsolete-comment",content:"Update or delete obsolete comments."},{header:"C3: Redundant Comment",slug:"c3-redundant-comment",content:"A redundant comment describes something able to sufficiently describe itself."},{header:"C4: Poorly Written Comment",slug:"c4-poorly-written-comment",content:"Comments should be brief, concise, correctly spelled."},{header:"C5: Commented-Out Code",slug:"c5-commented-out-code",content:"Ghost code. Delete it."},{header:"Environment",slug:"environment",content:""},{header:"E1: Build Requires More Than One Step",slug:"e1-build-requires-more-than-one-step",content:"Builds should require one command to check out and one command to run."},{header:"E2: Tests Require More Than One Step",slug:"e2-tests-require-more-than-one-step",content:"Tests should be run with one button click through an IDE, or else with one command."},{header:"Functions",slug:"functions",content:""},{header:"F1: Too Many Arguments",slug:"f1-too-many-arguments",content:"Functions should have no arguments, then one, then two, then three. No more than three."},{header:"F2: Output Arguments",slug:"f2-output-arguments",content:"Arguments are inputs, not outputs. If somethings state must be changed, let it be the state of the called object."},{header:"F3: Flag Arguments",slug:"f3-flag-arguments",content:"Eliminate boolean arguments."},{header:"F4: Dead Function",slug:"f4-dead-function",content:"Discard uncalled methods. This is dead code."},{header:"General",slug:"general",content:""},{header:"G1: Multiple Languages in One Source File",slug:"g1-multiple-languages-in-one-source-file",content:"Minimize the number of languages in a source file. Ideally, only one."},{header:"G2: Obvious Behavior is Unimplemented",slug:"g2-obvious-behavior-is-unimplemented",content:"The result of a function or class should not be a surprise."},{header:"G3: Incorrect Behavior at the Boundaries",slug:"g3-incorrect-behavior-at-the-boundaries",content:"Write tests for every boundary condition."},{header:"G4: Overridden Safeties",slug:"g4-overridden-safeties",content:"Overriding safeties and exerting manual control leads to code melt down."},{header:"G5: Duplication",slug:"g5-duplication",content:"Practice abstraction on duplicate code. Replace repetitive functions with polymorphism."},{header:"G6: Code at Wrong Level of Abstraction",slug:"g6-code-at-wrong-level-of-abstraction",content:"Make sure abstracted code is separated into different containers."},{header:"G7: Base Classes Depending on Their Derivatives",slug:"g7-base-classes-depending-on-their-derivatives",content:"Practice modularity."},{header:"G8: Too Much Information",slug:"g8-too-much-information",content:"Do a lot with a little. Limit the amount of things going on in a class or functions."},{header:"G9: Dead Code",slug:"g9-dead-code",content:"Delete unexecuted code."},{header:"G10: Vertical Separation",slug:"g10-vertical-separation",content:"Define variables and functions close to where they are called."},{header:"G11: Inconsistency",slug:"g11-inconsistency",content:"Choose a convention, and follow it. Remember no surprises."},{header:"G12: Clutter",slug:"g12-clutter",content:"Dead code."},{header:"G13: Artificial Coupling",slug:"g13-artificial-coupling",content:"Favor code that is clear, rather than convenient. Do not group code that favors mental mapping over clearness."},{header:"G14: Feature Envy",slug:"g14-feature-envy",content:"Methods of one class should not be interested with the methods of another class."},{header:"G15: Selector Arguments",slug:"g15-selector-arguments",content:"Do not flaunt false arguments at the end of functions."},{header:"G16: Obscured Intent",slug:"g16-obscured-intent",content:"Code should not be magic or obscure."},{header:"G17: Misplaced Responsibility",slug:"g17-misplaced-responsibility",content:"Use clear function name as waypoints for where to place your code."},{header:"G18: Inappropriate Static",slug:"g18-inappropriate-static",content:"Make your functions nonstatic."},{header:"G19: Use Explanatory Variables",slug:"g19-use-explanatory-variables",content:"Make explanatory variables, and lots of them."},{header:"G20: Function Names Should Say What They Do",slug:"g20-function-names-should-say-what-they-do",content:"..."},{header:"G21: Understand the Algorithm",slug:"g21-understand-the-algorithm",content:"Understand how a function works. Passing tests is not enough. Refactoring a function can lead to a better understanding of it."},{header:"G22: Make Logical Dependencies Physical",slug:"g22-make-logical-dependencies-physical",content:"Understand what your code is doing."},{header:"G23: Prefer Polymorphism to If/Else or Switch/Case",slug:"g23-prefer-polymorphism-to-if-else-or-switch-case",content:"Avoid the brute force of switch/case."},{header:"G24: Follow Standard Conventions",slug:"g24-follow-standard-conventions",content:"It doesn't matter what your teams convention is. Just that you have on and everyone follows it."},{header:"G25: Replace Magic Numbers with Named Constants",slug:"g25-replace-magic-numbers-with-named-constants",content:"Stop spelling out numbers."},{header:"G26: Be Precise",slug:"g26-be-precise",content:"Don't be lazy. Think of possible results, then cover and test them."},{header:"G27: Structure Over Convention",slug:"g27-structure-over-convention",content:"Design decisions should have a structure rather than a dogma."},{header:"G28: Encapsulate Conditionals",slug:"g28-encapsulate-conditionals",content:"Make your conditionals more precise."},{header:"G29: Avoid Negative Conditionals",slug:"g29-avoid-negative-conditionals",content:"Negative conditionals take more brain power to understand than a positive."},{header:"G31: Hidden Temporal Couplings",slug:"g31-hidden-temporal-couplings",content:"Use arguments that make temporal coupling explicit."},{header:"G32: Don’t Be Arbitrary",slug:"g32-don-t-be-arbitrary",content:"Your code's structure should communicate the reason for its structure."},{header:"G33: Encapsulate Boundary Conditions",slug:"g33-encapsulate-boundary-conditions",content:"Avoid leaking +1's and -1's into your code."},{header:"G34: Functions Should Descend Only One Level of Abstraction",slug:"g34-functions-should-descend-only-one-level-of-abstraction",content:"The toughest heuristic to follow. One level of abstraction below the function's described operation can help clarify your code."},{header:"G35: Keep Configurable Data at High Levels",slug:"g35-keep-configurable-data-at-high-levels",content:"High level constants are easy to change."},{header:"G36: Avoid Transitive Navigation",slug:"g36-avoid-transitive-navigation",content:"Write shy code. Modules should only know about their neighbors, not their neighbor's neighbors."},{header:"Names",slug:"names",content:""},{header:"N1: Choose Descriptive Names",slug:"n1-choose-descriptive-names",content:"Choose names that are descriptive and relevant."},{header:"N2: Choose Names at the Appropriate Level of Abstraction",slug:"n2-choose-names-at-the-appropriate-level-of-abstraction",content:"Think of names that are still clear to the user when used in different programs."},{header:"N3: Use Standard Nomenclature Where Possible",slug:"n3-use-standard-nomenclature-where-possible",content:"Use names that express their task."},{header:"N4: Unambiguous Names",slug:"n4-unambiguous-names",content:"Favor clearness over curtness. A long, expressive name is better than a short, dull one."},{header:"N5: Use Long Names for Long Scopes",slug:"n5-use-long-names-for-long-scopes",content:"A name's length should relate to its scope."},{header:"N6: Avoid Encodings",slug:"n6-avoid-encodings",content:"Do not encode names with type or scope information."},{header:"N7: Names Should Describe Side-Effects",slug:"n7-names-should-describe-side-effects",content:"Consider the side-effects of your function, and include that in its name."},{header:"Tests",slug:"tests",content:""},{header:"T1: Insufficient Tests",slug:"t1-insufficient-tests",content:"Test everything that can possibly break"},{header:"T2: Use a Coverage Tool!",slug:"t2-use-a-coverage-tool",content:"Use your IDE as a coverage tool."},{header:"T3: Don’t Skip Trivial Tests",slug:"t3-don-t-skip-trivial-tests",content:"..."},{header:"T4: An Ignored Test is a Question about an Ambiguity",slug:"t4-an-ignored-test-is-a-question-about-an-ambiguity",content:"If your test is ignored, the code is brought into question."},{header:"T5: Test Boundary Conditions",slug:"t5-test-boundary-conditions",content:"The middle is usually covered. Remember the boundaries."},{header:"T6: Exhaustively Test Near Bugs",slug:"t6-exhaustively-test-near-bugs",content:"Bugs are rarely alone. When you find one, look nearby for another."},{header:"T7: Patterns of Failure Are Revealing",slug:"t7-patterns-of-failure-are-revealing",content:"Test cases ordered well will reveal patterns of failure."},{header:"T8: Test Coverage Patterns Can Be Revealing",slug:"t8-test-coverage-patterns-can-be-revealing",content:"Similarly, look at the code that is or is not passed in a failure."},{header:"T9: Tests Should Be Fast",slug:"t9-tests-should-be-fast",content:"Slow tests won't get run."}]},{path:"/Career/AnythingYouWangt.html",title:"Anything You Want",pathLocale:"/",contents:[{header:"Anything You Want",slug:"anything-you-want",content:`Business is not about money. It's about making dreams come true for others and for yourself.
Making a company is a great way to improve the world while improving yourself.
When you make a company, you make a utopia. It's where you design your perfect world.
Never do anything just for the money.
Don't pursue business just for your own gain. Only answer the calls for help.
Succes comes from persistently improving and inventing, not from persisently promoting what's not working.
Your business plan is moot. You don't know what people really want until you start doing it.
Starting with no money is an advantage. You don't need money to start helping people.
You can't please everyone, so proudly exclude people.
Make yourself unneecessary to the running of your business.
The real point of doing anything is to be happy, so do only what makes you happy. When you make a business, you get to make a little universe where you control all the laws. This is your utopia.
A business plan should never take more than a few hours of work—hopefully no more than a few minutes. The best plans start simple. A quick glance and common sense should tell you if the numbers will work. The rest are details.
We all have lots of ideas, creations, and projects. When you present one to the world and it’s not a hit, don’t keep pushing it as is. Instead, get back to improving and inventing.
It means we should make another project. Don't waste much time fighting uphill battle against locked doors.
If you’re not saying, “Hell yeah!” about something, say no. When deciding whether to do something, if you feel anything less than “Wow! That would be amazing! Absolutely! Hell yeah!” then say no.
No business plan survives first contact with customers.
Never forget that absolutely everything you do is for your customers. Make every decision—even decisions about whether to expand the business, raise money, or promote someone—according to what’s best for your customers. If you’re ever unsure what to prioritize, just ask your customers the open-ended question, “How can I best help you now?” Then focus on satisfying those request.`}]},{path:"/Career/NOTE.html",title:"NOTE",pathLocale:"/",contents:[{header:"NOTE",slug:"note",content:`技术与业务两条腿走路:
1.提前对技术体系做布局，引领技术与项目，避免业务突然变化时陷入被动
2.对现有支撑业务“较为成熟”的“有瓶颈”的技术体系做出改革与突破
3.避免让自己成为“工具人” 1.不要以自己为中心去思考问题，要换位到“团队视角”，“合作视角”全方位立体多维度思考问题
2.推进事情要考虑：“共赢”，“利他” 所有来自「事」的困难都可以用态度解决，所有来自「人」的困难都可以用换位思考解决。 目标感，推进项目落地，拿结果。
要沉下心来做事，不浮躁，但行好事，莫问前程，最终的结果也是水到渠成。
要善于树立自己的个人品牌，以及不要给自己设限。
主要就是通过不断的参与项目进行历练，以及学习身边的老板/师兄的做事方式，多观察周围比自己优秀的同学`},{header:"不要事无巨细地请教老同学，要有Owner的心态",slug:"不要事无巨细地请教老同学-要有owner的心态",content:""},{header:"十分推荐在项目熟悉了解过程中沉淀自己的资料",slug:"十分推荐在项目熟悉了解过程中沉淀自己的资料",content:`第一步，了解业务
第二步：了解项目/产品
第三步：了解技术栈`},{header:"从小需求开始，尝试编码和逐步矫正",slug:"从小需求开始-尝试编码和逐步矫正",content:`第一步，了解项目架构，按照服务划分模块（预计耗时两天）
第二步：找准核心业务链路，将模块串起来，走读代码（预计耗时两天）
第三步：从小需求开始，尝试编码`},{header:"程序员是要专精，还是要广度？",slug:"程序员是要专精-还是要广度",content:`更早地认识自己和自己的方向，能更快地帮助我做出成绩。
及早的找到自己的方向+不懈的努力+亿点点的天赋
在这个过程中，我们自己的技术发展就像是一棵树，我们尽可以无限的去展开自己的枝叶，多了解一些不同的方
向和知识，但一定记住这是为了让自己的枝头长得更高。 对于个人而言，精进一门技术，不管是对于开发还是其他工作，都是重中之重！ 真正核心的系统一定是紧贴业务，而且很难大范围复用的，好的技术架构在设计的时候，讲究的是够用即
可，过度设计大部分就是没用的设计。在之后的迭代中，会随着业务的不断变化，被带动着自我进化，那最终的
产物也自然是和业务形态非常贴合。所以，我个人在选择的时候，一些核心的轮子，该造就造起来，但这些轮子
一定是带有业务特色的，比如我会去造一个业务组件库，但是我绝不会去造一个antd。`}]},{path:"/Career/Scarcity.html",title:"稀缺",pathLocale:"/",contents:[{header:"稀缺",slug:"稀缺",content:""},{header:"资源稀缺不可怕 就怕有稀缺心态",slug:"资源稀缺不可怕-就怕有稀缺心态",content:""},{header:"稀缺俘获大脑",slug:"稀缺俘获大脑",content:`在一个午餐时的场景：
如果服务速度很慢，排队等候取餐的人就会急不可耐。他们对食物的占有欲很强。有些人甚至会用胳膊环住餐盘，以保护盘中的食物。绝多数情况下，他们都十分安静，专心致志地进餐.....本来不爱吃某些食物的人，现在也不挑食了。他们会将所有食物都吃个精光，之后还会将盘子舔一编。
这是不是意味着去馆子吃饭，如果要排号，等待的时间把控合适，客人会觉得这家的味道是不错的。饿的时候，吃什么都好吃。但是现在的人们不缺吃的，并不能对食物营造出很强稀缺感，会不会有适得其反的情况。
我们的思想会自动而强有力地转向未得到满足的需求：对于饥饿的人来说，他们需要食物；对于忙碌的人来说，他们需要完成某项工作的时间；对于缺钱的人来说，他们需要想办法支付每个月的房租；对于孤独的人来说，他们需要他人的陪伴。稀缺造成的后果不仅仅是因为我们会因拥有的太少而感到不悦，而是因为它会改变我们的思维方式，强行侵入我们的思想中。
稀缺对人类大脑产生的影响，存在于潜意识中。无论大脑的主人是否愿意，稀缺都会牢牢地俘获他的注意力。`},{header:"经济学研究稀缺，但不触及心态",slug:"经济学研究稀缺-但不触及心态",content:`心智是有容量即带宽，包括认知能力和执行控制力。稀缺会降低所有这些带宽的容量，致使人们缺乏洞察力和前瞻性，还会减弱人们的执行控制力。
这是因为人们把所有的心智都划分给稀缺的事物，这样留给处理其他事件的心力就减少了。
稀缺会俘获我的注意力，并带来一点点好处：我们能够在应对迫切需求时，做的更好。但从长远角度来看，我们的损失更大：我们会忽视其他需要关注的事项，在生活的其他方面变得不那么有成效。`},{header:"稀缺心态是一切稀缺的根源",slug:"稀缺心态是一切稀缺的根源",content:"稀缺心态：当它俘获我们的注意力时，就会改变我们的思维方式，影响我们的决策和行为方式。"},{header:"专注的“得”与管窥的“失”",slug:"专注的-得-与管窥的-失",content:`稀缺，会迫使人做出选择。所有抽象的事物都会变得具体起来。
当稀缺俘获大脑时，人们的注意里会集中在如何以最有成效的方式去利用自身资源上。`},{header:"资源稀缺换来了专注和回报",slug:"资源稀缺换来了专注和回报",content:""}]},{path:"/Career/SoftSkills.html",title:"软技能",pathLocale:"/",contents:[{header:"软技能",slug:"软技能",content:""}]},{path:"/Career/conflict.html",title:"如何摆平日常冲突",pathLocale:"/",contents:[{header:"如何摆平日常冲突",slug:"如何摆平日常冲突",content:""},{header:"冲突的三个关键点",slug:"冲突的三个关键点",content:`冲突源自不匹配的期望 我/对方想从中得到什么？
沟通两方想要的结果`}]},{path:"/Career/performance.html",title:"Performance",pathLocale:"/",contents:[{header:"Performance",slug:"performance",content:""},{header:"主要表现及能力",slug:"主要表现及能力",content:`态度/承诺/积极性
专业精神和优秀品质
团队合作及信任`},{header:"专业技能",slug:"专业技能",content:`程式设计
架构
解决问题`}]},{path:"/Career/zhixing.html",title:"知行",pathLocale:"/",contents:[{header:"知行",slug:"知行",content:""}]},{path:"/Graphic/",title:"Graphic",pathLocale:"/",contents:[{header:"Graphic",slug:"graphic",content:""},{header:"OpenSource",slug:"opensource",content:"https://github.com/Gforcex/OpenGraphic"}]},{path:"/Playing/android-linux.html",title:"安装Linux在安卓手机上",pathLocale:"/",contents:[{header:"安装Linux在安卓手机上",slug:"安装linux在安卓手机上",content:`直接使用软件安装：https://github.com/EXALAB/AnLinux-App
192.168.50.85 连接：ssh u0_a120@192.168.50.19 -p 8022
密码：191231
\\192.168.50.19`},{header:"Termux",slug:"termux",content:`https://github.com/termux
远程连接端口好像是8022使用以下指令查询：
netstat -ntlp | grep sshd 安装完成后，出现了
sshd: no hostkeys available -- exiting 可以输入：ssh-keygen -A 手动载入`},{header:"proot-distro",slug:"proot-distro",content:`apt install proot proot-distro -y
安装Linux系统的软件，使用proot-distro list来查看可以安装的系统
在对应系统中安装openssh后，需要手动设置以下sshd的配置：
vim /etc/ssh/sshd_config 添加一个特殊的端口，如9022。然后设置Permit Root Login yes:`},{header:"prm",slug:"prm",content:`切换npm源的小软件：npm i prm-cli -g
# List all registries
prm ls
# Select a registry that you need to switch
prm use taobao`},{header:"Neofetch",slug:"neofetch",content:"可以查看系统的软件"},{header:"查看程序运行",slug:"查看程序运行",content:"ps -e | grep ssh"}]},{path:"/Playing/archlinux.html",title:"archlinux",pathLocale:"/",contents:[{header:"archlinux",slug:"archlinux",content:""},{header:"设置共享文件夹",slug:"设置共享文件夹",content:`https://xiaozhou.net/share_movie_between_archlinux_and_win7_via_samba-2012-04-20.html
重启服务：
system restart smb`}]},{path:"/Playing/compiler.html",title:"Compiler",pathLocale:"/",contents:[{header:"Compiler",slug:"compiler",content:`Creating a simple JIT compiler in C++
x86-64-minimal-JIT-compiler-Cpp https://github.com/sol-prog/x86-64-minimal-JIT-compiler-Cpp/tree/master`}]},{path:"/Playing/ish.html",title:"iSH",pathLocale:"/",contents:[{header:"iSH",slug:"ish",content:`一个在IOS系统中的Linux Shell命令行软件。官网： https://ish.app/
https://github.com/ish-app/ish`},{header:"修改版本",slug:"修改版本",content:`使用的Alpine Linux，如需更换版本是直接修改/etc/apk/repositories文件。
在alpine cdn可以查看有哪些版本可以修改。
具体步骤： 安装nano：app add nano
修改版本：nano /etc/apk/repositories
更新包：apk upgrade && apk fix`},{header:"Code Server",slug:"code-server",content:"https://coder.com/docs/code-server/latest/ios"}]},{path:"/Playing/router.html",title:"路由器",pathLocale:"/",contents:[{header:"路由器",slug:"路由器",content:`梅林安装教程：
https://www.koolcenter.com/posts/228
科学上网：
https://github.com/hq450/fancyss`}]},{path:"/Playing/steamdeck.html",title:"steamdeck",pathLocale:"/",contents:[{header:"steamdeck",slug:"steamdeck",content:""},{header:"商店换源",slug:"商店换源",content:`https://mirrors.sjtug.sjtu.edu.cn/docs/flathub
sudo flatpak remote-modify flathub --url=https://mirror.sjtu.edu.cn/flathub passwd
第二步，解锁只读权限
sudo steamos-readonly disable
b
第三步，安装火狐浏览器（已安装跳过）
sudo pacman -S firefox
第四步，添加下载源
sudo flatpak remote-add --if-not-exists Sjtu https://mirror.sjtu.edu.cn/flathub/flathub.flatpakrepo
删除添加源
sudo flatpak remote-delete Sjtu
覆盖重置为官方镜像源
sudo flatpak remote-modify flathub --url=https://flathub.org/repo`},{header:"Switch",slug:"switch",content:`涉及代码&地址 yuzu官网：https://yuzu-emu.org/
yuzu EA版发布页：https://github.com/pineappleEA/pineapple-src/releases
yuzu图文教程&key：https://ruisan.blog.jp/archives/13428851.html
固件下载站：https://darthsternie.net/switch-firmwares/`}]},{path:"/Playing/wechat-gpt.html",title:"Wechat GPT",pathLocale:"/",contents:[{header:"Wechat GPT",slug:"wechat-gpt",content:"https://github.com/fuergaosi233/wechat-chatgpt"}]},{path:"/Playing/zhuxian.html",title:"",pathLocale:"/",contents:[{header:"",slug:"",content:`最简单，最无脑，收益最快的收米攻略
诛仙世界攻略整合`}]},{path:"/Tools/AIDraw.html",title:"AI Draw",pathLocale:"/",contents:[{header:"AI Draw",slug:"ai-draw",content:`Viscom.ai
Krea.ai
Topaz Gigapixel`}]},{path:"/Tools/AnimationAITools.html",title:"Animation AI Tools",pathLocale:"/",contents:[{header:"Animation AI Tools",slug:"animation-ai-tools",content:`NVIDIA Audio2Face
move
cascadeur
Wonder Studio
MotionGPT
hedra
meshcapade
replikant
GODMODEAI`}]},{path:"/Tools/ArtTool.html",title:"Art Tools",pathLocale:"/",contents:[{header:"Art Tools",slug:"art-tools",content:""},{header:"A character generator for Windows and Linux, using LPC assets",slug:"a-character-generator-for-windows-and-linux-using-lpc-assets",content:"https://pflat.itch.io/lpc-character-generator"}]},{path:"/Tools/Cmake.html",title:"CMake",pathLocale:"/",contents:[{header:"CMake",slug:"cmake",content:""},{header:"Building a Basic Project",slug:"building-a-basic-project",content:`CmakeLists.txt：根目录下一定要有的文件
cmake_minimum_required()：设置cmake的版本
project()：传入项目名字与项目版本号，相当于Visual Studio中的解决方案
add_executable()：设置一个可执行的库，相当于Visual Studio中的一个可运行的项目(main)`},{header:"Specifying the C++ Standard",slug:"specifying-the-c-standard",content:`Cmake中有很多预设变量，详情可以看这里。
其中设置C++版本可以使用一下两个变量： CMAKE_CXX_STANDARD
CMAKE_CXX_STANDARD_REQUIRED 在CMakeLists.txt文件中添加一下代码，就是为工程设置C++11编码标准：
set(CMAKE_CXX_STANDARD 11)
set(CMAKE_CXX_STANDARD_REQUIRED True)`},{header:"Adding a Version Number and Configured Header File",slug:"adding-a-version-number-and-configured-header-file",content:`CMake中有很多预设变量，这些变量可以在c++中使用。需要在CMakeLists文件使用configure_file语句。用法如下：
configure_file(TutorialConfig.h.in TutorialConfig.h) 这里就是把与CMakeLists.txt同目录下的TutorialConfig.h.in文件拷贝到build文件夹里。当然复制目录和生成目录都可以自定义设置。
使用CMake中的变量时，需要使用@包裹着变量，实例如下：
#define CMAKE_PROJECT_VERSION_MAJOR @Tutorial_VERSION_MAJOR@`},{header:"Adding a Library",slug:"adding-a-library",content:`添加一个库工程，也就是Visual Studio中没有main函数的项目。使用一个文件夹作为库工程的根目录，在该根目录中需要加入CMakeLists.txt文件。在该文件中使用add_library()。使用实例如下：
add_library(lib_name header.h file1.cxx) 第一个参数为库名字，后面加上需要编入库的文件，当然可以使用set、file等命令来把多个文件集合为一个变量。
把库工程连接到执行工程中，首先需要链接库的CMakeLists文件，使用add_subdirectory()命令。传入库文件夹的相对于执行工程的CMakeLists文件的目录即可。如下目录：
│ CMakeLists.txt
│ tutorial.cxx
│ TutorialConfig.h.in
│
└───MathFunctions CMakeLists.txt MathFunctions.h mysqrt.cxx 使用add_subdirectory(MathFunctions)即可，然后使用target_link_libraries()命令把库链接到执行文件中。`},{header:"Making Our Library Optional",slug:"making-our-library-optional",content:`在项目中会使用一些配置来控制工程，使用option(<variable> "<help_text>" [value])命令来控制。
在configure_file文件中使用cmakedefine可以把option中设置的变量设置为宏变量，使用如下：
#cmakedefine USE_MAMATH`},{header:"Adding Usage Requirements for a Library",slug:"adding-usage-requirements-for-a-library",content:`以下为可以配置使用要求的命令： target_compile_definitions()
target_compile_options()
target_include_directories()
target_link_directories()
target_link_options()
target_precompile_headers()
target_sources() 其中使用需求有INTERFACE，PUBLIC，PRIVATE。他们的不同可以看这里。
举个例子：
add_library(MathFunctions mysqrt.cxx)
target_include_directories(MathFunctions INTERFACE \${CMAKE_CURRENT_SOURCE_DIR}) 该命令是把链接该库的所有target都自动添加引用路径。`},{header:"Adding Generator Expressions",slug:"adding-generator-expressions",content:"可以设置生成器的一些特殊构建信息。文档"},{header:"Setting the C++ Standard with Interface Libraries",slug:"setting-the-c-standard-with-interface-libraries",content:`使用一个公共库来设置编译要求，如设置c++版本，前面讲到使用set(CMAKE_CXX_STANDARD 11)该命令设置，这里可以创建一个公共库，专门来配置生成器的编译配置，示例如下：
add_library(tutorial_compiler_flags INTERFACE)
target_compile_features(tutorial_compiler_flags INTERFACE cxx_std_11) # 最终连接该库即可
target_link_libraries(Tutorial PUBLIC \${EXTRA_LIBS} tutorial_compiler_flags)`},{header:"Adding Compiler Warning Flags with Generator Expressions",slug:"adding-compiler-warning-flags-with-generator-expressions",content:""},{header:"Installing and Testing",slug:"installing-and-testing",content:""},{header:"Install Rules",slug:"install-rules",content:`安装就是把工程打包可执行文件与lib文件，打出目录如下：
├───bin
│ Tutorial.exe
│
├───include
│ MathFunctions.h
│ TutorialConfig.h
│
└───lib MathFunctions.lib 文件目录可以自定义，主要使用install()命令进行配置。主要分为三种： bin：可执行文件 install(TARGETS Tutorial DESTINATION bin)
include：头文件 install(FILES MathFunctions.h DESTINATION include)
lib：库文件set(installable_libs MathFunctions tutorial_compiler_flags)
install(TARGETS \${installable_libs} DESTINATION lib) 值得注意的是，需要把库或可执行文件全部配置完成后，再执行安装命令。
安装命令，需要先执行build命令再执行安装
cd build
cmake ..
cmake --build . --config Release
# 安装到默认文件夹
cmake --install . --config Release
# 指定安装目录
cmake --install . --config Release --prefix "/home/myuser/installdir"`},{header:"Testing Support",slug:"testing-support",content:`enable_testing() # Add a test called Runs which runs the following command:
# $ Tutorial 25
add_test(NAME Runs COMMAND Tutorial 25) # Add a test called Usage which runs the following command:
# $ Tutorial
# Make sure the expected output is displayed.
# Hint: Use the PASS_REGULAR_EXPRESSION property with "Usage.*number"
add_test(NAME Usage COMMAND Tutorial)
set_tests_properties(Usage PROPERTIES PASS_REGULAR_EXPRESSION "Usage:.*number") # Add a test which runs the following command:
# $ Tutorial 4
# Make sure the result is correct.
# Hint: Use the PASS_REGULAR_EXPRESSION property with "4 is 2"
add_test(NAME StandardUse COMMAND Tutorial 4)
set_tests_properties(StandardUse PROPERTIES PASS_REGULAR_EXPRESSION "4 is 2"
) # Add more tests. Create a function called do_test to avoid copy +
# paste. Test the following values: 4, 9, 5, 7, 25, -25 and 0.0001.
function(do_test target arg result) add_test(NAME Comp\${arg} COMMAND \${target} \${arg}) set_tests_properties(Comp\${arg} PROPERTIES PASS_REGULAR_EXPRESSION \${result} )
endfunction() # do a bunch of result based tests
do_test(Tutorial 4 "4 is 2")
do_test(Tutorial 9 "9 is 3")
do_test(Tutorial 5 "5 is 2.236")
do_test(Tutorial 7 "7 is 2.645")
do_test(Tutorial 25 "25 is 5")
do_test(Tutorial -25 "-25 is (-nan|nan|0)")
do_test(Tutorial 0.0001 "0.0001 is 0.01")`},{header:"Adding Support for a Testing Dashboard",slug:"adding-support-for-a-testing-dashboard",content:`可以设置后台编译结果查看，式例：https://my.cdash.org/index.php?project=CMakeTutorial
设置如下：
set(CTEST_PROJECT_NAME "CMakeTutorial")
set(CTEST_NIGHTLY_START_TIME "00:00:00 EST") set(CTEST_DROP_METHOD "http")
set(CTEST_DROP_SITE "my.cdash.org")
set(CTEST_DROP_LOCATION "/submit.php?project=CMakeTutorial")
set(CTEST_DROP_SITE_CDASH TRUE)`},{header:"Adding System Introspection",slug:"adding-system-introspection",content:`根据不同平台可以的标准库不同，来设置宏：
include(CheckCXXSourceCompiles) # Use check_cxx_source_compiles with simple C++ code to verify
# availability of:
# * std::log
# * std::exp
# Store the results in HAVE_LOG and HAVE_EXP respectively.
check_cxx_source_compiles(" #include <cmath> int main(){ std::log(1.0); return 0; }
" HAVE_LOG) if(HAVE_LOG) target_compile_definitions(MathFunctions PRIVATE "HAVE_LOG")
endif()`},{header:"Adding a Custom Command and Generated File",slug:"adding-a-custom-command-and-generated-file",content:`在构建时，可以执行特殊命令来生成文件，命令是由一个C++的可执行的库组成的。文档。这有两种方式调用： 直接运行
监听构建过程，指定某个阶段执行 PRE_BUILD
PRE_LINK
POST_BUILD add_custom_command( OUTPUT table.csv COMMAND makeTable -i \${CMAKE_CURRENT_SOURCE_DIR}/input.dat -o table.csv DEPENDS \${CMAKE_CURRENT_SOURCE_DIR}/input.dat VERBATIM)
add_custom_target(generate_table_csv DEPENDS table.csv) add_custom_command( OUTPUT foo.cxx COMMAND genFromTable -i table.csv -case foo -o foo.cxx DEPENDS table.csv # file-level dependency generate_table_csv # target-level dependency VERBATIM)
add_library(foo foo.cxx) add_custom_command( OUTPUT bar.cxx COMMAND genFromTable -i table.csv -case bar -o bar.cxx DEPENDS table.csv # file-level dependency generate_table_csv # target-level dependency VERBATIM)
add_library(bar bar.cxx)`},{header:"Packaging an Installer",slug:"packaging-an-installer",content:`在顶层CMakeLists.txt最后加上以下代码：
include(InstallRequiredSystemLibraries)
set(CPACK_RESOURCE_FILE_LICENSE "\${CMAKE_CURRENT_SOURCE_DIR}/License.txt")
set(CPACK_PACKAGE_VERSION_MAJOR "\${Tutorial_VERSION_MAJOR}")
set(CPACK_PACKAGE_VERSION_MINOR "\${Tutorial_VERSION_MINOR}")
set(CPACK_SOURCE_GENERATOR "TGZ")
include(CPack) 接着运行以下命令：
cmake --build .
# 默认打包设置，使用nsis
cpack # 同样可以指定设置打包压缩文件
# cpack -G ZIP -C Debug # 也可以指定打包设置
# cpack --config CPackSourceConfig.cmake 这里生成的就是install配置安装的包体。`},{header:"Selecting Static or Shared Libraries",slug:"selecting-static-or-shared-libraries",content:`使用BUILD_SHARED_LIBS字段来控制所有库共享属性，使用如下：
option(BUILD_SHARED_LIBS "Global flag to cause add_library() to create shared libraries if on" ON) 开关设置为ON/OFF。`},{header:"Adding Export Configuration",slug:"adding-export-configuration",content:"设置自定义命令"},{header:"Packaging Debug and Release",slug:"packaging-debug-and-release",content:""},{header:"常用命令",slug:"常用命令",content:`直接使用cmake命令在拥有CMakeLists.txt的目录下，会自动识别当前的运行的平台，来设置编译器和平台等。
需要特殊设置可以使用以下命令：
cmake -B $CMakeBuildPath -G $Generator -A $Arch -DCMAKE_TOOLCHAIN_FILE="$Toolchain" -DCMAKE_BUILD_TYPE=Release B 输出构建工程的路径
G 编译器
A 平台，64位或32位等 以下两个也可以在CMakeLists.txt中使用set命令直接设置： DCMAKE_TOOLCHAIN_FILE 工具链，特殊平台编译需要使用的一些预设
DCMAKE_BUILD_TYPE 打包的配置 Windows的几个编译配置： Release: high optimization level, no debug info, code or asserts.
Debug: No optimization, asserts enabled, [custom debug (output) code enabled],
debug info included in executable (so you can step through the code with a
debugger and have address to source-file:line-number translation).
RelWithDebInfo: optimized, with debug info, but no debug (output) code or asserts.
MinSizeRel: same as Release but optimizing for size rather than speed.`},{header:"常用变量",slug:"常用变量",content:`PROJECT_SOURCE_DIR: 使用project命令的目录
PROJECT_BINARY_DIR：build目录
CMAKE_CURRENT_SOURCE_DIR：当前CMakeLists文件目录`},{header:"常用语句设置",slug:"常用语句设置",content:""},{header:"target_include_directories",slug:"target-include-directories",content:`target_include_directories(Tutorial PUBLIC \${PROJECT_BINARY_DIR}) 文档
对一个Target指定一个路径，在写#include时，可以省略写指定的路径。有3个范围限定: INTERFACE：仅有头文件，没有实现。设置为公共库引用，可以把公共接口抽象出来，并将其与库实现分离。
PUBLIC: 在头文件和实现中使用，对应的路径
PRIVATE：只在实现中使用，对应的路径 范围参考`},{header:"list",slug:"list",content:"可以把一些变量存放到一个列表中，并对该列表进行维护。文档"},{header:"set",slug:"set",content:`建议直接使用set命令 而不是file(GLOB_RECURSE)，因为后者有以下缺点： GLOB 命令只会在 CMake 首次运行时执行一次，并且不会更新文件列表，因此如果你添加或删除了文件，则不会自动更新 CMake 构建。
对于大型项目来说，GLOB 命令可能会变得很慢，因为它需要扫描整个源目录树。
GLOB 命令无法处理重命名和移动文件的情况。 可以使用set命令直接储存文件，使用如下：
set(SOURCES src/foo.cpp src/bar.cpp )
add_library(my_lib \${SOURCES})`},{header:"设置VS使用文件夹包裹",slug:"设置vs使用文件夹包裹",content:`if (CMAKE_GENERATOR MATCHES "Visual Studio") set_property(GLOBAL PROPERTY USE_FOLDERS ON)
endif()`},{header:"cmake_dependent_option",slug:"cmake-dependent-option",content:`https://cmake.org/cmake/help/latest/module/CMakeDependentOption.html
cmake_dependent_option(USE_FOO "Use Foo" ON "USE_BAR" OFF) 如果USE_BAR为ON，那么USE_FOO为ON，否则为OFF。简单来说就是依赖项为真，那么选项的值就为前面，反之为后面。
该设置不会有引用属性，也就是后续修改USE_BAR值，USE_FOO值并不会修改。`},{header:"模板",slug:"模板",content:`# 设置cmake版本
cmake_minimum_required(VERSION 3.0.0) # 设置项目名称为dome # 这里对应变量\${PROJECT_NAME}
project(dome VERSION 0.1.0) # 设置引用目录 可省略头文件目录
include_directories(\${PROJECT_SOURCE_DIR}/include/) # 搜索src模板下的cpp文件（顶层）设置到变量SOURCE_FILES
file(GLOB_RECURSE SOURCE_FILES \${PROJECT_SOURCE_DIR}/src/*cpp)
# 打印
#message(\${SOURCE_FILES}) # 这里设置两个库 dome_src dome_libsrc
# 这里有个奇异的点就是 库的名字必须是\${PROJECT_NAME}这个开头 不然无法链接到
add_library(\${PROJECT_NAME}_src SHARED \${SOURCE_FILES})
# 这个是直接输入源文件到库
add_library(\${PROJECT_NAME}_libsrc SHARED libsrc/i.cpp) # 添加可执行文件 编译
add_executable(\${PROJECT_NAME} example/i_love_China.cpp) # 这里把库文件链接到可执行文件中
target_link_libraries(\${PROJECT_NAME}
\${PROJECT_NAME}_src
\${PROJECT_NAME}_libsrc)`},{header:"报错",slug:"报错",content:`Failed to run MSBuild command: C:/Program Files (x86)/Microsoft Visual Studio/2019/Professional/MSBuild/Current/Bin/MSBuild.exe to get the value of VCTargetsPath: Access violation 解决：https://stackoverflow.com/questions/61842794/cmake-cant-get-the-value-of-vctargetspath-when-generating-for-uwp
From VisualStudio Installer app, click Modify and install C++ Universal Windows Platform support for v142 build tools (ARM64) individual component.`},{header:"Notes",slug:"notes",content:"cmake marco和function 的区别不大，但是前者是有点像值传递的感觉，后者有点像引用传递。"},{header:"引用",slug:"引用",content:`https://cmake.org/cmake/help/latest/guide/tutorial/index.html
https://modern-cmake-cn.github.io/Modern-CMake-zh_CN/`}]},{path:"/Tools/Git.html",title:"Git",pathLocale:"/",contents:[{header:"Git",slug:"git",content:""},{header:"SSH",slug:"ssh",content:"github-key —— 私钥 github-key.pub —— 公钥 https://gitee.com/help/articles/4229#article-header0 https://www.cnblogs.com/cangqinglang/p/11727867.html https://docs.github.com/cn/free-pro-team@latest/github/authenticating-to-github/connecting-to-github-with-ssh"},{header:"使用git把某一次commit修改过的文件打包",slug:"使用git把某一次commit修改过的文件打包",content:`把新增加的文件使用git add添加进改动
使用git commit提交改动
使用git log查看提交的commit id
使用命令
git diff-tree -r --no-commit-id --name-only 23cde4766b6d879cbae59c5ee9705f5694acb707 | xargs tar -rf mytarfile.tar`},{header:"快速更新submodule",slug:"快速更新submodule",content:`If it's the first time you check-out a repo you need to use --init first:
git submodule update --init --recursive For git 1.8.2 or above, the option --remote was added to support updating to latest tips of remote branches:
git submodule update --recursive --remote 如果更新补下来子集，可以直接进入子集文件夹 ，然后clone下来即可。
把修改的文件打包`},{header:"两个远程仓库地址",slug:"两个远程仓库地址",content:`添加远程
git remote add 仓库A url
git remote add 仓库B url git remote -v 合并其他源到本地分支
git merge remote/branch`},{header:"GitHub Action Pages",slug:"github-action-pages",content:`在markdown仓库配置Action Repository secrets时，这里配置的时私钥，需要把私钥的所有内容复制（包括-----BEGIN OPENSSH PRIVATE KEY-----和最后一行）。在另一个仓库配置Deloy Keys就是配置公钥，可以不需要配置，如果在账户中设置了SSH的。
GitHub Actions 来自动部署 Hexo`},{header:"SSH 连接不上",slug:"ssh-连接不上",content:`既然和GitHub建立ssh连接的时候提示connection refused，那我们就详细看看建立ssh连接的过程中发生了什么，可以使用ssh -v命令，-v表示verbose，会打出详细日志。
$ ssh -vT git@github.com
OpenSSH_9.0p1, OpenSSL 1.1.1o 3 May 2022
debug1: Reading configuration data /etc/ssh/ssh_config
debug1: Connecting to github.com [::1] port 22.
debug1: connect to address ::1 port 22: Connection refused
debug1: Connecting to github.com [127.0.0.1] port 22.
debug1: connect to address 127.0.0.1 port 22: Connection refused
ssh: connect to host github.com port 22: Connection refused 从上面的信息马上就发现了诡异的地方，连接http://github.com的地址居然是::1和127.0.0.1。前者是IPV6的localhost地址，后者是IPV4的localhost地址。
到这里问题就很明确了，是DNS解析出问题了，导致http://github.com域名被解析成了localhost的ip地址，就自然连不上GitHub了。
Windows下执行ipconfig /flushdns 清楚DNS缓存后也没用，最后修改hosts文件，增加一条github.com的域名映射搞定。
140.82.113.4 github.com
查找http://github.com的ip地址可以使用https://www.ipaddress.com/来查询，也可以使用nslookup命令
nslookup github.com 8.8.8.8
nslookup是域名解析工具，8.8.8.8是Google的DNS服务器地址。直接使用
nslookup github.com
就会使用本机已经设置好的DNS服务器进行域名解析，ipconfig /all可以查看本机DNS服务器地址。
这个问题其实就是DNS解析被污染了，有2种可能：
DNS解析被运营商劫持了
使用了科学上网工具
按照我上面写的解决方案操作即可解决。`},{header:"References",slug:"references",content:`https://chaxuri.com/archives/43.html
https://stackoverflow.com/questions/15589682/ssh-connect-to-host-github-com-port-22-connection-timed-out
https://docs.github.com/en/authentication/troubleshooting-ssh/error-permission-denied-publickey
https://gist.github.com/Tamal/1cc77f88ef3e900aeae65f0e5e504794`}]},{path:"/Tools/PowerShell.html",title:"PowerShell",pathLocale:"/",contents:[{header:"PowerShell",slug:"powershell",content:""},{header:"Materals",slug:"materals",content:"https://learn.microsoft.com/en-us/powershell/scripting/learn/ps101"}]},{path:"/Tools/VisualStudio.html",title:"Visual Studio",pathLocale:"/",contents:[{header:"Visual Studio",slug:"visual-studio",content:""},{header:"TemplateClass",slug:"templateclass",content:`/******************************************************************
** $safeitemrootname$.cpp
** @Author : BanMing ** @Date : $time$
** @Description : *******************************************************************/ /******************************************************************
** @File : $FILE_BASE$.$FILE_EXT$
** @Author : BanMing ** @Date : $DATE$
** @Description : *******************************************************************/`},{header:"重置编辑器",slug:"重置编辑器",content:`devenv.exe /resetsettings
devenv.exe /resetuserdata`},{header:"输出在debug面板",slug:"输出在debug面板",content:"使用函数：OutputDebugString"},{header:"Incredibuild",slug:"incredibuild",content:`--------------------Build System Warning---------------------------------------
Checking MSBuild version: Cannot load version info from: �l�R�ct Visual Studio Solution File, Format VersionMSBuild\\Current\\Bin\\amd64\\, Error: 123 -------------------------------------------------------------------------------
--------------------Build System Warning---------------------------------------
Visual Studio does not include an English language pack: This version of Visual Studio does not include a built-in English language pack. For the best Incredibuild experience, it is highly recommended to install a Visual Studio English language pack. ------------------------------------------------------------------------------- Build ID: {184494E3-2125-4767-B661-F6D0037AE45A} Active code page: 437
The filename, directory name, or volume label syntax is incorrect. 2 build system warning(s): - Checking MSBuild version - Visual Studio does not include an English language pack 解决方案： On your machine, in the Window Search, type in Region
A window should appear, go to the Administrative tab
A Region Settings window will pop up, ensure the Current system locale is English (United States), and the checkbox is uncheck for 'Beta: Use Unicode UTF-8 for worldwide language support'. See screenshot below as reference.
You can try a build to see if this takes away the messages, but a machine restart may be needed after making any changes. https://stackoverflow.com/questions/77229261/incredibuild-add-in-fails-to-build-c-solution-in-visual-studio`}]},{path:"/Tools/pcg.html",title:"Procedural Content Generation in Games",pathLocale:"/",contents:[{header:"Procedural Content Generation in Games",slug:"procedural-content-generation-in-games",content:"Book Link"}]},{path:"/Web/Netcore.html",title:"Netcore",pathLocale:"/",contents:[{header:"Netcore",slug:"netcore",content:`https://www.gamereplays.org/overwatch/portals.php?show=page&name=overwatch-a-guide-to-understanding-netcode
https://zhuanlan.zhihu.com/p/141555559
https://www.bilibili.com/video/BV1ox411s7Fd?t=1043
https://github.com/QXSoftware/qxsoftware.github.io/blob/e9061b0c72c3d0ad53dd924bded5cd39751e0875/_posts/2020-05-31-Game-Netcode.MD`}]},{path:"/Web/Vuepress.html",title:"Vuepress",pathLocale:"/",contents:[{header:"Vuepress",slug:"vuepress",content:""},{header:"plugin",slug:"plugin",content:`vuepress-theme-hope
vuepress-plugin-full-text-search2`},{header:"tips",slug:"tips",content:`图片放大：需要放大的使用![]() 不需要放大且需要自定义大小使用<img src="" width="100%"> 运行打包后的vue项目，可以使用http-server，安装：
npm install -g http-server 在打包文件夹里执行http-server即可。`}]},{path:"/Animation/CharacterAnimation/SkeletalAnimation.html",title:"Skeletal Animation",pathLocale:"/",contents:[{header:"Skeletal Animation",slug:"skeletal-animation",content:""},{header:"Keyframe animation basics",slug:"keyframe-animation-basics",content:`帧动画由一段时间中几个特定时间点和物体姿势组成。如下图：
Alt text
其中姿势可以由位置，缩放，旋转组成。在DX9中使用D3DXKEY_VECTOR3表示位置和缩放，使用D3DXKEY_QUATERNION表示旋转。
struct D3DXKEY_VECTOR3 {
FLOAT Time;
D3DXVECTOR3 Value;
};
struct D3DXKEY_QUATERNION {
FLOAT Time;
D3DXQUATERNION Value;
}; 使用ID3DXKeyframedAnimationSet来表示一个帧动画，其中主要方法： D3DXCreateKeyframedAnimationSet 创建
RegisterAnimationSRTKeys 添加动画帧
GetSRT 通过时间获得SRT`},{header:"Loading animation data",slug:"loading-animation-data",content:"使用方法D3DXLoadMeshHierarchyFromX加载x文件中的动画信息到ID3DXAnimationController。"},{header:"The ID3DXAnimationController",slug:"the-id3dxanimationcontroller",content:`用来激活当前播放的动画，动画混合等。主要使用到API SetTrackAnimationSet 设置当前播放的动画
AdvanceTime 采样下一个时间的动画姿势 获取动画信息示例：
void SkinnedMesh::GetAnimations(std::vector<std::string>& animations)
{ ID3DXAnimationSet* anim = NULL; for (size_t i = 0; i < m_pAnimControl->GetMaxNumAnimationSets(); i++) { anim = NULL; m_pAnimControl->GetAnimationSet(i, &anim); if (anim != NULL) { animations.push_back(anim->GetName()); anim->Release(); } }
}`},{header:"Having multiple controllers affecting the same mesh",slug:"having-multiple-controllers-affecting-the-same-mesh",content:`渲染多个物体，使用同一个mesh数据，但是播放不同的动画。效果如下：
Alt text
这里使用CloneAnimationController复制多份动画控制器。渲染步骤： Call AdvanceTime() for the active animation controller.
Calculate the world matrix for this character instance.
Update the combined transformation matrices for the skinned mesh with
the world matrix.
Render the skinned mesh.
Repeat with the next character instance. 值得注意的是这里使用的GPU蒙皮，每个人物是分别提交的。直接使用CPU蒙皮的话还是需要多个mesh。直接使用CPU蒙皮如下：
Alt text`}]},{path:"/Animation/CharacterAnimation/SkinnedMeshes.html",title:"Skinned Meshes",pathLocale:"/",contents:[{header:"Skinned Meshes",slug:"skinned-meshes",content:""},{header:"Basics of bone hierarchies",slug:"basics-of-bone-hierarchies",content:`在DX9中使用LPD3DXFRAME作为基础的节点数据结构，内容有：
struct D3DXFRAME {
LPSTR Name; //Name of bone
D3DXMATRIX TransformationMatrix; //Local bone pos, rot & sca
LPD3DXMESHCONTAINER pMeshContainer; //Mesh connected to bone
D3DXFRAME* pFrameSibling; //Sibling bone pointer
D3DXFRAME* pFrameFirstChild; //First child bone
}; 值得注意的是这里节点是有同层级的，以下是输出节点的测试代码：
void PrintHierarchy(D3DXFRAME *bone)
{ //Print Bone Name cout << bone->Name; //Traverse Siblings if(bone->pFrameSibling != NULL) PrintHierarchy(bone->pFrameSibling); //Traverse Children if(bone->pFrameFirstChild != NULL) PrintHierarchy(bone->pFrameSibling);
}`},{header:"Loading bone hierarchies from an .x file",slug:"loading-bone-hierarchies-from-an-x-file",content:`使用 D3DXLoadMeshHierarchyFromX 方法加载骨骼数据，方法如下：
HRESULT D3DXLoadMeshHierarchyFromX(
LPCSTR Filename,
DWORD MeshOptions,
LPDIRECT3DDEVICE9 pDevice,
LPD3DXALLOCATEHIERARCHY pAlloc,
LPD3DXLOADUSERDATA pUserDataLoader,
LPD3DXFRAME* ppFrameHierarchy,
LPD3DXANIMATIONCONTROLLER* ppAnimController
); 其中需要自定义实现以下ID3DXAllocateHierarchy接口，其中有四个方法需要实现：
HRESULT CreateFrame(LPCSTR Name, LPD3DXFRAME* ppNewFrame) override;
HRESULT CreateMeshContainer(THIS_ LPCSTR Name, CONST D3DXMESHDATA* pMeshData, CONST D3DXMATERIAL* pMaterials, CONST D3DXEFFECTINSTANCE* pEffectInstances, DWORD NumMaterials, CONST DWORD* pAdjacency, LPD3DXSKININFO pSkinInfo, LPD3DXMESHCONTAINER* ppNewMeshContainer) override;
HRESULT DestroyFrame(LPD3DXFRAME pFrameToFree)override;
HRESULT DestroyMeshContainer(LPD3DXMESHCONTAINER pMeshContainerBase)override; 这个功能主要让我们自定义初始化骨骼节点数据，具体的结构功能如下：
HRESULT BoneHierarchyLoader::CreateMeshContainer(...)
{ //Create new Bone Mesh ... //Get mesh data here ... //Copy materials and load textures (like with a static mesh) ... if(pSkinInfo != NULL) { //Store Skin Info and convert mesh to Index Blended Mesh ... } //Set ppNewMeshContainer to newly created boneMesh container ...
}`},{header:"Software skinning",slug:"software-skinning",content:`主要的步骤： Overload D3DXFRAM
Overload D3DXMESHCONTAINER
Implement the ID3DXAllocateHierarchy interface
Load a bone hierarhy and associated meshes, skinning information, erc, with the D3DXLoadMeshHierachyFromX() function
For each frame, update the skeleton pose (i.e. the SkinnedMesh::UpdateMatrices() function)
Update the target mesh using ID3DXSkinInfo::UpdateSkinnedMesh()
Render the target mesh as a common static mesh CPU蒙皮不需要我们自己处理权重计算，应该是boneMesh->pSkinInfo->UpdateSkinnedMesh(boneMesh->currentBoneMatrices, NULL, src, dest);这个方法里面计算。`},{header:"Hardware skinning",slug:"hardware-skinning",content:`主要的步骤： Overload D3DXFRAM
Overload D3DXMESHCONTAINER
Implement the ID3DXAllocateHierarchy interface
Load a bone hierarhy and associated meshes, skinning information, erc, with the D3DXLoadMeshHierachyFromX() function
For each frame, update the skeleton pose (i.e. the SkinnedMesh::UpdateMatrices() function)
Upload the Matrix Palette (bone matrices) to the vertex shader
Render the Index Blended Mesh using the vertex shader GPU蒙皮需要自己在shader中处理权重混合，一个顶点受四根骨骼影响，如下图：`},{header:"Rendering static meshes in a bone hierarchy",slug:"rendering-static-meshes-in-a-bone-hierarchy",content:`静态mesh还是有骨骼，所以前几个步骤是一样： Overload D3DXFRAM
Overload D3DXMESHCONTAINER
Implement the ID3DXAllocateHierarchy interface
Load a bone hierarhy and associated meshes, skinning information, erc, with the D3DXLoadMeshHierachyFromX() function
Set bone world transform to the static mesh, in order to animate static with bone
Render static mesh with boneMesh->OriginalMesh->DrawSubset(i);`}]},{path:"/Animation/MotionMatching/Code%20vs%20Data%20Driven%20Displacement.html",title:"Code vs Data Driven Displacement",pathLocale:"/",contents:[{header:"Code vs Data Driven Displacement",slug:"code-vs-data-driven-displacement",content:"原文地址：https://theorangeduck.com/page/code-vs-data-driven-displacement"},{header:"Definitions",slug:"definitions",content:""},{header:"The Simulation Object",slug:"the-simulation-object",content:`把手柄输入转化为预测要移动的物体。 将输入转化为速度的代码：
vec3 desired_velocity_update( const vec3 gamepadstick_left, const float camera_azimuth, const quat simulation_rotation, const float fwrd_speed, const float side_speed, const float back_speed)
{ // Find stick position in world space by rotating using camera azimuth vec3 global_stick_direction = quat_mul_vec3( quat_from_angle_axis(camera_azimuth, vec3(0, 1, 0)), gamepadstick_left); // Find stick position local to current facing direction vec3 local_stick_direction = quat_inv_mul_vec3( simulation_rotation, global_stick_direction); // Scale stick by forward, sideways and backwards speeds vec3 local_desired_velocity = local_stick_direction.z > 0.0 ? vec3(side_speed, 0.0f, fwrd_speed) * local_stick_direction : vec3(side_speed, 0.0f, back_speed) * local_stick_direction; // Re-orientate into the world space return quat_mul_vec3(simulation_rotation, local_desired_velocity);
}`},{header:"The Character Entity",slug:"the-character-entity",content:"这就是玩家可以看到角色。角色的移动数据是来自动画切片，这种方式叫作数据驱动。 动画切片：https://github.com/ubisoft/ubisoft-laforge-animation-dataset"},{header:"Simulation Bone",slug:"simulation-bone",content:`模拟骨骼是给模拟对象使用的，用来代表移动旋转。通常是骨骼的根节点。
为了最大程度的减少视觉物体和模拟物体之间的脱节，是将脊椎骨骼之一投影到地面上，然后使用Savitzky-Golay过滤器平滑其位置-使它作为模拟骨骼的位置。然后将髋骨向前的方向，投影到地面上，用同样的方法抹平。将其旋转为绕垂直轴的旋转，并将其用作模拟骨骼的旋转。 这个原理是，平滑消除了因臀部前后摆动而引起的任何晓得振荡和方向变化；更接近地匹配临界阻尼弹簧产出的运动风格。这种方式并不适用于循环动画和小块动画。
画出行走和奔跑两个动画，模拟骨骼的轨迹，如下图： 同样可以画出两个动画的速度，加速度，角度速度的变化图： 这里记录模拟物体移动的数据； 然后再把模拟物体移动的数据做图像化，把轨迹和速度画出来，并与原动画的数据画在一起如下： 可以看到上图中有很多重叠的部分，这就说明模拟对象和角色实体的模拟骨骼之间有相当不错的匹配。这就意味着，给我们拥有的动画数据和模拟对象设置，很有可能再模拟对象的运动和角色的运动之间实现良好的视觉匹配。`},{header:"Character Controller",slug:"character-controller",content:""},{header:"Synchronization",slug:"synchronization",content:`有两种方式： 直接使用模拟物体同步到角色：会出现滑步
由数据驱动模拟物体：这会造成延迟感 那么想到的方式就是直接混合这两者。`},{header:"Adjustment",slug:"adjustment",content:""},{header:"Reference",slug:"reference",content:`https://static-wordpress.ubisoft.com/montreal.ubisoft.com/wp-content/uploads/2020/07/09154101/Learned_Motion_Matching.pdf
https://www.gdcvault.com/play/1027378/Motion-Matching-in-The-Last`}]},{path:"/Animation/MotionMatching/LearnedMotionMatching.html",title:"Learned Motion Matching",pathLocale:"/",contents:[{header:"Learned Motion Matching",slug:"learned-motion-matching",content:""},{header:"Reference",slug:"reference",content:`https://github.com/pau1o-hs/Learned-Motion-Matching?tab=readme-ov-file
https://theorangeduck.com/media/uploads/other_stuff/Learned_Motion_Matching.pdf
https://github.com/orangeduck/Motion-Matching`}]},{path:"/Animation/MotionMatching/MotionFileds.html",title:"Motion Fields",pathLocale:"/",contents:[{header:"Motion Fields",slug:"motion-fields",content:"motion-fields.pdf"},{header:"Reference",slug:"reference",content:"https://grail.cs.washington.edu/projects/motion-fields/motion-fields.pdf"}]},{path:"/Animation/MotionMatching/MotionGraphs.html",title:"Motion Graphs",pathLocale:"/",contents:[{header:"Motion Graphs",slug:"motion-graphs",content:`内容来自于这篇论文。在Motion Matching中会使用这里面动画切换的技术。
动作捕捉的数据很难更改？编辑技术仅对运动的微小更改才可靠。如果数据跟实际使用场景的需求不同，就必须重新补捉，这代价就十分大了。这个是真的么？
这篇论文的目标是保留动作捕捉的真实感，同时也赋予用户控制和指挥角色的能力。简单来说，就是不需要担心角色是否有正确的动画，这个系统会从列表中选取最符合当前情况的一个动画来播放。
这篇论文提供了一个方法：把所有的基础动捕动画合成一个数据库，这个数据库叫做Motion Graphs。其主要功能是选择当前需要的动画，且可以自动生成两个动画之间的过渡。
Motion Graphs把动画合成问题转化为以下问题之一选择节点序列或图形寻路。`},{header:"Related Work",slug:"related-work",content:`Motion Graphs是创建一个连续流式动画序列，而不是去修改任何一个原动画数据。
Motion Graphs是一个自动的move trees。自动生成。`},{header:"Motion Graph Construction",slug:"motion-graph-construction",content:`一个运动片段被定义为角色参数的定期采样，其中包括根关节的位置和四元数代表每个关节的方向。
标记初始化动画切片相似的程度，直接混合两个切片得到过渡动画。 describe our algorithm for detecting a set of candidate transition
points
how we select among these candidate transitions
how blends are created at the chosen transition points
how to prune the graph to eliminate problematic edges`},{header:"Detecting Candidate Transitions",slug:"detecting-candidate-transitions",content:`动捕数据就是： Vector：根节点位置
Quaternion：骨骼节点的旋转 普通的混合有以下三点问题： 简单的向量无法解释混合使用到的所有参数。如某些骨骼在混合时，他对结果的影响过大。需要手动添加混合权重来平衡混合。
运动仅定义为刚性2D坐标变换。
丝滑的混合不仅需要节点的位置和旋转信息，还需要速度加速度等数据，来做支撑。 把两个姿势转化为点集合（point clouds），然后求这两个点集中的两个点的距离。
这里是有点没看明白，他后面求权重用这个距离，然后所有距离的最小值作为权重。没明白。
最后就怎么转化到了一张图啊，还是2D。`},{header:"Selecting Transition Points",slug:"selecting-transition-points",content:"设置一个阈值来做过渡"},{header:"Creating Transitions",slug:"creating-transitions",content:`如果求到的两个点集合（A,B）的距离能够满足阈值，然后就创建一个从当前帧开始长度为k的两段动画的过渡。首先从2D的转换图上对其动画B。
然后对节点的位置使用线性插值，对旋转使用球面线性插值。`},{header:"Pruning The Graph",slug:"pruning-the-graph",content:`不是所有节点都可以从一个节点到另一个节点。所以需要对节点裁剪，这里我理解的是对每个节点做分类，也有就是打上标签。
把同一标签的节点集合起来做连接。SCC是一组节点的极大集合，使得任意有序节点对(u,v)都存在连接图行走。SCC可以使用Tarjan算法在O(V+E)时间内计算。`},{header:"Extracting Motion",slug:"extracting-motion",content:""},{header:"Converting Graph Walks To Motion",slug:"converting-graph-walks-to-motion",content:"动作图上的每个边都是一段动作，图行走对应于通过将这些片段依次放置来生成的动作。"},{header:"Searching For Motion",slug:"searching-for-motion",content:"使用了公式，没看懂。看起来就是求图的最短路径的问题。"},{header:"Deciding What To Ask For",slug:"deciding-what-to-ask-for",content:""},{header:"Reference",slug:"reference",content:`https://research.cs.wisc.edu/graphics/Papers/Gleicher/Mocap/mograph.pdf
https://github.com/nunosilva800/Motion-Graphs
https://github.com/maxxgx/motion-graphs/tree/master
https://research.cs.wisc.edu/graphics/Gallery/kovar.vol/MoGraphs/
https://www.youtube.com/watch?v=otGinWYXl-8`}]},{path:"/Animation/MotionMatching/",title:"Motion Matching",pathLocale:"/",contents:[{header:"Motion Matching",slug:"motion-matching",content:`Motion Matching is a simple idea, that helps us reason about movement description and control.
It’s also a new type of animation system, with three advantages: High quality
Controllable responsiveness
Minimal manual work`},{header:"播放动画",slug:"播放动画",content:`一段播放动画的代码：
// start
if (!walking && wantToWalk)
{ PlayAnim(StartAnim); walking = true;
} // walk loop
if (IsPlaying(StartAnim) && IsAtEndOfAnim())
{ PlayAnim(WalkLoopAnim);
} // stop
if (walking && !wantToWalk)
{ PlayAnim(StopAnim); walking = false;
} 同样可以使用状态机，可视化：
但如果动画过多就会出现下图：
当然还有混合树的情况播放动画：
if (speed > 3.0f)
{ PlayAnim(RunAnim);
}
else if (speed > 0.0f)
{ PlayAnim(WalkAnim);
}
else
{ PlayAnim(IdleAnim);
} 同样也可以使用可视化工具来处理：`},{header:"多个参数控制动画",slug:"多个参数控制动画",content:"如果有多个数据都会影响着动画的播放，就是需要配表来控制标准选择动画，然后实时传递值给动画控制器。这个逻辑就是动画蓝图的功能。"},{header:"改变固定动画播放路径",slug:"改变固定动画播放路径",content:"Motion Graphs"},{header:"选择下一个动画",slug:"选择下一个动画",content:`Reinforcement Learning Based Character Locomotion in Hitman: Absolution
Motion Fields for Interactive Character Animation
Motion Fields 性能消耗非常大，这里只使用了跳转到其他动画的任何一帧。`},{header:"选择正确的开始和结束时间",slug:"选择正确的开始和结束时间",content:`姿势匹配
速度匹配
精确的末端位置匹配`},{header:"原理简介",slug:"原理简介",content:"核心逻辑：每一帧都去寻找最合适的动画，然后跳转播放。"},{header:"Mocap",slug:"mocap",content:"先做动作捕捉"},{header:"Code",slug:"code",content:`下面是每帧计算匹配的简单代码：
int m_CurrentAnimIndex;
int m_CurrentAnimTime; void AmoUpdate(Goal goal, float dt)
{ m_CurrentAnimTime += dt; Pose currentPose = EValuateLerpedPoseFromData(m_CurrentAnimIndex, m_CurrentAnimTime); float bestCost = 1000000; Pose bestPose; // loop on all mocap for (int i = 0; i < m_Poses.Size(); i++) { Pose candidatePose = m_Poses[i]; // every candidate jumping point has a cost float thisCost = ComputeCost(currentPose, candidatePose, goal); if (thisCost < bestCost) { // remember the best candidate bestCost = thisCost; bestPose = candidatePose; } } bool theWinnerIsAtTheSameLocation = m_CurrentAnimIndex == bestPose.m_AnimIndex && fabs(m_CurrentAnimTime - bestPose.m_AnimTime) < 0.2f; if(!theWinnerIsAtTheSmaeLocation) { // blend to the winning location m_CurrentAnimIndex = bestPose.m_AnimIndex; m_CurrentAnimTime = bestPose.m_AnimTime; PlayAnimStartingAtTime(m_CurrentAnimIndex, m_CurrentAnimTime, 0.25f); }
}`},{header:"Trick 1: Posematch only a few bones",slug:"trick-1-posematch-only-a-few-bones",content:`Local velocity
Feet positions
Feet velocities
Weapon position`},{header:"Trick 2: Just check where a piece of animation brings you if you play it",slug:"trick-2-just-check-where-a-piece-of-animation-brings-you-if-you-play-it",content:`动画的目标，部分代码：
class TrajectoryPoint
{ Vector3 m_Position; float m_Sight; float m_TimeDelay;
}; // desired goal, sent by gameplay each frame
class Goal
{ Array<TrajectoryPoint> m_DesiredTrajectory; Stance m_DesiredStance; // ...
}; 计算调整到新的姿势的花销的代码：
float ComputeCost(Pose currentPose, Pose candidatePose, Goal goal)
{ float cost = 0.0f; // how much the candidate jumping position matches the current situation cost += ComputeCurrentCost(currentPose, candidatePose); // this is our responsivity slider static float reponsivity = 1.0f; // how much the candidate piece of motion matches the desired trajectory cost += responsivity * ComputeFutureCost(candidatePose, goal); return cost;
}`},{header:"Match more things",slug:"match-more-things",content:`Future Stance Matching
Elegantly find transitions when they exist`},{header:"Optimizations",slug:"optimizations",content:`LOD
KD-Tree
Motion Shaders`},{header:"Trajectory Simulation Choices",slug:"trajectory-simulation-choices",content:`Displacement from Animation?
Displacement from Simulation? 更可控，可预测`},{header:"Workflow",slug:"workflow",content:`Mocap is tweaked, imported, and marked up
At runtime Gameplay makes a request(desired trajectory and event constraints)
The animation system continuously finds the best piece of data to play
We modify the result to precisely match gameplay and environment`},{header:"Procedural Touchups",slug:"procedural-touchups",content:""},{header:"Orientation corrections",slug:"orientation-corrections",content:`Let the animation decide rotation
Correctt to match future desired position
Orientation to match future desired orientation`},{header:"Sliding Prevention",slug:"sliding-prevention",content:"Lock the toe when it doesn’t move too much in the main animation"},{header:"Slope Warping",slug:"slope-warping",content:`Carefully tweak ground smoothing
Smoothly pull the hips down
Prefer smoothness over absolute penetration prevention
Don’t break the pose: Never hyper-extend the knee`},{header:"Slope Animations",slug:"slope-animations",content:`Slope anims are automatically chosen by 3D trajectory matching
IK only compensate for what is missing from the anim`},{header:"Spine Pitch Bending",slug:"spine-pitch-bending",content:"Keep whole upper body in sync"},{header:"Reference",slug:"reference",content:`https://gdcvault.com/play/1023280/Motion-Matching-and-The-Road
https://ubm-twvideo01.s3.amazonaws.com/o1/vault/gdc2016/Presentations/Clavet_Simon_MotionMatching.pdf
https://research.cs.wisc.edu/graphics/Papers/Gleicher/Mocap/mograph.pdf
https://github.com/JLPM22/MotionMatching
https://zhuanlan.zhihu.com/p/50141261`}]},{path:"/Animation/games103/RigidBody.html",title:"刚体",pathLocale:"/",contents:[{header:"刚体",slug:"刚体",content:""},{header:"什么是刚体？",slug:"什么是刚体",content:"一个物体表面很结实，它没有形变"},{header:"刚体模拟",slug:"刚体模拟",content:"更新不同时间点物体的状态"},{header:"刚体运动",slug:"刚体运动",content:`只允许刚体平移和旋转
TODO 刚体模拟过程`},{header:"旋转矩阵",slug:"旋转矩阵",content:`优点： 可以很方便的旋转任意向量 缺点： 有冗余：矩阵有九个元素，旋转只有三个方向
不直观且复杂
计算时间微分也就是求角速度不是那么容易`},{header:"欧拉角旋转",slug:"欧拉角旋转",content:`优点： 直观 缺点： 万象锁
计算时间微分也就是求角速度不是那么容易`},{header:"四元数旋转",slug:"四元数旋转",content:`最开始是用来定义一个三维空间中一个点，前一个数为实数s，后一个数v为向量即三个虚数。
在Unity中 s 为 w，v 为 x,y,z`},{header:"如何使用四元数表示旋转",slug:"如何使用四元数表示旋转",content:"我们需要绕 v 向量旋转Θ角度，可以写成下面这样，于此同时也约束了旋转向量的长度。"},{header:"角速度",slug:"角速度",content:""},{header:"力矩",slug:"力矩",content:""},{header:"距离函数",slug:"距离函数",content:"检测是否产生碰撞"},{header:"Penalty",slug:"penalty",content:`当发生碰撞了过后，就对物体施加一个力。
速度、位移下一帧更新。`},{header:"Impulse",slug:"impulse",content:"发生碰撞后，速度、位移马上更新。"},{header:"阅读",slug:"阅读",content:`https://graphics.pixar.com/pbm2001/
Witkin and Baraff. 2001. Physically Based Modeling – Rigid Body Dynamics. SIGGRAPH Courses.`}]},{path:"/Animation/games103/cloth.html",title:"Physics-Based Cloth Simulation",pathLocale:"/",contents:[{header:"Physics-Based Cloth Simulation",slug:"physics-based-cloth-simulation",content:""},{header:"A Mass-Spring System",slug:"a-mass-spring-system",content:""},{header:"An Ideal Spring",slug:"an-ideal-spring",content:""},{header:"Explicit Integration of A Mass-Spring System",slug:"explicit-integration-of-a-mass-spring-system",content:"显示积分有一个问题，如果弹性系数过大，弹簧会来回弹跳。"},{header:"Implicit Integration",slug:"implicit-integration",content:"弹力是一个 holonomic，只跟位置相关的方程。"},{header:"Newton-Raphson Method",slug:"newton-raphson-method",content:`解决非线性系统
限制：函数需要连续
一阶导数就是在描述一个函数的切方向
对一个函数的一阶导数做一个泰勒展开:
$\${F}'(x)\\approx{F}'(x{(k)}) +{F}''(x)(x-x^{k})$$
也就是一阶导数可以是在k位置的一阶导数加上k位置的二阶导数乘以Δx。
方法流程就是： 从$x^0$开始计算直到Δx足够小时就中断。
函数的一阶导数等于0时，既可以是最大值也可以最小值。可以使用二阶导数来判断是最大值还是最小值： F''（x）> 0 ,最小值
F''（x）< 0 ,最大值
如果二阶导数永远大于0，那么函数没有最大值，存在唯一的一个最小值。`},{header:"Simulation by Newton`s Method",slug:"simulation-by-newton-s-method",content:""},{header:"Implicit Simulation",slug:"implicit-simulation",content:"我们就对每一个顶点模拟，计算它的速度与位置。"},{header:"Step 1 Initial",slug:"step-1-initial",content:`初始速度为重力速度：$v_i\\ =(v_i+dt*g)*damping$
然后计算初步预测每个点的位置：$\\tilde{x_i}=x_i+dt*v_i$
同步初步预测位置到每个点：$x_i=\\tilde{x_i}$`},{header:"Step 2 Grandient Calculation",slug:"step-2-grandient-calculation",content:`我们使用隐式积分计算速度与位置是：
$$
\\begin{cases}
v^{[1]} = v^{[0]}+\\Delta t M^{-1} f^{[1]} \\
x^{[1]} = x^{[0]}+\\Delta tv^{[1]}
\\end{cases}
$$
我们可以用速度计算出位置
$$
\\begin{cases}
x^{[1]} = x^{[0]}+\\Delta tv^{[0]}+ \\Delta t^2 M^{-1} f^{[1]}\\
v^{[1]} = (x{[1]}-x)/\\Delta t
\\end{cases}
$$
然后可以转为以下公式，最后对$x^{[1]}$与$F(x)$求导数，得到到梯度 $\\nabla(F(x^{[1]}))$ 计算方式。 对于每一个顶点的梯度就是为：
$$g_i=\\frac{1}{\\Delta t^2}m_i(x_i-\\tilde{x_i})+f_i$$
这里的力包含了弹力和重力，弹力可以使用公式得到： 这里每个顶点的弹力是相互的，相加为零。同时一个顶点可能会被多个弹簧相连，所以我们需要计算当前顶点的所有弹力相加。 我们就对所有弹簧遍历，对每根弹簧上的顶点计算弹力，然后叠加到梯度上去，我们可以得到公式：
$$
\\begin{cases}
g_i = g_i + k(1-\\frac{L_e}{||X_i-X_j||})(X_i-X_j)\\
g_j = g_j - k(1-\\frac{L_e}{||X_i-X_j||})(X_i-X_j)
\\end{cases}
$$`},{header:"Step 3 Finishing",slug:"step-3-finishing",content:`我们这里使用简单的方式来代替计算Hessian矩阵，更新位置使用梯度的公式：
$$X_i=X_i-(\\frac{1}{\\Delta t2}m_i+4k)g_i$$
同时再更新速度：
$$V = V + \\frac{1}{\\Delta t} (X-\\tilde{X})$$`},{header:"Bending and Locking Issues",slug:"bending-and-locking-issues",content:""},{header:"A CO-Rotational Method",slug:"a-co-rotational-method",content:""},{header:"The Locking Issue",slug:"the-locking-issue",content:`拉伸和弯曲时独立的问题
弹簧锁死翻折`},{header:"Position Base Dynamics",slug:"position-base-dynamics",content:""},{header:"问题",slug:"问题",content:"收敛 是什么意思？ 效果，效率 隐式积分与显示积分的区别？"}]},{path:"/Animation/games103/math.html",title:"Math",pathLocale:"/",contents:[{header:"Math",slug:"math",content:""},{header:"向量",slug:"向量",content:"向量实际用的到一些小例子："},{header:"线性插值",slug:"线性插值",content:"两个向量值的插值范围"},{header:"向量投影",slug:"向量投影",content:"投影计算，已知o,q,v求得 s 点"},{header:"平面判断",slug:"平面判断",content:"判断p点位平面那个方位 n 为平面的法线，只需要盘点法线和法线与平面交点点乘的结果正负即可。"},{header:"射线与圆的碰撞",slug:"射线与圆的碰撞",content:`我们要求一个从p点出发的射线是否与以c点为圆心半径为r的圆相交也就是发生碰撞 首先我们假设交点为p(t),同时根据插值公式得到：p(t) = p + vt
我们只需要判断p(t)点到c点的距离是否等于圆心即可，就可以得到
||p(t) - c|| = r
两边在平方
||p(t) - c||² = r²
再根据一个向量的模的平方为该向量点乘自己
(p - c + tv) · (p - c + tv) = r²
根据多项式变形得到
(v · v)t² + 2(p - c) · vt + (p - c) · (p - c) - r² = 0
求解二元一次方程即可，一般解有三种情况： 没有解：无交点
一个解：一个交点
两个解：两个交点`},{header:"三角形的法线与面积",slug:"三角形的法线与面积",content:`叉乘可以获得三角形的法向量和面积
法向量方向是根据叉乘的顺序获得`},{header:"判断一个点是否在三角形内",slug:"判断一个点是否在三角形内",content:"与平面法向量同方向就在 内部"},{header:"重心",slug:"重心",content:`点乘法向量是因为如果点在三角形外面，他的面积就可能是负值。也可以使用线性插值来计算。
使用在三角形着色上。`},{header:"四面体求体积",slug:"四面体求体积",content:""},{header:"四面体重心权重",slug:"四面体重心权重",content:""},{header:"判断射线是否与三角形相交",slug:"判断射线是否与三角形相交",content:"只需要设置一个交点，然后使用交点与任意个顶点相连得到的向量，检测这个向量是否垂直于三角形的法向量 。"},{header:"矩阵",slug:"矩阵",content:`转置矩阵
对角矩阵，对角线有值，其余地方为0
单位矩阵：特殊的对角矩阵
对称矩阵`},{header:"正交矩阵",slug:"正交矩阵",content:`两两垂直的三个轴 如果使用一个正交矩阵代表着局部坐标，然后对其旋转。
这个旋转矩阵就是描述物体本地坐标的状态。`},{header:"奇异值分解",slug:"奇异值分解",content:"任何的线性变化都可以分解成三个步骤：旋转，缩放，旋转"},{header:"特征值分解",slug:"特征值分解",content:"只考虑对称值的特征分解"},{header:"对称",slug:"对称",content:""},{header:"正定矩阵",slug:"正定矩阵",content:""},{header:"线性问题",slug:"线性问题",content:`已知矩阵A和结果向量b，需要求解x
一般不使用A的逆来做，因为计算量大和内存消耗大`},{header:"直接法",slug:"直接法",content:""},{header:"迭代法",slug:"迭代法",content:""},{header:"微积分",slug:"微积分",content:""},{header:"一阶导数",slug:"一阶导数",content:"向量对实数求导 向量对向量求导"},{header:"二阶导数",slug:"二阶导数",content:""},{header:"计算弹簧",slug:"计算弹簧",content:""}]},{path:"/Animation/games103/",title:"Games 103",pathLocale:"/",contents:[{header:"Games 103",slug:"games-103",content:`http://games-cn.org/games103/
PPT : https://www.aliyundrive.com/s/YGuzfDCzw4n
https://www.bilibili.com/video/BV12Q4y1S73g`}]},{path:"/Animation/gameOpenGL/AbstractRender.html",title:"Abstract Renderer",pathLocale:"/",contents:[{header:"Abstract Renderer",slug:"abstract-renderer",content:""},{header:"How to create shader",slug:"how-to-create-shader",content:""},{header:"How to store mesh data in buffers",slug:"how-to-store-mesh-data-in-buffers",content:`使用attribute来存储这些信息，属于每个顶点的信息： Position
Normal
UV or texture coordinate
Color`},{header:"How to bind those buffers as shader attributes",slug:"how-to-bind-those-buffers-as-shader-attributes",content:""},{header:"How to send uniform data to a shader",slug:"how-to-send-uniform-data-to-a-shader",content:"像是常量，只需要设置一次"},{header:"How to render with index buffers",slug:"how-to-render-with-index-buffers",content:"跟attribute相像，可以用来画primitives，这个是用来存储模型的几何数据。"},{header:"How to load textures",slug:"how-to-load-textures",content:"使用stb_image加载图片信息，再把图片传给gpu，生成mipmap。"},{header:"Basic OpenGL concepts",slug:"basic-opengl-concepts",content:""},{header:"Creating and working with simple shaders",slug:"creating-and-working-with-simple-shaders",content:""}]},{path:"/Animation/gameOpenGL/AnimationClip.html",title:"AnimationClip",pathLocale:"/",contents:[{header:"AnimationClip",slug:"animationclip",content:"动画切片就是一个TransformTrack的集合 。在动画切片中的某一个时刻的截图叫做姿势。下图展示出各个类之间的关系： 几种根节点的层级关系："}]},{path:"/Animation/gameOpenGL/BlendAnimation.html",title:"Blend between Animations",pathLocale:"/",contents:[{header:"Blend between Animations",slug:"blend-between-animations",content:""},{header:"Pose blending",slug:"pose-blending",content:`线性插值两个pose，跟插值两个vector类似。在混合两个姿势时，分别混合每个节点的Transform信息，这里我们使用本地空间来做混合。
我们可以设置一个混合父节点，在混合时，我们只混合这个父节点一下的节点。这样就可以让我们在每次混合时，不需要去混合一些不动的节点。`},{header:"Crossfading animation",slug:"crossfading-animation",content:"是一种快速的动画到另一个动画的混合。交叉淡出的目的是隐藏两个动画直接的过渡。"},{header:"Additive blending",slug:"additive-blending",content:`用于通过添加额外的关节运动来修改动画，公式：
outPose = inPose + (addPose - basePose)`}]},{path:"/Animation/gameOpenGL/Buffers.html",title:"Buffers",pathLocale:"/",contents:[{header:"Buffers",slug:"buffers",content:""},{header:"Attributes",slug:"attributes",content:`最常见属性有： Position：本地坐标
Normal：顶点指向的方向
UV or texture coordinate：在贴图里归一化的坐标
Color：一个vector3来代表顶点的颜色`}]},{path:"/Animation/gameOpenGL/Curves-Frames-Tracks.html",title:"Curves Frames Tracks",pathLocale:"/",contents:[{header:"Curves Frames Tracks",slug:"curves-frames-tracks",content:""},{header:"Understand cubic Bézier splines and how to evaluate them",slug:"understand-cubic-bezier-splines-and-how-to-evaluate-them",content:`贝塞尔曲线就是有两个点且这个两个点分别有一个控制器，在这两个点之间生成的插值曲线。 生成这个曲线的方式就是不断的做插值。我们先把这四个点连接起来，然后对每个线段求插值得到新的三个点。 然后把新的三个点连接起来，再对新的线段做插值得到新的两个点 最后把新的两个点连接起来，求新的线段的插值。 最后得到的点就是在贝塞尔曲线上。我们把[0,1]之间都求到最后一个点的插值，就会描绘出现贝塞尔曲线。
在实现上我们可以把三次插值计算公式合并起来，再合并同类项得到：
P1((1-t)^3) +C1(3(1-t)2t) +C2(3(1-t)t^2) +P2(t^3)`},{header:"Understand cubic Hermite splines and how to evaluate them",slug:"understand-cubic-hermite-splines-and-how-to-evaluate-them",content:"Hermite曲线跟贝塞尔曲线相似且不一样，它有两个点和两个斜率构成。斜率也被称为切线。Hermite的例子： https://en.wikipedia.org/wiki/Cubic_Hermite_spline"},{header:"Understand common interpolation methods",slug:"understand-common-interpolation-methods",content:"constant curve：保持一个值直到下一个关键帧。 linear curve：就是两个关键帧连线 cubic curve：用点和切线来定义的"},{header:"Be able to create cubic, linear, and constant keyframes",slug:"be-able-to-create-cubic-linear-and-constant-keyframes",content:""},{header:"Understand how keyframes make up a cubic, linear, or constant track",slug:"understand-how-keyframes-make-up-a-cubic-linear-or-constant-track",content:"关键帧就是时间和值的结合。Track是一系列的Frames组成"},{header:"Be able to evaluate cubic, linear, and constant tracks",slug:"be-able-to-evaluate-cubic-linear-and-constant-tracks",content:""},{header:"Be able to combine three independent tracks into one transform track",slug:"be-able-to-combine-three-independent-tracks-into-one-transform-track",content:""}]},{path:"/Animation/gameOpenGL/DualQuaternions.html",title:"Using Dual Quaternions for Skinning",pathLocale:"/",contents:[{header:"Using Dual Quaternions for Skinning",slug:"using-dual-quaternions-for-skinning",content:"之前实现的蒙皮混合插值叫作线性插值，这种线性插值在有体积旋转是会出现一定的问题。如下图 ： 为了解决这个问题，我们可以使用对偶四元数来做混合。"},{header:"Introducing dual quaternions",slug:"introducing-dual-quaternions",content:`对偶数跟虚数很像，对偶数由一个实数部分和对偶部分组成。假设ε是对偶操作符，一个对偶数可以表示为：$x= real + εdual$，其中 $ε^2=0$ 并且 $ε\\ne0$
它可以代表这两个四元数或者8方位的浮点数
具体的可以参看资料：https://cs.gmu.edu/~jmlien/teaching/cs451/uploads/Main/dual-quaternion.pdf`},{header:"Implementing dual quaternions",slug:"implementing-dual-quaternions",content:`点乘结果属性： 如果为正数，对偶四元数点在相同方向
如果为负数 ，对偶四元数点在反方向
如果 为0，对偶四元数垂直`},{header:"Skinning with dual quaternions",slug:"skinning-with-dual-quaternions",content:`我们需要使用对偶四元数替换蒙皮中的矩阵。
三个步骤需要使用对偶四元数替换矩阵： Convert the matrices to dual quaternions in the vertex shader
Convert the matrices of the current pose to dual quaternions, then pass dual quaternions to the vertex shader
Convert each transform of the current pose to a dual quaternion, then accumulate the world transform as a dual quaternion`},{header:"Understand how to use dual quaternions skinning",slug:"understand-how-to-use-dual-quaternions-skinning",content:""},{header:"Refence",slug:"refence",content:""}]},{path:"/Animation/gameOpenGL/GPUCrows.html",title:"Rendering Instanced Crowds",pathLocale:"/",contents:[{header:"Rendering Instanced Crowds",slug:"rendering-instanced-crowds",content:"简单来说把动画数据存储到贴图上，在shader的顶点函数中计算动画蒙皮。"},{header:"Storing arbitrary data in textures",slug:"storing-arbitrary-data-in-textures",content:"可以使用一个GL_RGBA32F格式的贴图来存储动画信息，每个像素有4个32位浮点数来存。"},{header:"Retrieving arbitrary data from textures",slug:"retrieving-arbitrary-data-from-textures",content:"在shader中可以对其采样读取"},{header:"Baking animations into a texture",slug:"baking-animations-into-a-texture",content:"贴图的横坐标为帧数，纵坐标为骨骼信息，骨骼信息有三个：位置、旋转、缩放。一个信息放一个像素。简单的示意图： 每一格就是一个像素。"},{header:"Sampling animation textures in a vertex shader",slug:"sampling-animation-textures-in-a-vertex-shader",content:""},{header:"Optimizing the crowd system",slug:"optimizing-the-crowd-system",content:""}]},{path:"/Animation/gameOpenGL/InverseKinematics.html",title:"Inverse Kinematics",pathLocale:"/",contents:[{header:"Inverse Kinematics",slug:"inverse-kinematics",content:"逆向运动学是处理一个特殊节点怎么移动到一个世界坐标的位置上的过程。"},{header:"Understand how CCD IK works",slug:"understand-how-ccd-ik-works",content:`CCD是循环旋转下降（Cyclic Coordinate Descent）,这个算法有三个基础概念： Goal：目标的世界坐标点
Ik chain：所有需要移动和选择的节点列表
End effector：节点列表末端 这个算法原理很简单，它是一个迭代算法。最开始迭代从节点列表的倒数第二个节点开始，倒数第一个是End effector。我们来解释一次迭代的过程： 求当前节点到目标点的向量：Joint to Target
求当前节点到末端节点的向量：Joint to Effector
旋转Joint to Effector向量与Jointt to Target同方向 我们可以看这个图比较清晰，这里画出来两次迭代： 我们需要多次迭代，直到effector离目标点足够接近。`},{header:"Implement a CCD solver",slug:"implement-a-ccd-solver",content:"迭代的次数需要固定，不能让他无线循环。"},{header:"Understand how FABRIK works",slug:"understand-how-fabrik-works",content:`FABRILK是正反向运动学（Forward And Backward Reaching Inverse Kinematics），这个算法我们只用位置来计算，不像CCD使用旋转。同样的也需要三个参数： Goal：目标的世界坐标点
Ik chain：所有需要移动和选择的节点列表
End effector：节点列表末端 这个算法分成两部分： 反向迭代：先把最后一个节点开始移动到目标节点位置，然后从后到前依次移动列表中的节点，移动的长度为两节点之间的长度，也就是骨骼的长度；移动的方向是当前节点到下一个节点的方向。
正向迭代：先把头节点移动到之前反向迭代的位置，然后从前到后依次移动列表中的节点，移动的长度为两节点之间的长度，也就是骨骼的长度；移动的方向是当前节点到上一个节点的位置。 我们可以看这个图，前两步骤是反向迭代，后三步是正向迭代： 这个算法对于人体动画生成会更加的自然。`},{header:"Ball-and-socket constraints",slug:"ball-and-socket-constraints",content:`这个办法是对旋转角度的限制，父节点旋转和子节点旋转的角度不能超过多少，超过了就以限制角度为准。形象点说就是跟肩膀关节一样是一样的。像是下面这张图一样，黑色的关节只能在白色这个关节凹陷处旋转。 以下是伪代码：
void ApplyBallSocketConstraint(int i, float limit) { quat parentRot = i == 0 ? mOffset.rotation :GetWorldTransform(i - 1).rotation; quat thisRot = GetWorldTransform(i).rotation; vec3 parentDir = parentRot * vec3(0, 0, 1); vec3 thisDir = thisRot * vec3(0, 0, 1); float angle = ::angle(parentDir, thisDir); if (angle > limit * QUAT_DEG2RAD) { vec3 correction = crHoss(parentDir, thisDir); quat worldSpaceRotation = parentRot *angleAxis(limit * QUAT_DEG2RAD, correction);mChain[i].rotation = worldSpaceRotation * inverse(parentRot); }
}`},{header:"Hinge constraints",slug:"hinge-constraints",content:`这个限制是只允许旋转沿着一个特殊的轴的旋转，这个像肘和膝盖，跟我们生活中的铰链一样。 所以我们只需知道当前节点与父节点的世界空间旋转，用旋转四元数乘以轴法线，并找到两者之间的一个四元数，这个就是我们需要的旋转的量，以下是伪代码：
void ApplyHingeSocketConstraint(int i, vec3axis) { Transform joint = GetWorldTransform(i); Transform parent = GetWorldTransform(i -1); vec3 currentHinge = joint.rotation * axis; vec3 desiredHinge = parent.rotation * axis; mChain[i].rotation = mChain[i].rotation * fromToRotation(currentHinge, desiredHinge);
}`},{header:"Understand where and how IK solvers fit into an animation pipeline",slug:"understand-where-and-how-ik-solvers-fit-into-an-animation-pipeline",content:`有两种常使用IK的地方：手的位置和脚的位置。
有两个常见的问题在我们做IK解决方案时： What happens if the up motion is too far away?
At what point in the animation cycle can we interpolate between pinned and non-pinned positions? 我们举一个简单的计算脚部IK的例子： 从髋关节（Hip）出射出一条射线A到脚踝（Ankle） 射线碰撞到物体，碰撞点作为IK节点列表的当前目标点
没有发生碰撞，脚踝就作为当前目标点 同样从髋关节（Hip）出射出一条射线B，不对射线B做长度限制 射线检测碰到物体，碰撞点作为未来的目标点
没有发生碰撞，把未来的目标点作为当前的目标点 如果我们单纯直接使用目标点 只用当前目标点：角色的脚可能会突然弹到地面
只用未来目标点：角色的脚只会在地面拖着 所以我们需要做插值： 当角色的脚在碰撞点上，使用使用未来目标点
当角色的脚在碰撞点下，使用当前目标点`},{header:"Finding the foot goals",slug:"finding-the-foot-goals",content:"我们从髋关节（hip）下面一点发出直的射线到角色脚踝下面一点。射线的方向是髋关节到脚踝。 如果有碰撞，碰撞点就为目标点，没有目标点就是脚踝的位置。需要注意的是，我们改变的位置是脚踝而不是脚底板，所以如果有碰撞点，需要把目标点上移一段距离，如图 ："},{header:"Interpolating the foot goals",slug:"interpolating-the-foot-goals",content:`对于插值，我们需要知道是对什么插值，是对那两个值插值，是对动画切片中的腿的位置和IK射线检测计算出来腿的位置做插值，首先需要知道腿当前是属于那个阶段： 在地面上
被提起来
悬挂
正在被放置 不同的阶段使用插值比例是不一样的，如果当前腿的位置是在地面上，我们就直接可以使用动画切片的位置；如果腿不在地面上，我们就需要让腿回来地面上，这时就需要使用IK计算出来腿的位置在哪里。
这样一来我们就可以清晰知道插值的边界是哪里，当脚离开地面数值就为0，然后脚在地面时数值就为1。这个脚的位置数据是直接使用的动画切片的位置来做判断。我们可以使用一个曲线来线性来画出来，把当前动画化切片的播放时间单位话，整个切片时间就是0到1.`},{header:"Vertical character placement",slug:"vertical-character-placement",content:"IK拉伸和普通动画切片的比较： 在垂直方向，需要把脚稍微向下一段距离，这样可以让IK系统避免拉伸。"},{header:"IK Pass",slug:"ik-pass",content:"复制当前姿势的节点到IK解决系统中。对于每一只腿，复制髋关节的世界坐标到IK系统的根节点里。复制膝盖的本地坐标到节点1。复制脚踝的本地坐标到节点2。然后运行IK解决。"},{header:"Foot alignment",slug:"foot-alignment",content:""}]},{path:"/Animation/gameOpenGL/Matrix.html",title:"Matrix",pathLocale:"/",contents:[{header:"Matrix",slug:"matrix",content:"在内存中的存放，一个列为主的矩阵在内存中的存放其实是一个线性映射，第几行对应着数组元素的第几个组。 对应的求出以列为主的矩阵中某个元素的公式就是column * numberOfCloumns + row，比如说第2列，第3行的元素在数组中的索引就是7。"}]},{path:"/Animation/gameOpenGL/MeshSkinning.html",title:"Mesh Skinning",pathLocale:"/",contents:[{header:"Mesh Skinning",slug:"mesh-skinning",content:"当一个网格和一个骨骼被创建。每个顶点会分配给一个或多个骨骼，这个过程叫做绑定（Rigging）。骨骼被创建时的姿势叫做绑定姿势(bind pose)，这个姿势把骨骼正好融合在网格内部。 这里我认为绑定姿势也就是我们在软件中编辑动画的基础姿势。骨骼和蒙皮之间的关系是配置好了的，如权重等。换句话说就是骨骼和蒙皮之间的距离是固定好了的。我们在计算其他姿势时就可以获得这个距离来计算其他姿势下蒙皮的 位置，因为骨骼的位置就是姿势的样子，在模型文件中已经存了数据。"},{header:"Understand how a skinned mesh is different from a non-skinnedmesh",slug:"understand-how-a-skinned-mesh-is-different-from-a-non-skinnedmesh",content:"蒙皮是处理决定那个顶点应该被分配到那个骨骼上。一个顶点可以影响到多个骨骼。 Rig skinning:每个顶点对应一个骨骼，把一个顶点乘以多个矩阵得到最后的坐标。在关节处不能自然的弯曲。通过将三角形的呃呃不同顶点分配给不同的骨头，可以避免在关节处（如肘部）的网格断裂。这样造成网格不能保持好体积，这样看起来很奇怪 Smooth skinning：顶点对应着多个骨骼。超过一个骨骼可以影响到一个顶点。每个影响都有一个权重，这个权重用于混合顶点。下图就是同一顶点影响两个骨骼的情况，我们取0.5的权重值。"},{header:"Understand the entire skinning pipeline",slug:"understand-the-entire-skinning-pipeline",content:`普通顶点管线和绑定蒙皮顶点关系对比： 我们需要明白一个目的，我们最终需要呈现在屏幕中是蒙皮，也就是说我们要渲染的是蒙皮。而在模型文件我们一般是存储的骨骼节点的位置，所以我们需要实时根据骨骼节点位置去计算出对应蒙皮三角形中顶点的位置。
这就是为什们我们需要增加两个步骤的原因。这里为什么我们乘以绑定矩阵的逆就可以蒙皮空的坐标呢？
我们可以这样思考，把姿势看作矩阵: 把绑定姿势作为基础姿势 B ，其他姿势 C 都可以通过绑定姿势乘以一个矩阵 M 得到，那么我们就可以得到公式: C = B * M。
现在有一个姿势 C，并且已知绑定姿势 B，就可以求到 M = C * inverse(B)
再使用 M 乘以蒙皮的顶点，就得到蒙皮点在这个姿势下模型空间位置。
后面就是可以一样的计算了。`},{header:"Implement a skeleton class",slug:"implement-a-skeleton-class",content:"所有的绑定姿势和绑定姿势的逆都共享给所有游戏场景中的角色。"},{header:"Load the bind pose of a skeleton from a glTF file",slug:"load-the-bind-pose-of-a-skeleton-from-a-gltf-file",content:`加载rest姿势
读取有多少个cgltf_skin
从每个皮肤中读取逆矩阵inverse_bind_matrices
对逆矩阵取逆就可以获得节点的世界坐标
再根据世界坐标求到每个节点的本地坐标`},{header:"Implement a skinned mesh class",slug:"implement-a-skinned-mesh-class",content:""},{header:"Load skinned meshes from a gLTF file",slug:"load-skinned-meshes-from-a-gltf-file",content:""},{header:"Implement CPU skinning",slug:"implement-cpu-skinning",content:""},{header:"Implement GPU skinning",slug:"implement-gpu-skinning",content:""}]},{path:"/Animation/gameOpenGL/OptimizePipeline.html",title:"Optimizing the Animation Pipeline",pathLocale:"/",contents:[{header:"Optimizing the Animation Pipeline",slug:"optimizing-the-animation-pipeline",content:""},{header:"Pre-generating the skin matrix",slug:"pre-generating-the-skin-matrix",content:`顶点着色器的最大的问题是系统会占用大量的Uniform槽位。我们可以把pose matrix和inverse bind pose在CPU中计算好了再传入。这样我们就可以节约很多槽位（480个）。
我们可以统一先计算这两个矩阵相乘，然后修改CPU和GPU蒙皮的实现，使他们连个传入的参数都为这两个矩阵相乘。`},{header:"Storing the skin pallette in a texture",slug:"storing-the-skin-pallette-in-a-texture",content:"我们可以使用FLOAT32的贴图来储存动画矩阵，这种贴图每个顶点中的每个元素都可以拥有32位的浮点数。我们可以把动画矩阵转存到贴图中去，然后在顶点函数中进行采样即可。这种方式我们可以减少槽位道一个。但是他的缺点也很明显就是速度。使用采样的速度比直接使用数组查询会慢很多。"},{header:"Faster sampling",slug:"faster-sampling",content:`因为我们在对每个Track采样时，在给定时间后需要去定位这个时间是属于哪个Frame中的，然后对其插值。这样的话我们就需要去遍历整个Frame列表去找到合适两帧去插值。这个遍历就非常的消耗，因为我们需要对每个骨骼做这个操作。当这个动画切片时间非常长时，这个循环就会非常的久。
我们可以把所有Frame做归一化。把整个列表映射到一个固定的时间间隔的查询表中。比如说我们假设每秒钟采样60次，那么我们的时间键可以1/60，然后新建一个以1/60时间为间隔的列表，把Frame列表映射到这个列表中。`},{header:"The Pose palette generation",slug:"the-pose-palette-generation",content:`在求得一个姿势的系列矩阵时，我们需要把每个节点的Transform转换为矩阵，同时他是世界坐标的，所以我们就需要把本地的转化为世界空间中。
在从本地空间转化到世界空间时，我们需要对每个节点迭代他的父节点，直到父节点为根节点时。
这个计算是有一点浪费的，我们遍历可能会多次计算同一个父节点。
如果说计算节点从骨骼的根节点计算到尾节点，也就是从上到下依次每层来计算。这样在计算时，我们就不需要每次重新计算当前节点的父节点的世界空间，因为之前我们就计算过了。
我们可以使用缓存世界空间的方式来做，可以分两个循环来做，第一个循环找到和缓存世界矩阵。如果节点的父节点的索引小于节点的索引，说明我们之前计算过这个父节点的世界矩阵，反之我们就需要跳出第一个循环。
第二循环是使用原来的方式跌代求每个节点的世界矩阵。
这个方式的前提就是需要我们把越上层的父节放在数组的越前面。`},{header:"Exploring Pose::GetGlobalTransform",slug:"exploring-pose-getglobaltransform",content:`因为我们随时都可能获取一个节点的世界坐标，所以我们可以设置两个数组来缓存世界坐标，一个存储世界坐标，一个存储标记当前节点是否需要更新世界坐标。
这种做法唯一的缺点就是会增加大量的内存。
这里的的优化只适用于有很多关键帧的动画。如果帧少的话我们可以使用二分查找。`}]},{path:"/Animation/gameOpenGL/Quaternions.html",title:"Quaternions",pathLocale:"/",contents:[{header:"Quaternions",slug:"quaternions",content:`绕轴旋转 θ 可以在球体上表示为任何有向弧，在垂直于旋转轴的平面上长度为 θ/2。正角产生绕轴逆时针旋转。
为什么是1/2呢？因为一个四元数可以记录2个圆周，也就是720度，但是sin/cos的循环时360度，所以为了适配就除以2。`},{header:"Different methods for creating quaternions",slug:"different-methods-for-creating-quaternions",content:""},{header:"Retrieving the angle and axis of aquaternion",slug:"retrieving-the-angle-and-axis-of-aquaternion",content:""},{header:"Basic component-wise operations",slug:"basic-component-wise-operations",content:""},{header:"The length and dot product of two quaternions",slug:"the-length-and-dot-product-of-two-quaternions",content:""},{header:"Inverting quaternions",slug:"inverting-quaternions",content:"当一个四元数被归一化后，他的共轨和逆向时一样。"},{header:"Combining quaternions",slug:"combining-quaternions",content:""},{header:"Transforming vectors by quaternions",slug:"transforming-vectors-by-quaternions",content:"纯四元数就是，旋转轴时单位向量，w是0时。"},{header:"Interpolating between quaternions",slug:"interpolating-between-quaternions",content:`四元数是一个旋转角度，而不是方向。做插值，就是从一个角度变道另一个角度。在旋转中，我们可以获得最长的路径或者最短的路径。插值最好使用最短的路径。在两个四元数点乘时，大于零时就是取得最短路径，小于零时就是取得最长路径。如果我们需要使用最短路径，就可以做如下操作：
quat SampleFunction(const quat& a, const quat& b) { if (dot(a, b) < 0.0f) { b = -b; } return slerp(a, b, 0.5f);
}`},{header:"Converting quaternions and matrices",slug:"converting-quaternions-and-matrices",content:""}]},{path:"/Animation/gameOpenGL/",title:"Hands-On C++ Game Animation Programming",pathLocale:"/",contents:[{header:"Hands-On C++ Game Animation Programming",slug:"hands-on-c-game-animation-programming",content:`链接 ：https://weread.qq.com/web/reader/97932dc0722ff7e59799e8ckc81322c012c81e728d9d180
官方代码：https://github.com/gszauer/GameAnimationProgramming
练习代码：https://github.com/BanMing/AnimationLab/tree/master/GameAnimation`}]},{path:"/Animation/gameOpenGL/Transforms.html",title:"Transforms",pathLocale:"/",contents:[{header:"Transforms",slug:"transforms",content:"Understand what a transform is"},{header:"Understand how to combine transforms",slug:"understand-how-to-combine-transforms",content:"转移子物体到父物体的空间中"},{header:"Convert between transforms and matrices",slug:"convert-between-transforms-and-matrices",content:""},{header:"Understand how to apply transforms to points and vectors",slug:"understand-how-to-apply-transforms-to-points-and-vectors",content:`获得一个点在一个transform空间的位置。
http://gabormakesgames.com/transforms.html
Transform combine(const Transform& a, const Transform& b) { Transform out; out.scale = a.scale * b.scale; out.rotation = b.rotation * a.rotation; out.position = a.rotation * (a.scale * b.position); out.position = a.position + out.position; return out;
} Matrix combine(Transform transform) { Matrix localMatrix = ToMatrix(transform); Matrix parentMatrix = ToMatrix(transform.parent); return localMatrix * parentMatrix; Matrix GetInParentMatrix(Transform transform) { Matrix localMatrix = ToMatrix(transform); Matrix localParentMatrix = ToMatrix(transform.parent); return localParentMatrix * localMatrix;
}`}]},{path:"/Animation/gameOpenGL/Vectors.html",title:"Vector",pathLocale:"/",contents:[{header:"Vector",slug:"vector",content:`实列网站：https://gabormakesgames.com/blog_vectors.html
因为浮点数比较计算会有不精确的时候，我们使用一个 epsilon = 0.000001f 的特定数值来比较。`},{header:"Interpolation",slug:"interpolation",content:"计算出两个点之间的某一个位置"},{header:"lerp",slug:"lerp",content:`把两点之间的距离归一化得到一个插值t t = 0 ：插值结果为起点
t = 1 ：插值结果为终点
0 < t < 1 ：插值结果为中间`},{header:"slerp",slug:"slerp",content:"以弧度值来做插值（spherical linear interpolation），与线性插值的对比如下： 在我们知道了两个点之间的角度时，我们可以用以下公式来求插值结果："},{header:"nlerp",slug:"nlerp",content:"他的插值移动速度不是固定的，而是要更快一些。就是把线性插值再做一次归一化。对比如下："},{header:"generally",slug:"generally",content:"nlerp是一个好的选择优于slerp。"}]},{path:"/Animation/gameOpenGL/glTF.html",title:"gltf",pathLocale:"/",contents:[{header:"gltf",slug:"gltf",content:`引导：https://www.khronos.org/files/gltf20-reference-guide.pdf
三方库:https://github.com/jkuhlmann/cgltf
在线工具：https://gltf-viewer.donmccurdy.com/`},{header:"Understanding what data is inside of a glTF file",slug:"understanding-what-data-is-inside-of-a-gltf-file",content:`是一个json格式的数据。他包含了整个场景的数据。包含了静态网格，蒙皮（是描述模型顶点如何受到transform或者骨骼的影响的一个物件。），相机，PBR材质。
一个glTF文件中拥有一个或多个场景，一个场景有有一个或多个节点。一个节点可以是：蒙皮，网格，动画，相机，灯光，混合权重等。
每个网格，蒙皮和动画的信息都存在数组buffers中。使用accessors和bufferViews来获得其中的数据。
其中的数据访问流向：`},{header:"Implementing a glTF loading using cgltf",slug:"implementing-a-gltf-loading-using-cgltf",content:"各个部分的类图关系如下： 如何访问数据流程："},{header:"Learning how to export glTF files from Blender",slug:"learning-how-to-export-gltf-files-from-blender",content:`怎么使用gltf加载 动画
https://github.com/KhronosGroup/glTF-Tutorials/blob/master/gltfTutorial/gltfTutorial_006_SimpleAnimation.md`}]},{path:"/Basic/algorithm/",title:"算法",pathLocale:"/",contents:[{header:"算法",slug:"算法",content:""}]},{path:"/Basic/design/Bottom-UpAndTop-Down.html",title:"自底向上与自顶向下的区别",pathLocale:"/",contents:[{header:"自底向上与自顶向下的区别",slug:"自底向上与自顶向下的区别",content:""},{header:"自顶向下模型",slug:"自顶向下模型",content:`在这种设计模型中，这个系统时定制的，我们并不知道系统每个部分的细节是什么。在每个部分中还有更多的细节。如果我们去深入了解一个这样设计的程序，需要一定是时间。这个我们做项目计划一样，我们已经有一个目标。我需要做的就是： 把大的目标分散成小目标
再把小目标分散成更小的目标，直到这个小目标很容易去完成。`},{header:"优势",slug:"优势",content:`把问题拆分可以让我们更清楚需要做什么
每一步的细化，使问题变得更加的简单和容易解决
模块化的解决方案可以得到复用
把问题拆分后可以让多人来解决这个问题`},{header:"自底向上模型",slug:"自底向上模型",content:"这个设计中，系统中单独的模块就定义了细节。这个模块链接起来就可以组成一个大的系统。比如我们需要造一辆汽车，我们知道汽车都需要轮胎，方向盘，这些都是汽车的配件，当我们把这些配件组装起来，那我们就认为这个就是一辆车。同时我们也可以时常替换某个组件，比如说轮胎，我们可以把轮胎换成赛车轮胎。"},{header:"优势",slug:"优势-1",content:`做决策是从低级别来考虑的，这可以最大化复现性
自定义具有更多灵活性`},{header:"区别",slug:"区别",content:`自顶向下
自底向上 我们的关注点是把问题拆分的更小
我们直接解决较小的问题，再把这些解决方案组装起来 主要使用在结构化编程语言：C、Fortran
主要使用在面向对象编程语言：C++、C# 每一个模块都是独立的，所以会有冗余
冗余最小化通过数据驱动 模块之间交互很少
模块之间需要交互数据 很难被识别
我们不能构建程序从已经存在的程序中 细节实现会有一定的难度
不是我们正常的思维方式`}]},{path:"/Basic/design/",title:"程序设计",pathLocale:"/",contents:[{header:"程序设计",slug:"程序设计",content:""}]},{path:"/Basic/language/",title:"语言",pathLocale:"/",contents:[{header:"语言",slug:"语言",content:""}]},{path:"/Basic/math/FixedPoints.html",title:"Fixed Points",pathLocale:"/",contents:[{header:"Fixed Points",slug:"fixed-points",content:`浮点数计算很慢？
定点数在计算是会更快一些
在计算除法的时候，一般都会比较慢，我们可以使用左移来替换。`}]},{path:"/Basic/math/SIMD.html",title:"Single Instruction Multipe Data",pathLocale:"/",contents:[{header:"Single Instruction Multipe Data",slug:"single-instruction-multipe-data",content:`https://developer.arm.com/Architectures/Neon
https://github.com/ermig1979/Simd
https://stackoverflow.blog/2020/07/08/improving-performance-with-simd-intrinsics-in-three-use-cases/
https://www.intel.com/content/www/us/en/docs/cpp-compiler/developer-guide-reference/2021-8/c-classes-and-simd-operations.html`}]},{path:"/Basic/math/comparing-floats.html",title:"Comparing Floats",pathLocale:"/",contents:[{header:"Comparing Floats",slug:"comparing-floats",content:"https://bitbashing.io/comparing-floats.html"}]},{path:"/Basic/math/matrix.html",title:"Matrix",pathLocale:"/",contents:[{header:"Matrix",slug:"matrix",content:`https://betterexplained.com/articles/matrix-multiplication/
https://www.cnblogs.com/noluye/p/12262580.html`}]},{path:"/Basic/network/",title:"计算机网络",pathLocale:"/",contents:[{header:"计算机网络",slug:"计算机网络",content:`本节部分知识点来自《计算机网络（第 7 版）》 计算机网络体系结构：
计算机网络体系结构`},{header:"各层作用及协议",slug:"各层作用及协议",content:`分层
作用
协议 物理层
通过媒介传输比特，确定机械及电气规范（比特 Bit）
RJ45、CLOCK、IEEE802.3（中继器，集线器） 数据链路层
将比特组装成帧和点到点的传递（帧 Frame）
PPP、FR、HDLC、VLAN、MAC（网桥，交换机） 网络层
负责数据包从源到宿的传递和网际互连（包 Packet）
IP、ICMP、ARP、RARP、OSPF、IPX、RIP、IGRP（路由器） 运输层
提供端到端的可靠报文传递和错误恢复（ 段Segment）
TCP、UDP、SPX 会话层
建立、管理和终止会话（会话协议数据单元 SPDU）
NFS、SQL、NETBIOS、RPC 表示层
对数据进行翻译、加密和压缩（表示协议数据单元 PPDU）
JPEG、MPEG、ASII 应用层
允许访问OSI环境的手段（应用协议数据单元 APDU）
FTP、DNS、Telnet、SMTP、HTTP、WWW、NFS`},{header:"物理层",slug:"物理层",content:`传输数据的单位：比特
数据传输系统：源系统（源点、发送器） --> 传输系统 --> 目的系统（接收器、终点） 通道： 单向通道（单工通道）：只有一个方向通信，没有反方向交互，如广播
双向交替通信（半双工通信）：通信双方都可发消息，但不能同时发送或接收
双向同时通信（全双工通信）：通信双方可以同时发送和接收信息 通道复用技术： 频分复用（FDM，Frequency Division Multiplexing）：不同用户在不同频带，所用用户在同样时间占用不同带宽资源
时分复用（TDM，Time Division Multiplexing）：不同用户在同一时间段的不同时间片，所有用户在不同时间占用同样的频带宽度
波分复用（WDM，Wavelength Division Multiplexing）：光的频分复用
码分复用（CDM，Code Division Multiplexing）：不同用户使用不同的码，可以在同样时间使用同样频带通信`},{header:"数据链路层",slug:"数据链路层",content:`主要信道： 点对点信道
广播信道`},{header:"点对点信道",slug:"点对点信道",content:`数据单元：帧 三个基本问题： 封装成帧：把网络层的 IP 数据报封装成帧，SOH - 数据部分 - EOT
透明传输：不管数据部分什么字符，都能传输出去；可以通过字节填充方法解决（冲突字符前加转义字符）
差错检测：降低误码率（BER，Bit Error Rate），广泛使用循环冗余检测（CRC，Cyclic Redundancy Check） 点对点协议（Point-to-Point Protocol）： 点对点协议（Point-to-Point Protocol）：用户计算机和 ISP 通信时所使用的协议`},{header:"广播信道",slug:"广播信道",content:`广播通信： 硬件地址（物理地址、MAC 地址）
单播（unicast）帧（一对一）：收到的帧的 MAC 地址与本站的硬件地址相同
广播（broadcast）帧（一对全体）：发送给本局域网上所有站点的帧
多播（multicast）帧（一对多）：发送给本局域网上一部分站点的帧`},{header:"网络层",slug:"网络层",content:`IP（Internet Protocol，网际协议）是为计算机网络相互连接进行通信而设计的协议。
ARP（Address Resolution Protocol，地址解析协议）
ICMP（Internet Control Message Protocol，网际控制报文协议）
IGMP（Internet Group Management Protocol，网际组管理协议）`},{header:"IP 网际协议",slug:"ip-网际协议",content:`IP 地址分类： IP 地址 ::= {<网络号>,<主机号>} IP 地址类别
网络号
网络范围
主机号
IP 地址范围 A 类
8bit，第一位固定为 0
0 — 127
24bit
1.0.0.0 — 127.255.255.255 B 类
16bit，前两位固定为 10
128.0 — 191.255
16bit
128.0.0.0 — 191.255.255.255 C 类
24bit，前三位固定为 110
192.0.0 — 223.255.255
8bit
192.0.0.0 — 223.255.255.255 D 类
前四位固定为 1110，后面为多播地址 E 类
前五位固定为 11110，后面保留为今后所用 IP 数据报格式：
IP 数据报格式`},{header:"ICMP 网际控制报文协议",slug:"icmp-网际控制报文协议",content:`ICMP 报文格式：
ICMP 报文格式
应用： PING（Packet InterNet Groper，分组网间探测）测试两个主机之间的连通性
TTL（Time To Live，生存时间）该字段指定 IP 包被路由器丢弃之前允许通过的最大网段数量`},{header:"内部网关协议",slug:"内部网关协议",content:`RIP（Routing Information Protocol，路由信息协议）
OSPF（Open Sortest Path First，开放最短路径优先）`},{header:"外部网关协议",slug:"外部网关协议",content:"BGP（Border Gateway Protocol，边界网关协议）"},{header:"IP多播",slug:"ip多播",content:`IGMP（Internet Group Management Protocol，网际组管理协议）
多播路由选择协议`},{header:"VPN 和 NAT",slug:"vpn-和-nat",content:`VPN（Virtual Private Network，虚拟专用网）
NAT（Network Address Translation，网络地址转换）`},{header:"路由表包含什么？",slug:"路由表包含什么",content:`网络 ID（Network ID, Network number）：就是目标地址的网络 ID。
子网掩码（subnet mask）：用来判断 IP 所属网络
下一跳地址/接口（Next hop / interface）：就是数据在发送到目标地址的旅途中下一站的地址。其中 interface 指向 next hop（即为下一个 route）。一个自治系统（AS, Autonomous system）中的 route 应该包含区域内所有的子网络，而默认网关（Network id: 0.0.0.0, Netmask: 0.0.0.0）指向自治系统的出口。 根据应用和执行的不同，路由表可能含有如下附加信息： 花费（Cost）：就是数据发送过程中通过路径所需要的花费。
路由的服务质量
路由中需要过滤的出/入连接列表`},{header:"运输层",slug:"运输层",content:`协议： TCP（Transmission Control Protocol，传输控制协议）
UDP（User Datagram Protocol，用户数据报协议） 端口： 应用程序
FTP
TELNET
SMTP
DNS
TFTP
HTTP
HTTPS
SNMP 端口号
21
23
25
53
69
80
443
161`},{header:"TCP",slug:"tcp",content:`TCP（Transmission Control Protocol，传输控制协议）是一种面向连接的、可靠的、基于字节流的传输层通信协议，其传输的单位是报文段。 特征： 面向连接
只能点对点（一对一）通信
可靠交互
全双工通信
面向字节流 TCP 如何保证可靠传输： 确认和超时重传
数据合理分片和排序
流量控制
拥塞控制
数据校验 TCP 报文结构
TCP 报文
TCP 首部
TCP 首部
TCP：状态控制码（Code，Control Flag），占 6 比特，含义如下： URG：紧急比特（urgent），当 URG＝1 时，表明紧急指针字段有效，代表该封包为紧急封包。它告诉系统此报文段中有紧急数据，应尽快传送(相当于高优先级的数据)， 且上图中的 Urgent Pointer 字段也会被启用。
ACK：确认比特（Acknowledge）。只有当 ACK＝1 时确认号字段才有效，代表这个封包为确认封包。当 ACK＝0 时，确认号无效。
PSH：（Push function）若为 1 时，代表要求对方立即传送缓冲区内的其他对应封包，而无需等缓冲满了才送。
RST：复位比特(Reset)，当 RST＝1 时，表明 TCP 连接中出现严重差错（如由于主机崩溃或其他原因），必须释放连接，然后再重新建立运输连接。
SYN：同步比特(Synchronous)，SYN 置为 1，就表示这是一个连接请求或连接接受报文，通常带有 SYN 标志的封包表示『主动』要连接到对方的意思。
FIN：终止比特(Final)，用来释放一个连接。当 FIN＝1 时，表明此报文段的发送端的数据已发送完毕，并要求释放运输连接。`},{header:"UDP",slug:"udp",content:`UDP（User Datagram Protocol，用户数据报协议）是 OSI（Open System Interconnection 开放式系统互联） 参考模型中一种无连接的传输层协议，提供面向事务的简单不可靠信息传送服务，其传输的单位是用户数据报。 特征： 无连接
尽最大努力交付
面向报文
没有拥塞控制
支持一对一、一对多、多对一、多对多的交互通信
首部开销小 包大小： 在局域网环境下，UDP的数据最大为1472字节。
网络上的标准MTU为576，所以在网络上的UDP数据包最好是576 - 20 - 8 =548字节内。 因为在IP层组包时会发生错误，那么包就会被丢弃，所以UDP包在应用层一定要注意大小。
UDP 报文结构
UDP 报文
UDP 首部
UDP 首部 TCP/UDP 图片来源于：https://github.com/JerryC8080/understand-tcp-udp`},{header:"TCP 与 UDP 的区别",slug:"tcp-与-udp-的区别",content:`TCP 面向连接，UDP 是无连接的；
TCP 提供可靠的服务，也就是说，通过 TCP 连接传送的数据，无差错，不丢失，不重复，且按序到达；UDP 尽最大努力交付，即不保证可靠交付
TCP 的逻辑通信信道是全双工的可靠信道；UDP 则是不可靠信道
每一条 TCP 连接只能是点到点的；UDP 支持一对一，一对多，多对一和多对多的交互通信
TCP 面向字节流（可能出现黏包问题），实际上是 TCP 把数据看成一连串无结构的字节流；UDP 是面向报文的（不会出现黏包问题）
UDP 没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如 IP 电话，实时视频会议等）
TCP 首部开销20字节；UDP 的首部开销小，只有 8 个字节
UPD 有发送包的大小限制`},{header:"TCP 黏包问题",slug:"tcp-黏包问题",content:""},{header:"原因",slug:"原因",content:"TCP 是一个基于字节流的传输服务（UDP 基于报文的），“流” 意味着 TCP 所传输的数据是没有边界的。所以可能会出现两个数据包黏在一起的情况。"},{header:"解决",slug:"解决",content:`发送定长包。如果每个消息的大小都是一样的，那么在接收对等方只要累计接收数据，直到数据等于一个定长的数值就将它作为一个消息。
包头加上包体长度。包头是定长的 4 个字节，说明了包体的长度。接收对等方先接收包头长度，依据包头长度来接收包体。
在数据包之间设置边界，如添加特殊符号 \\r\\n 标记。FTP 协议正是这么做的。但问题在于如果数据正文中也含有 \\r\\n，则会误判为消息的边界。
使用更加复杂的应用层协议。`},{header:"TCP 流量控制",slug:"tcp-流量控制",content:""},{header:"概念",slug:"概念",content:"流量控制（flow control）就是让发送方的发送速率不要太快，要让接收方来得及接收。"},{header:"方法",slug:"方法",content:"利用可变窗口进行流量控制 简单地说接收方有一个缓存池子，它只能缓存一定量的没有处理的数据，发多了让发送端等等再发。"},{header:"TCP 拥塞控制",slug:"tcp-拥塞控制",content:""},{header:"概念",slug:"概念-1",content:"拥塞控制就是防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。"},{header:"方法",slug:"方法-1",content:`慢开始( slow-start )
拥塞避免( congestion avoidance )
快重传( fast retransmit )
快恢复( fast recovery ) TCP的拥塞控制图`},{header:"TCP 稳定传输",slug:"tcp-稳定传输",content:""},{header:"TCP 传输连接管理",slug:"tcp-传输连接管理",content:"因为 TCP 三次握手建立连接、四次挥手释放连接很重要，所以附上《计算机网络（第 7 版）-谢希仁》书中对此章的详细描述：<TCP-transport-connection-management>"},{header:"TCP 三次握手建立连接",slug:"tcp-三次握手建立连接",content:`TCP三次握手建立连接
【TCP 建立连接全过程解释】 客户端发送 SYN 给服务器，说明客户端请求建立连接；
服务端收到客户端发的 SYN，并回复 SYN+ACK 给客户端（同意建立连接）；
客户端收到服务端的 SYN+ACK 后，回复 ACK 给服务端（表示客户端收到了服务端发的同意报文）；
服务端收到客户端的 ACK，连接已建立，可以数据传输。 【数值说明】
TCP三次握手建立连接`},{header:"TCP 为什么要进行三次握手？",slug:"tcp-为什么要进行三次握手",content:"【答案一】因为信道不可靠，而 TCP 想在不可靠信道上建立可靠地传输，那么三次通信是理论上的最小值。（而 UDP 则不需建立可靠传输，因此 UDP 不需要三次握手。） Google Groups . TCP 建立连接为什么是三次握手？{技术}{网络通信} 【答案二】因为双方都需要确认对方收到了自己发送的序列号，确认过程最少要进行三次通信。 知乎 . TCP 为什么是三次握手，而不是两次或四次？ 【答案三】为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。 《计算机网络（第 7 版）-谢希仁》"},{header:"TCP 四次挥手释放连接",slug:"tcp-四次挥手释放连接",content:`TCP四次挥手释放连接
【TCP 释放连接全过程解释】 客户端发送 FIN 给服务器，说明客户端不必发送数据给服务器了（请求释放从客户端到服务器的连接）；
服务器接收到客户端发的 FIN，并回复 ACK 给客户端（同意释放从客户端到服务器的连接）；
客户端收到服务端回复的 ACK，此时从客户端到服务器的连接已释放（但服务端到客户端的连接还未释放，并且客户端还可以接收数据）；
服务端继续发送之前没发完的数据给客户端；
服务端发送 FIN+ACK 给客户端，说明服务端发送完了数据（请求释放从服务端到客户端的连接，就算没收到客户端的回复，过段时间也会自动释放）；
客户端收到服务端的 FIN+ACK，并回复 ACK 给客户端（同意释放从服务端到客户端的连接）；
服务端收到客户端的 ACK 后，释放从服务端到客户端的连接。 【数值说明】
TCP三次握手建立连接`},{header:"TCP 为什么要进行四次挥手？",slug:"tcp-为什么要进行四次挥手",content:`【问题一】TCP 为什么要进行四次挥手？ / 为什么 TCP 建立连接需要三次，而释放连接则需要四次？
【答案一】因为 TCP 是全双工模式，客户端请求关闭连接后，客户端向服务端的连接关闭（一二次挥手），服务端继续传输之前没传完的数据给客户端（数据传输），服务端向客户端的连接关闭（三四次挥手）。所以 TCP 释放连接时服务器的 ACK 和 FIN 是分开发送的（中间隔着数据传输），而 TCP 建立连接时服务器的 ACK 和 SYN 是一起发送的（第二次握手），所以 TCP 建立连接需要三次，而释放连接则需要四次。
【问题二】为什么 TCP 连接时可以 ACK 和 SYN 一起发送，而释放时则 ACK 和 FIN 分开发送呢？（ACK 和 FIN 分开是指第二次和第三次挥手）
【答案二】因为客户端请求释放时，服务器可能还有数据需要传输给客户端，因此服务端要先响应客户端 FIN 请求（服务端发送 ACK），然后数据传输，传输完成后，服务端再提出 FIN 请求（服务端发送 FIN）；而连接时则没有中间的数据传输，因此连接时可以 ACK 和 SYN 一起发送。
【问题三】为什么客户端释放最后需要 TIME-WAIT 等待 2MSL 呢？
【答案三】 为了保证客户端发送的最后一个 ACK 报文能够到达服务端。若未成功到达，则服务端超时重传 FIN+ACK 报文段，客户端再重传 ACK，并重新计时。
防止已失效的连接请求报文段出现在本连接中。TIME-WAIT 持续 2MSL 可使本连接持续的时间内所产生的所有报文段都从网络中消失，这样可使下次连接中不会出现旧的连接报文段。`},{header:"TCP 有限状态机",slug:"tcp-有限状态机",content:`TCP 有限状态机图片
TCP 的有限状态机`},{header:"应用层",slug:"应用层",content:""},{header:"DNS",slug:"dns",content:"DNS（Domain Name System，域名系统）是互联网的一项服务。它作为将域名和 IP 地址相互映射的一个分布式数据库，能够使人更方便地访问互联网。DNS 使用 TCP 和 UDP 端口 53。当前，对于每一级域名长度的限制是 63 个字符，域名总长度则不能超过 253 个字符。 域名： 域名 ::= {<三级域名>.<二级域名>.<顶级域名>}，如：blog.ban-ming.com"},{header:"FTP",slug:"ftp",content:`FTP（File Transfer Protocol，文件传输协议）是用于在网络上进行文件传输的一套标准协议，使用客户/服务器模式，使用 TCP 数据报，提供交互式访问，双向传输。
TFTP（Trivial File Transfer Protocol，简单文件传输协议）一个小且易实现的文件传输协议，也使用客户-服务器方式，使用UDP数据报，只支持文件传输而不支持交互，没有列目录，不能对用户进行身份鉴定`},{header:"TELNET",slug:"telnet",content:"TELNET 协议是 TCP/IP 协议族中的一员，是 Internet 远程登陆服务的标准协议和主要方式。它为用户提供了在本地计算机上完成远程主机工作的能力。 HTTP（HyperText Transfer Protocol，超文本传输协议）是用于从 WWW（World Wide Web，万维网）服务器传输超文本到本地浏览器的传送协议。 SMTP（Simple Mail Transfer Protocol，简单邮件传输协议）是一组用于由源地址到目的地址传送邮件的规则，由它来控制信件的中转方式。SMTP 协议属于 TCP/IP 协议簇，它帮助每台计算机在发送或中转信件时找到下一个目的地。 Socket 建立网络通信连接至少要一对端口号（Socket）。Socket 本质是编程接口（API），对 TCP/IP 的封装，TCP/IP 也要提供可供程序员做网络开发所用的接口，这就是 Socket 编程接口。"},{header:"WWW",slug:"www",content:"WWW（World Wide Web，环球信息网，万维网）是一个由许多互相链接的超文本组成的系统，通过互联网访问"},{header:"URL",slug:"url",content:`URL（Uniform Resource Locator，统一资源定位符）是因特网上标准的资源的地址（Address） 标准格式： 协议类型:[//服务器地址[:端口号]][/资源层级UNIX文件路径]文件名[?查询][#片段ID] 完整格式： 协议类型:[//[访问资源需要的凭证信息@]服务器地址[:端口号]][/资源层级UNIX文件路径]文件名[?查询][#片段ID] 其中【访问凭证信息@；:端口号；?查询；#片段ID】都属于选填项
如：http://ban-ming.com/docs/basic/network/#URL`},{header:"HTTP",slug:"http",content:`HTTP（HyperText Transfer Protocol，超文本传输协议）是一种用于分布式、协作式和超媒体信息系统的应用层协议。HTTP 是万维网的数据通信的基础。
请求方法 方法
意义 OPTIONS
请求一些选项信息，允许客户端查看服务器的性能 GET
请求指定的页面信息，并返回实体主体 HEAD
类似于 get 请求，只不过返回的响应中没有具体的内容，用于获取报头 POST
向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST请求可能会导致新的资源的建立和/或已有资源的修改 PUT
从客户端向服务器传送的数据取代指定的文档的内容 DELETE
请求服务器删除指定的页面 TRACE
回显服务器收到的请求，主要用于测试或诊断 状态码（Status-Code） 1xx：表示通知信息，如请求收到了或正在进行处理 100 Continue：继续，客户端应继续其请求
101 Switching Protocols 切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，例如，切换到 HTTP 的新版本协议 2xx：表示成功，如接收或知道了 200 OK: 请求成功 3xx：表示重定向，如要完成请求还必须采取进一步的行动 301 Moved Permanently: 永久移动。请求的资源已被永久的移动到新 URL，返回信息会包括新的 URL，浏览器会自动定向到新 URL。今后任何新的请求都应使用新的 URL 代替 4xx：表示客户的差错，如请求中有错误的语法或不能完成 400 Bad Request: 客户端请求的语法错误，服务器无法理解
401 Unauthorized: 请求要求用户的身份认证
403 Forbidden: 服务器理解请求客户端的请求，但是拒绝执行此请求（权限不够）
404 Not Found: 服务器无法根据客户端的请求找到资源（网页）。通过此代码，网站设计人员可设置 “您所请求的资源无法找到” 的个性页面
408 Request Timeout: 服务器等待客户端发送的请求时间过长，超时 5xx：表示服务器的差错，如服务器失效无法完成请求 500 Internal Server Error: 服务器内部错误，无法完成请求
503 Service Unavailable: 由于超载或系统维护，服务器暂时的无法处理客户端的请求。延时的长度可包含在服务器的 Retry-After 头信息中
504 Gateway Timeout: 充当网关或代理的服务器，未及时从远端服务器获取请求 更多状态码：菜鸟教程 . HTTP状态码`},{header:"其他协议",slug:"其他协议",content:`SMTP（Simple Main Transfer Protocol，简单邮件传输协议）是在 Internet 传输 Email 的标准，是一个相对简单的基于文本的协议。在其之上指定了一条消息的一个或多个接收者（在大多数情况下被确认是存在的），然后消息文本会被传输。可以很简单地通过 Telnet 程序来测试一个 SMTP 服务器。SMTP 使用 TCP 端口 25。
DHCP（Dynamic Host Configuration Protocol，动态主机设置协议）是一个局域网的网络协议，使用 UDP 协议工作，主要有两个用途： 用于内部网络或网络服务供应商自动分配 IP 地址给用户
用于内部网络管理员作为对所有电脑作中央管理的手段 SNMP（Simple Network Management Protocol，简单网络管理协议）构成了互联网工程工作小组（IETF，Internet Engineering Task Force）定义的 Internet 协议族的一部分。该协议能够支持网络管理系统，用以监测连接到网络上的设备是否有任何引起管理上关注的情况。`},{header:"Socket编程",slug:"socket编程",content:"Linux Socket 编程（不限 Linux） Socket 客户端服务器通讯"},{header:"Socket 中的 read()、write() 函数",slug:"socket-中的-read-、write-函数",content:`ssize_t read(int fd, void *buf, size_t count);
ssize_t write(int fd, const void *buf, size_t count);`},{header:"read()",slug:"read",content:`read 函数是负责从 fd 中读取内容。
当读成功时，read 返回实际所读的字节数。
如果返回的值是 0 表示已经读到文件的结束了，小于 0 表示出现了错误。
如果错误为 EINTR 说明读是由中断引起的；如果是 ECONNREST 表示网络连接出了问题。`},{header:"write()",slug:"write",content:`write 函数将 buf 中的 nbytes 字节内容写入文件描述符 fd。
成功时返回写的字节数。失败时返回 -1，并设置 errno 变量。
在网络程序中，当我们向套接字文件描述符写时有俩种可能。
（1）write 的返回值大于 0，表示写了部分或者是全部的数据。
（2）返回的值小于 0，此时出现了错误。
如果错误为 EINTR 表示在写的时候出现了中断错误；如果为 EPIPE 表示网络连接出现了问题（对方已经关闭了连接）。`},{header:"Socket 中 TCP 的三次握手建立连接",slug:"socket-中-tcp-的三次握手建立连接",content:`我们知道 TCP 建立连接要进行 “三次握手”，即交换三个分组。大致流程如下： 客户端向服务器发送一个 SYN J
服务器向客户端响应一个 SYN K，并对 SYN J 进行确认 ACK J+1
客户端再想服务器发一个确认 ACK K+1 只有就完了三次握手，但是这个三次握手发生在 Socket 的那几个函数中呢？请看下图：
socket 中发送的 TCP 三次握手
从图中可以看出： 当客户端调用 connect 时，触发了连接请求，向服务器发送了 SYN J 包，这时 connect 进入阻塞状态；
服务器监听到连接请求，即收到 SYN J 包，调用 accept 函数接收请求向客户端发送 SYN K ，ACK J+1，这时 accept 进入阻塞状态；
客户端收到服务器的 SYN K ，ACK J+1 之后，这时 connect 返回，并对 SYN K 进行确认；
服务器收到 ACK K+1 时，accept 返回，至此三次握手完毕，连接建立。`},{header:"Socket 中 TCP 的四次握手释放连接",slug:"socket-中-tcp-的四次握手释放连接",content:`上面介绍了 socket 中 TCP 的三次握手建立过程，及其涉及的 socket 函数。现在我们介绍 socket 中的四次握手释放连接的过程，请看下图：
socket 中发送的 TCP 四次握手
图示过程如下： 某个应用进程首先调用 close 主动关闭连接，这时 TCP 发送一个 FIN M；
另一端接收到 FIN M 之后，执行被动关闭，对这个 FIN 进行确认。它的接收也作为文件结束符传递给应用进程，因为 FIN 的接收意味着应用进程在相应的连接上再也接收不到额外数据；
一段时间之后，接收到文件结束符的应用进程调用 close 关闭它的 socket。这导致它的 TCP 也发送一个 FIN N；
接收到这个 FIN 的源发送端 TCP 对它进行确认。 这样每个方向上都有一个 FIN 和 ACK。`}]},{path:"/Basic/network/SystemDesign.html",title:"System Design Course",pathLocale:"/",contents:[{header:"System Design Course",slug:"system-design-course",content:""},{header:"Table of contents",slug:"table-of-contents",content:`Getting Started What is system design? Chapter I IP
OSI Model
TCP and UDP
Domain Name System (DNS)
Load Balancing
Clustering
Caching
Content Delivery Network (CDN)
Proxy
Availability
Scalability
Storage Chapter II Databases and DBMS
SQL databases
NoSQL databases
SQL vs NoSQL databases
Database Replication
Indexes
Normalization and Denormalization
ACID and BASE consistency models
CAP theorem
PACELC Theorem
Transactions
Distributed Transactions
Sharding
Consistent Hashing
Database Federation Chapter III N-tier architecture
Message Brokers
Message Queues
Publish-Subscribe
Enterprise Service Bus (ESB)
Monoliths and Microservices
Event-Driven Architecture (EDA)
Event Sourcing
Command and Query Responsibility Segregation (CQRS)
API Gateway
REST, GraphQL, gRPC
Long polling, WebSockets, Server-Sent Events (SSE) Chapter IV Geohashing and Quadtrees
Circuit breaker
Rate Limiting
Service Discovery
SLA, SLO, SLI
Disaster recovery
Virtual Machines (VMs) and Containers
OAuth 2.0 and OpenID Connect (OIDC)
Single Sign-On (SSO)
SSL, TLS, mTLS Chapter V System Design Interviews
URL Shortener
WhatsApp
Twitter
Netflix
Uber Appendix Next Steps
References`},{header:"What is system design?",slug:"what-is-system-design",content:`Before we start this course, let's talk about what even is system design.
System design is the process of defining the architecture, interfaces, and data
for a system that satisfies specific requirements. System design meets the needs
of your business or organization through coherent and efficient systems. It requires
a systematic approach to building and engineering systems. A good system design requires
us to think about everything, from infrastructure all the way down to the data and how it's stored.`},{header:"Why is System Design so important?",slug:"why-is-system-design-so-important",content:`System design helps us define a solution that meets the business requirements. It is
one of the earliest decisions we can make when building a system. Often it is essential
to think from a high level as these decisions are very difficult to correct later. It
also makes it easier to reason about and manage architectural changes as the system evolves.`},{header:"IP",slug:"ip",content:`An IP address is a unique address that identifies a device on the internet or a local network. IP stands for "Internet Protocol", which is the set of rules governing the format of data sent via the internet or local network.
In essence, IP addresses are the identifier that allows information to be sent between devices on a network. They contain location information and make devices accessible for communication. The internet needs a way to differentiate between different computers, routers, and websites. IP addresses provide a way of doing so and form an essential part of how the internet works.`},{header:"Versions",slug:"versions",content:"Now, let's learn about the different versions of IP addresses:"},{header:"IPv4",slug:"ipv4",content:`The original Internet Protocol is IPv4 which uses a 32-bit numeric dot-decimal notation that only allows for around 4 billion IP addresses. Initially, it was more than enough but as internet adoption grew, we needed something better.
Example: 102.22.192.181`},{header:"IPv6",slug:"ipv6",content:`IPv6 is a new protocol that was introduced in 1998. Deployment commenced in the mid-2000s and since the internet users have grown exponentially, it is still ongoing.
This new protocol uses 128-bit alphanumeric hexadecimal notation. This means that IPv6 can provide about ~340e+36 IP addresses. That's more than enough to meet the growing demand for years to come.
Example: 2001:0db8:85a3:0000:0000:8a2e:0370:7334`},{header:"Types",slug:"types",content:"Let's discuss types of IP addresses:"},{header:"Public",slug:"public",content:`A public IP address is an address where one primary address is associated with your whole network. In this type of IP address, each of the connected devices has the same IP address.
Example: IP address provided to your router by the ISP.`},{header:"Private",slug:"private",content:`A private IP address is a unique IP number assigned to every device that connects to your internet network, which includes devices like computers, tablets, and smartphones, which are used in your household.
Example: IP addresses generated by your home router for your devices.`},{header:"Static",slug:"static",content:`A static IP address does not change and is one that was manually created, as opposed to having been assigned. These addresses are usually more expensive but are more reliable.
Example: They are usually used for important things like reliable geo-location services, remote access, server hosting, etc.`},{header:"Dynamic",slug:"dynamic",content:`A dynamic IP address changes from time to time and is not always the same. It has been assigned by a Dynamic Host Configuration Protocol (DHCP) server. Dynamic IP addresses are the most common type of internet protocol address. They are cheaper to deploy and allow us to reuse IP addresses within a network as needed.
Example: They are more commonly used for consumer equipment and personal use.`},{header:"OSI Model",slug:"osi-model",content:`The OSI Model is a logical and conceptual model that defines network communication used by systems open to interconnection and communication with other systems. The Open System Interconnection (OSI Model) also defines a logical network and effectively describes computer packet transfer by using various layers of protocols.
The OSI Model can be seen as a universal language for computer networking. It's based on the concept of splitting up a communication system into seven abstract layers, each one stacked upon the last.`},{header:"Why does the OSI model matter?",slug:"why-does-the-osi-model-matter",content:`The Open System Interconnection (OSI) model has defined the common terminology used in networking discussions and documentation. This allows us to take a very complex communications process apart and evaluate its components.
While this model is not directly implemented in the TCP/IP networks that are most common today, it can still help us do so much more, such as: Make troubleshooting easier and help identify threats across the entire stack.
Encourage hardware manufacturers to create networking products that can communicate with each other over the network.
Essential for developing a security-first mindset.
Separate a complex function into simpler components.`},{header:"Layers",slug:"layers",content:`The seven abstraction layers of the OSI model can be defined as follows, from top to bottom:
osi-model`},{header:"Application",slug:"application",content:"This is the only layer that directly interacts with data from the user. Software applications like web browsers and email clients rely on the application layer to initiate communication. But it should be made clear that client software applications are not part of the application layer, rather the application layer is responsible for the protocols and data manipulation that the software relies on to present meaningful data to the user. Application layer protocols include HTTP as well as SMTP."},{header:"Presentation",slug:"presentation",content:"The presentation layer is also called the Translation layer. The data from the application layer is extracted here and manipulated as per the required format to transmit over the network. The functions of the presentation layer are translation, encryption/decryption, and compression."},{header:"Session",slug:"session",content:"This is the layer responsible for opening and closing communication between the two devices. The time between when the communication is opened and closed is known as the session. The session layer ensures that the session stays open long enough to transfer all the data being exchanged, and then promptly closes the session in order to avoid wasting resources. The session layer also synchronizes data transfer with checkpoints."},{header:"Transport",slug:"transport",content:"The transport layer (also known as layer 4) is responsible for end-to-end communication between the two devices. This includes taking data from the session layer and breaking it up into chunks called segments before sending it to the Network layer (layer 3). It is also responsible for reassembling the segments on the receiving device into data the session layer can consume."},{header:"Network",slug:"network",content:"The network layer is responsible for facilitating data transfer between two different networks. The network layer breaks up segments from the transport layer into smaller units, called packets, on the sender's device, and reassembles these packets on the receiving device. The network layer also finds the best physical path for the data to reach its destination this is known as routing. If the two devices communicating are on the same network, then the network layer is unnecessary."},{header:"Data Link",slug:"data-link",content:"The data link layer is very similar to the network layer, except the data link layer facilitates data transfer between two devices on the same network. The data link layer takes packets from the network layer and breaks them into smaller pieces called frames."},{header:"Physical",slug:"physical",content:"This layer includes the physical equipment involved in the data transfer, such as the cables and switches. This is also the layer where the data gets converted into a bit stream, which is a string of 1s and 0s. The physical layer of both devices must also agree on a signal convention so that the 1s can be distinguished from the 0s on both devices."},{header:"TCP and UDP",slug:"tcp-and-udp",content:""},{header:"TCP",slug:"tcp",content:`Transmission Control Protocol (TCP) is connection-oriented, meaning once a connection has been established, data can be transmitted in both directions. TCP has built-in systems to check for errors and to guarantee data will be delivered in the order it was sent, making it the perfect protocol for transferring information like still images, data files, and web pages.
tcp
But while TCP is instinctively reliable, its feedback mechanisms also result in a larger overhead, translating to greater use of the available bandwidth on the network.`},{header:"UDP",slug:"udp",content:`User Datagram Protocol (UDP) is a simpler, connectionless internet protocol in which error-checking and recovery services are not required. With UDP, there is no overhead for opening a connection, maintaining a connection, or terminating a connection. Data is continuously sent to the recipient, whether or not they receive it.
udp
It is largely preferred for real-time communications like broadcast or multicast network transmission. We should use UDP over TCP when we need the lowest latency and late data is worse than the loss of data.`},{header:"TCP vs UDP",slug:"tcp-vs-udp",content:`TCP is a connection-oriented protocol, whereas UDP is a connectionless protocol. A key difference between TCP and UDP is speed, as TCP is comparatively slower than UDP. Overall, UDP is a much faster, simpler, and more efficient protocol, however, retransmission of lost data packets is only possible with TCP.
TCP provides ordered delivery of data from user to server (and vice versa), whereas UDP is not dedicated to end-to-end communications, nor does it check the readiness of the receiver. Feature
TCP
UDP Connection
Requires an established connection
Connectionless protocol Guaranteed delivery
Can guarantee delivery of data
Cannot guarantee delivery of data Re-transmission
Re-transmission of lost packets is possible
No re-transmission of lost packets Speed
Slower than UDP
Faster than TCP Broadcasting
Does not support broadcasting
Supports broadcasting Use cases
HTTPS, HTTP, SMTP, POP, FTP, etc
Video streaming, DNS, VoIP, etc`},{header:"Domain Name System (DNS)",slug:"domain-name-system-dns",content:`Earlier we learned about IP addresses that enable every machine to connect with other machines. But as we know humans are more comfortable with names than numbers. It's easier to remember a name like google.com than something like 122.250.192.232.
This brings us to Domain Name System (DNS) which is a hierarchical and decentralized naming system used for translating human-readable domain names to IP addresses.`},{header:"How DNS works",slug:"how-dns-works",content:`how-dns-works
DNS lookup involves the following eight steps: A client types example.com into a web browser, the query travels to the internet and is received by a DNS resolver.
The resolver then recursively queries a DNS root nameserver.
The root server responds to the resolver with the address of a Top-Level Domain (TLD).
The resolver then makes a request to the .com TLD.
The TLD server then responds with the IP address of the domain's nameserver, example.com.
Lastly, the recursive resolver sends a query to the domain's nameserver.
The IP address for example.com is then returned to the resolver from the nameserver.
The DNS resolver then responds to the web browser with the IP address of the domain requested initially. Once the IP address has been resolved, the client should be able to request content from the resolved IP address. For example, the resolved IP may return a webpage to be rendered in the browser.`},{header:"Server types",slug:"server-types",content:"Now, let's look at the four key groups of servers that make up the DNS infrastructure."},{header:"DNS Resolver",slug:"dns-resolver",content:"A DNS resolver (also known as a DNS recursive resolver) is the first stop in a DNS query. The recursive resolver acts as a middleman between a client and a DNS nameserver. After receiving a DNS query from a web client, a recursive resolver will either respond with cached data, or send a request to a root nameserver, followed by another request to a TLD nameserver, and then one last request to an authoritative nameserver. After receiving a response from the authoritative nameserver containing the requested IP address, the recursive resolver then sends a response to the client."},{header:"DNS root server",slug:"dns-root-server",content:`A root server accepts a recursive resolver's query which includes a domain name, and the root nameserver responds by directing the recursive resolver to a TLD nameserver, based on the extension of that domain (.com, .net, .org, etc.). The root nameservers are overseen by a nonprofit called the Internet Corporation for Assigned Names and Numbers (ICANN).
There are 13 DNS root nameservers known to every recursive resolver. Note that while there are 13 root nameservers, that doesn't mean that there are only 13 machines in the root nameserver system. There are 13 types of root nameservers, but there are multiple copies of each one all over the world, which use Anycast routing to provide speedy responses.`},{header:"TLD nameserver",slug:"tld-nameserver",content:`A TLD nameserver maintains information for all the domain names that share a common domain extension, such as .com, .net, or whatever comes after the last dot in a URL.
Management of TLD nameservers is handled by the Internet Assigned Numbers Authority (IANA), which is a branch of ICANN. The IANA breaks up the TLD servers into two main groups: Generic top-level domains: These are domains like .com, .org, .net, .edu, and .gov.
Country code top-level domains: These include any domains that are specific to a country or state. Examples include .uk, .us, .ru, and .jp.`},{header:"Authoritative DNS server",slug:"authoritative-dns-server",content:"The authoritative nameserver is usually the resolver's last step in the journey for an IP address. The authoritative nameserver contains information specific to the domain name it serves (e.g. google.com) and it can provide a recursive resolver with the IP address of that server found in the DNS A record, or if the domain has a CNAME record (alias) it will provide the recursive resolver with an alias domain, at which point the recursive resolver will have to perform a whole new DNS lookup to procure a record from an authoritative nameserver (often an A record containing an IP address). If it cannot find the domain, returns the NXDOMAIN message."},{header:"Query Types",slug:"query-types",content:"There are three types of queries in a DNS system:"},{header:"Recursive",slug:"recursive",content:"In a recursive query, a DNS client requires that a DNS server (typically a DNS recursive resolver) will respond to the client with either the requested resource record or an error message if the resolver can't find the record."},{header:"Iterative",slug:"iterative",content:"In an iterative query, a DNS client provides a hostname, and the DNS Resolver returns the best answer it can. If the DNS resolver has the relevant DNS records in its cache, it returns them. If not, it refers the DNS client to the Root Server or another Authoritative Name Server that is nearest to the required DNS zone. The DNS client must then repeat the query directly against the DNS server it was referred."},{header:"Non-recursive",slug:"non-recursive",content:"A non-recursive query is a query in which the DNS Resolver already knows the answer. It either immediately returns a DNS record because it already stores it in a local cache, or queries a DNS Name Server which is authoritative for the record, meaning it definitely holds the correct IP for that hostname. In both cases, there is no need for additional rounds of queries (like in recursive or iterative queries). Rather, a response is immediately returned to the client."},{header:"Record Types",slug:"record-types",content:`DNS records (aka zone files) are instructions that live in authoritative DNS servers and provide information about a domain including what IP address is associated with that domain and how to handle requests for that domain.
These records consist of a series of text files written in what is known as DNS syntax. DNS syntax is just a string of characters used as commands that tell the DNS server what to do. All DNS records also have a "TTL", which stands for time-to-live, and indicates how often a DNS server will refresh that record.
There are more record types but for now, let's look at some of the most commonly used ones: A (Address record): This is the record that holds the IP address of a domain.
AAAA (IP Version 6 Address record): The record that contains the IPv6 address for a domain (as opposed to A records, which stores the IPv4 address).
CNAME (Canonical Name record): Forwards one domain or subdomain to another domain, does NOT provide an IP address.
MX (Mail exchanger record): Directs mail to an email server.
TXT (Text Record): This record lets an admin store text notes in the record. These records are often used for email security.
NS (Name Server records): Stores the name server for a DNS entry.
SOA (Start of Authority): Stores admin information about a domain.
SRV (Service Location record): Specifies a port for specific services.
PTR (Reverse-lookup Pointer records): Provides a domain name in reverse lookups.
CERT (Certificate record): Stores public key certificates.`},{header:"Subdomains",slug:"subdomains",content:`A subdomain is an additional part of our main domain name. It is commonly used to logically separate a website into sections. We can create multiple subdomains or child domains on the main domain.
For example, blog.example.com where blog is the subdomain, example is the primary domain and .com is the top-level domain (TLD). Similar examples can be support.example.com or careers.example.com.`},{header:"DNS Zones",slug:"dns-zones",content:"A DNS zone is a distinct part of the domain namespace which is delegated to a legal entity like a person, organization, or company, who is responsible for maintaining the DNS zone. A DNS zone is also an administrative function, allowing for granular control of DNS components, such as authoritative name servers."},{header:"DNS Caching",slug:"dns-caching",content:`A DNS cache (sometimes called a DNS resolver cache) is a temporary database, maintained by a computer's operating system, that contains records of all the recent visits and attempted visits to websites and other internet domains. In other words, a DNS cache is just a memory of recent DNS lookups that our computer can quickly refer to when it's trying to figure out how to load a website.
The Domain Name System implements a time-to-live (TTL) on every DNS record. TTL specifies the number of seconds the record can be cached by a DNS client or server. When the record is stored in a cache, whatever TTL value came with it gets stored as well. The server continues to update the TTL of the record stored in the cache, counting down every second. When it hits zero, the record is deleted or purged from the cache. At that point, if a query for that record is received, the DNS server has to start the resolution process.`},{header:"Reverse DNS",slug:"reverse-dns",content:`A reverse DNS lookup is a DNS query for the domain name associated with a given IP address. This accomplishes the opposite of the more commonly used forward DNS lookup, in which the DNS system is queried to return an IP address. The process of reverse resolving an IP address uses PTR records. If the server does not have a PTR record, it cannot resolve a reverse lookup.
Reverse lookups are commonly used by email servers. Email servers check and see if an email message came from a valid server before bringing it onto their network. Many email servers will reject messages from any server that does not support reverse lookups or from a server that is highly unlikely to be legitimate.
Note: Reverse DNS lookups are not universally adopted as they are not critical to the normal function of the internet.`},{header:"Examples",slug:"examples",content:`These are some widely used managed DNS solutions: Route53
Cloudflare DNS
Google Cloud DNS
Azure DNS
NS1`},{header:"Load Balancing",slug:"load-balancing",content:`Load balancing lets us distribute incoming network traffic across multiple resources ensuring high availability and reliability by sending requests only to resources that are online. This provides the flexibility to add or subtract resources as demand dictates.
load-balancing
For additional scalability and redundancy, we can try to load balance at each layer of our system:
load-balancing-layers`},{header:"But why?",slug:"but-why",content:`Modern high-traffic websites must serve hundreds of thousands, if not millions, of concurrent requests from users or clients. To cost-effectively scale to meet these high volumes, modern computing best practice generally requires adding more servers.
A load balancer can sit in front of the servers and route client requests across all servers capable of fulfilling those requests in a manner that maximizes speed and capacity utilization. This ensures that no single server is overworked, which could degrade performance. If a single server goes down, the load balancer redirects traffic to the remaining online servers. When a new server is added to the server group, the load balancer automatically starts sending requests to it.`},{header:"Workload distribution",slug:"workload-distribution",content:`This is the core functionality provided by a load balancer and has several common variations: Host-based: Distributes requests based on the requested hostname.
Path-based: Using the entire URL to distribute requests as opposed to just the hostname.
Content-based: Inspects the message content of a request. This allows distribution based on content such as the value of a parameter.`},{header:"Layers",slug:"layers-1",content:"Generally speaking, load balancers operate at one of the two levels:"},{header:"Network layer",slug:"network-layer",content:"This is the load balancer that works at the network's transport layer, also known as layer 4. This performs routing based on networking information such as IP addresses and is not able to perform content-based routing. These are often dedicated hardware devices that can operate at high speed."},{header:"Application layer",slug:"application-layer",content:"This is the load balancer that operates at the application layer, also known as layer 7. Load balancers can read requests in their entirety and perform content-based routing. This allows the management of load based on a full understanding of traffic."},{header:"Types",slug:"types-1",content:"Let's look at different types of load balancers:"},{header:"Software",slug:"software",content:`Software load balancers usually are easier to deploy than hardware versions. They also tend to be more cost-effective and flexible, and they are used in conjunction with software development environments. The software approach gives us the flexibility of configuring the load balancer to our environment's specific needs. The boost in flexibility may come at the cost of having to do more work to set up the load balancer. Compared to hardware versions, which offer more of a closed-box approach, software balancers give us more freedom to make changes and upgrades.
Software load balancers are widely used and are available either as installable solutions that require configuration and management or as a managed cloud service.`},{header:"Hardware",slug:"hardware",content:`As the name implies, a hardware load balancer relies on physical, on-premises hardware to distribute application and network traffic. These devices can handle a large volume of traffic but often carry a hefty price tag and are fairly limited in terms of flexibility.
Hardware load balancers include proprietary firmware that requires maintenance and updates as new versions, and security patches are released.`},{header:"DNS",slug:"dns",content:`DNS load balancing is the practice of configuring a domain in the Domain Name System (DNS) such that client requests to the domain are distributed across a group of server machines.
Unfortunately, DNS load balancing has inherent problems limiting its reliability and efficiency. Most significantly, DNS does not check for server and network outages, or errors. It always returns the same set of IP addresses for a domain even if servers are down or inaccessible.`},{header:"Routing Algorithms",slug:"routing-algorithms",content:`Now, let's discuss commonly used routing algorithms: Round-robin: Requests are distributed to application servers in rotation.
Weighted Round-robin: Builds on the simple Round-robin technique to account for differing server characteristics such as compute and traffic handling capacity using weights that can be assigned via DNS records by the administrator.
Least Connections: A new request is sent to the server with the fewest current connections to clients. The relative computing capacity of each server is factored into determining which one has the least connections.
Least Response Time: Sends requests to the server selected by a formula that combines the fastest response time and fewest active connections.
Least Bandwidth: This method measures traffic in megabits per second (Mbps), sending client requests to the server with the least Mbps of traffic.
Hashing: Distributes requests based on a key we define, such as the client IP address or the request URL.`},{header:"Advantages",slug:"advantages",content:`Load balancing also plays a key role in preventing downtime, other advantages of load balancing include the following: Scalability
Redundancy
Flexibility
Efficiency`},{header:"Redundant load balancers",slug:"redundant-load-balancers",content:`As you must've already guessed, the load balancer itself can be a single point of failure. To overcome this, a second or N number of load balancers can be used in a cluster mode.
And, if there's a failure detection and the active load balancer fails, another passive load balancer can take over which will make our system more fault-tolerant.
redundant-load-balancing`},{header:"Features",slug:"features",content:`Here are some commonly desired features of load balancers: Autoscaling: Starting up and shutting down resources in response to demand conditions.
Sticky sessions: The ability to assign the same user or device to the same resource in order to maintain the session state on the resource.
Healthchecks: The ability to determine if a resource is down or performing poorly in order to remove the resource from the load balancing pool.
Persistence connections: Allowing a server to open a persistent connection with a client such as a WebSocket.
Encryption: Handling encrypted connections such as TLS and SSL.
Certificates: Presenting certificates to a client and authentication of client certificates.
Compression: Compression of responses.
Caching: An application-layer load balancer may offer the ability to cache responses.
Logging: Logging of request and response metadata can serve as an important audit trail or source for analytics data.
Request tracing: Assigning each request a unique id for the purposes of logging, monitoring, and troubleshooting.
Redirects: The ability to redirect an incoming request based on factors such as the requested path.
Fixed response: Returning a static response for a request such as an error message.`},{header:"Examples",slug:"examples-1",content:`Following are some of the load balancing solutions commonly used in the industry: Amazon Elastic Load Balancing
Azure Load Balancing
GCP Load Balancing
DigitalOcean Load Balancer
Nginx
HAProxy`},{header:"Clustering",slug:"clustering",content:`At a high level, a computer cluster is a group of two or more computers, or nodes, that run in parallel to achieve a common goal. This allows workloads consisting of a high number of individual, parallelizable tasks to be distributed among the nodes in the cluster. As a result, these tasks can leverage the combined memory and processing power of each computer to increase overall performance.
To build a computer cluster, the individual nodes should be connected to a network to enable internode communication. The software can then be used to join the nodes together and form a cluster. It may have a shared storage device and/or local storage on each node.
cluster
Typically, at least one node is designated as the leader node and acts as the entry point to the cluster. The leader node may be responsible for delegating incoming work to the other nodes and, if necessary, aggregating the results and returning a response to the user.
Ideally, a cluster functions as if it were a single system. A user accessing the cluster should not need to know whether the system is a cluster or an individual machine. Furthermore, a cluster should be designed to minimize latency and prevent bottlenecks in node-to-node communication.`},{header:"Types",slug:"types-2",content:`Computer clusters can generally be categorized into three types: Highly available or fail-over
Load balancing
High-performance computing`},{header:"Configurations",slug:"configurations",content:"The two most commonly used high availability (HA) clustering configurations are active-active and active-passive."},{header:"Active-Active",slug:"active-active",content:`active-active
An active-active cluster is typically made up of at least two nodes, both actively running the same kind of service simultaneously. The main purpose of an active-active cluster is to achieve load balancing. A load balancer distributes workloads across all nodes to prevent any single node from getting overloaded. Because there are more nodes available to serve, there will also be an improvement in throughput and response times.`},{header:"Active-Passive",slug:"active-passive",content:`active-passive
Like the active-active cluster configuration, an active-passive cluster also consists of at least two nodes. However, as the name active-passive implies, not all nodes are going to be active. For example, in the case of two nodes, if the first node is already active, then the second node must be passive or on standby.`},{header:"Advantages",slug:"advantages-1",content:`Four key advantages of cluster computing are as follows: High availability
Scalability
Performance
Cost-effective`},{header:"Load balancing vs Clustering",slug:"load-balancing-vs-clustering",content:`Load balancing shares some common traits with clustering, but they are different processes. Clustering provides redundancy and boosts capacity and availability. Servers in a cluster are aware of each other and work together toward a common purpose. But with load balancing, servers are not aware of each other. Instead, they react to the requests they receive from the load balancer.
We can employ load balancing in conjunction with clustering, but it also is applicable in cases involving independent servers that share a common purpose such as to run a website, business application, web service, or some other IT resource.`},{header:"Challenges",slug:"challenges",content:`The most obvious challenge clustering presents is the increased complexity of installation and maintenance. An operating system, the application, and its dependencies must each be installed and updated on every node.
This becomes even more complicated if the nodes in the cluster are not homogeneous. Resource utilization for each node must also be closely monitored, and logs should be aggregated to ensure that the software is behaving correctly.
Additionally, storage becomes more difficult to manage, a shared storage device must prevent nodes from overwriting one another and distributed data stores have to be kept in sync.`},{header:"Examples",slug:"examples-2",content:`Clustering is commonly used in the industry, and often many technologies offer some sort of clustering mode. For example: Containers (e.g. Kubernetes, Amazon ECS)
Databases (e.g. Cassandra, MongoDB)
Cache (e.g. Redis)`},{header:"Caching",slug:"caching",content:`"There are only two hard things in Computer Science: cache invalidation and naming things." - Phil Karlton
caching
A cache's primary purpose is to increase data retrieval performance by reducing the need to access the underlying slower storage layer. Trading off capacity for speed, a cache typically stores a subset of data transiently, in contrast to databases whose data is usually complete and durable.
Caches take advantage of the locality of reference principle "recently requested data is likely to be requested again".`},{header:"Caching and Memory",slug:"caching-and-memory",content:`Like a computer's memory, a cache is a compact, fast-performing memory that stores data in a hierarchy of levels, starting at level one, and progressing from there sequentially. They are labeled as L1, L2, L3, and so on. A cache also gets written if requested, such as when there has been an update and new content needs to be saved to the cache, replacing the older content that was saved.
No matter whether the cache is read or written, it's done one block at a time. Each block also has a tag that includes the location where the data was stored in the cache. When data is requested from the cache, a search occurs through the tags to find the specific content that's needed in level one (L1) of the memory. If the correct data isn't found, more searches are conducted in L2.
If the data isn't found there, searches are continued in L3, then L4, and so on until it has been found, then, it's read and loaded. If the data isn't found in the cache at all, then it's written into it for quick retrieval the next time.`},{header:"Cache hit and Cache miss",slug:"cache-hit-and-cache-miss",content:""},{header:"Cache hit",slug:"cache-hit",content:`A cache hit describes the situation where content is successfully served from the cache. The tags are searched in the memory rapidly, and when the data is found and read, it's considered a cache hit.
Cold, Warm, and Hot Caches
A cache hit can also be described as cold, warm, or hot. In each of these, the speed at which the data is read is described.
A hot cache is an instance where data was read from the memory at the fastest possible rate. This happens when the data is retrieved from L1.
A cold cache is the slowest possible rate for data to be read, though, it's still successful so it's still considered a cache hit. The data is just found lower in the memory hierarchy such as in L3, or lower.
A warm cache is used to describe data that's found in L2 or L3. It's not as fast as a hot cache, but it's still faster than a cold cache. Generally, calling a cache warm is used to express that it's slower and closer to a cold cache than a hot one.`},{header:"Cache miss",slug:"cache-miss",content:"A cache miss refers to the instance when the memory is searched, and the data isn't found. When this happens, the content is transferred and written into the cache."},{header:"Cache Invalidation",slug:"cache-invalidation",content:"Cache invalidation is a process where the computer system declares the cache entries as invalid and removes or replaces them. If the data is modified, it should be invalidated in the cache, if not, this can cause inconsistent application behavior. There are three kinds of caching systems:"},{header:"Write-through cache",slug:"write-through-cache",content:`write-through-cache
Data is written into the cache and the corresponding database simultaneously.
Pro: Fast retrieval, complete data consistency between cache and storage.
Con: Higher latency for write operations.`},{header:"Write-around cache",slug:"write-around-cache",content:`write-around-cache
Where write directly goes to the database or permanent storage, bypassing the cache.
Pro: This may reduce latency.
Con: It increases cache misses because the cache system has to read the information from the database in case of a cache miss. As a result, this can lead to higher read latency in the case of applications that write and re-read the information quickly. Read happen from slower back-end storage and experiences higher latency.`},{header:"Write-back cache",slug:"write-back-cache",content:`write-back-cache
Where the write is only done to the caching layer and the write is confirmed as soon as the write to the cache completes. The cache then asynchronously syncs this write to the database.
Pro: This would lead to reduced latency and high throughput for write-intensive applications.
Con: There is a risk of data loss in case the caching layer crashes. We can improve this by having more than one replica acknowledging the write in the cache.`},{header:"Eviction policies",slug:"eviction-policies",content:`Following are some of the most common cache eviction policies: First In First Out (FIFO): The cache evicts the first block accessed first without any regard to how often or how many times it was accessed before.
Last In First Out (LIFO): The cache evicts the block accessed most recently first without any regard to how often or how many times it was accessed before.
Least Recently Used (LRU): Discards the least recently used items first.
Most Recently Used (MRU): Discards, in contrast to LRU, the most recently used items first.
Least Frequently Used (LFU): Counts how often an item is needed. Those that are used least often are discarded first.
Random Replacement (RR): Randomly selects a candidate item and discards it to make space when necessary.`},{header:"Distributed Cache",slug:"distributed-cache",content:`distributed-cache
A distributed cache is a system that pools together the random-access memory (RAM) of multiple networked computers into a single in-memory data store used as a data cache to provide fast access to data. While most caches are traditionally in one physical server or hardware component, a distributed cache can grow beyond the memory limits of a single computer by linking together multiple computers.`},{header:"Global Cache",slug:"global-cache",content:`global-cache
As the name suggests, we will have a single shared cache that all the application nodes will use. When the requested data is not found in the global cache, it's the responsibility of the cache to find out the missing piece of data from the underlying data store.`},{header:"Use cases",slug:"use-cases",content:`Caching can have many real-world use cases such as: Database Caching
Content Delivery Network (CDN)
Domain Name System (DNS) Caching
API Caching When not to use caching?
Let's also look at some scenarios where we should not use cache: Caching isn't helpful when it takes just as long to access the cache as it does to access the primary data store.
Caching doesn't work as well when requests have low repetition (higher randomness), because caching performance comes from repeated memory access patterns.
Caching isn't helpful when the data changes frequently, as the cached version gets out of sync, and the primary data store must be accessed every time. It's important to note that a cache should not be used as permanent data storage. They are almost always implemented in volatile memory because it is faster, and thus should be considered transient.`},{header:"Advantages",slug:"advantages-2",content:`Below are some advantages of caching: Improves performance
Reduce latency
Reduce load on the database
Reduce network cost
Increase Read Throughput`},{header:"Examples",slug:"examples-3",content:`Here are some commonly used technologies for caching: Redis
Memcached
Amazon Elasticache
Aerospike`},{header:"Content Delivery Network (CDN)",slug:"content-delivery-network-cdn",content:`A content delivery network (CDN) is a geographically distributed group of servers that work together to provide fast delivery of internet content. Generally, static files such as HTML/CSS/JS, photos, and videos are served from CDN.
cdn-map`},{header:"Why use a CDN?",slug:"why-use-a-cdn",content:"Content Delivery Network (CDN) increases content availability and redundancy while reducing bandwidth costs and improving security. Serving content from CDNs can significantly improve performance as users receive content from data centers close to them and our servers do not have to serve requests that the CDN fulfills."},{header:"How does a CDN work?",slug:"how-does-a-cdn-work",content:`cdn
In a CDN, the origin server contains the original versions of the content while the edge servers are numerous and distributed across various locations around the world.
To minimize the distance between the visitors and the website's server, a CDN stores a cached version of its content in multiple geographical locations known as edge locations. Each edge location contains several caching servers responsible for content delivery to visitors within its proximity.
Once the static assets are cached on all the CDN servers for a particular location, all subsequent website visitor requests for static assets will be delivered from these edge servers instead of the origin, thus reducing the origin load and improving scalability.
For example, when someone in the UK requests our website which might be hosted in the USA, they will be served from the closest edge location such as the London edge location. This is much quicker than having the visitor make a complete request to the origin server which will increase the latency.`},{header:"Types",slug:"types-3",content:"CDNs are generally divided into two types:"},{header:"Push CDNs",slug:"push-cdns",content:`Push CDNs receive new content whenever changes occur on the server. We take full responsibility for providing content, uploading directly to the CDN, and rewriting URLs to point to the CDN. We can configure when content expires and when it is updated. Content is uploaded only when it is new or changed, minimizing traffic, but maximizing storage.
Sites with a small amount of traffic or sites with content that isn't often updated work well with push CDNs. Content is placed on the CDNs once, instead of being re-pulled at regular intervals.`},{header:"Pull CDNs",slug:"pull-cdns",content:`In a Pull CDN situation, the cache is updated based on request. When the client sends a request that requires static assets to be fetched from the CDN if the CDN doesn't have it, then it will fetch the newly updated assets from the origin server and populate its cache with this new asset, and then send this new cached asset to the user.
Contrary to the Push CDN, this requires less maintenance because cache updates on CDN nodes are performed based on requests from the client to the origin server. Sites with heavy traffic work well with pull CDNs, as traffic is spread out more evenly with only recently-requested content remaining on the CDN.`},{header:"Disadvantages",slug:"disadvantages",content:`As we all know good things come with extra costs, so let's discuss some disadvantages of CDNs: Extra charges: It can be expensive to use a CDN, especially for high-traffic services.
Restrictions: Some organizations and countries have blocked the domains or IP addresses of popular CDNs.
Location: If most of our audience is located in a country where the CDN has no servers, the data on our website may have to travel further than without using any CDN.`},{header:"Examples",slug:"examples-4",content:`Here are some widely used CDNs: Amazon CloudFront
Google Cloud CDN
Cloudflare CDN
Fastly`},{header:"Proxy",slug:"proxy",content:"A proxy server is an intermediary piece of hardware/software sitting between the client and the backend server. It receives requests from clients and relays them to the origin servers. Typically, proxies are used to filter requests, log requests, or sometimes transform requests (by adding/removing headers, encrypting/decrypting, or compression)."},{header:"Types",slug:"types-4",content:"There are two types of proxies:"},{header:"Forward Proxy",slug:"forward-proxy",content:`A forward proxy, often called a proxy, proxy server, or web proxy is a server that sits in front of a group of client machines. When those computers make requests to sites and services on the internet, the proxy server intercepts those requests and then communicates with web servers on behalf of those clients, like a middleman.
forward-proxy
Advantages
Here are some advantages of a forward proxy: Block access to certain content
Allows access to geo-restricted content
Provides anonymity
Avoid other browsing restrictions Although proxies provide the benefits of anonymity, they can still track our personal information. Setup and maintenance of a proxy server can be costly and requires configurations.`},{header:"Reverse Proxy",slug:"reverse-proxy",content:`A reverse proxy is a server that sits in front of one or more web servers, intercepting requests from clients. When clients send requests to the origin server of a website, those requests are intercepted by the reverse proxy server.
The difference between a forward and reverse proxy is subtle but important. A simplified way to sum it up would be to say that a forward proxy sits in front of a client and ensures that no origin server ever communicates directly with that specific client. On the other hand, a reverse proxy sits in front of an origin server and ensures that no client ever communicates directly with that origin server.
reverse-proxy
Introducing reverse proxy results in increased complexity. A single reverse proxy is a single point of failure, configuring multiple reverse proxies (i.e. a failover) further increases complexity.
Advantages
Here are some advantages of using a reverse proxy: Improved security
Caching
SSL encryption
Load balancing
Scalability and flexibility`},{header:"Load balancer vs Reverse Proxy",slug:"load-balancer-vs-reverse-proxy",content:"Wait, isn't reverse proxy similar to a load balancer? Well, no as a load balancer is useful when we have multiple servers. Often, load balancers route traffic to a set of servers serving the same function, while reverse proxies can be useful even with just one web server or application server. A reverse proxy can also act as a load balancer but not the other way around."},{header:"Examples",slug:"examples-5",content:`Below are some commonly used proxy technologies: Nginx
HAProxy
Traefik
Envoy`},{header:"Availability",slug:"availability",content:"Availability is the time a system remains operational to perform its required function in a specific period. It is a simple measure of the percentage of time that a system, service, or machine remains operational under normal conditions."},{header:"The Nine's of availability",slug:"the-nine-s-of-availability",content:`Availability is often quantified by uptime (or downtime) as a percentage of time the service is available. It is generally measured in the number of 9s.
$$
Availability = \\frac{Uptime}{(Uptime + Downtime)}
$$
If availability is 99.00% available, it is said to have "2 nines" of availability, and if it is 99.9%, it is called "3 nines", and so on. Availability (Percent)
Downtime (Year)
Downtime (Month)
Downtime (Week) 90% (one nine)
36.53 days
72 hours
16.8 hours 99% (two nines)
3.65 days
7.20 hours
1.68 hours 99.9% (three nines)
8.77 hours
43.8 minutes
10.1 minutes 99.99% (four nines)
52.6 minutes
4.32 minutes
1.01 minutes 99.999% (five nines)
5.25 minutes
25.9 seconds
6.05 seconds 99.9999% (six nines)
31.56 seconds
2.59 seconds
604.8 milliseconds 99.99999% (seven nines)
3.15 seconds
263 milliseconds
60.5 milliseconds 99.999999% (eight nines)
315.6 milliseconds
26.3 milliseconds
6 milliseconds 99.9999999% (nine nines)
31.6 milliseconds
2.6 milliseconds
0.6 milliseconds`},{header:"Availability in Sequence vs Parallel",slug:"availability-in-sequence-vs-parallel",content:"If a service consists of multiple components prone to failure, the service's overall availability depends on whether the components are in sequence or in parallel."},{header:"Sequence",slug:"sequence",content:`Overall availability decreases when two components are in sequence.
$$
Availability \\space (Total) = Availability \\space (Foo) * Availability \\space (Bar)
$$
For example, if both Foo and Bar each had 99.9% availability, their total availability in sequence would be 99.8%.`},{header:"Parallel",slug:"parallel",content:`Overall availability increases when two components are in parallel.
$$
Availability \\space (Total) = 1 - (1 - Availability \\space (Foo)) * (1 - Availability \\space (Bar))
$$
For example, if both Foo and Bar each had 99.9% availability, their total availability in parallel would be 99.9999%.`},{header:"Availability vs Reliability",slug:"availability-vs-reliability",content:"If a system is reliable, it is available. However, if it is available, it is not necessarily reliable. In other words, high reliability contributes to high availability, but it is possible to achieve high availability even with an unreliable system."},{header:"High availability vs Fault Tolerance",slug:"high-availability-vs-fault-tolerance",content:`Both high availability and fault tolerance apply to methods for providing high uptime levels. However, they accomplish the objective differently.
A fault-tolerant system has no service interruption but a significantly higher cost, while a highly available system has minimal service interruption. Fault-tolerance requires full hardware redundancy as if the main system fails, with no loss in uptime, another system should take over.`},{header:"Scalability",slug:"scalability",content:`Scalability is the measure of how well a system responds to changes by adding or removing resources to meet demands.
scalability
Let's discuss different types of scaling:`},{header:"Vertical scaling",slug:"vertical-scaling",content:"Vertical scaling (also known as scaling up) expands a system's scalability by adding more power to an existing machine. In other words, vertical scaling refers to improving an application's capability via increasing hardware capacity."},{header:"Advantages",slug:"advantages-3",content:`Simple to implement
Easier to manage
Data consistent`},{header:"Disadvantages",slug:"disadvantages-1",content:`Risk of high downtime
Harder to upgrade
Can be a single point of failure`},{header:"Horizontal scaling",slug:"horizontal-scaling",content:"Horizontal scaling (also known as scaling out) expands a system's scale by adding more machines. It improves the performance of the server by adding more instances to the existing pool of servers, allowing the load to be distributed more evenly."},{header:"Advantages",slug:"advantages-4",content:`Increased redundancy
Better fault tolerance
Flexible and efficient
Easier to upgrade`},{header:"Disadvantages",slug:"disadvantages-2",content:`Increased complexity
Data inconsistency
Increased load on downstream services`},{header:"Storage",slug:"storage",content:"Storage is a mechanism that enables a system to retain data, either temporarily or permanently. This topic is mostly skipped over in the context of system design, however, it is important to have a basic understanding of some common types of storage techniques that can help us fine-tune our storage components. Let's discuss some important storage concepts:"},{header:"RAID",slug:"raid",content:`RAID (Redundant Array of Independent Disks) is a way of storing the same data on multiple hard disks or solid-state drives (SSDs) to protect data in the case of a drive failure.
There are different RAID levels, however, and not all have the goal of providing redundancy. Let's discuss some commonly used RAID levels: RAID 0: Also known as striping, data is split evenly across all the drives in the array.
RAID 1: Also known as mirroring, at least two drives contains the exact copy of a set of data. If a drive fails, others will still work.
RAID 5: Striping with parity. Requires the use of at least 3 drives, striping the data across multiple drives like RAID 0, but also has a parity distributed across the drives.
RAID 6: Striping with double parity. RAID 6 is like RAID 5, but the parity data are written to two drives.
RAID 10: Combines striping plus mirroring from RAID 0 and RAID 1. It provides security by mirroring all data on secondary drives while using striping across each set of drives to speed up data transfers.`},{header:"Comparison",slug:"comparison",content:`Let's compare all the features of different RAID levels: Features
RAID 0
RAID 1
RAID 5
RAID 6
RAID 10 Description
Striping
Mirroring
Striping with Parity
Striping with double parity
Striping and Mirroring Minimum Disks
2
2
3
4
4 Read Performance
High
High
High
High
High Write Performance
High
Medium
High
High
Medium Cost
Low
High
Low
Low
High Fault Tolerance
None
Single-drive failure
Single-drive failure
Two-drive failure
Up to one disk failure in each sub-array Capacity Utilization
100%
50%
67%-94%
50%-80%
50%`},{header:"Volumes",slug:"volumes",content:"Volume is a fixed amount of storage on a disk or tape. The term volume is often used as a synonym for the storage itself, but it is possible for a single disk to contain more than one volume or a volume to span more than one disk."},{header:"File storage",slug:"file-storage",content:`File storage is a solution to store data as files and present it to its final users as a hierarchical directories structure. The main advantage is to provide a user-friendly solution to store and retrieve files. To locate a file in file storage, the complete path of the file is required. It is economical and easily structured and is usually found on hard drives, which means that they appear exactly the same for the user and on the hard drive.
Example: Amazon EFS, Azure files, Google Cloud Filestore, etc.`},{header:"Block storage",slug:"block-storage",content:`Block storage divides data into blocks (chunks) and stores them as separate pieces. Each block of data is given a unique identifier, which allows a storage system to place the smaller pieces of data wherever it is most convenient.
Block storage also decouples data from user environments, allowing that data to be spread across multiple environments. This creates multiple paths to the data and allows the user to retrieve it quickly. When a user or application requests data from a block storage system, the underlying storage system reassembles the data blocks and presents the data to the user or application
Example: Amazon EBS.`},{header:"Object Storage",slug:"object-storage",content:`Object storage, which is also known as object-based storage, breaks data files up into pieces called objects. It then stores those objects in a single repository, which can be spread out across multiple networked systems.
Example: Amazon S3, Azure Blob Storage, Google Cloud Storage, etc.`},{header:"NAS",slug:"nas",content:"A NAS (Network Attached Storage) is a storage device connected to a network that allows storage and retrieval of data from a central location for authorized network users. NAS devices are flexible, meaning that as we need additional storage, we can add to what we have. It's faster, less expensive, and provides all the benefits of a public cloud on-site, giving us complete control."},{header:"HDFS",slug:"hdfs",content:`The Hadoop Distributed File System (HDFS) is a distributed file system designed to run on commodity hardware. HDFS is highly fault-tolerant and is designed to be deployed on low-cost hardware. HDFS provides high throughput access to application data and is suitable for applications that have large data sets. It has many similarities with existing distributed file systems.
HDFS is designed to reliably store very large files across machines in a large cluster. It stores each file as a sequence of blocks, all blocks in a file except the last block are the same size. The blocks of a file are replicated for fault tolerance.`},{header:"Databases and DBMS",slug:"databases-and-dbms",content:""},{header:"What is a Database?",slug:"what-is-a-database",content:"A database is an organized collection of structured information, or data, typically stored electronically in a computer system. A database is usually controlled by a Database Management System (DBMS). Together, the data and the DBMS, along with the applications that are associated with them, are referred to as a database system, often shortened to just database."},{header:"What is DBMS?",slug:"what-is-dbms",content:"A database typically requires a comprehensive database software program known as a Database Management System (DBMS). A DBMS serves as an interface between the database and its end-users or programs, allowing users to retrieve, update, and manage how the information is organized and optimized. A DBMS also facilitates oversight and control of databases, enabling a variety of administrative operations such as performance monitoring, tuning, and backup and recovery."},{header:"Components",slug:"components",content:"Here are some common components found across different databases:"},{header:"Schema",slug:"schema",content:"The role of a schema is to define the shape of a data structure, and specify what kinds of data can go where. Schemas can be strictly enforced across the entire database, loosely enforced on part of the database, or they might not exist at all."},{header:"Table",slug:"table",content:"Each table contains various columns just like in a spreadsheet. A table can have as meager as two columns and upwards of a hundred or more columns, depending upon the kind of information being put in the table."},{header:"Column",slug:"column",content:"A column contains a set of data values of a particular type, one value for each row of the database. A column may contain text values, numbers, enums, timestamps, etc."},{header:"Row",slug:"row",content:"Data in a table is recorded in rows. There can be thousands or millions of rows in a table having any particular information."},{header:"Types",slug:"types-5",content:`database-types
Below are different types of databases: SQL
NoSQL Document
Key-value
Graph
Timeseries
Wide column
Multi-model SQL and NoSQL databases are broad topics and will be discussed separately in SQL databases and NoSQL databases. Learn how they compare to each other in SQL vs NoSQL databases.`},{header:"Challenges",slug:"challenges-1",content:`Some common challenges faced while running databases at scale: Absorbing significant increases in data volume: The explosion of data coming in from sensors, connected machines, and dozens of other sources.
Ensuring data security: Data breaches are happening everywhere these days, it's more important than ever to ensure that data is secure but also easily accessible to users.
Keeping up with demand: Companies need real-time access to their data to support timely decision-making and to take advantage of new opportunities.
Managing and maintaining the database and infrastructure: As databases become more complex and data volumes grow, companies are faced with the expense of hiring additional talent to manage their databases.
Removing limits on scalability: A business needs to grow if it's going to survive, and its data management must grow along with it. But it's very difficult to predict how much capacity the company will need, particularly with on-premises databases.
Ensuring data residency, data sovereignty, or latency requirements: Some organizations have use cases that are better suited to run on-premises. In those cases, engineered systems that are pre-configured and pre-optimized for running the database are ideal.`},{header:"SQL databases",slug:"sql-databases",content:`A SQL (or relational) database is a collection of data items with pre-defined relationships between them. These items are organized as a set of tables with columns and rows. Tables are used to hold information about the objects to be represented in the database. Each column in a table holds a certain kind of data and a field stores the actual value of an attribute. The rows in the table represent a collection of related values of one object or entity.
Each row in a table could be marked with a unique identifier called a primary key, and rows among multiple tables can be made related using foreign keys. This data can be accessed in many different ways without re-organizing the database tables themselves. SQL databases usually follow the ACID consistency model.`},{header:"Materialized views",slug:"materialized-views",content:`A materialized view is a pre-computed data set derived from a query specification and stored for later use. Because the data is pre-computed, querying a materialized view is faster than executing a query against the base table of the view. This performance difference can be significant when a query is run frequently or is sufficiently complex.
It also enables data subsetting and improves the performance of complex queries that run on large data sets which reduces network loads. There are other uses of materialized views, but they are mostly used for performance and replication.`},{header:"N+1 query problem",slug:"n-1-query-problem",content:`The N+1 query problem happens when the data access layer executes N additional SQL statements to fetch the same data that could have been retrieved when executing the primary SQL query. The larger the value of N, the more queries will be executed, the larger the performance impact.
This is commonly seen in GraphQL and ORM (Object-Relational Mapping) tools and can be addressed by optimizing the SQL query or using a dataloader that batches consecutive requests and makes a single data request under the hood.`},{header:"Advantages",slug:"advantages-5",content:`Let's look at some advantages of using relational databases: Simple and accurate
Accessibility
Data consistency
Flexibility`},{header:"Disadvantages",slug:"disadvantages-3",content:`Below are the disadvantages of relational databases: Expensive to maintain
Difficult schema evolution
Performance hits (join, denormalization, etc.)
Difficult to scale due to poor horizontal scalability`},{header:"Examples",slug:"examples-6",content:`Here are some commonly used relational databases: PostgreSQL
MySQL
MariaDB
Amazon Aurora`},{header:"NoSQL databases",slug:"nosql-databases",content:`NoSQL is a broad category that includes any database that doesn't use SQL as its primary data access language. These types of databases are also sometimes referred to as non-relational databases. Unlike in relational databases, data in a NoSQL database doesn't have to conform to a pre-defined schema. NoSQL databases follow BASE consistency model.
Below are different types of NoSQL databases:`},{header:"Document",slug:"document",content:`A document database (also known as a document-oriented database or a document store) is a database that stores information in documents. They are general-purpose databases that serve a variety of use cases for both transactional and analytical applications.
Advantages Intuitive and flexible
Easy horizontal scaling
Schemaless Disadvantages Schemaless
Non-relational Examples MongoDB
Amazon DocumentDB
CouchDB`},{header:"Key-value",slug:"key-value",content:`One of the simplest types of NoSQL databases, key-value databases save data as a group of key-value pairs made up of two data items each. They're also sometimes referred to as a key-value store.
Advantages Simple and performant
Highly scalable for high volumes of traffic
Session management
Optimized lookups Disadvantages Basic CRUD
Values can't be filtered
Lacks indexing and scanning capabilities
Not optimized for complex queries Examples Redis
Memcached
Amazon DynamoDB
Aerospike`},{header:"Graph",slug:"graph",content:`A graph database is a NoSQL database that uses graph structures for semantic queries with nodes, edges, and properties to represent and store data instead of tables or documents.
The graph relates the data items in the store to a collection of nodes and edges, the edges representing the relationships between the nodes. The relationships allow data in the store to be linked together directly and, in many cases, retrieved with one operation.
Advantages Query speed
Agile and flexible
Explicit data representation Disadvantages Complex
No standardized query language Use cases Fraud detection
Recommendation engines
Social networks
Network mapping Examples Neo4j
ArangoDB
Amazon Neptune
JanusGraph`},{header:"Time series",slug:"time-series",content:`A time-series database is a database optimized for time-stamped, or time series, data.
Advantages Fast insertion and retrieval
Efficient data storage Use cases IoT data
Metrics analysis
Application monitoring
Understand financial trends Examples InfluxDB
Apache Druid`},{header:"Wide column",slug:"wide-column",content:`Wide column databases, also known as wide column stores, are schema-agnostic. Data is stored in column families, rather than in rows and columns.
Advantages Highly scalable, can handle petabytes of data
Ideal for real-time big data applications Disadvantages Expensive
Increased write time Use cases Business analytics
Attribute-based data storage Examples BigTable
Apache Cassandra
ScyllaDB`},{header:"Multi-model",slug:"multi-model",content:`Multi-model databases combine different database models (i.e. relational, graph, key-value, document, etc.) into a single, integrated backend. This means they can accommodate various data types, indexes, queries, and store data in more than one model.
Advantages Flexibility
Suitable for complex projects
Data consistent Disadvantages Complex
Less mature Examples ArangoDB
Azure Cosmos DB
Couchbase`},{header:"SQL vs NoSQL databases",slug:"sql-vs-nosql-databases",content:"In the world of databases, there are two main types of solutions, SQL (relational) and NoSQL (non-relational) databases. Both of them differ in the way they were built, the kind of information they store, and how they store it. Relational databases are structured and have predefined schemas while non-relational databases are unstructured, distributed, and have a dynamic schema."},{header:"High-level differences",slug:"high-level-differences",content:"Here are some high-level differences between SQL and NoSQL:"},{header:"Storage",slug:"storage-1",content:`SQL stores data in tables, where each row represents an entity and each column represents a data point about that entity.
NoSQL databases have different data storage models such as key-value, graph, document, etc.`},{header:"Schema",slug:"schema-1",content:`In SQL, each record conforms to a fixed schema, meaning the columns must be decided and chosen before data entry and each row must have data for each column. The schema can be altered later, but it involves modifying the database using migrations.
Whereas in NoSQL, schemas are dynamic. Fields can be added on the fly, and each record (or equivalent) doesn't have to contain data for each field.`},{header:"Querying",slug:"querying",content:`SQL databases use SQL (structured query language) for defining and manipulating the data, which is very powerful.
In a NoSQL database, queries are focused on a collection of documents. Different databases have different syntax for querying.`},{header:"Scalability",slug:"scalability-1",content:`In most common situations, SQL databases are vertically scalable, which can get very expensive. It is possible to scale a relational database across multiple servers, but this is a challenging and time-consuming process.
On the other hand, NoSQL databases are horizontally scalable, meaning we can add more servers easily to our NoSQL database infrastructure to handle large traffic. Any cheap commodity hardware or cloud instances can host NoSQL databases, thus making it a lot more cost-effective than vertical scaling. A lot of NoSQL technologies also distribute data across servers automatically.`},{header:"Reliability",slug:"reliability",content:`The vast majority of relational databases are ACID compliant. So, when it comes to data reliability and a safe guarantee of performing transactions, SQL databases are still the better bet.
Most of the NoSQL solutions sacrifice ACID compliance for performance and scalability.`},{header:"Reasons",slug:"reasons",content:`As always we should always pick the technology that fits the requirements better. So, let's look at some reasons for picking SQL or NoSQL based database:
For SQL Structured data with strict schema
Relational data
Need for complex joins
Transactions
Lookups by index are very fast For NoSQL Dynamic or flexible schema
Non-relational data
No need for complex joins
Very data-intensive workload
Very high throughput for IOPS`},{header:"Database Replication",slug:"database-replication",content:"Replication is a process that involves sharing information to ensure consistency between redundant resources such as multiple databases, to improve reliability, fault-tolerance, or accessibility."},{header:"Master-Slave Replication",slug:"master-slave-replication",content:`The master serves reads and writes, replicating writes to one or more slaves, which serve only reads. Slaves can also replicate additional slaves in a tree-like fashion. If the master goes offline, the system can continue to operate in read-only mode until a slave is promoted to a master or a new master is provisioned.
master-slave-replication`},{header:"Advantages",slug:"advantages-6",content:`Backups of the entire database of relatively no impact on the master.
Applications can read from the slave(s) without impacting the master.
Slaves can be taken offline and synced back to the master without any downtime.`},{header:"Disadvantages",slug:"disadvantages-4",content:`Replication adds more hardware and additional complexity.
Downtime and possibly loss of data when a master fails.
All writes also have to be made to the master in a master-slave architecture.
The more read slaves, the more we have to replicate, which will increase replication lag.`},{header:"Master-Master Replication",slug:"master-master-replication",content:`Both masters serve reads/writes and coordinate with each other. If either master goes down, the system can continue to operate with both reads and writes.
master-master-replication`},{header:"Advantages",slug:"advantages-7",content:`Applications can read from both masters.
Distributes write load across both master nodes.
Simple, automatic, and quick failover.`},{header:"Disadvantages",slug:"disadvantages-5",content:`Not as simple as master-slave to configure and deploy.
Either loosely consistent or have increased write latency due to synchronization.
Conflict resolution comes into play as more write nodes are added and as latency increases.`},{header:"Synchronous vs Asynchronous replication",slug:"synchronous-vs-asynchronous-replication",content:`The primary difference between synchronous and asynchronous replication is how the data is written to the replica. In synchronous replication, data is written to primary storage and the replica simultaneously. As such, the primary copy and the replica should always remain synchronized.
In contrast, asynchronous replication copies the data to the replica after the data is already written to the primary storage. Although the replication process may occur in near-real-time, it is more common for replication to occur on a scheduled basis and it is more cost-effective.`},{header:"Indexes",slug:"indexes",content:`Indexes are well known when it comes to databases, they are used to improve the speed of data retrieval operations on the data store. An index makes the trade-offs of increased storage overhead, and slower writes (since we not only have to write the data but also have to update the index) for the benefit of faster reads. Indexes are used to quickly locate data without having to examine every row in a database table. Indexes can be created using one or more columns of a database table, providing the basis for both rapid random lookups and efficient access to ordered records.
indexes
An index is a data structure that can be perceived as a table of contents that points us to the location where actual data lives. So when we create an index on a column of a table, we store that column and a pointer to the whole row in the index. Indexes are also used to create different views of the same data. For large data sets, this is an excellent way to specify different filters or sorting schemes without resorting to creating multiple additional copies of the data.
One quality that database indexes can have is that they can be dense or sparse. Each of these index qualities comes with its own trade-offs. Let's look at how each index type would work:`},{header:"Dense Index",slug:"dense-index",content:`In a dense index, an index record is created for every row of the table. Records can be located directly as each record of the index holds the search key value and the pointer to the actual record.
dense-index
Dense indexes require more maintenance than sparse indexes at write-time. Since every row must have an entry, the database must maintain the index on inserts, updates, and deletes. Having an entry for every row also means that dense indexes will require more memory. The benefit of a dense index is that values can be quickly found with just a binary search. Dense indexes also do not impose any ordering requirements on the data.`},{header:"Sparse Index",slug:"sparse-index",content:`In a sparse index, records are created only for some of the records.
sparse-index
Sparse indexes require less maintenance than dense indexes at write-time since they only contain a subset of the values. This lighter maintenance burden means that inserts, updates, and deletes will be faster. Having fewer entries also means that the index will use less memory. Finding data is slower since a scan across the page typically follows the binary search. Sparse indexes are also optional when working with ordered data.`},{header:"Normalization and Denormalization",slug:"normalization-and-denormalization",content:""},{header:"Terms",slug:"terms",content:"Before we go any further, let's look at some commonly used terms in normalization and denormalization."},{header:"Keys",slug:"keys",content:`Primary key: Column or group of columns that can be used to uniquely identify every row of the table.
Composite key: A primary key made up of multiple columns.
Super key: Set of all keys that can uniquely identify all the rows present in a table.
Candidate key: Attributes that identify rows uniquely in a table.
Foreign key: It is a reference to a primary key of another table.
Alternate key: Keys that are not primary keys are known as alternate keys.
Surrogate key: A system-generated value that uniquely identifies each entry in a table when no other column was able to hold properties of a primary key.`},{header:"Dependencies",slug:"dependencies",content:`Partial dependency: Occurs when the primary key determines some other attributes.
Functional dependency: It is a relationship that exists between two attributes, typically between the primary key and non-key attribute within a table.
Transitive functional dependency: Occurs when some non-key attribute determines some other attribute.`},{header:"Anomalies",slug:"anomalies",content:`Database anomaly happens when there is a flaw in the database due to incorrect planning or storing everything in a flat database. This is generally addressed by the process of normalization.
There are three types of database anomalies:
Insertion anomaly: Occurs when we are not able to insert certain attributes in the database without the presence of other attributes.
Update anomaly: Occurs in case of data redundancy and partial update. In other words, a correct update of the database needs other actions such as addition, deletion, or both.
Deletion anomaly: Occurs where deletion of some data requires deletion of other data.
Example
Let's consider the following table which is not normalized: ID
Name
Role
Team 1
Peter
Software Engineer
A 2
Brian
DevOps Engineer
B 3
Hailey
Product Manager
C 4
Hailey
Product Manager
C 5
Steve
Frontend Engineer
D Let's imagine, we hired a new person "John" but they might not be assigned a team immediately. This will cause an insertion anomaly as the team attribute is not yet present.
Next, let's say Hailey from Team C got promoted, to reflect that change in the database, we will need to update 2 rows to maintain consistency which can cause an update anomaly.
Finally, we would like to remove Team B but to do that we will also need to remove additional information such as name and role, this is an example of a deletion anomaly.`},{header:"Normalization",slug:"normalization",content:"Normalization is the process of organizing data in a database. This includes creating tables and establishing relationships between those tables according to rules designed both to protect the data and to make the database more flexible by eliminating redundancy and inconsistent dependency."},{header:"Why do we need normalization?",slug:"why-do-we-need-normalization",content:"The goal of normalization is to eliminate redundant data and ensure data is consistent. A fully normalized database allows its structure to be extended to accommodate new types of data without changing the existing structure too much. As a result, applications interacting with the database are minimally affected."},{header:"Normal forms",slug:"normal-forms",content:`Normal forms are a series of guidelines to ensure that the database is normalized. Let's discuss some essential normal forms:
1NF
For a table to be in the first normal form (1NF), it should follow the following rules: Repeating groups are not permitted.
Identify each set of related data with a primary key.
Set of related data should have a separate table.
Mixing data types in the same column is not permitted. 2NF
For a table to be in the second normal form (2NF), it should follow the following rules: Satisfies the first normal form (1NF).
Should not have any partial dependency. 3NF
For a table to be in the third normal form (3NF), it should follow the following rules: Satisfies the second normal form (2NF).
Transitive functional dependencies are not permitted. BCNF
Boyce-Codd normal form (or BCNF) is a slightly stronger version of the third normal form (3NF) used to address certain types of anomalies not dealt with by 3NF as originally defined. Sometimes it is also known as the 3.5 normal form (3.5NF).
For a table to be in the Boyce-Codd normal form (BCNF), it should follow the following rules: Satisfied the third normal form (3NF).
For every functional dependency X → Y, X should be the super key. There are more normal forms such as 4NF, 5NF, and 6NF but we won't discuss them here. Check out this amazing video that goes into detail.
In a relational database, a relation is often described as "normalized" if it meets the third normal form. Most 3NF relations are free of insertion, update, and deletion anomalies.
As with many formal rules and specifications, real-world scenarios do not always allow for perfect compliance. If you decide to violate one of the first three rules of normalization, make sure that your application anticipates any problems that could occur, such as redundant data and inconsistent dependencies.`},{header:"Advantages",slug:"advantages-8",content:`Here are some advantages of normalization: Reduces data redundancy.
Better data design.
Increases data consistency.
Enforces referential integrity.`},{header:"Disadvantages",slug:"disadvantages-6",content:`Let's look at some disadvantages of normalization: Data design is complex.
Slower performance.
Maintenance overhead.
Require more joins.`},{header:"Denormalization",slug:"denormalization",content:`Denormalization is a database optimization technique in which we add redundant data to one or more tables. This can help us avoid costly joins in a relational database. It attempts to improve read performance at the expense of some write performance. Redundant copies of the data are written in multiple tables to avoid expensive joins.
Once data becomes distributed with techniques such as federation and sharding, managing joins across the network further increases complexity. Denormalization might circumvent the need for such complex joins.
Note: Denormalization does not mean reversing normalization.`},{header:"Advantages",slug:"advantages-9",content:`Let's look at some advantages of denormalization: Retrieving data is faster.
Writing queries is easier.
Reduction in number of tables.
Convenient to manage.`},{header:"Disadvantages",slug:"disadvantages-7",content:`Below are some disadvantages of denormalization: Expensive inserts and updates.
Increases complexity of database design.
Increases data redundancy.
More chances of data inconsistency.`},{header:"ACID and BASE consistency models",slug:"acid-and-base-consistency-models",content:"Let's discuss the ACID and BASE consistency models."},{header:"ACID",slug:"acid",content:`The term ACID stands for Atomicity, Consistency, Isolation, and Durability. ACID properties are used for maintaining data integrity during transaction processing.
In order to maintain consistency before and after a transaction relational databases follow ACID properties. Let us understand these terms:`},{header:"Atomic",slug:"atomic",content:"All operations in a transaction succeed or every operation is rolled back."},{header:"Consistent",slug:"consistent",content:"On the completion of a transaction, the database is structurally sound."},{header:"Isolated",slug:"isolated",content:"Transactions do not contend with one another. Contentious access to data is moderated by the database so that transactions appear to run sequentially."},{header:"Durable",slug:"durable",content:"Once the transaction has been completed and the writes and updates have been written to the disk, it will remain in the system even if a system failure occurs."},{header:"BASE",slug:"base",content:`With the increasing amount of data and high availability requirements, the approach to database design has also changed dramatically. To increase the ability to scale and at the same time be highly available, we move the logic from the database to separate servers. In this way, the database becomes more independent and focused on the actual process of storing data.
In the NoSQL database world, ACID transactions are less common as some databases have loosened the requirements for immediate consistency, data freshness, and accuracy in order to gain other benefits, like scale and resilience.
BASE properties are much looser than ACID guarantees, but there isn't a direct one-for-one mapping between the two consistency models. Let us understand these terms:`},{header:"Basic Availability",slug:"basic-availability",content:"The database appears to work most of the time."},{header:"Soft-state",slug:"soft-state",content:"Stores don't have to be write-consistent, nor do different replicas have to be mutually consistent all the time."},{header:"Eventual consistency",slug:"eventual-consistency",content:"The data might not be consistent immediately but eventually, it becomes consistent. Reads in the system are still possible even though they may not give the correct response due to inconsistency."},{header:"ACID vs BASE Trade-offs",slug:"acid-vs-base-trade-offs",content:`There's no right answer to whether our application needs an ACID or a BASE consistency model. Both the models have been designed to satisfy different requirements. While choosing a database we need to keep the properties of both the models and the requirements of our application in mind.
Given BASE's loose consistency, developers need to be more knowledgeable and rigorous about consistent data if they choose a BASE store for their application. It's essential to be familiar with the BASE behavior of the chosen database and work within those constraints.
On the other hand, planning around BASE limitations can sometimes be a major disadvantage when compared to the simplicity of ACID transactions. A fully ACID database is the perfect fit for use cases where data reliability and consistency are essential.`},{header:"CAP Theorem",slug:"cap-theorem",content:`CAP theorem states that a distributed system can deliver only two of the three desired characteristics Consistency, Availability, and Partition tolerance (CAP).
cap-theorem
Let's take a detailed look at the three distributed system characteristics to which the CAP theorem refers.`},{header:"Consistency",slug:"consistency",content:'Consistency means that all clients see the same data at the same time, no matter which node they connect to. For this to happen, whenever data is written to one node, it must be instantly forwarded or replicated across all the nodes in the system before the write is deemed "successful".'},{header:"Availability",slug:"availability-1",content:"Availability means that any client making a request for data gets a response, even if one or more nodes are down."},{header:"Partition tolerance",slug:"partition-tolerance",content:"Partition tolerance means the system continues to work despite message loss or partial failure. A system that is partition-tolerant can sustain any amount of network failure that doesn't result in a failure of the entire network. Data is sufficiently replicated across combinations of nodes and networks to keep the system up through intermittent outages."},{header:"Consistency-Availability Tradeoff",slug:"consistency-availability-tradeoff",content:"We live in a physical world and can't guarantee the stability of a network, so distributed databases must choose Partition Tolerance (P). This implies a tradeoff between Consistency (C) and Availability (A)."},{header:"CA database",slug:"ca-database",content:`A CA database delivers consistency and availability across all nodes. It can't do this if there is a partition between any two nodes in the system, and therefore can't deliver fault tolerance.
Example: PostgreSQL, MariaDB.`},{header:"CP database",slug:"cp-database",content:`A CP database delivers consistency and partition tolerance at the expense of availability. When a partition occurs between any two nodes, the system has to shut down the non-consistent node until the partition is resolved.
Example: MongoDB, Apache HBase.`},{header:"AP database",slug:"ap-database",content:`An AP database delivers availability and partition tolerance at the expense of consistency. When a partition occurs, all nodes remain available but those at the wrong end of a partition might return an older version of data than others. When the partition is resolved, the AP databases typically re-syncs the nodes to repair all inconsistencies in the system.
Example: Apache Cassandra, CouchDB.`},{header:"PACELC Theorem",slug:"pacelc-theorem",content:`The PACELC theorem is an extension of the CAP theorem. The CAP theorem states that in the case of network partitioning (P) in a distributed system, one has to choose between Availability (A) and Consistency (C).
PACELC extends the CAP theorem by introducing latency (L) as an additional attribute of a distributed system. The theorem states that else (E), even when the system is running normally in the absence of partitions, one has to choose between latency (L) and consistency (C).
The PACELC theorem was first described by Daniel J. Abadi.
pacelc-theorem
PACELC theorem was developed to address a key limitation of the CAP theorem as it makes no provision for performance or latency.
For example, according to the CAP theorem, a database can be considered Available if a query returns a response after 30 days. Obviously, such latency would be unacceptable for any real-world application.`},{header:"Transactions",slug:"transactions",content:`A transaction is a series of database operations that are considered to be a "single unit of work". The operations in a transaction either all succeed, or they all fail. In this way, the notion of a transaction supports data integrity when part of a system fails. Not all databases choose to support ACID transactions, usually because they are prioritizing other optimizations that are hard or theoretically impossible to implement together.
Usually, relational databases support ACID transactions, and non-relational databases don't (there are exceptions).`},{header:"States",slug:"states",content:`A transaction in a database can be in one of the following states:
transaction-states`},{header:"Active",slug:"active",content:"In this state, the transaction is being executed. This is the initial state of every transaction."},{header:"Partially Committed",slug:"partially-committed",content:"When a transaction executes its final operation, it is said to be in a partially committed state."},{header:"Committed",slug:"committed",content:"If a transaction executes all its operations successfully, it is said to be committed. All its effects are now permanently established on the database system."},{header:"Failed",slug:"failed",content:"The transaction is said to be in a failed state if any of the checks made by the database recovery system fails. A failed transaction can no longer proceed further."},{header:"Aborted",slug:"aborted",content:`If any of the checks fail and the transaction has reached a failed state, then the recovery manager rolls back all its write operations on the database to bring the database back to its original state where it was prior to the execution of the transaction. Transactions in this state are aborted.
The database recovery module can select one of the two operations after a transaction aborts: Restart the transaction
Kill the transaction`},{header:"Terminated",slug:"terminated",content:"If there isn't any roll-back or the transaction comes from the committed state, then the system is consistent and ready for a new transaction and the old transaction is terminated."},{header:"Distributed Transactions",slug:"distributed-transactions",content:"A distributed transaction is a set of operations on data that is performed across two or more databases. It is typically coordinated across separate nodes connected by a network, but may also span multiple databases on a single server."},{header:"Why do we need distributed transactions?",slug:"why-do-we-need-distributed-transactions",content:`Unlike an ACID transaction on a single database, a distributed transaction involves altering data on multiple databases. Consequently, distributed transaction processing is more complicated, because the database must coordinate the committing or rollback of the changes in a transaction as a self-contained unit.
In other words, all the nodes must commit, or all must abort and the entire transaction rolls back. This is why we need distributed transactions.
Now, let's look at some popular solutions for distributed transactions:`},{header:"Two-Phase commit",slug:"two-phase-commit",content:`two-phase-commit
The two-phase commit (2PC) protocol is a distributed algorithm that coordinates all the processes that participate in a distributed transaction on whether to commit or abort (roll back) the transaction.
This protocol achieves its goal even in many cases of temporary system failure and is thus widely used. However, it is not resilient to all possible failure configurations, and in rare cases, manual intervention is needed to remedy an outcome.
This protocol requires a coordinator node, which basically coordinates and oversees the transaction across different nodes. The coordinator tries to establish the consensus among a set of processes in two phases, hence the name.`},{header:"Phases",slug:"phases",content:`Two-phase commit consists of the following phases:
Prepare phase
The prepare phase involves the coordinator node collecting consensus from each of the participant nodes. The transaction will be aborted unless each of the nodes responds that they're prepared.
Commit phase
If all participants respond to the coordinator that they are prepared, then the coordinator asks all the nodes to commit the transaction. If a failure occurs, the transaction will be rolled back.`},{header:"Problems",slug:"problems",content:`Following problems may arise in the two-phase commit protocol: What if one of the nodes crashes?
What if the coordinator itself crashes?
It is a blocking protocol.`},{header:"Three-phase commit",slug:"three-phase-commit",content:`three-phase-commit
Three-phase commit (3PC) is an extension of the two-phase commit where the commit phase is split into two phases. This helps with the blocking problem that occurs in the two-phase commit protocol.`},{header:"Phases",slug:"phases-1",content:`Three-phase commit consists of the following phases:
Prepare phase
This phase is the same as the two-phase commit.
Pre-commit phase
Coordinator issues the pre-commit message and all the participating nodes must acknowledge it. If a participant fails to receive this message in time, then the transaction is aborted.
Commit phase
This step is also similar to the two-phase commit protocol.`},{header:"Why is the Pre-commit phase helpful?",slug:"why-is-the-pre-commit-phase-helpful",content:`The pre-commit phase accomplishes the following: If the participant nodes are found in this phase, that means that every participant has completed the first phase. The completion of prepare phase is guaranteed.
Every phase can now time out and avoid indefinite waits.`},{header:"Sagas",slug:"sagas",content:`sagas
A saga is a sequence of local transactions. Each local transaction updates the database and publishes a message or event to trigger the next local transaction in the saga. If a local transaction fails because it violates a business rule then the saga executes a series of compensating transactions that undo the changes that were made by the preceding local transactions.`},{header:"Coordination",slug:"coordination",content:`There are two common implementation approaches: Choreography: Each local transaction publishes domain events that trigger local transactions in other services.
Orchestration: An orchestrator tells the participants what local transactions to execute.`},{header:"Problems",slug:"problems-1",content:`The Saga pattern is particularly hard to debug.
There's a risk of cyclic dependency between saga participants.
Lack of participant data isolation imposes durability challenges.
Testing is difficult because all services must be running to simulate a transaction.`},{header:"Sharding",slug:"sharding",content:"Before we discuss sharding, let's talk about data partitioning:"},{header:"Data Partitioning",slug:"data-partitioning",content:"Data partitioning is a technique to break up a database into many smaller parts. It is the process of splitting up a database or a table across multiple machines to improve the manageability, performance, and availability of a database."},{header:"Methods",slug:"methods",content:`There are many different ways one could use to decide how to break up an application database into multiple smaller DBs. Below are three of the most popular methods used by various large-scale applications:
Horizontal Partitioning (or Sharding)
In this strategy, we split the table data horizontally based on the range of values defined by the partition key. It is also referred to as database sharding.
Vertical Partitioning
In vertical partitioning, we partition the data vertically based on columns. We divide tables into relatively smaller tables with few elements, and each part is present in a separate partition.
In this tutorial, we will specifically focus on sharding.`},{header:"What is sharding?",slug:"what-is-sharding",content:`Sharding is a database architecture pattern related to horizontal partitioning, which is the practice of separating one table's rows into multiple different tables, known as partitions or shards. Each partition has the same schema and columns, but also a subset of the shared data. Likewise, the data held in each is unique and independent of the data held in other partitions.
sharding
The justification for data sharding is that, after a certain point, it is cheaper and more feasible to scale horizontally by adding more machines than to scale it vertically by adding powerful servers. Sharding can be implemented at both application or the database level.`},{header:"Partitioning criteria",slug:"partitioning-criteria",content:"There are a large number of criteria available for data partitioning. Some most commonly used criteria are:"},{header:"Hash-Based",slug:"hash-based",content:`This strategy divides the rows into different partitions based on a hashing algorithm rather than grouping database rows based on continuous indexes.
The disadvantage of this method is that dynamically adding/removing database servers becomes expensive.`},{header:"List-Based",slug:"list-based",content:"In list-based partitioning, each partition is defined and selected based on the list of values on a column rather than a set of contiguous ranges of values."},{header:"Range Based",slug:"range-based",content:`Range partitioning maps data to various partitions based on ranges of values of the partitioning key. In other words, we partition the table in such a way that each partition contains rows within a given range defined by the partition key.
Ranges should be contiguous but not overlapping, where each range specifies a non-inclusive lower and upper bound for a partition. Any partitioning key values equal to or higher than the upper bound of the range are added to the next partition.`},{header:"Composite",slug:"composite",content:"As the name suggests, composite partitioning partitions the data based on two or more partitioning techniques. Here we first partition the data using one technique, and then each partition is further subdivided into sub-partitions using the same or some other method."},{header:"Advantages",slug:"advantages-10",content:`But why do we need sharding? Here are some advantages: Availability: Provides logical independence to the partitioned database, ensuring the high availability of our application. Here individual partitions can be managed independently.
Scalability: Proves to increase scalability by distributing the data across multiple partitions.
Security: Helps improve the system's security by storing sensitive and non-sensitive data in different partitions. This could provide better manageability and security to sensitive data.
Query Performance: Improves the performance of the system. Instead of querying the whole database, now the system has to query only a smaller partition.
Data Manageability: Divides tables and indexes into smaller and more manageable units.`},{header:"Disadvantages",slug:"disadvantages-8",content:`Complexity: Sharding increases the complexity of the system in general.
Joins across shards: Once a database is partitioned and spread across multiple machines it is often not feasible to perform joins that span multiple database shards. Such joins will not be performance efficient since data has to be retrieved from multiple servers.
Rebalancing: If the data distribution is not uniform or there is a lot of load on a single shard, in such cases we have to rebalance our shards so that the requests are as equally distributed among the shards as possible.`},{header:"When to use sharding?",slug:"when-to-use-sharding",content:`Here are some reasons where sharding might be the right choice: Leveraging existing hardware instead of high-end machines.
Maintain data in distinct geographic regions.
Quickly scale by adding more shards.
Better performance as each machine is under less load.
When more concurrent connections are required.`},{header:"Consistent Hashing",slug:"consistent-hashing",content:"Let's first understand the problem we're trying to solve."},{header:"Why do we need this?",slug:"why-do-we-need-this",content:`In traditional hashing-based distribution methods, we use a hash function to hash our partition keys (i.e. request ID or IP). Then if we use the modulo against the total number of nodes (server or databases). This will give us the node where we want to route our request.
simple-hashing
$$
\\begin{align*}
& Hash(key_1) \\to H_1 \\bmod N = Node_0 \\
& Hash(key_2) \\to H_2 \\bmod N = Node_1 \\
& Hash(key_3) \\to H_3 \\bmod N = Node_2 \\
& ... \\
& Hash(key_n) \\to H_n \\bmod N = Node_{n-1}
\\end{align*}
$$
Where,
key: Request ID or IP.
H: Hash function result.
N: Total number of nodes.
Node: The node where the request will be routed.
The problem with this is if we add or remove a node, it will cause N to change, meaning our mapping strategy will break as the same requests will now map to a different server. As a consequence, the majority of requests will need to be redistributed which is very inefficient.
We want to uniformly distribute requests among different nodes such that we should be able to add or remove nodes with minimal effort. Hence, we need a distribution scheme that does not depend directly on the number of nodes (or servers), so that, when adding or removing nodes, the number of keys that need to be relocated is minimized.
Consistent hashing solves this horizontal scalability problem by ensuring that every time we scale up or down, we do not have to re-arrange all the keys or touch all the servers.
Now that we understand the problem, let's discuss consistent hashing in detail.`},{header:"How does it work",slug:"how-does-it-work",content:`Consistent Hashing is a distributed hashing scheme that operates independently of the number of nodes in a distributed hash table by assigning them a position on an abstract circle, or hash ring. This allows servers and objects to scale without affecting the overall system.
consistent-hashing
Using consistent hashing, only K/N data would require re-distributing.
$$
R = K/N
$$
Where,
R: Data that would require re-distribution.
K: Number of partition keys.
N: Number of nodes.
The output of the hash function is a range let's say 0...m-1 which we can represent on our hash ring. We hash the requests and distribute them on the ring depending on what the output was. Similarly, we also hash the node and distribute them on the same ring as well.
$$
\\begin{align*}
& Hash(key_1) = P_1 \\
& Hash(key_2) = P_2 \\
& Hash(key_3) = P_3 \\
& ... \\
& Hash(key_n) = P_{m-1}
\\end{align*}
$$
Where,
key: Request/Node ID or IP.
P: Position on the hash ring.
m: Total range of the hash ring.
Now, when the request comes in we can simply route it to the closest node in a clockwise (can be counterclockwise as well) manner. This means that if a new node is added or removed, we can use the nearest node and only a fraction of the requests need to be re-routed.
In theory, consistent hashing should distribute the load evenly however it doesn't happen in practice. Usually, the load distribution is uneven and one server may end up handling the majority of the request becoming a hotspot, essentially a bottleneck for the system. We can fix this by adding extra nodes but that can be expensive.
Let's see how we can address these issues.`},{header:"Virtual Nodes",slug:"virtual-nodes",content:`In order to ensure a more evenly distributed load, we can introduce the idea of a virtual node, sometimes also referred to as a VNode.
Instead of assigning a single position to a node, the hash range is divided into multiple smaller ranges, and each physical node is assigned several of these smaller ranges. Each of these subranges is considered a VNode. Hence, virtual nodes are basically existing physical nodes mapped multiple times across the hash ring to minimize changes to a node's assigned range.
virtual-nodes
For this, we can use k number of hash functions.
$$
\\begin{align*}
& Hash_1(key_1) = P_1 \\
& Hash_2(key_2) = P_2 \\
& Hash_3(key_3) = P_3 \\
& . . . \\
& Hash_k(key_n) = P_{m-1}
\\end{align*}
$$
Where,
key: Request/Node ID or IP.
k: Number of hash functions.
P: Position on the hash ring.
m: Total range of the hash ring.
As VNodes help spread the load more evenly across the physical nodes on the cluster by diving the hash ranges into smaller subranges, this speeds up the re-balancing process after adding or removing nodes. This also helps us reduce the probability of hotspots.`},{header:"Data replication",slug:"data-replication",content:`To ensure high availability and durability, consistent hashing replicates each data item on multiple N nodes in the system where the value N is equivalent to the replication factor.
The replication factor is the number of nodes that will receive the copy of the same data. In eventually consistent systems, this is done asynchronously.`},{header:"Advantages",slug:"advantages-11",content:`Let's look at some advantages of consistent hashing: Makes rapid scaling up and down more predictable.
Facilitates partitioning and replication across nodes.
Enables scalability and availability.
Reduces hotspots.`},{header:"Disadvantages",slug:"disadvantages-9",content:`Below are some disadvantages of consistent hashing: Increases complexity.
Cascading failures.
Load distribution can still be uneven.
Key management can be expensive when nodes transiently fail.`},{header:"Examples",slug:"examples-7",content:`Let's look at some examples where consistent hashing is used: Data partitioning in Apache Cassandra.
Load distribution across multiple storage hosts in Amazon DynamoDB.`},{header:"Database Federation",slug:"database-federation",content:`Federation (or functional partitioning) splits up databases by function. The federation architecture makes several distinct physical databases appear as one logical database to end-users.
All of the components in a federation are tied together by one or more federal schemas that express the commonality of data throughout the federation. These federated schemas are used to specify the information that can be shared by the federation components and to provide a common basis for communication among them.
database-federation
Federation also provides a cohesive, unified view of data derived from multiple sources. The data sources for federated systems can include databases and various other forms of structured and unstructured data.`},{header:"Characteristics",slug:"characteristics",content:`Let's look at some key characteristics of a federated database: Transparency: Federated database masks user differences and implementations of underlying data sources. Therefore, the users do not need to be aware of where the data is stored.
Heterogeneity: Data sources can differ in many ways. A federated database system can handle different hardware, network protocols, data models, etc.
Extensibility: New sources may be needed to meet the changing needs of the business. A good federated database system needs to make it easy to add new sources.
Autonomy: A Federated database does not change existing data sources, interfaces should remain the same.
Data integration: A federated database can integrate data from different protocols, database management systems, etc.`},{header:"Advantages",slug:"advantages-12",content:`Here are some advantages of federated databases: Flexible data sharing.
Autonomy among the database components.
Access heterogeneous data in a unified way.
No tight coupling of applications with legacy databases.`},{header:"Disadvantages",slug:"disadvantages-10",content:`Below are some disadvantages of federated databases: Adds more hardware and additional complexity.
Joining data from two databases is complex.
Dependence on autonomous data sources.
Query performance and scalability.`},{header:"N-tier architecture",slug:"n-tier-architecture",content:`N-tier architecture divides an application into logical layers and physical tiers. Layers are a way to separate responsibilities and manage dependencies. Each layer has a specific responsibility. A higher layer can use services in a lower layer, but not the other way around.
n-tier-architecture
Tiers are physically separated, running on separate machines. A tier can call to another tier directly, or use asynchronous messaging. Although each layer might be hosted in its own tier, that's not required. Several layers might be hosted on the same tier. Physically separating the tiers improves scalability and resiliency and adds latency from the additional network communication.
An N-tier architecture can be of two types: In a closed layer architecture, a layer can only call the next layer immediately down.
In an open layer architecture, a layer can call any of the layers below it. A closed-layer architecture limits the dependencies between layers. However, it might create unnecessary network traffic, if one layer simply passes requests along to the next layer.`},{header:"Types of N-Tier architectures",slug:"types-of-n-tier-architectures",content:"Let's look at some examples of N-Tier architecture:"},{header:"3-Tier architecture",slug:"_3-tier-architecture",content:`3-Tier is widely used and consists of the following different layers: Presentation layer: Handles user interactions with the application.
Business Logic layer: Accepts the data from the application layer, validates it as per business logic and passes it to the data layer.
Data Access layer: Receives the data from the business layer and performs the necessary operation on the database.`},{header:"2-Tier architecture",slug:"_2-tier-architecture",content:"In this architecture, the presentation layer runs on the client and communicates with a data store. There is no business logic layer or immediate layer between client and server."},{header:"Single Tier or 1-Tier architecture",slug:"single-tier-or-1-tier-architecture",content:"It is the simplest one as it is equivalent to running the application on a personal computer. All of the required components for an application to run are on a single application or server."},{header:"Advantages",slug:"advantages-13",content:`Here are some advantages of using N-tier architecture: Can improve availability.
Better security as layers can behave like a firewall.
Separate tiers allow us to scale them as needed.
Improve maintenance as different people can manage different tiers.`},{header:"Disadvantages",slug:"disadvantages-11",content:`Below are some disadvantages of N-tier architecture: Increased complexity of the system as a whole.
Increased network latency as the number of tiers increases.
Expensive as every tier will have its own hardware cost.
Difficult to manage network security.`},{header:"Message Brokers",slug:"message-brokers",content:`A message broker is a software that enables applications, systems, and services to communicate with each other and exchange information. The message broker does this by translating messages between formal messaging protocols. This allows interdependent services to "talk" with one another directly, even if they were written in different languages or implemented on different platforms.
message-broker
Message brokers can validate, store, route, and deliver messages to the appropriate destinations. They serve as intermediaries between other applications, allowing senders to issue messages without knowing where the receivers are, whether or not they are active, or how many of them there are. This facilitates the decoupling of processes and services within systems.`},{header:"Models",slug:"models",content:`Message brokers offer two basic message distribution patterns or messaging styles: Point-to-Point messaging: This is the distribution pattern utilized in message queues with a one-to-one relationship between the message's sender and receiver.
Publish-subscribe messaging: In this message distribution pattern, often referred to as "pub/sub", the producer of each message publishes it to a topic, and multiple message consumers subscribe to topics from which they want to receive messages. We will discuss these messaging patterns in detail in the later tutorials.`},{header:"Message brokers vs Event streaming",slug:"message-brokers-vs-event-streaming",content:`Message brokers can support two or more messaging patterns, including message queues and pub/sub, while event streaming platforms only offer pub/sub-style distribution patterns. Designed for use with high volumes of messages, event streaming platforms are readily scalable. They're capable of ordering streams of records into categories called topics and storing them for a predetermined amount of time. Unlike message brokers, however, event streaming platforms cannot guarantee message delivery or track which consumers have received the messages.
Event streaming platforms offer more scalability than message brokers but fewer features that ensure fault tolerance like message resending, as well as more limited message routing and queueing capabilities.`},{header:"Message brokers vs Enterprise Service Bus (ESB)",slug:"message-brokers-vs-enterprise-service-bus-esb",content:`Enterprise Service Bus (ESB) infrastructure is complex and can be challenging to integrate and expensive to maintain. It's difficult to troubleshoot them when problems occur in production environments, they're not easy to scale, and updating is tedious.
Whereas message brokers are a "lightweight" alternative to ESBs that provide similar functionality, a mechanism for inter-service communication, at a lower cost. They're well-suited for use in the microservices architectures that have become more prevalent as ESBs have fallen out of favor.`},{header:"Examples",slug:"examples-8",content:`Here are some commonly used message brokers: NATS
Apache Kafka
RabbitMQ
ActiveMQ`},{header:"Message Queues",slug:"message-queues",content:`A message queue is a form of service-to-service communication that facilitates asynchronous communication. It asynchronously receives messages from producers and sends them to consumers.
Queues are used to effectively manage requests in large-scale distributed systems. In small systems with minimal processing loads and small databases, writes can be predictably fast. However, in more complex and large systems writes can take an almost non-deterministic amount of time.
message-queue`},{header:"Working",slug:"working",content:`Messages are stored in the queue until they are processed and deleted. Each message is processed only once by a single consumer. Here's how it works: A producer publishes a job to the queue, then notifies the user of the job status.
A consumer picks up the job from the queue, processes it, then signals that the job is complete.`},{header:"Advantages",slug:"advantages-14",content:`Let's discuss some advantages of using a message queue: Scalability: Message queues make it possible to scale precisely where we need to. When workloads peak, multiple instances of our application can add all requests to the queue without the risk of collision.
Decoupling: Message queues remove dependencies between components and significantly simplify the implementation of decoupled applications.
Performance: Message queues enable asynchronous communication, which means that the endpoints that are producing and consuming messages interact with the queue, not each other. Producers can add requests to the queue without waiting for them to be processed.
Reliability: Queues make our data persistent, and reduce the errors that happen when different parts of our system go offline.`},{header:"Features",slug:"features-1",content:"Now, let's discuss some desired features of message queues:"},{header:"Push or Pull Delivery",slug:"push-or-pull-delivery",content:"Most message queues provide both push and pull options for retrieving messages. Pull means continuously querying the queue for new messages. Push means that a consumer is notified when a message is available. We can also use long-polling to allow pulls to wait a specified amount of time for new messages to arrive."},{header:"FIFO (First-In-First-Out) Queues",slug:"fifo-first-in-first-out-queues",content:'In these queues, the oldest (or first) entry, sometimes called the "head" of the queue, is processed first.'},{header:"Schedule or Delay Delivery",slug:"schedule-or-delay-delivery",content:"Many message queues support setting a specific delivery time for a message. If we need to have a common delay for all messages, we can set up a delay queue."},{header:"At-Least-Once Delivery",slug:"at-least-once-delivery",content:"Message queues may store multiple copies of messages for redundancy and high availability, and resend messages in the event of communication failures or errors to ensure they are delivered at least once."},{header:"Exactly-Once Delivery",slug:"exactly-once-delivery",content:"When duplicates can't be tolerated, FIFO (first-in-first-out) message queues will make sure that each message is delivered exactly once (and only once) by filtering out duplicates automatically."},{header:"Dead-letter Queues",slug:"dead-letter-queues",content:"A dead-letter queue is a queue to which other queues can send messages that can't be processed successfully. This makes it easy to set them aside for further inspection without blocking the queue processing or spending CPU cycles on a message that might never be consumed successfully."},{header:"Ordering",slug:"ordering",content:"Most message queues provide best-effort ordering which ensures that messages are generally delivered in the same order as they're sent and that a message is delivered at least once."},{header:"Poison-pill Messages",slug:"poison-pill-messages",content:"Poison pills are special messages that can be received, but not processed. They are a mechanism used in order to signal a consumer to end its work so it is no longer waiting for new inputs, and are similar to closing a socket in a client/server model."},{header:"Security",slug:"security",content:"Message queues will authenticate applications that try to access the queue, this allows us to encrypt messages over the network as well as in the queue itself."},{header:"Task Queues",slug:"task-queues",content:"Tasks queues receive tasks and their related data, run them, then deliver their results. They can support scheduling and can be used to run computationally-intensive jobs in the background."},{header:"Backpressure",slug:"backpressure",content:"If queues start to grow significantly, the queue size can become larger than memory, resulting in cache misses, disk reads, and even slower performance. Backpressure can help by limiting the queue size, thereby maintaining a high throughput rate and good response times for jobs already in the queue. Once the queue fills up, clients get a server busy or HTTP 503 status code to try again later. Clients can retry the request at a later time, perhaps with exponential backoff strategy."},{header:"Examples",slug:"examples-9",content:`Following are some widely used message queues: Amazon SQS
RabbitMQ
ActiveMQ
ZeroMQ`},{header:"Publish-Subscribe",slug:"publish-subscribe",content:`Similar to a message queue, publish-subscribe is also a form of service-to-service communication that facilitates asynchronous communication. In a pub/sub model, any message published to a topic is pushed immediately to all the subscribers of the topic.
publish-subscribe
The subscribers to the message topic often perform different functions, and can each do something different with the message in parallel. The publisher doesn't need to know who is using the information that it is broadcasting, and the subscribers don't need to know where the message comes from. This style of messaging is a bit different than message queues, where the component that sends the message often knows the destination it is sending to.`},{header:"Working",slug:"working-1",content:`Unlike message queues, which batch messages until they are retrieved, message topics transfer messages with little or no queuing and push them out immediately to all subscribers. Here's how it works: A message topic provides a lightweight mechanism to broadcast asynchronous event notifications and endpoints that allow software components to connect to the topic in order to send and receive those messages.
To broadcast a message, a component called a publisher simply pushes a message to the topic.
All components that subscribe to the topic (known as subscribers) will receive every message that was broadcasted.`},{header:"Advantages",slug:"advantages-15",content:`Let's discuss some advantages of using publish-subscribe: Eliminate Polling: Message topics allow instantaneous, push-based delivery, eliminating the need for message consumers to periodically check or "poll" for new information and updates. This promotes faster response time and reduces the delivery latency which can be particularly problematic in systems where delays cannot be tolerated.
Dynamic Targeting: Pub/Sub makes the discovery of services easier, more natural, and less error-prone. Instead of maintaining a roster of peers where an application can send messages, a publisher will simply post messages to a topic. Then, any interested party will subscribe its endpoint to the topic, and start receiving these messages. Subscribers can change, upgrade, multiply or disappear and the system dynamically adjusts.
Decoupled and Independent Scaling: Publishers and subscribers are decoupled and work independently from each other, which allows us to develop and scale them independently.
Simplify Communication: The Publish-Subscribe model reduces complexity by removing all the point-to-point connections with a single connection to a message topic, which will manage subscriptions and decide what messages should be delivered to which endpoints.`},{header:"Features",slug:"features-2",content:"Now, let's discuss some desired features of publish-subscribe:"},{header:"Push Delivery",slug:"push-delivery",content:"Pub/Sub messaging instantly pushes asynchronous event notifications when messages are published to the message topic. Subscribers are notified when a message is available."},{header:"Multiple Delivery Protocols",slug:"multiple-delivery-protocols",content:"In the Publish-Subscribe model, topics can typically connect to multiple types of endpoints, such as message queues, serverless functions, HTTP servers, etc."},{header:"Fanout",slug:"fanout",content:"This scenario happens when a message is sent to a topic and then replicated and pushed to multiple endpoints. Fanout provides asynchronous event notifications which in turn allows for parallel processing."},{header:"Filtering",slug:"filtering",content:"This feature empowers the subscriber to create a message filtering policy so that it will only get the notifications it is interested in, as opposed to receiving every single message posted to the topic."},{header:"Durability",slug:"durability",content:"Pub/Sub messaging services often provide very high durability, and at least once delivery, by storing copies of the same message on multiple servers."},{header:"Security",slug:"security-1",content:"Message topics authenticate applications that try to publish content, this allows us to use encrypted endpoints and encrypt messages in transit over the network."},{header:"Examples",slug:"examples-10",content:`Here are some technologies commonly used for publish-subscribe: Amazon SNS
Google Pub/Sub`},{header:"Enterprise Service Bus (ESB)",slug:"enterprise-service-bus-esb",content:`An Enterprise Service Bus (ESB) is an architectural pattern whereby a centralized software component performs integrations between applications. It performs transformations of data models, handles connectivity, performs message routing, converts communication protocols, and potentially manages the composition of multiple requests. The ESB can make these integrations and transformations available as a service interface for reuse by new applications.
enterprise-service-bus`},{header:"Advantages",slug:"advantages-16",content:`In theory, a centralized ESB offers the potential to standardize and dramatically simplify communication, messaging, and integration between services across the enterprise. Here are some advantages of using an ESB: Improved developer productivity: Enables developers to incorporate new technologies into one part of an application without touching the rest of the application.
Simpler, more cost-effective scalability: Components can be scaled independently of others.
Greater resilience: Failure of one component does not impact the others, and each microservice can adhere to its own availability requirements without risking the availability of other components in the system.`},{header:"Disadvantages",slug:"disadvantages-12",content:`While ESBs were deployed successfully in many organizations, in many other organizations the ESB came to be seen as a bottleneck. Here are some disadvantages of using an ESB: Making changes or enhancements to one integration could destabilize others who use that same integration.
A single point of failure can bring down all communications.
Updates to the ESB often impact existing integrations, so there is significant testing required to perform any update.
ESB is centrally managed which makes cross-team collaboration challenging.
High configuration and maintenance complexity.`},{header:"Examples",slug:"examples-11",content:`Below are some widely used Enterprise Service Bus (ESB) technologies: Azure Service Bus
IBM App Connect
Apache Camel
Fuse ESB`},{header:"Monoliths and Microservices",slug:"monoliths-and-microservices",content:""},{header:"Monoliths",slug:"monoliths",content:`A monolith is a self-contained and independent application. It is built as a single unit and is responsible for not just a particular task, but can perform every step needed to satisfy a business need.
monolith`},{header:"Advantages",slug:"advantages-17",content:`Following are some advantages of monoliths: Simple to develop or debug.
Fast and reliable communication.
Easy monitoring and testing.
Supports ACID transactions.`},{header:"Disadvantages",slug:"disadvantages-13",content:`Some common disadvantages of monoliths are: Maintenance becomes hard as the codebase grows.
Tightly coupled application, hard to extend.
Requires commitment to a particular technology stack.
On each update, the entire application is redeployed.
Reduced reliability as a single bug can bring down the entire system.
Difficult to scale or adopt new technologies.`},{header:"Modular monoliths",slug:"modular-monoliths",content:`A Modular Monolith is an approach where we build and deploy a single application (that's the Monolith part), but we build it in a way that breaks up the code into independent modules for each of the features needed in our application.
This approach reduces the dependencies of a module in such as way that we can enhance or change a module without affecting other modules. When done right, this can be really beneficial in the long term as it reduces the complexity that comes with maintaining a monolith as the system grows.`},{header:"Microservices",slug:"microservices",content:`A microservices architecture consists of a collection of small, autonomous services where each service is self-contained and should implement a single business capability within a bounded context. A bounded context is a natural division of business logic that provides an explicit boundary within which a domain model exists.
microservices
Each service has a separate codebase, which can be managed by a small development team. Services can be deployed independently and a team can update an existing service without rebuilding and redeploying the entire application.
Services are responsible for persisting their own data or external state (database per service). This differs from the traditional model, where a separate data layer handles data persistence.`},{header:"Characteristics",slug:"characteristics-1",content:`The microservices architecture style has the following characteristics: Loosely coupled: Services should be loosely coupled so that they can be independently deployed and scaled. This will lead to the decentralization of development teams and thus, enabling them to develop and deploy faster with minimal constraints and operational dependencies.
Small but focused: It's about scope and responsibilities and not size, a service should be focused on a specific problem. Basically, "It does one thing and does it well". Ideally, they can be independent of the underlying architecture.
Built for businesses: The microservices architecture is usually organized around business capabilities and priorities.
Resilience & Fault tolerance: Services should be designed in such a way that they still function in case of failure or errors. In environments with independently deployable services, failure tolerance is of the highest importance.
Highly maintainable: Service should be easy to maintain and test because services that cannot be maintained will be rewritten.`},{header:"Advantages",slug:"advantages-18",content:`Here are some advantages of microservices architecture: Loosely coupled services.
Services can be deployed independently.
Highly agile for multiple development teams.
Improves fault tolerance and data isolation.
Better scalability as each service can be scaled independently.
Eliminates any long-term commitment to a particular technology stack.`},{header:"Disadvantages",slug:"disadvantages-14",content:`Microservices architecture brings its own set of challenges: Complexity of a distributed system.
Testing is more difficult.
Expensive to maintain (individual servers, databases, etc.).
Inter-service communication has its own challenges.
Data integrity and consistency.
Network congestion and latency.`},{header:"Best practices",slug:"best-practices",content:`Let's discuss some microservices best practices: Model services around the business domain.
Services should have loose coupling and high functional cohesion.
Isolate failures and use resiliency strategies to prevent failures within a service from cascading.
Services should only communicate through well-designed APIs. Avoid leaking implementation details.
Data storage should be private to the service that owns the data
Avoid coupling between services. Causes of coupling include shared database schemas and rigid communication protocols.
Decentralize everything. Individual teams are responsible for designing and building services. Avoid sharing code or data schemas.
Fail fast by using a circuit breaker to achieve fault tolerance.
Ensure that the API changes are backward compatible.`},{header:"Pitfalls",slug:"pitfalls",content:`Below are some common pitfalls of microservices architecture: Service boundaries are not based on the business domain.
Underestimating how hard is to build a distributed system.
Shared database or common dependencies between services.
Lack of Business Alignment.
Lack of clear ownership.
Lack of idempotency.
Trying to do everything ACID instead of BASE.
Lack of design for fault tolerance may result in cascading failures.`},{header:"Beware of the distributed monolith",slug:"beware-of-the-distributed-monolith",content:`Distributed Monolith is a system that resembles the microservices architecture but is tightly coupled within itself like a monolithic application. Adopting microservices architecture comes with a lot of advantages. But while making one, there are good chances that we might end up with a distributed monolith.
Our microservices are just a distributed monolith if any of these apply to it: Requires low latency communication.
Services don't scale easily.
Dependency between services.
Sharing the same resources such as databases.
Tightly coupled systems. One of the primary reasons to build an application using microservices architecture is to have scalability. Therefore, microservices should have loosely coupled services which enable every service to be independent. The distributed monolith architecture takes this away and causes most components to depend on one another, increasing design complexity.`},{header:"Microservices vs Service-oriented architecture (SOA)",slug:"microservices-vs-service-oriented-architecture-soa",content:`You might have seen Service-oriented architecture (SOA) mentioned around the internet, sometimes even interchangeably with microservices, but they are different from each other and the main distinction between the two approaches comes down to scope.
Service-oriented architecture (SOA) defines a way to make software components reusable via service interfaces. These interfaces utilize common communication standards and focus on maximizing application service reusability whereas microservices are built as a collection of various smallest independent service units focused on team autonomy and decoupling.`},{header:"Why you don't need microservices",slug:"why-you-don-t-need-microservices",content:`architecture-range
So, you might be wondering, monoliths seem like a bad idea to begin with, why would anyone use that?
Well, it depends. While each approach has its own advantages and disadvantages, it is advised to start with a monolith when building a new system. It is important to understand, that microservices are not a silver bullet, instead, they solve an organizational problem. Microservices architecture is about your organizational priorities and team as much as it's about technology.
Before making the decision to move to microservices architecture, you need to ask yourself questions like: "Is the team too large to work effectively on a shared codebase?"
"Are teams blocked on other teams?"
"Does microservices deliver clear business value for us?"
"Is my business mature enough to use microservices?"
"Is our current architecture limiting us with communication overhead?" If your application does not require to be broken down into microservices, you don't need this. There is no absolute necessity that all applications should be broken down into microservices.
We frequently draw inspiration from companies such as Netflix and their use of microservices, but we overlook the fact that we are not Netflix. They went through a lot of iterations and models before they had a market-ready solution, and this architecture became acceptable for them when they identified and solved the problem they were trying to tackle.
That's why it's essential to understand in-depth if your business actually needs microservices. What I'm trying to say is microservices are solutions to complex concerns and if your business doesn't have complex issues, you don't need them.`},{header:"Event-Driven Architecture (EDA)",slug:"event-driven-architecture-eda",content:"Event-Driven Architecture (EDA) is about using events as a way to communicate within a system. Generally, leveraging a message broker to publish and consume events asynchronously. The publisher is unaware of who is consuming an event and the consumers are unaware of each other. Event-Driven Architecture is simply a way of achieving loose coupling between services within a system."},{header:"What is an event?",slug:"what-is-an-event",content:"An event is a data point that represents state changes in a system. It doesn't specify what should happen and how the change should modify the system, it only notifies the system of a particular state change. When a user makes an action, they trigger an event."},{header:"Components",slug:"components-1",content:`Event-driven architectures have three key components: Event producers: Publishes an event to the router.
Event routers: Filters and pushes the events to consumers.
Event consumers: Uses events to reflect changes in the system. event-driven-architecture
Note: Dots in the diagram represents different events in the system.`},{header:"Patterns",slug:"patterns",content:`There are several ways to implement the event-driven architecture, and which method we use depends on the use case but here are some common examples: Sagas
Publish-Subscribe
Event Sourcing
Command and Query Responsibility Segregation (CQRS) Note: Each of these methods is discussed separately.`},{header:"Advantages",slug:"advantages-19",content:`Let's discuss some advantages: Decoupled producers and consumers.
Highly scalable and distributed.
Easy to add new consumers.
Improves agility.`},{header:"Challenges",slug:"challenges-2",content:`Here are some challenges of event-drive architecture: Guaranteed delivery.
Error handling is difficult.
Event-driven systems are complex in general.
Exactly once, in-order processing of events.`},{header:"Use cases",slug:"use-cases-1",content:`Below are some common use cases where event-driven architectures are beneficial: Metadata and metrics.
Server and security logs.
Integrating heterogeneous systems.
Fanout and parallel processing.`},{header:"Examples",slug:"examples-12",content:`Here are some widely used technologies for implementing event-driven architectures: NATS
Apache Kafka
Amazon EventBridge
Amazon SNS
Google PubSub`},{header:"Event Sourcing",slug:"event-sourcing",content:`Instead of storing just the current state of the data in a domain, use an append-only store to record the full series of actions taken on that data. The store acts as the system of record and can be used to materialize the domain objects.
event-sourcing
This can simplify tasks in complex domains, by avoiding the need to synchronize the data model and the business domain, while improving performance, scalability, and responsiveness. It can also provide consistency for transactional data, and maintain full audit trails and history that can enable compensating actions.`},{header:"Event sourcing vs Event-Driven Architecture (EDA)",slug:"event-sourcing-vs-event-driven-architecture-eda",content:`Event sourcing is seemingly constantly being confused with Event-driven Architecture (EDA). Event-driven architecture is about using events to communicate between service boundaries. Generally, leveraging a message broker to publish and consume events asynchronously within other boundaries.
Whereas, event sourcing is about using events as a state, which is a different approach to storing data. Rather than storing the current state, we're instead going to be storing events. Also, event sourcing is one of the several patterns to implement an event-driven architecture.`},{header:"Advantages",slug:"advantages-20",content:`Let's discuss some advantages of using event sourcing: Excellent for real-time data reporting.
Great for fail-safety, data can be reconstituted from the event store.
Extremely flexible, any type of message can be stored.
Preferred way of achieving audit logs functionality for high compliance systems.`},{header:"Disadvantages",slug:"disadvantages-15",content:`Following are the disadvantages of event sourcing: Requires an extremely efficient network infrastructure.
Requires a reliable way to control message formats, such as a schema registry.
Different events will contain different payloads.`},{header:"Command and Query Responsibility Segregation (CQRS)",slug:"command-and-query-responsibility-segregation-cqrs",content:`Command Query Responsibility Segregation (CQRS) is an architectural pattern that divides a system's actions into commands and queries. It was first described by Greg Young.
In CQRS, a command is an instruction, a directive to perform a specific task. It is an intention to change something and doesn't return a value, only an indication of success or failure. And, a query is a request for information that doesn't change the system's state or cause any side effects.
command-and-query-responsibility-segregation
The core principle of CQRS is the separation of commands and queries. They perform fundamentally different roles within a system, and separating them means that each can be optimized as needed, which distributed systems can really benefit from.`},{header:"CQRS with Event Sourcing",slug:"cqrs-with-event-sourcing",content:`The CQRS pattern is often used along with the Event Sourcing pattern. CQRS-based systems use separate read and write data models, each tailored to relevant tasks and often located in physically separate stores.
When used with the Event Sourcing pattern, the store of events is the write model and is the official source of information. The read model of a CQRS-based system provides materialized views of the data, typically as highly denormalized views.`},{header:"Advantages",slug:"advantages-21",content:`Let's discuss some advantages of CQRS: Allows independent scaling of read and write workloads.
Easier scaling, optimizations, and architectural changes.
Closer to business logic with loose coupling.
The application can avoid complex joins when querying.
Clear boundaries between the system behavior.`},{header:"Disadvantages",slug:"disadvantages-16",content:`Below are some disadvantages of CQRS: More complex application design.
Message failures or duplicate messages can occur.
Dealing with eventual consistency is a challenge.
Increased system maintenance efforts.`},{header:"Use cases",slug:"use-cases-2",content:`Here are some scenarios where CQRS will be helpful: The performance of data reads must be fine-tuned separately from the performance of data writes.
The system is expected to evolve over time and might contain multiple versions of the model, or where business rules change regularly.
Integration with other systems, especially in combination with event sourcing, where the temporal failure of one subsystem shouldn't affect the availability of the others.
Better security to ensure that only the right domain entities are performing writes on the data.`},{header:"API Gateway",slug:"api-gateway",content:`The API Gateway is an API management tool that sits between a client and a collection of backend services. It is a single entry point into a system that encapsulates the internal system architecture and provides an API that is tailored to each client. It also has other responsibilities such as authentication, monitoring, load balancing, caching, throttling, logging, etc.
api-gateway`},{header:"Why do we need an API Gateway?",slug:"why-do-we-need-an-api-gateway",content:"The granularity of APIs provided by microservices is often different than what a client needs. Microservices typically provide fine-grained APIs, which means that clients need to interact with multiple services. Hence, an API gateway can provide a single entry point for all clients with some additional features and better management."},{header:"Features",slug:"features-3",content:`Below are some desired features of an API Gateway: Authentication and Authorization
Service discovery
Reverse Proxy
Caching
Security
Retry and Circuit breaking
Load balancing
Logging, Tracing
API composition
Rate limiting and throttling
Versioning
Routing
IP whitelisting or blacklisting`},{header:"Advantages",slug:"advantages-22",content:`Let's look at some advantages of using an API Gateway: Encapsulates the internal structure of an API.
Provides a centralized view of the API.
Simplifies the client code.
Monitoring, analytics, tracing, and other such features.`},{header:"Disadvantages",slug:"disadvantages-17",content:`Here are some possible disadvantages of an API Gateway: Possible single point of failure.
Might impact performance.
Can become a bottleneck if not scaled properly.
Configuration can be challenging.`},{header:"Backend For Frontend (BFF) pattern",slug:"backend-for-frontend-bff-pattern",content:`In the Backend For Frontend (BFF) pattern, we create separate backend services to be consumed by specific frontend applications or interfaces. This pattern is useful when we want to avoid customizing a single backend for multiple interfaces. This pattern was first described by Sam Newman.
Also, sometimes the output of data returned by the microservices to the front end is not in the exact format or filtered as needed by the front end. To solve this issue, the frontend should have some logic to reformat the data, and therefore, we can use BFF to shift some of this logic to the intermediate layer.
backend-for-frontend
The primary function of the backend for the frontend pattern is to get the required data from the appropriate service, format the data, and sent it to the frontend.
GraphQL performs really well as a backend for frontend (BFF).`},{header:"When to use this pattern?",slug:"when-to-use-this-pattern",content:`We should consider using a Backend For Frontend (BFF) pattern when: A shared or general purpose backend service must be maintained with significant development overhead.
We want to optimize the backend for the requirements of a specific client.
Customizations are made to a general-purpose backend to accommodate multiple interfaces.`},{header:"Examples",slug:"examples-13",content:`Following are some widely used gateways technologies: Amazon API Gateway
Apigee API Gateway
Azure API Gateway
Kong API Gateway`},{header:"REST, GraphQL, gRPC",slug:"rest-graphql-grpc",content:"A good API design is always a crucial part of any system. But it is also important to pick the right API technology. So, in this tutorial, we will briefly discuss different API technologies such as REST, GraphQL, and gRPC."},{header:"What's an API?",slug:"what-s-an-api",content:`Before we even get into API technologies, let's first understand what is an API.
API stands for Application Programming Interface. It is a set of definitions and protocols for building and integrating application software. It's sometimes referred to as a contract between an information provider and an information user establishing the content required from the producer and the content required by the consumer.
In other words, if you want to interact with a computer or system to retrieve information or perform a function, an API helps you communicate what you want to that system so it can understand and complete the request.`},{header:"REST",slug:"rest",content:`A REST API (also known as RESTful API) is an application programming interface that conforms to the constraints of REST architectural style and allows for interaction with RESTful web services. REST stands for Representational State Transfer and it was first introduced by Roy Fielding in the year 2000.
In REST API, the fundamental unit is a resource.`},{header:"Concepts",slug:"concepts",content:`Let's discuss some concepts of a RESTful API.
Constraints
In order for an API to be considered RESTful, it has to conform to these architectural constraints: Uniform Interface: There should be a uniform way of interacting with a given server.
Client-Server: A client-server architecture managed through HTTP.
Stateless: No client context shall be stored on the server between requests.
Cacheable: Every response should include whether the response is cacheable or not and for how much duration responses can be cached at the client-side.
Layered system: An application architecture needs to be composed of multiple layers.
Code on demand: Return executable code to support a part of your application. (optional) HTTP Verbs
HTTP defines a set of request methods to indicate the desired action to be performed for a given resource. Although they can also be nouns, these request methods are sometimes referred to as HTTP verbs. Each of them implements a different semantic, but some common features are shared by a group of them.
Below are some commonly used HTTP verbs: GET: Request a representation of the specified resource.
HEAD: Response is identical to a GET request, but without the response body.
POST: Submits an entity to the specified resource, often causing a change in state or side effects on the server.
PUT: Replaces all current representations of the target resource with the request payload.
DELETE: Deletes the specified resource.
PATCH: Applies partial modifications to a resource. HTTP response codes
HTTP response status codes indicate whether a specific HTTP request has been successfully completed.
There are five classes defined by the standard: 1xx - Informational responses.
2xx - Successful responses.
3xx - Redirection responses.
4xx - Client error responses.
5xx - Server error responses. For example, HTTP 200 means that the request was successful.`},{header:"Advantages",slug:"advantages-23",content:`Let's discuss some advantages of REST API: Simple and easy to understand.
Flexible and portable.
Good caching support.
Client and server are decoupled.`},{header:"Disadvantages",slug:"disadvantages-18",content:`Let's discuss some disadvantages of REST API: Over-fetching of data.
Sometimes multiple round trips to the server are required.`},{header:"Use cases",slug:"use-cases-3",content:"REST APIs are pretty much used universally and are the default standard for designing APIs. Overall REST APIs are quite flexible and can fit almost all scenarios."},{header:"Example",slug:"example",content:`Here's an example usage of a REST API that operates on a users resource. URI
HTTP verb
Description /users
GET
Get all users /users/{id}
GET
Get a user by id /users
POST
Add a new user /users/{id}
PATCH
Update a user by id /users/{id}
DELETE
Delete a user by id There is so much more to learn when it comes to REST APIs, I will highly recommend looking into Hypermedia as the Engine of Application State (HATEOAS).`},{header:"GraphQL",slug:"graphql",content:`GraphQL is a query language and server-side runtime for APIs that prioritizes giving clients exactly the data they request and no more. It was developed by Facebook and later open-sourced in 2015.
GraphQL is designed to make APIs fast, flexible, and developer-friendly. Additionally, GraphQL gives API maintainers the flexibility to add or deprecate fields without impacting existing queries. Developers can build APIs with whatever methods they prefer, and the GraphQL specification will ensure they function in predictable ways to clients.
In GraphQL, the fundamental unit is a query.`},{header:"Concepts",slug:"concepts-1",content:`Let's briefly discuss some key concepts in GraphQL:
Schema
A GraphQL schema describes the functionality clients can utilize once they connect to the GraphQL server.
Queries
A query is a request made by the client. It can consist of fields and arguments for the query. The operation type of a query can also be a mutation which provides a way to modify server-side data.
Resolvers
Resolver is a collection of functions that generate responses for a GraphQL query. In simple terms, a resolver acts as a GraphQL query handler.`},{header:"Advantages",slug:"advantages-24",content:`Let's discuss some advantages of GraphQL: Eliminates over-fetching of data.
Strongly defined schema.
Code generation support.
Payload optimization.`},{header:"Disadvantages",slug:"disadvantages-19",content:`Let's discuss some disadvantages of GraphQL: Shifts complexity to server-side.
Caching becomes hard.
Versioning is ambiguous.
N+1 problem.`},{header:"Use cases",slug:"use-cases-4",content:`GraphQL proves to be essential in the following scenarios: Reducing app bandwidth usage as we can query multiple resources in a single query.
Rapid prototyping for complex systems.
When we are working with a graph-like data model.`},{header:"Example",slug:"example-1",content:`Here's a GraphQL schema that defines a User type and a Query type.
type Query { getUser: User
} type User { id: ID name: String city: String state: String
} Using the above schema, the client can request the required fields easily without having to fetch the entire resource or guess what the API might return.
{ getUser { id name city }
} This will give the following response to the client.
{ "getUser": { "id": 123, "name": "Karan", "city": "San Francisco" }
} Learn more about GraphQL at graphql.org.`},{header:"gRPC",slug:"grpc",content:"gRPC is a modern open-source high-performance Remote Procedure Call (RPC) framework that can run in any environment. It can efficiently connect services in and across data centers with pluggable support for load balancing, tracing, health checking, authentication and much more."},{header:"Concepts",slug:"concepts-2",content:`Let's discuss some key concepts of gRPC.
Protocol buffers
Protocol buffers provide a language and platform-neutral extensible mechanism for serializing structured data in a forward and backward-compatible way. It's like JSON, except it's smaller and faster, and it generates native language bindings.
Service definition
Like many RPC systems, gRPC is based on the idea of defining a service and specifying the methods that can be called remotely with their parameters and return types. gRPC uses protocol buffers as the Interface Definition Language (IDL) for describing both the service interface and the structure of the payload messages.`},{header:"Advantages",slug:"advantages-25",content:`Let's discuss some advantages of gRPC: Lightweight and efficient.
High performance.
Built-in code generation support.
Bi-directional streaming.`},{header:"Disadvantages",slug:"disadvantages-20",content:`Let's discuss some disadvantages of gRPC: Relatively new compared to REST and GraphQL.
Limited browser support.
Steeper learning curve.
Not human readable.`},{header:"Use cases",slug:"use-cases-5",content:`Below are some good use cases for gRPC: Real-time communication via bi-directional streaming.
Efficient inter-service communication in microservices.
Low latency and high throughput communication.
Polyglot environments.`},{header:"Example",slug:"example-2",content:`Here's a basic example of a gRPC service defined in a *.proto file. Using this definition, we can easily code generate the HelloService service in the programming language of our choice.
service HelloService { rpc SayHello (HelloRequest) returns (HelloResponse);
} message HelloRequest { string greeting = 1;
} message HelloResponse { string reply = 1;
}`},{header:"REST vs GraphQL vs gRPC",slug:"rest-vs-graphql-vs-grpc",content:`Now that we know how these API designing techniques work, let's compare them based on the following parameters: Will it cause tight coupling?
How chatty (distinct API calls to get needed information) are the APIs?
What's the performance like?
How complex is it to integrate?
How well does the caching work?
Built-in tooling and code generation?
What's API discoverability like?
How easy is it to version APIs? Type
Coupling
Chattiness
Performance
Complexity
Caching
Codegen
Discoverability
Versioning REST
Low
High
Good
Medium
Great
Bad
Good
Easy GraphQL
Medium
Low
Good
High
Custom
Good
Good
Custom gRPC
High
Medium
Great
Low
Custom
Great
Bad
Hard`},{header:"Which API technology is better?",slug:"which-api-technology-is-better",content:"Well, the answer is none of them. There is no silver bullet as each of these technologies has its own advantages and disadvantages. Users only care about using our APIs in a consistent way, so make sure to focus on your domain and requirements when designing your API."},{header:"Long polling, WebSockets, Server-Sent Events (SSE)",slug:"long-polling-websockets-server-sent-events-sse",content:"Web applications were initially developed around a client-server model, where the web client is always the initiator of transactions like requesting data from the server. Thus, there was no mechanism for the server to independently send, or push, data to the client without the client first making a request. Let's discuss some approaches to overcome this problem."},{header:"Long polling",slug:"long-polling",content:`HTTP Long polling is a technique used to push information to a client as soon as possible from the server. As a result, the server does not have to wait for the client to send a request.
In Long polling, the server does not close the connection once it receives a request from the client. Instead, the server responds only if any new message is available or a timeout threshold is reached.
long-polling
Once the client receives a response, it immediately sends a new request to the server to have a new pending connection to send data to the client, and the operation is repeated. With this approach, the server emulates a real-time server push feature.`},{header:"Working",slug:"working-2",content:`Let's understand how long polling works: The client makes an initial request and waits for a response.
The server receives the request and delays sending anything until an update is available.
Once an update is available, the response is sent to the client.
The client receives the response and makes a new request immediately or after some defined interval to establish a connection again.`},{header:"Advantages",slug:"advantages-26",content:`Here are some advantages of long polling: Easy to implement, good for small-scale projects.
Nearly universally supported.`},{header:"Disadvantages",slug:"disadvantages-21",content:`A major downside of long polling is that it is usually not scalable. Below are some of the other reasons: Creates a new connection each time, which can be intensive on the server.
Reliable message ordering can be an issue for multiple requests.
Increased latency as the server needs to wait for a new request.`},{header:"WebSockets",slug:"websockets",content:`WebSocket provides full-duplex communication channels over a single TCP connection. It is a persistent connection between a client and a server that both parties can use to start sending data at any time.
The client establishes a WebSocket connection through a process known as the WebSocket handshake. If the process succeeds, then the server and client can exchange data in both directions at any time. The WebSocket protocol enables the communication between a client and a server with lower overheads, facilitating real-time data transfer from and to the server.
websockets
This is made possible by providing a standardized way for the server to send content to the client without being asked and allowing for messages to be passed back and forth while keeping the connection open.`},{header:"Working",slug:"working-3",content:`Let's understand how WebSockets work: The client initiates a WebSocket handshake process by sending a request.
The request also contains an HTTP Upgrade header that allows the request to switch to the WebSocket protocol (ws://).
The server sends a response to the client, acknowledging the WebSocket handshake request.
A WebSocket connection will be opened once the client receives a successful handshake response.
Now the client and server can start sending data in both directions allowing real-time communication.
The connection is closed once the server or the client decides to close the connection.`},{header:"Advantages",slug:"advantages-27",content:`Below are some advantages of WebSockets: Full-duplex asynchronous messaging.
Better origin-based security model.
Lightweight for both client and server.`},{header:"Disadvantages",slug:"disadvantages-22",content:`Let's discuss some disadvantages of WebSockets: Terminated connections aren't automatically recovered.
Older browsers don't support WebSockets (becoming less relevant).`},{header:"Server-Sent Events (SSE)",slug:"server-sent-events-sse",content:`Server-Sent Events (SSE) is a way of establishing long-term communication between client and server that enables the server to proactively push data to the client.
server-sent-events
It is unidirectional, meaning once the client sends the request it can only receive the responses without the ability to send new requests over the same connection.`},{header:"Working",slug:"working-4",content:`Let's understand how server-sent events work: The client makes a request to the server.
The connection between client and server is established and it remains open.
The server sends responses or events to the client when new data is available.`},{header:"Advantages",slug:"advantages-28",content:`Simple to implement and use for both client and server.
Supported by most browsers.
No trouble with firewalls.`},{header:"Disadvantages",slug:"disadvantages-23",content:`Unidirectional nature can be limiting.
Limitation for the maximum number of open connections.
Does not support binary data.`},{header:"Geohashing and Quadtrees",slug:"geohashing-and-quadtrees",content:""},{header:"Geohashing",slug:"geohashing",content:`Geohashing is a geocoding method used to encode geographic coordinates such as latitude and longitude into short alphanumeric strings. It was created by Gustavo Niemeyer in 2008.
For example, San Francisco with coordinates 37.7564, -122.4016 can be represented in geohash as 9q8yy9mf.`},{header:"How does Geohashing work?",slug:"how-does-geohashing-work",content:`Geohash is a hierarchical spatial index that uses Base-32 alphabet encoding, the first character in a geohash identifies the initial location as one of the 32 cells. This cell will also contain 32 cells. This means that to represent a point, the world is recursively divided into smaller and smaller cells with each additional bit until the desired precision is attained. The precision factor also determines the size of the cell.
geohashing
Geohashing guarantees that points are spatially closer if their Geohashes share a longer prefix which means the more characters in the string, the more precise the location. For example, geohashes 9q8yy9mf and 9q8yy9vx are spatially closer as they share the prefix 9q8yy9.
Geohashing can also be used to provide a degree of anonymity as we don't need to expose the exact location of the user because depending on the length of the geohash we just know they are somewhere within an area.
The cell sizes of the geohashes of different lengths are as follows: Geohash length
Cell width
Cell height 1
5000 km
5000 km 2
1250 km
1250 km 3
156 km
156 km 4
39.1 km
19.5 km 5
4.89 km
4.89 km 6
1.22 km
0.61 km 7
153 m
153 m 8
38.2 m
19.1 m 9
4.77 m
4.77 m 10
1.19 m
0.596 m 11
149 mm
149 mm 12
37.2 mm
18.6 mm`},{header:"Use cases",slug:"use-cases-6",content:`Here are some common use cases for Geohashing: It is a simple way to represent and store a location in a database.
It can also be shared on social media as URLs since it is easier to share, and remember than latitudes and longitudes.
We can efficiently find the nearest neighbors of a point through very simple string comparisons and efficient searching of indexes.`},{header:"Examples",slug:"examples-14",content:`Geohashing is widely used and it is supported by popular databases. MySQL
Redis
Amazon DynamoDB
Google Cloud Firestore`},{header:"Quadtrees",slug:"quadtrees",content:`A quadtree is a tree data structure in which each internal node has exactly four children. They are often used to partition a two-dimensional space by recursively subdividing it into four quadrants or regions. Each child or leaf node stores spatial information. Quadtrees are the two-dimensional analog of Octrees which are used to partition three-dimensional space.
quadtree`},{header:"Types of Quadtrees",slug:"types-of-quadtrees",content:`Quadtrees may be classified according to the type of data they represent, including areas, points, lines, and curves. The following are common types of quadtrees: Point quadtrees
Point-region (PR) quadtrees
Polygonal map (PM) quadtrees
Compressed quadtrees
Edge quadtrees`},{header:"Why do we need Quadtrees?",slug:"why-do-we-need-quadtrees",content:`Aren't latitudes and longitudes enough? Why do we need quadtrees? While in theory using latitude and longitude we can determine things such as how close points are to each other using euclidean distance, for practical use cases it is simply not scalable because of its CPU-intensive nature with large data sets.
quadtree-subdivision
Quadtrees enable us to search points within a two-dimensional range efficiently, where those points are defined as latitude/longitude coordinates or as cartesian (x, y) coordinates. Additionally, we can save further computation by only subdividing a node after a certain threshold. And with the application of mapping algorithms such as the Hilbert curve, we can easily improve range query performance.`},{header:"Use cases",slug:"use-cases-7",content:`Below are some common uses of quadtrees: Image representation, processing, and compression.
Spacial indexing and range queries.
Location-based services like Google Maps, Uber, etc.
Mesh generation and computer graphics.
Sparse data storage.`},{header:"Circuit breaker",slug:"circuit-breaker",content:`The circuit breaker is a design pattern used to detect failures and encapsulates the logic of preventing a failure from constantly recurring during maintenance, temporary external system failure, or unexpected system difficulties.
circuit-breaker
The basic idea behind the circuit breaker is very simple. We wrap a protected function call in a circuit breaker object, which monitors for failures. Once the failures reach a certain threshold, the circuit breaker trips, and all further calls to the circuit breaker return with an error, without the protected call being made at all. Usually, we'll also want some kind of monitor alert if the circuit breaker trips.`},{header:"Why do we need circuit breaking?",slug:"why-do-we-need-circuit-breaking",content:"It's common for software systems to make remote calls to software running in different processes, probably on different machines across a network. One of the big differences between in-memory calls and remote calls is that remote calls can fail, or hang without a response until some timeout limit is reached. What's worse is if we have many callers on an unresponsive supplier, then we can run out of critical resources leading to cascading failures across multiple systems."},{header:"States",slug:"states-1",content:"Let's discuss circuit breaker states:"},{header:"Closed",slug:"closed",content:"When everything is normal, the circuit breakers remain closed, and all the request passes through to the services as normal. If the number of failures increases beyond the threshold, the circuit breaker trips and goes into an open state."},{header:"Open",slug:"open",content:"In this state circuit breaker returns an error immediately without even invoking the services. The Circuit breakers move into the half-open state after a certain timeout period elapses. Usually, it will have a monitoring system where the timeout will be specified."},{header:"Half-open",slug:"half-open",content:"In this state, the circuit breaker allows a limited number of requests from the service to pass through and invoke the operation. If the requests are successful, then the circuit breaker will go to the closed state. However, if the requests continue to fail, then it goes back to the open state."},{header:"Rate Limiting",slug:"rate-limiting",content:`Rate limiting refers to preventing the frequency of an operation from exceeding a defined limit. In large-scale systems, rate limiting is commonly used to protect underlying services and resources. Rate limiting is generally used as a defensive mechanism in distributed systems, so that shared resources can maintain availability. It also protects our APIs from unintended or malicious overuse by limiting the number of requests that can reach our API in a given period of time.
rate-limiting`},{header:"Why do we need Rate Limiting?",slug:"why-do-we-need-rate-limiting",content:`Rate limiting is a very important part of any large-scale system and it can be used to accomplish the following: Avoid resource starvation as a result of Denial of Service (DoS) attacks.
Rate Limiting helps in controlling operational costs by putting a virtual cap on the auto-scaling of resources which if not monitored might lead to exponential bills.
Rate limiting can be used as defense or mitigation against some common attacks.
For APIs that process massive amounts of data, rate limiting can be used to control the flow of that data.`},{header:"Algorithms",slug:"algorithms",content:"There are various algorithms for API rate limiting, each with its advantages and disadvantages. Let's briefly discuss some of these algorithms:"},{header:"Leaky Bucket",slug:"leaky-bucket",content:"Leaky Bucket is an algorithm that provides a simple, intuitive approach to rate limiting via a queue. When registering a request, the system appends it to the end of the queue. Processing for the first item on the queue occurs at a regular interval or first-in, first-out (FIFO). If the queue is full, then additional requests are discarded (or leaked)."},{header:"Token Bucket",slug:"token-bucket",content:"Here we use a concept of a bucket. When a request comes in, a token from the bucket must be taken and processed. The request will be refused if no token is available in the bucket, and the requester will have to try again later. As a result, the token bucket gets refreshed after a certain time period."},{header:"Fixed Window",slug:"fixed-window",content:"The system uses a window size of n seconds to track the fixed window algorithm rate. Each incoming request increments the counter for the window. It discards the request if the counter exceeds a threshold."},{header:"Sliding Log",slug:"sliding-log",content:"Sliding Log rate-limiting involves tracking a time-stamped log for each request. The system stores these logs in a time-sorted hash set or table. It also discards logs with timestamps beyond a threshold. When a new request comes in, we calculate the sum of logs to determine the request rate. If the request would exceed the threshold rate, then it is held."},{header:"Sliding Window",slug:"sliding-window",content:"Sliding Window is a hybrid approach that combines the fixed window algorithm's low processing cost and the sliding log's improved boundary conditions. Like the fixed window algorithm, we track a counter for each fixed window. Next, we account for a weighted value of the previous window's request rate based on the current timestamp to smooth out bursts of traffic."},{header:"Rate Limiting in Distributed Systems",slug:"rate-limiting-in-distributed-systems",content:"Rate Limiting becomes complicated when distributed systems are involved. The two broad problems that come with rate limiting in distributed systems are:"},{header:"Inconsistencies",slug:"inconsistencies",content:`When using a cluster of multiple nodes, we might need to enforce a global rate limit policy. Because if each node were to track its rate limit, a consumer could exceed a global rate limit when sending requests to different nodes. The greater the number of nodes, the more likely the user will exceed the global limit.
The simplest way to solve this problem is to use sticky sessions in our load balancers so that each consumer gets sent to exactly one node but this causes a lack of fault tolerance and scaling problems. Another approach might be to use a centralized data store like Redis but this will increase latency and cause race conditions.`},{header:"Race Conditions",slug:"race-conditions",content:`This issue happens when we use a naive "get-then-set" approach, in which we retrieve the current rate limit counter, increment it, and then push it back to the datastore. This model's problem is that additional requests can come through in the time it takes to perform a full cycle of read-increment-store, each attempting to store the increment counter with an invalid (lower) counter value. This allows a consumer to send a very large number of requests to bypass the rate limiting controls.
One way to avoid this problem is to use some sort of distributed locking mechanism around the key, preventing any other processes from accessing or writing to the counter. Though the lock will become a significant bottleneck and will not scale well. A better approach might be to use a "set-then-get" approach, allowing us to quickly increment and check counter values without letting the atomic operations get in the way.`},{header:"Service Discovery",slug:"service-discovery",content:"Service discovery is the detection of services within a computer network. Service Discovery Protocol (SDP) is a networking standard that accomplishes the detection of networks by identifying resources."},{header:"Why do we need Service Discovery?",slug:"why-do-we-need-service-discovery",content:"In a monolithic application, services invoke one another through language-level methods or procedure calls. However, modern microservices-based applications typically run in virtualized or containerized environments where the number of instances of a service and their locations change dynamically. Consequently, we need a mechanism that enables the clients of service to make requests to a dynamically changing set of ephemeral service instances."},{header:"Implementations",slug:"implementations",content:"There are two main service discovery patterns:"},{header:"Client-side discovery",slug:"client-side-discovery",content:`client-side-service-discovery
In this approach, the client obtains the location of another service by querying a service registry which is responsible for managing and storing the network locations of all the services.`},{header:"Server-side discovery",slug:"server-side-discovery",content:`server-side-service-discovery
In this approach, we use an intermediate component such as a load balancer. The client makes a request to the service via a load balancer which then forwards the request to an available service instance.`},{header:"Service Registry",slug:"service-registry",content:"A service registry is basically a database containing the network locations of service instances to which the clients can reach out. A Service Registry must be highly available and up-to-date."},{header:"Service Registration",slug:"service-registration",content:"We also need a way to obtain service information, often known as service registration. Let's look at two possible service registration approaches:"},{header:"Self-Registration",slug:"self-registration",content:"When using the self-registration model, a service instance is responsible for registering and de-registering itself in the Service Registry. In addition, if necessary, a service instance sends heartbeat requests to keep its registration alive."},{header:"Third-party Registration",slug:"third-party-registration",content:"The registry keeps track of changes to running instances by polling the deployment environment or subscribing to events. When it detects a newly available service instance, it records it in its database. The Service Registry also de-registers terminated service instances."},{header:"Service mesh",slug:"service-mesh",content:"Service-to-service communication is essential in a distributed application but routing this communication, both within and across application clusters, becomes increasingly complex as the number of services grows. Service mesh enables managed, observable, and secure communication between individual services. It works with a service discovery protocol to detect services. Istio and envoy are some of the most commonly used service mesh technologies."},{header:"Examples",slug:"examples-15",content:`Here are some commonly used service discovery infrastructure tools: etcd
Consul
Apache Thrift
Apache Zookeeper`},{header:"SLA, SLO, SLI",slug:"sla-slo-sli",content:"Let's briefly discuss SLA, SLO, and SLI. These are mostly related to the business and site reliability side of things but good to know nonetheless."},{header:"Why are they important?",slug:"why-are-they-important",content:"SLAs, SLOs, and SLIs allow companies to define, track and monitor the promises made for a service to its users. Together, SLAs, SLOs, and SLIs should help teams generate more user trust in their services with an added emphasis on continuous improvement to incident management and response processes."},{header:"SLA",slug:"sla",content:`An SLA, or Service Level Agreement, is an agreement made between a company and its users of a given service. The SLA defines the different promises that the company makes to users regarding specific metrics, such as service availability.
SLAs are often written by a company's business or legal team.`},{header:"SLO",slug:"slo",content:"An SLO, or Service Level Objective, is the promise that a company makes to users regarding a specific metric such as incident response or uptime. SLOs exist within an SLA as individual promises contained within the full user agreement. The SLO is the specific goal that the service must meet in order to comply with the SLA. SLOs should always be simple, clearly defined, and easily measured to determine whether or not the objective is being fulfilled."},{header:"SLI",slug:"sli",content:"An SLI, or Service Level Indicator, is a key metric used to determine whether or not the SLO is being met. It is the measured value of the metric described within the SLO. In order to remain in compliance with the SLA, the SLI's value must always meet or exceed the value determined by the SLO."},{header:"Disaster recovery",slug:"disaster-recovery",content:`Disaster recovery (DR) is a process of regaining access and functionality of the infrastructure after events like a natural disaster, cyber attack, or even business disruptions.
Disaster recovery relies upon the replication of data and computer processing in an off-premises location not affected by the disaster. When servers go down because of a disaster, a business needs to recover lost data from a second location where the data is backed up. Ideally, an organization can transfer its computer processing to that remote location as well in order to continue operations.
Disaster Recovery is often not actively discussed during system design interviews but it's important to have some basic understanding of this topic. You can learn more about disaster recovery from AWS Well-Architected Framework.`},{header:"Why is disaster recovery important?",slug:"why-is-disaster-recovery-important",content:`Disaster recovery can have the following benefits: Minimize interruption and downtime
Limit damages
Fast restoration
Better customer retention`},{header:"Terms",slug:"terms-1",content:`Let's discuss some important terms relevantly for disaster recovery:
disaster-recovery`},{header:"RTO",slug:"rto",content:"Recovery Time Objective (RTO) is the maximum acceptable delay between the interruption of service and restoration of service. This determines what is considered an acceptable time window when service is unavailable."},{header:"RPO",slug:"rpo",content:"Recovery Point Objective (RPO) is the maximum acceptable amount of time since the last data recovery point. This determines what is considered an acceptable loss of data between the last recovery point and the interruption of service."},{header:"Strategies",slug:"strategies",content:"A variety of disaster recovery (DR) strategies can be part of a disaster recovery plan."},{header:"Back-up",slug:"back-up",content:"This is the simplest type of disaster recovery and involves storing data off-site or on a removable drive."},{header:"Cold Site",slug:"cold-site",content:"In this type of disaster recovery, an organization sets up basic infrastructure in a second site."},{header:"Hot site",slug:"hot-site",content:"A hot site maintains up-to-date copies of data at all times. Hot sites are time-consuming to set up and more expensive than cold sites, but they dramatically reduce downtime."},{header:"Virtual Machines (VMs) and Containers",slug:"virtual-machines-vms-and-containers",content:"Before we discuss virtualization vs containerization, let's learn what are virtual machines (VMs) and Containers."},{header:"Virtual Machines (VM)",slug:"virtual-machines-vm",content:`A Virtual Machine (VM) is a virtual environment that functions as a virtual computer system with its own CPU, memory, network interface, and storage, created on a physical hardware system. A software called a hypervisor separates the machine's resources from the hardware and provisions them appropriately so they can be used by the VM.
VMs are isolated from the rest of the system, and multiple VMs can exist on a single piece of hardware, like a server. They can be moved between host servers depending on the demand or to use resources more efficiently.`},{header:"What is a Hypervisor?",slug:"what-is-a-hypervisor",content:"A Hypervisor sometimes called a Virtual Machine Monitor (VMM), isolates the operating system and resources from the virtual machines and enables the creation and management of those VMs. The hypervisor treats resources like CPU, memory, and storage as a pool of resources that can be easily reallocated between existing guests or new virtual machines."},{header:"Why use a Virtual Machine?",slug:"why-use-a-virtual-machine",content:`Server consolidation is a top reason to use VMs. Most operating system and application deployments only use a small amount of the physical resources available. By virtualizing our servers, we can place many virtual servers onto each physical server to improve hardware utilization. This keeps us from needing to purchase additional physical resources.
A VM provides an environment that is isolated from the rest of a system, so whatever is running inside a VM won't interfere with anything else running on the host hardware. Because VMs are isolated, they are a good option for testing new applications or setting up a production environment. We can also run a single-purpose VM to support a specific use case.`},{header:"Containers",slug:"containers",content:"A container is a standard unit of software that packages up code and all its dependencies such as specific versions of runtimes and libraries so that the application runs quickly and reliably from one computing environment to another. Containers offer a logical packaging mechanism in which applications can be abstracted from the environment in which they actually run. This decoupling allows container-based applications to be deployed easily and consistently, regardless of the target environment."},{header:"Why do we need containers?",slug:"why-do-we-need-containers",content:`Let's discuss some advantages of using containers:
Separation of responsibility
Containerization provides a clear separation of responsibility, as developers focus on application logic and dependencies, while operations teams can focus on deployment and management.
Workload portability
Containers can run virtually anywhere, greatly easing development and deployment.
Application isolation
Containers virtualize CPU, memory, storage, and network resources at the operating system level, providing developers with a view of the OS logically isolated from other applications.
Agile development
Containers allow developers to move much more quickly by avoiding concerns about dependencies and environments.
Efficient operations
Containers are lightweight and allow us to use just the computing resources we need.`},{header:"Virtualization vs Containerization",slug:"virtualization-vs-containerization",content:`virtualization-vs-containerization
In traditional virtualization, a hypervisor virtualizes physical hardware. The result is that each virtual machine contains a guest OS, a virtual copy of the hardware that the OS requires to run, and an application and its associated libraries and dependencies.
Instead of virtualizing the underlying hardware, containers virtualize the operating system so each container contains only the application and its dependencies making them much more lightweight than VMs. Containers also share the OS kernel and use a fraction of the memory VMs require.`},{header:"OAuth 2.0 and OpenID Connect (OIDC)",slug:"oauth-2-0-and-openid-connect-oidc",content:""},{header:"OAuth 2.0",slug:"oauth-2-0",content:"OAuth 2.0, which stands for Open Authorization, is a standard designed to provide consented access to resources on behalf of the user, without ever sharing the user's credentials. OAuth 2.0 is an authorization protocol and not an authentication protocol, it is designed primarily as a means of granting access to a set of resources, for example, remote APIs or user's data."},{header:"Concepts",slug:"concepts-3",content:`The OAuth 2.0 protocol defines the following entities: Resource Owner: The user or system that owns the protected resources and can grant access to them.
Client: The client is the system that requires access to the protected resources.
Authorization Server: This server receives requests from the Client for Access Tokens and issues them upon successful authentication and consent by the Resource Owner.
Resource Server: A server that protects the user's resources and receives access requests from the Client. It accepts and validates an Access Token from the Client and returns the appropriate resources.
Scopes: They are used to specify exactly the reason for which access to resources may be granted. Acceptable scope values, and which resources they relate to, are dependent on the Resource Server.
Access Token: A piece of data that represents the authorization to access resources on behalf of the end-user.`},{header:"How does OAuth 2.0 work?",slug:"how-does-oauth-2-0-work",content:`Let's learn how OAuth 2.0 works:
oauth2 The client requests authorization from the Authorization Server, supplying the client id and secret as identification. It also provides the scopes and an endpoint URI to send the Access Token or the Authorization Code.
The Authorization Server authenticates the client and verifies that the requested scopes are permitted.
The resource owner interacts with the authorization server to grant access.
The Authorization Server redirects back to the client with either an Authorization Code or Access Token, depending on the grant type. A Refresh Token may also be returned.
With the Access Token, the client can request access to the resource from the Resource Server.`},{header:"Disadvantages",slug:"disadvantages-24",content:`Here are the most common disadvantages of OAuth 2.0: Lacks built-in security features.
No standard implementation.
No common set of scopes.`},{header:"OpenID Connect",slug:"openid-connect",content:`OAuth 2.0 is designed only for authorization, for granting access to data and features from one application to another. OpenID Connect (OIDC) is a thin layer that sits on top of OAuth 2.0 that adds login and profile information about the person who is logged in.
When an Authorization Server supports OIDC, it is sometimes called an identity provider (IdP), since it provides information about the Resource Owner back to the Client. OpenID Connect is relatively new, resulting in lower adoption and industry implementation of best practices compared to OAuth.`},{header:"Concepts",slug:"concepts-4",content:`The OpenID Connect (OIDC) protocol defines the following entities: Relying Party: The current application.
OpenID Provider: This is essentially an intermediate service that provides a one-time code to the Relying Party.
Token Endpoint: A web server that accepts the One-Time Code (OTC) and provides an access code that's valid for an hour. The main difference between OIDC and OAuth 2.0 is that the token is provided using JSON Web Token (JWT).
UserInfo Endpoint: The Relying Party communicates with this endpoint, providing a secure token and receiving information about the end-user Both OAuth 2.0 and OIDC are easy to implement and are JSON based, which is supported by most web and mobile applications. However, the OpenID Connect (OIDC) specification is more strict than that of basic OAuth.`},{header:"Single Sign-On (SSO)",slug:"single-sign-on-sso",content:`Single Sign-On (SSO) is an authentication process in which a user is provided access to multiple applications or websites by using only a single set of login credentials. This prevents the need for the user to log separately into the different applications.
The user credentials and other identifying information are stored and managed by a centralized system called Identity Provider (IdP). The Identity Provider is a trusted system that provides access to other websites and applications.
Single Sign-On (SSO) based authentication systems are commonly used in enterprise environments where employees require access to multiple applications of their organizations.`},{header:"Components",slug:"components-2",content:"Let's discuss some key components of Single Sign-On (SSO)."},{header:"Identity Provider (IdP)",slug:"identity-provider-idp",content:`User Identity information is stored and managed by a centralized system called Identity Provider (IdP). The Identity Provider authenticates the user and provides access to the service provider.
The identity provider can directly authenticate the user by validating a username and password or by validating an assertion about the user's identity as presented by a separate identity provider. The identity provider handles the management of user identities in order to free the service provider from this responsibility.`},{header:"Service Provider",slug:"service-provider",content:"A service provider provides services to the end-user. They rely on identity providers to assert the identity of a user, and typically certain attributes about the user are managed by the identity provider. Service providers may also maintain a local account for the user along with attributes that are unique to their service."},{header:"Identity Broker",slug:"identity-broker",content:"An identity broker acts as an intermediary that connects multiple service providers with various different identity providers. Using Identity Broker, we can perform single sign-on over any application without the hassle of the protocol it follows."},{header:"SAML",slug:"saml",content:`Security Assertion Markup Language is an open standard that allows clients to share security information about identity, authentication, and permission across different systems. SAML is implemented with the Extensible Markup Language (XML) standard for sharing data.
SAML specifically enables identity federation, making it possible for identity providers (IdPs) to seamlessly and securely pass authenticated identities and their attributes to service providers.`},{header:"How does SSO work?",slug:"how-does-sso-work",content:`Now, let's discuss how Single Sign-On works:
sso The user requests a resource from their desired application.
The application redirects the user to the Identity Provider (IdP) for authentication.
The user signs in with their credentials (usually, username and password).
Identity Provider (IdP) sends a Single Sign-On response back to the client application.
The application grants access to the user.`},{header:"SAML vs OAuth 2.0 and OpenID Connect (OIDC)",slug:"saml-vs-oauth-2-0-and-openid-connect-oidc",content:`There are many differences between SAML, OAuth, and OIDC. SAML uses XML to pass messages, while OAuth and OIDC use JSON. OAuth provides a simpler experience, while SAML is geared towards enterprise security.
OAuth and OIDC use RESTful communication extensively, which is why mobile, and modern web applications find OAuth and OIDC a better experience for the user. SAML, on the other hand, drops a session cookie in a browser that allows a user to access certain web pages. This is great for short-lived workloads.
OIDC is developer-friendly and simpler to implement, which broadens the use cases for which it might be implemented. It can be implemented from scratch pretty fast, via freely available libraries in all common programming languages. SAML can be complex to install and maintain, which only enterprise-size companies can handle well.
OpenID Connect is essentially a layer on top of the OAuth framework. Therefore, it can offer a built-in layer of permission that asks a user to agree to what the service provider might access. Although SAML is also capable of allowing consent flow, it achieves this by hard-coding carried out by a developer and not as part of its protocol.
Both of these authentication protocols are good at what they do. As always, a lot depends on our specific use cases and target audience.`},{header:"Advantages",slug:"advantages-29",content:`Following are the benefits of using Single Sign-On: Ease of use as users only need to remember one set of credentials.
Ease of access without having to go through a lengthy authorization process.
Enforced security and compliance to protect sensitive data.
Simplifying the management with reduced IT support cost and admin time.`},{header:"Disadvantages",slug:"disadvantages-25",content:`Here are some disadvantages of Single Sign-On: Single Password Vulnerability, if the main SSO password gets compromised, all the supported applications get compromised.
The authentication process using Single Sign-On is slower than traditional authentication as every application has to request the SSO provider for verification.`},{header:"Examples",slug:"examples-16",content:`These are some commonly used Identity Providers (IdP): Okta
Google
Auth0
OneLogin`},{header:"SSL, TLS, mTLS",slug:"ssl-tls-mtls",content:`Let's briefly discuss some important communication security protocols such as SSL, TLS, and mTLS. I would say that from a "big picture" system design perspective, this topic is not very important but still good to know about.`},{header:"SSL",slug:"ssl",content:"SSL stands for Secure Sockets Layer, and it refers to a protocol for encrypting and securing communications that take place on the internet. It was first developed in 1995 but since has been deprecated in favor of TLS (Transport Layer Security)."},{header:"Why is it called an SSL certificate if it is deprecated?",slug:"why-is-it-called-an-ssl-certificate-if-it-is-deprecated",content:"Most major certificate providers still refer to certificates as SSL certificates, which is why the naming convention persists."},{header:"Why was SSL so important?",slug:"why-was-ssl-so-important",content:"Originally, data on the web was transmitted in plaintext that anyone could read if they intercepted the message. SSL was created to correct this problem and protect user privacy. By encrypting any data that goes between the user and a web server, SSL also stops certain kinds of cyber attacks by preventing attackers from tampering with data in transit."},{header:"TLS",slug:"tls",content:`Transport Layer Security, or TLS, is a widely adopted security protocol designed to facilitate privacy and data security for communications over the internet. TLS evolved from a previous encryption protocol called Secure Sockets Layer (SSL). A primary use case of TLS is encrypting the communication between web applications and servers.
There are three main components to what the TLS protocol accomplishes: Encryption: hides the data being transferred from third parties.
Authentication: ensures that the parties exchanging information are who they claim to be.
Integrity: verifies that the data has not been forged or tampered with.`},{header:"mTLS",slug:"mtls",content:"Mutual TLS, or mTLS, is a method for mutual authentication. mTLS ensures that the parties at each end of a network connection are who they claim to be by verifying that they both have the correct private key. The information within their respective TLS certificates provides additional verification."},{header:"Why use mTLS?",slug:"why-use-mtls",content:`mTLS helps ensure that the traffic is secure and trusted in both directions between a client and server. This provides an additional layer of security for users who log in to an organization's network or applications. It also verifies connections with client devices that do not follow a login process, such as Internet of Things (IoT) devices.
Nowadays, mTLS is commonly used by microservices or distributed systems in a zero trust security model to verify each other.`},{header:"System Design Interviews",slug:"system-design-interviews",content:`System design is a very extensive topic and system design interviews are designed to evaluate your capability to produce technical solutions to abstract problems, as such, they're not designed for a specific answer. The unique aspect of system design interviews is the two-way nature between the candidate and the interviewer.
Expectations are quite different at different engineering levels as well. This is because someone with a lot of practical experience will approach it quite differently from someone who's new in the industry. As a result, it's hard to come up with a single strategy that will help us stay organized during the interview.
Let's look at some common strategies for the system design interviews:`},{header:"Requirements clarifications",slug:"requirements-clarifications",content:"System design interview questions, by nature, are vague or abstract. Asking questions about the exact scope of the problem, and clarifying functional requirements early in the interview is essential. Usually, requirements are divided into three parts:"},{header:"Functional requirements",slug:"functional-requirements",content:`These are the requirements that the end user specifically demands as basic functionalities that the system should offer. All these functionalities need to be necessarily incorporated into the system as part of the contract.
For example: "What are the features that we need to design for this system?"
"What are the edge cases we need to consider, if any, in our design?"`},{header:"Non-functional requirements",slug:"non-functional-requirements",content:`These are the quality constraints that the system must satisfy according to the project contract. The priority or extent to which these factors are implemented varies from one project to another. They are also called non-behavioral requirements. For example, portability, maintainability, reliability, scalability, security, etc.
For example: "Each request should be processed with the minimum latency"
"System should be highly available"`},{header:"Extended requirements",slug:"extended-requirements",content:`These are basically "nice to have" requirements that might be out of the scope of the system.
For example: "Our system should record metrics and analytics"
"Service health and performance monitoring?"`},{header:"Estimation and Constraints",slug:"estimation-and-constraints",content:`Estimate the scale of the system we're going to design. It is important to ask questions such as: "What is the desired scale that this system will need to handle?"
"What is the read/write ratio of our system?"
"How many requests per second?"
"How much storage will be needed?" These questions will help us scale our design later.`},{header:"Data model design",slug:"data-model-design",content:`Once we have the estimations, we can start with defining the database schema. Doing so in the early stages of the interview would help us to understand the data flow which is the core of every system. In this step, we basically define all the entities and relationships between them. "What are the different entities in the system?"
"What are the relationships between these entities?"
"How many tables do we need?"
"Is NoSQL a better choice here?"`},{header:"API design",slug:"api-design",content:`Next, we can start designing APIs for the system. These APIs will help us define the expectations from the system explicitly. We don't have to write any code, just a simple interface defining the API requirements such as parameters, functions, classes, types, entities, etc.
For example:
createUser(name: string, email: string): User It is advised to keep the interface as simple as possible and come back to it later when covering extended requirements.`},{header:"High-level component design",slug:"high-level-component-design",content:`Now we have established our data model and API design, it's time to identify system components (such as Load Balancers, API Gateway, etc.) that are needed to solve our problem and draft the first design of our system. "Is it best to design a monolithic or a microservices architecture?"
"What type of database should we use?" Once we have a basic diagram, we can start discussing with the interviewer how the system will work from the client's perspective.`},{header:"Detailed design",slug:"detailed-design",content:`Now it's time to go into detail about the major components of the system we designed. As always discuss with the interviewer which component may need further improvements.
Here is a good opportunity to demonstrate your experience in the areas of your expertise. Present different approaches, advantages, and disadvantages. Explain your design decisions, and back them up with examples. This is also a good time to discuss any additional features the system might be able to support, though this is optional. "How should we partition our data?"
"What about load distribution?"
"Should we use cache?"
"How will we handle a sudden spike in traffic?" Also, try not to be too opinionated about certain technologies, statements like "I believe that NoSQL databases are just better, SQL databases are not scalable" reflect poorly. As someone who has interviewed a lot of people over the years, my two cents here would be to be humble about what you know and what you do not. Use your existing knowledge with examples to navigate this part of the interview.`},{header:"Identify and resolve bottlenecks",slug:"identify-and-resolve-bottlenecks",content:`Finally, it's time to discuss bottlenecks and approaches to mitigate them. Here are some important questions to ask: "Do we have enough database replicas?"
"Is there any single point of failure?"
"Is database sharding required?"
"How can we make our system more robust?"
"How to improve the availability of our cache?" Make sure to read the engineering blog of the company you're interviewing with. This will help you get a sense of what technology stack they're using and which problems are important to them.`},{header:"URL Shortener",slug:"url-shortener",content:"Let's design a URL shortener, similar to services like Bitly, TinyURL."},{header:"What is a URL Shortener?",slug:"what-is-a-url-shortener",content:`A URL shortener service creates an alias or a short URL for a long URL. Users are redirected to the original URL when they visit these short links.
For example, the following long URL can be changed to a shorter URL.
Long URL: https://karanpratapsingh.com/courses/system-design/url-shortener
Short URL: https://bit.ly/3I71d3o`},{header:"Why do we need a URL shortener?",slug:"why-do-we-need-a-url-shortener",content:"URL shortener saves space in general when we are sharing URLs. Users are also less likely to mistype shorter URLs. Moreover, we can also optimize links across devices, this allows us to track individual links."},{header:"Requirements",slug:"requirements",content:"Our URL shortening system should meet the following requirements:"},{header:"Functional requirements",slug:"functional-requirements-1",content:`Given a URL, our service should generate a shorter and unique alias for it.
Users should be redirected to the original URL when they visit the short link.
Links should expire after a default timespan.`},{header:"Non-functional requirements",slug:"non-functional-requirements-1",content:`High availability with minimal latency.
The system should be scalable and efficient.`},{header:"Extended requirements",slug:"extended-requirements-1",content:`Prevent abuse of services.
Record analytics and metrics for redirections.`},{header:"Estimation and Constraints",slug:"estimation-and-constraints-1",content:`Let's start with the estimation and constraints.
Note: Make sure to check any scale or traffic related assumptions with your interviewer.`},{header:"Traffic",slug:"traffic",content:`This will be a read-heavy system, so let's assume a 100:1 read/write ratio with 100 million links generated per month.
Reads/Writes Per month
For reads per month:
$$
100 \\times 100 \\space million = 10 \\space billion/month
$$
Similarly for writes:
$$
1 \\times 100 \\space million = 100 \\space million/month
$$
What would be Requests Per Second (RPS) for our system?
100 million requests per month translate into 40 requests per second.
$$
\\frac{100 \\space million}{(30 \\space days \\times 24 \\space hrs \\times 3600 \\space seconds)} = \\sim 40 \\space URLs/second
$$
And with a 100:1 read/write ratio, the number of redirections will be:
$$
100 \\times 40 \\space URLs/second = 4000 \\space requests/second
$$`},{header:"Bandwidth",slug:"bandwidth",content:`Since we expect about 40 URLs every second, and if we assume each request is of size 500 bytes then the total incoming data for write requests would be:
$$
40 \\times 500 \\space bytes = 20 \\space KB/second
$$
Similarly, for the read requests, since we expect about 4K redirections, the total outgoing data would be:
$$
4000 \\space URLs/second \\times 500 \\space bytes = \\sim 2 \\space MB/second
$$`},{header:"Storage",slug:"storage-2",content:`For storage, we will assume we store each link or record in our database for 10 years. Since we expect around 100M new requests every month, the total number of records we will need to store would be:
$$
100 \\space million \\times 10\\space years \\times 12 \\space months = 12 \\space billion
$$
Like earlier, if we assume each stored record will be approximately 500 bytes. We will need around 6TB of storage:
$$
12 \\space billion \\times 500 \\space bytes = 6 \\space TB
$$`},{header:"Cache",slug:"cache",content:`For caching, we will follow the classic Pareto principle also known as the 80/20 rule. This means that 80% of the requests are for 20% of the data, so we can cache around 20% of our requests.
Since we get around 4K read or redirection requests each second, this translates into 350M requests per day.
$$
4000 \\space URLs/second \\times 24 \\space hours \\times 3600 \\space seconds = \\sim 350 \\space million \\space requests/day
$$
Hence, we will need around 35GB of memory per day.
$$
20 \\space percent \\times 350 \\space million \\times 500 \\space bytes = 35 \\space GB/day
$$`},{header:"High-level estimate",slug:"high-level-estimate",content:`Here is our high-level estimate: Type
Estimate Writes (New URLs)
40/s Reads (Redirection)
4K/s Bandwidth (Incoming)
20 KB/s Bandwidth (Outgoing)
2 MB/s Storage (10 years)
6 TB Memory (Caching)
~35 GB/day`},{header:"Data model design",slug:"data-model-design-1",content:`Next, we will focus on the data model design. Here is our database schema:
url-shortener-datamodel
Initially, we can get started with just two tables:
users
Stores user's details such as name, email, createdAt, etc.
urls
Contains the new short URL's properties such as expiration, hash, originalURL, and userID of the user who created the short URL. We can also use the hash column as an index to improve the query performance.`},{header:"What kind of database should we use?",slug:"what-kind-of-database-should-we-use",content:`Since the data is not strongly relational, NoSQL databases such as Amazon DynamoDB, Apache Cassandra, or MongoDB will be a better choice here, if we do decide to use an SQL database then we can use something like Azure SQL Database or Amazon RDS.
For more details, refer to SQL vs NoSQL.`},{header:"API design",slug:"api-design-1",content:"Let us do a basic API design for our services:"},{header:"Create URL",slug:"create-url",content:`This API should create a new short URL in our system given an original URL.
createURL(apiKey: string, originalURL: string, expiration?: Date): string Parameters
API Key (string): API key provided by the user.
Original URL (string): Original URL to be shortened.
Expiration (Date): Expiration date of the new URL (optional).
Returns
Short URL (string): New shortened URL.`},{header:"Get URL",slug:"get-url",content:`This API should retrieve the original URL from a given short URL.
getURL(apiKey: string, shortURL: string): string Parameters
API Key (string): API key provided by the user.
Short URL (string): Short URL mapped to the original URL.
Returns
Original URL (string): Original URL to be retrieved.`},{header:"Delete URL",slug:"delete-url",content:`This API should delete a given shortURL from our system.
deleteURL(apiKey: string, shortURL: string): boolean Parameters
API Key (string): API key provided by the user.
Short URL (string): Short URL to be deleted.
Returns
Result (boolean): Represents whether the operation was successful or not.`},{header:"Why do we need an API key?",slug:"why-do-we-need-an-api-key",content:"As you must've noticed, we're using an API key to prevent abuse of our services. Using this API key we can limit the users to a certain number of requests per second or minute. This is quite a standard practice for developer APIs and should cover our extended requirement."},{header:"High-level design",slug:"high-level-design",content:"Now let us do a high-level design of our system."},{header:"URL Encoding",slug:"url-encoding",content:`Our system's primary goal is to shorten a given URL, let's look at different approaches:
Base62 Approach
In this approach, we can encode the original URL using Base62 which consists of the capital letters A-Z, the lower case letters a-z, and the numbers 0-9.
$$
Number \\space of \\space URLs = 62^N
$$
Where,
N: Number of characters in the generated URL.
So, if we want to generate a URL that is 7 characters long, we will generate ~3.5 trillion different URLs.
$$
\\begin{gather*}
62^5 = \\sim 916 \\space million \\space URLs \\
62^6 = \\sim 56.8 \\space billion \\space URLs \\
62^7 = \\sim 3.5 \\space trillion \\space URLs
\\end{gather*}
$$
This is the simplest solution here, but it does not guarantee non-duplicate or collision-resistant keys.
MD5 Approach
The MD5 message-digest algorithm is a widely used hash function producing a 128-bit hash value (or 32 hexadecimal digits). We can use these 32 hexadecimal digits for generating 7 characters long URL.
$$
MD5(original_url) \\rightarrow base62encode \\rightarrow hash
$$
However, this creates a new issue for us, which is duplication and collision. We can try to re-compute the hash until we find a unique one but that will increase the overhead of our systems. It's better to look for more scalable approaches.
Counter Approach
In this approach, we will start with a single server which will maintain the count of the keys generated. Once our service receives a request, it can reach out to the counter which returns a unique number and increments the counter. When the next request comes the counter again returns the unique number and this goes on.
$$
Counter(0-3.5 \\space trillion) \\rightarrow base62encode \\rightarrow hash
$$
The problem with this approach is that it can quickly become a single point for failure. And if we run multiple instances of the counter we can have collision as it's essentially a distributed system.
To solve this issue we can use a distributed system manager such as Zookeeper which can provide distributed synchronization. Zookeeper can maintain multiple ranges for our servers.
$$
\\begin{align*}
& Range \\space 1: \\space 1 \\rightarrow 1,000,000 \\
& Range \\space 2: \\space 1,000,001 \\rightarrow 2,000,000 \\
& Range \\space 3: \\space 2,000,001 \\rightarrow 3,000,000 \\
& ...
\\end{align*}
$$
Once a server reaches its maximum range Zookeeper will assign an unused counter range to the new server. This approach can guarantee non-duplicate and collision-resistant URLs. Also, we can run multiple instances of Zookeeper to remove the single point of failure.`},{header:"Key Generation Service (KGS)",slug:"key-generation-service-kgs",content:`As we discussed, generating a unique key at scale without duplication and collisions can be a bit of a challenge. To solve this problem, we can create a standalone Key Generation Service (KGS) that generates a unique key ahead of time and stores it in a separate database for later use. This approach can make things simple for us.
How to handle concurrent access?
Once the key is used, we can mark it in the database to make sure we don't reuse it, however, if there are multiple server instances reading data concurrently, two or more servers might try to use the same key.
The easiest way to solve this would be to store keys in two tables. As soon as a key is used, we move it to a separate table with appropriate locking in place. Also, to improve reads, we can keep some of the keys in memory.
KGS database estimations
As per our discussion, we can generate up to ~56.8 billion unique 6 character long keys which will result in us having to store 300 GB of keys.
$$
6 \\space characters \\times 56.8 \\space billion = \\sim 390 \\space GB
$$
While 390 GB seems like a lot for this simple use case, it is important to remember this is for the entirety of our service lifetime and the size of the keys database would not increase like our main database.`},{header:"Caching",slug:"caching-1",content:`Now, let's talk about caching. As per our estimations, we will require around ~35 GB of memory per day to cache 20% of the incoming requests to our services. For this use case, we can use Redis or Memcached servers alongside our API server.
For more details, refer to caching.`},{header:"Design",slug:"design",content:`Now that we have identified some core components, let's do the first draft of our system design.
url-shortener-basic-design
Here's how it works:
Creating a new URL When a user creates a new URL, our API server requests a new unique key from the Key Generation Service (KGS).
Key Generation Service provides a unique key to the API server and marks the key as used.
API server writes the new URL entry to the database and cache.
Our service returns an HTTP 201 (Created) response to the user. Accessing a URL When a client navigates to a certain short URL, the request is sent to the API servers.
The request first hits the cache, and if the entry is not found there then it is retrieved from the database and an HTTP 301 (Redirect) is issued to the original URL.
If the key is still not found in the database, an HTTP 404 (Not found) error is sent to the user.`},{header:"Detailed design",slug:"detailed-design-1",content:"It's time to discuss the finer details of our design."},{header:"Data Partitioning",slug:"data-partitioning-1",content:`To scale out our databases we will need to partition our data. Horizontal partitioning (aka Sharding) can be a good first step. We can use partitions schemes such as: Hash-Based Partitioning
List-Based Partitioning
Range Based Partitioning
Composite Partitioning The above approaches can still cause uneven data and load distribution, we can solve this using Consistent hashing.
For more details, refer to Sharding and Consistent Hashing.`},{header:"Database cleanup",slug:"database-cleanup",content:`This is more of a maintenance step for our services and depends on whether we keep the expired entries or remove them. If we do decide to remove expired entries, we can approach this in two different ways:
Active cleanup
In active cleanup, we will run a separate cleanup service which will periodically remove expired links from our storage and cache. This will be a very lightweight service like a cron job.
Passive cleanup
For passive cleanup, we can remove the entry when a user tries to access an expired link. This can ensure a lazy cleanup of our database and cache.`},{header:"Cache",slug:"cache-1",content:`Now let us talk about caching.
Which cache eviction policy to use?
As we discussed before, we can use solutions like Redis or Memcached and cache 20% of the daily traffic but what kind of cache eviction policy would best fit our needs?
Least Recently Used (LRU) can be a good policy for our system. In this policy, we discard the least recently used key first.
How to handle cache miss?
Whenever there is a cache miss, our servers can hit the database directly and update the cache with the new entries.`},{header:"Metrics and Analytics",slug:"metrics-and-analytics",content:"Recording analytics and metrics is one of our extended requirements. We can store and update metadata like visitor's country, platform, the number of views, etc alongside the URL entry in our database."},{header:"Security",slug:"security-2",content:`For security, we can introduce private URLs and authorization. A separate table can be used to store user ids that have permission to access a specific URL. If a user does not have proper permissions, we can return an HTTP 401 (Unauthorized) error.
We can also use an API Gateway as they can support capabilities like authorization, rate limiting, and load balancing out of the box.`},{header:"Identify and resolve bottlenecks",slug:"identify-and-resolve-bottlenecks-1",content:`url-shortener-advanced-design
Let us identify and resolve bottlenecks such as single points of failure in our design: "What if the API service or Key Generation Service crashes?"
"How will we distribute our traffic between our components?"
"How can we reduce the load on our database?"
"What if the key database used by KGS fails?"
"How to improve the availability of our cache?" To make our system more resilient we can do the following: Running multiple instances of our Servers and Key Generation Service.
Introducing load balancers between clients, servers, databases, and cache servers.
Using multiple read replicas for our database as it's a read-heavy system.
Standby replica for our key database in case it fails.
Multiple instances and replicas for our distributed cache.`},{header:"WhatsApp",slug:"whatsapp",content:"Let's design a WhatsApp like instant messaging service, similar to services like Facebook Messenger, and WeChat."},{header:"What is WhatsApp?",slug:"what-is-whatsapp",content:"WhatsApp is a chat application that provides instant messaging services to its users. It is one of the most used mobile applications on the planet, connecting over 2 billion users in 180+ countries. WhatsApp is also available on the web."},{header:"Requirements",slug:"requirements-1",content:"Our system should meet the following requirements:"},{header:"Functional requirements",slug:"functional-requirements-2",content:`Should support one-on-one chat.
Group chats (max 100 people).
Should support file sharing (image, video, etc.).`},{header:"Non-functional requirements",slug:"non-functional-requirements-2",content:`High availability with minimal latency.
The system should be scalable and efficient.`},{header:"Extended requirements",slug:"extended-requirements-2",content:`Sent, Delivered, and Read receipts of the messages.
Show the last seen time of users.
Push notifications.`},{header:"Estimation and Constraints",slug:"estimation-and-constraints-2",content:`Let's start with the estimation and constraints.
Note: Make sure to check any scale or traffic-related assumptions with your interviewer.`},{header:"Traffic",slug:"traffic-1",content:`Let us assume we have 50 million daily active users (DAU) and on average each user sends at least 10 messages to 2 different people every day. This gives us 2 billion messages per day.
$$
50 \\space million \\times 20 \\space messages = 2 \\space billion/day
$$
Messages can also contain media such as images, videos, or other files. We can assume that 5 percent of messages are media files shared by the users, which gives us additional 200 million files we would need to store.
$$
5 \\space percent \\times 2 \\space billion = 200 \\space million/day
$$
What would be Requests Per Second (RPS) for our system?
2 billion requests per day translate into 24K requests per second.
$$
\\frac{2 \\space billion}{(24 \\space hrs \\times 3600 \\space seconds)} = \\sim 24K \\space requests/second
$$`},{header:"Storage",slug:"storage-3",content:`If we assume each message on average is 100 bytes, we will require about 200 GB of database storage every day.
$$
2 \\space billion \\times 100 \\space bytes = \\sim 200 \\space GB/day
$$
As per our requirements, we also know that around 5 percent of our daily messages (100 million) are media files. If we assume each file is 50 KB on average, we will require 10 TB of storage every day.
$$
100 \\space million \\times 100 \\space KB = 10 \\space TB/day
$$
And for 10 years, we will require about 38 PB of storage.
$$
(10 \\space TB + 0.2 \\space TB) \\times 10 \\space years \\times 365 \\space days = \\sim 38 \\space PB
$$`},{header:"Bandwidth",slug:"bandwidth-1",content:`As our system is handling 10.2 TB of ingress every day, we will require a minimum bandwidth of around 120 MB per second.
$$
\\frac{10.2 \\space TB}{(24 \\space hrs \\times 3600 \\space seconds)} = \\sim 120 \\space MB/second
$$`},{header:"High-level estimate",slug:"high-level-estimate-1",content:`Here is our high-level estimate: Type
Estimate Daily active users (DAU)
50 million Requests per second (RPS)
24K/s Storage (per day)
~10.2 TB Storage (10 years)
~38 PB Bandwidth
~120 MB/s`},{header:"Data model design",slug:"data-model-design-2",content:`This is the general data model which reflects our requirements.
whatsapp-datamodel
We have the following tables:
users
This table will contain a user's information such as name, phoneNumber, and other details.
messages
As the name suggests, this table will store messages with properties such as type (text, image, video, etc.), content, and timestamps for message delivery. The message will also have a corresponding chatID or groupID.
chats
This table basically represents a private chat between two users and can contain multiple messages.
users_chats
This table maps users and chats as multiple users can have multiple chats (N:M relationship) and vice versa.
groups
This table represents a group made up of multiple users.
users_groups
This table maps users and groups as multiple users can be a part of multiple groups (N:M relationship) and vice versa.`},{header:"What kind of database should we use?",slug:"what-kind-of-database-should-we-use-1",content:`While our data model seems quite relational, we don't necessarily need to store everything in a single database, as this can limit our scalability and quickly become a bottleneck.
We will split the data between different services each having ownership over a particular table. Then we can use a relational database such as PostgreSQL or a distributed NoSQL database such as Apache Cassandra for our use case.`},{header:"API design",slug:"api-design-2",content:"Let us do a basic API design for our services:"},{header:"Get all chats or groups",slug:"get-all-chats-or-groups",content:`This API will get all chats or groups for a given userID.
getAll(userID: UUID): Chat[] | Group[] Parameters
User ID (UUID): ID of the current user.
Returns
Result (Chat[] | Group[]): All the chats and groups the user is a part of.`},{header:"Get messages",slug:"get-messages",content:`Get all messages for a user given the channelID (chat or group id).
getMessages(userID: UUID, channelID: UUID): Message[] Parameters
User ID (UUID): ID of the current user.
Channel ID (UUID): ID of the channel (chat or group) from which messages need to be retrieved.
Returns
Messages (Message[]): All the messages in a given chat or group.`},{header:"Send message",slug:"send-message",content:`Send a message from a user to a channel (chat or group).
sendMessage(userID: UUID, channelID: UUID, message: Message): boolean Parameters
User ID (UUID): ID of the current user.
Channel ID (UUID): ID of the channel (chat or group) user wants to send a message to.
Message (Message): The message (text, image, video, etc.) that the user wants to send.
Returns
Result (boolean): Represents whether the operation was successful or not.`},{header:"Join or leave a group",slug:"join-or-leave-a-group",content:`Send a message from a user to a channel (chat or group).
joinGroup(userID: UUID, channelID: UUID): boolean
leaveGroup(userID: UUID, channelID: UUID): boolean Parameters
User ID (UUID): ID of the current user.
Channel ID (UUID): ID of the channel (chat or group) the user wants to join or leave.
Returns
Result (boolean): Represents whether the operation was successful or not.`},{header:"High-level design",slug:"high-level-design-1",content:"Now let us do a high-level design of our system."},{header:"Architecture",slug:"architecture",content:`We will be using microservices architecture since it will make it easier to horizontally scale and decouple our services. Each service will have ownership of its own data model. Let's try to divide our system into some core services.
User Service
This is an HTTP-based service that handles user-related concerns such as authentication and user information.
Chat Service
The chat service will use WebSockets and establish connections with the client to handle chat and group message-related functionality. We can also use cache to keep track of all the active connections sort of like sessions which will help us determine if the user is online or not.
Notification Service
This service will simply send push notifications to the users. It will be discussed in detail separately.
Presence Service
The presence service will keep track of the last seen status of all users. It will be discussed in detail separately.
Media service
This service will handle the media (images, videos, files, etc.) uploads. It will be discussed in detail separately.
What about inter-service communication and service discovery?
Since our architecture is microservices-based, services will be communicating with each other as well. Generally, REST or HTTP performs well but we can further improve the performance using gRPC which is more lightweight and efficient.
Service discovery is another thing we will have to take into account. We can also use a service mesh that enables managed, observable, and secure communication between individual services.
Note: Learn more about REST, GraphQL, gRPC and how they compare with each other.`},{header:"Real-time messaging",slug:"real-time-messaging",content:`How do we efficiently send and receive messages? We have two different options:
Pull model
The client can periodically send an HTTP request to servers to check if there are any new messages. This can be achieved via something like Long polling.
Push model
The client opens a long-lived connection with the server and once new data is available it will be pushed to the client. We can use WebSockets or Server-Sent Events (SSE) for this.
The pull model approach is not scalable as it will create unnecessary request overhead on our servers and most of the time the response will be empty, thus wasting our resources. To minimize latency, using the push model with WebSockets is a better choice because then we can push data to the client once it's available without any delay, given the connection is open with the client. Also, WebSockets provide full-duplex communication, unlike Server-Sent Events (SSE) which are only unidirectional.
Note: Learn more about Long polling, WebSockets, Server-Sent Events (SSE).`},{header:"Last seen",slug:"last-seen",content:`To implement the last seen functionality, we can use a heartbeat mechanism, where the client can periodically ping the servers indicating its liveness. Since this needs to be as low overhead as possible, we can store the last active timestamp in the cache as follows: Key
Value User A
2022-07-01T14:32:50 User B
2022-07-05T05:10:35 User C
2022-07-10T04:33:25 This will give us the last time the user was active. This functionality will be handled by the presence service combined with Redis or Memcached as our cache.
Another way to implement this is to track the latest action of the user, once the last activity crosses a certain threshold, such as "user hasn't performed any action in the last 30 seconds", we can show the user as offline and last seen with the last recorded timestamp. This will be more of a lazy update approach and might benefit us over heartbeat in certain cases.`},{header:"Notifications",slug:"notifications",content:`Once a message is sent in a chat or a group, we will first check if the recipient is active or not, we can get this information by taking the user's active connection and last seen into consideration.
If the recipient is not active, the chat service will add an event to a message queue with additional metadata such as the client's device platform which will be used to route the notification to the correct platform later on.
The notification service will then consume the event from the message queue and forward the request to Firebase Cloud Messaging (FCM) or Apple Push Notification Service (APNS) based on the client's device platform (Android, iOS, web, etc). We can also add support for email and SMS.
Why are we using a message queue?
Since most message queues provide best-effort ordering which ensures that messages are generally delivered in the same order as they're sent and that a message is delivered at least once which is an important part of our service functionality.
While this seems like a classic publish-subscribe use case, it is actually not as mobile devices and browsers each have their own way of handling push notifications. Usually, notifications are handled externally via Firebase Cloud Messaging (FCM) or Apple Push Notification Service (APNS) unlike message fan-out which we commonly see in backend services. We can use something like Amazon SQS or RabbitMQ to support this functionality.`},{header:"Read receipts",slug:"read-receipts",content:"Handling read receipts can be tricky, for this use case we can wait for some sort of Acknowledgment (ACK) from the client to determine if the message was delivered and update the corresponding deliveredAt field. Similarly, we will mark the message as seen once the user opens the chat and update the corresponding seenAt timestamp field."},{header:"Design",slug:"design-1",content:`Now that we have identified some core components, let's do the first draft of our system design.
whatsapp-basic-design`},{header:"Detailed design",slug:"detailed-design-2",content:"It's time to discuss our design decisions in detail."},{header:"Data Partitioning",slug:"data-partitioning-2",content:`To scale out our databases we will need to partition our data. Horizontal partitioning (aka Sharding) can be a good first step. We can use partitions schemes such as: Hash-Based Partitioning
List-Based Partitioning
Range Based Partitioning
Composite Partitioning The above approaches can still cause uneven data and load distribution, we can solve this using Consistent hashing.
For more details, refer to Sharding and Consistent Hashing.`},{header:"Caching",slug:"caching-2",content:`In a messaging application, we have to be careful about using cache as our users expect the latest data, but many users will be requesting the same messages, especially in a group chat. So, to prevent usage spikes from our resources we can cache older messages.
Some group chats can have thousands of messages and sending that over the network will be really inefficient, to improve efficiency we can add pagination to our system APIs. This decision will be helpful for users with limited network bandwidth as they won't have to retrieve old messages unless requested.
Which cache eviction policy to use?
We can use solutions like Redis or Memcached and cache 20% of the daily traffic but what kind of cache eviction policy would best fit our needs?
Least Recently Used (LRU) can be a good policy for our system. In this policy, we discard the least recently used key first.
How to handle cache miss?
Whenever there is a cache miss, our servers can hit the database directly and update the cache with the new entries.
For more details, refer to Caching.`},{header:"Media access and storage",slug:"media-access-and-storage",content:`As we know, most of our storage space will be used for storing media files such as images, videos, or other files. Our media service will be handling both access and storage of the user media files.
But where can we store files at scale? Well, object storage is what we're looking for. Object stores break data files up into pieces called objects. It then stores those objects in a single repository, which can be spread out across multiple networked systems. We can also use distributed file storage such as HDFS or GlusterFS.
Fun fact: WhatsApp deletes media on its servers once it has been downloaded by the user.
We can use object stores like Amazon S3, Azure Blob Storage, or Google Cloud Storage for this use case.`},{header:"Content Delivery Network (CDN)",slug:"content-delivery-network-cdn-1",content:"Content Delivery Network (CDN) increases content availability and redundancy while reducing bandwidth costs. Generally, static files such as images, and videos are served from CDN. We can use services like Amazon CloudFront or Cloudflare CDN for this use case."},{header:"API gateway",slug:"api-gateway-1",content:`Since we will be using multiple protocols like HTTP, WebSocket, TCP/IP, deploying multiple L4 (transport layer) or L7 (application layer) type load balancers separately for each protocol will be expensive. Instead, we can use an API Gateway that supports multiple protocols without any issues.
API Gateway can also offer other features such as authentication, authorization, rate limiting, throttling, and API versioning which will improve the quality of our services.
We can use services like Amazon API Gateway or Azure API Gateway for this use case.`},{header:"Identify and resolve bottlenecks",slug:"identify-and-resolve-bottlenecks-2",content:`whatsapp-advanced-design
Let us identify and resolve bottlenecks such as single points of failure in our design: "What if one of our services crashes?"
"How will we distribute our traffic between our components?"
"How can we reduce the load on our database?"
"How to improve the availability of our cache?"
"Wouldn't API Gateway be a single point of failure?"
"How can we make our notification system more robust?"
"How can we reduce media storage costs"?
"Does chat service has too much responsibility?" To make our system more resilient we can do the following: Running multiple instances of each of our services.
Introducing load balancers between clients, servers, databases, and cache servers.
Using multiple read replicas for our databases.
Multiple instances and replicas for our distributed cache.
We can have a standby replica of our API Gateway.
Exactly once delivery and message ordering is challenging in a distributed system, we can use a dedicated message broker such as Apache Kafka or NATS to make our notification system more robust.
We can add media processing and compression capabilities to the media service to compress large files similar to WhatsApp which will save a lot of storage space and reduce cost.
We can create a group service separate from the chat service to further decouple our services.`},{header:"Twitter",slug:"twitter",content:"Let's design a Twitter like social media service, similar to services like Facebook, Instagram, etc."},{header:"What is Twitter?",slug:"what-is-twitter",content:"Twitter is a social media service where users can read or post short messages (up to 280 characters) called tweets. It is available on the web and mobile platforms such as Android and iOS."},{header:"Requirements",slug:"requirements-2",content:"Our system should meet the following requirements:"},{header:"Functional requirements",slug:"functional-requirements-3",content:`Should be able to post new tweets (can be text, image, video, etc.).
Should be able to follow other users.
Should have a newsfeed feature consisting of tweets from the people the user is following.
Should be able to search tweets.`},{header:"Non-Functional requirements",slug:"non-functional-requirements-3",content:`High availability with minimal latency.
The system should be scalable and efficient.`},{header:"Extended requirements",slug:"extended-requirements-3",content:`Metrics and analytics.
Retweet functionality.
Favorite tweets.`},{header:"Estimation and Constraints",slug:"estimation-and-constraints-3",content:`Let's start with the estimation and constraints.
Note: Make sure to check any scale or traffic-related assumptions with your interviewer.`},{header:"Traffic",slug:"traffic-2",content:`This will be a read-heavy system, let us assume we have 1 billion total users with 200 million daily active users (DAU), and on average each user tweets 5 times a day. This gives us 1 billion tweets per day.
$$
200 \\space million \\times 5 \\space tweets = 1 \\space billion/day
$$
Tweets can also contain media such as images, or videos. We can assume that 10 percent of tweets are media files shared by the users, which gives us additional 100 million files we would need to store.
$$
10 \\space percent \\times 1 \\space billion = 100 \\space million/day
$$
What would be Requests Per Second (RPS) for our system?
1 billion requests per day translate into 12K requests per second.
$$
\\frac{1 \\space billion}{(24 \\space hrs \\times 3600 \\space seconds)} = \\sim 12K \\space requests/second
$$`},{header:"Storage",slug:"storage-4",content:`If we assume each message on average is 100 bytes, we will require about 100 GB of database storage every day.
$$
1 \\space billion \\times 100 \\space bytes = \\sim 100 \\space GB/day
$$
We also know that around 10 percent of our daily messages (100 million) are media files per our requirements. If we assume each file is 50 KB on average, we will require 5 TB of storage every day.
$$
100 \\space million \\times 100 \\space KB = 5 \\space TB/day
$$
And for 10 years, we will require about 19 PB of storage.
$$
(5 \\space TB + 0.1 \\space TB) \\times 365 \\space days \\times 10 \\space years = \\sim 19 \\space PB
$$`},{header:"Bandwidth",slug:"bandwidth-2",content:`As our system is handling 5.1 TB of ingress every day, we will require a minimum bandwidth of around 60 MB per second.
$$
\\frac{5.1 \\space TB}{(24 \\space hrs \\times 3600 \\space seconds)} = \\sim 60 \\space MB/second
$$`},{header:"High-level estimate",slug:"high-level-estimate-2",content:`Here is our high-level estimate: Type
Estimate Daily active users (DAU)
100 million Requests per second (RPS)
12K/s Storage (per day)
~5.1 TB Storage (10 years)
~19 PB Bandwidth
~60 MB/s`},{header:"Data model design",slug:"data-model-design-3",content:`This is the general data model which reflects our requirements.
twitter-datamodel
We have the following tables:
users
This table will contain a user's information such as name, email, dob, and other details.
tweets
As the name suggests, this table will store tweets and their properties such as type (text, image, video, etc.), content, etc. We will also store the corresponding userID.
favorites
This table maps tweets with users for the favorite tweets functionality in our application.
followers
This table maps the followers and followees as users can follow each other (N:M relationship).
feeds
This table stores feed properties with the corresponding userID.
feeds_tweets
This table maps tweets and feed (N:M relationship).`},{header:"What kind of database should we use?",slug:"what-kind-of-database-should-we-use-2",content:`While our data model seems quite relational, we don't necessarily need to store everything in a single database, as this can limit our scalability and quickly become a bottleneck.
We will split the data between different services each having ownership over a particular table. Then we can use a relational database such as PostgreSQL or a distributed NoSQL database such as Apache Cassandra for our use case.`},{header:"API design",slug:"api-design-3",content:"Let us do a basic API design for our services:"},{header:"Post a tweet",slug:"post-a-tweet",content:`This API will allow the user to post a tweet on the platform.
postTweet(userID: UUID, content: string, mediaURL?: string): boolean Parameters
User ID (UUID): ID of the user.
Content (string): Contents of the tweet.
Media URL (string): URL of the attached media (optional).
Returns
Result (boolean): Represents whether the operation was successful or not.`},{header:"Follow or unfollow a user",slug:"follow-or-unfollow-a-user",content:`This API will allow the user to follow or unfollow another user.
follow(followerID: UUID, followeeID: UUID): boolean
unfollow(followerID: UUID, followeeID: UUID): boolean Parameters
Follower ID (UUID): ID of the current user.
Followee ID (UUID): ID of the user we want to follow or unfollow.
Media URL (string): URL of the attached media (optional).
Returns
Result (boolean): Represents whether the operation was successful or not.`},{header:"Get newsfeed",slug:"get-newsfeed",content:`This API will return all the tweets to be shown within a given newsfeed.
getNewsfeed(userID: UUID): Tweet[] Parameters
User ID (UUID): ID of the user.
Returns
Tweets (Tweet[]): All the tweets to be shown within a given newsfeed.`},{header:"High-level design",slug:"high-level-design-2",content:"Now let us do a high-level design of our system."},{header:"Architecture",slug:"architecture-1",content:`We will be using microservices architecture since it will make it easier to horizontally scale and decouple our services. Each service will have ownership of its own data model. Let's try to divide our system into some core services.
User Service
This service handles user-related concerns such as authentication and user information.
Newsfeed Service
This service will handle the generation and publishing of user newsfeeds. It will be discussed in detail separately.
Tweet Service
The tweet service will handle tweet-related use cases such as posting a tweet, favorites, etc.
Search Service
The service is responsible for handling search-related functionality. It will be discussed in detail separately.
Media service
This service will handle the media (images, videos, files, etc.) uploads. It will be discussed in detail separately.
Notification Service
This service will simply send push notifications to the users.
Analytics Service
This service will be used for metrics and analytics use cases.
What about inter-service communication and service discovery?
Since our architecture is microservices-based, services will be communicating with each other as well. Generally, REST or HTTP performs well but we can further improve the performance using gRPC which is more lightweight and efficient.
Service discovery is another thing we will have to take into account. We can also use a service mesh that enables managed, observable, and secure communication between individual services.
Note: Learn more about REST, GraphQL, gRPC and how they compare with each other.`},{header:"Newsfeed",slug:"newsfeed",content:`When it comes to the newsfeed, it seems easy enough to implement, but there are a lot of things that can make or break this feature. So, let's divide our problem into two parts:
Generation
Let's assume we want to generate the feed for user A, we will perform the following steps: Retrieve the IDs of all the users and entities (hashtags, topics, etc.) user A follows.
Fetch the relevant tweets for each of the retrieved IDs.
Use a ranking algorithm to rank the tweets based on parameters such as relevance, time, engagement, etc.
Return the ranked tweets data to the client in a paginated manner. Feed generation is an intensive process and can take quite a lot of time, especially for users following a lot of people. To improve the performance, the feed can be pre-generated and stored in the cache, then we can have a mechanism to periodically update the feed and apply our ranking algorithm to the new tweets.
Publishing
Publishing is the step where the feed data is pushed according to each specific user. This can be a quite heavy operation, as a user may have millions of friends or followers. To deal with this, we have three different approaches: Pull Model (or Fan-out on load) newsfeed-pull-model
When a user creates a tweet, and a follower reloads their newsfeed, the feed is created and stored in memory. The most recent feed is only loaded when the user requests it. This approach reduces the number of write operations on our database.
The downside of this approach is that the users will not be able to view recent feeds unless they "pull" the data from the server, which will increase the number of read operations on the server. Push Model (or Fan-out on write) newsfeed-push-model
In this model, once a user creates a tweet, it is "pushed" to all the follower's feeds immediately. This prevents the system from having to go through a user's entire followers list to check for updates.
However, the downside of this approach is that it would increase the number of write operations on the database. Hybrid Model A third approach is a hybrid model between the pull and push model. It combines the beneficial features of the above two models and tries to provide a balanced approach between the two.
The hybrid model allows only users with a lesser number of followers to use the push model. For users with a higher number of followers such as celebrities, the pull model is used.`},{header:"Ranking Algorithm",slug:"ranking-algorithm",content:`As we discussed, we will need a ranking algorithm to rank each tweet according to its relevance to each specific user.
For example, Facebook used to utilize an EdgeRank algorithm. Here, the rank of each feed item is described by:
$$
Rank = Affinity \\times Weight \\times Decay
$$
Where,
Affinity: is the "closeness" of the user to the creator of the edge. If a user frequently likes, comments, or messages the edge creator, then the value of affinity will be higher, resulting in a higher rank for the post.
Weight: is the value assigned according to each edge. A comment can have a higher weightage than likes, and thus a post with more comments is more likely to get a higher rank.
Decay: is the measure of the creation of the edge. The older the edge, the lesser will be the value of decay and eventually the rank.
Nowadays, algorithms are much more complex and ranking is done using machine learning models which can take thousands of factors into consideration.`},{header:"Retweets",slug:"retweets",content:`Retweets are one of our extended requirements. To implement this feature, we can simply create a new tweet with the user id of the user retweeting the original tweet and then modify the type enum and content property of the new tweet to link it with the original tweet.
For example, the type enum property can be of type tweet, similar to text, video, etc and content can be the id of the original tweet. Here the first row indicates the original tweet while the second row is how we can represent a retweet. id
userID
type
content
createdAt ad34-291a-45f6-b36c
7a2c-62c4-4dc8-b1bb
text
Hey, this is my first tweet…
1658905644054 f064-49ad-9aa2-84a6
6aa2-2bc9-4331-879f
tweet
ad34-291a-45f6-b36c
1658906165427 This is a very basic implementation. To improve this we can create a separate table itself to store retweets.`},{header:"Search",slug:"search",content:`Sometimes traditional DBMS are not performant enough, we need something which allows us to store, search, and analyze huge volumes of data quickly and in near real-time and give results within milliseconds. Elasticsearch can help us with this use case.
Elasticsearch is a distributed, free and open search and analytics engine for all types of data, including textual, numerical, geospatial, structured, and unstructured. It is built on top of Apache Lucene.
How do we identify trending topics?
Trending functionality will be based on top of the search functionality. We can cache the most frequently searched queries, hashtags, and topics in the last N seconds and update them every M seconds using some sort of batch job mechanism. Our ranking algorithm can also be applied to the trending topics to give them more weight and personalize them for the user.`},{header:"Notifications",slug:"notifications-1",content:`Push notifications are an integral part of any social media platform. We can use a message queue or a message broker such as Apache Kafka with the notification service to dispatch requests to Firebase Cloud Messaging (FCM) or Apple Push Notification Service (APNS) which will handle the delivery of the push notifications to user devices.
For more details, refer to the WhatsApp system design where we discuss push notifications in detail.`},{header:"Detailed design",slug:"detailed-design-3",content:"It's time to discuss our design decisions in detail."},{header:"Data Partitioning",slug:"data-partitioning-3",content:`To scale out our databases we will need to partition our data. Horizontal partitioning (aka Sharding) can be a good first step. We can use partitions schemes such as: Hash-Based Partitioning
List-Based Partitioning
Range Based Partitioning
Composite Partitioning The above approaches can still cause uneven data and load distribution, we can solve this using Consistent hashing.
For more details, refer to Sharding and Consistent Hashing.`},{header:"Mutual friends",slug:"mutual-friends",content:`For mutual friends, we can build a social graph for every user. Each node in the graph will represent a user and a directional edge will represent followers and followees. After that, we can traverse the followers of a user to find and suggest a mutual friend. This would require a graph database such as Neo4j and ArangoDB.
This is a pretty simple algorithm, to improve our suggestion accuracy, we will need to incorporate a recommendation model which uses machine learning as part of our algorithm.`},{header:"Metrics and Analytics",slug:"metrics-and-analytics-1",content:"Recording analytics and metrics is one of our extended requirements. As we will be using Apache Kafka to publish all sorts of events, we can process these events and run analytics on the data using Apache Spark which is an open-source unified analytics engine for large-scale data processing."},{header:"Caching",slug:"caching-3",content:`In a social media application, we have to be careful about using cache as our users expect the latest data. So, to prevent usage spikes from our resources we can cache the top 20% of the tweets.
To further improve efficiency we can add pagination to our system APIs. This decision will be helpful for users with limited network bandwidth as they won't have to retrieve old messages unless requested.
Which cache eviction policy to use?
We can use solutions like Redis or Memcached and cache 20% of the daily traffic but what kind of cache eviction policy would best fit our needs?
Least Recently Used (LRU) can be a good policy for our system. In this policy, we discard the least recently used key first.
How to handle cache miss?
Whenever there is a cache miss, our servers can hit the database directly and update the cache with the new entries.
For more details, refer to Caching.`},{header:"Media access and storage",slug:"media-access-and-storage-1",content:`As we know, most of our storage space will be used for storing media files such as images, videos, or other files. Our media service will be handling both access and storage of the user media files.
But where can we store files at scale? Well, object storage is what we're looking for. Object stores break data files up into pieces called objects. It then stores those objects in a single repository, which can be spread out across multiple networked systems. We can also use distributed file storage such as HDFS or GlusterFS.`},{header:"Content Delivery Network (CDN)",slug:"content-delivery-network-cdn-2",content:"Content Delivery Network (CDN) increases content availability and redundancy while reducing bandwidth costs. Generally, static files such as images, and videos are served from CDN. We can use services like Amazon CloudFront or Cloudflare CDN for this use case."},{header:"Identify and resolve bottlenecks",slug:"identify-and-resolve-bottlenecks-3",content:`twitter-advanced-design
Let us identify and resolve bottlenecks such as single points of failure in our design: "What if one of our services crashes?"
"How will we distribute our traffic between our components?"
"How can we reduce the load on our database?"
"How to improve the availability of our cache?"
"How can we make our notification system more robust?"
"How can we reduce media storage costs"? To make our system more resilient we can do the following: Running multiple instances of each of our services.
Introducing load balancers between clients, servers, databases, and cache servers.
Using multiple read replicas for our databases.
Multiple instances and replicas for our distributed cache.
Exactly once delivery and message ordering is challenging in a distributed system, we can use a dedicated message broker such as Apache Kafka or NATS to make our notification system more robust.
We can add media processing and compression capabilities to the media service to compress large files which will save a lot of storage space and reduce cost.`},{header:"Netflix",slug:"netflix",content:"Let's design a Netflix like video streaming service, similar to services like Amazon Prime Video, Disney Plus, Hulu, Youtube, Vimeo, etc."},{header:"What is Netflix?",slug:"what-is-netflix",content:"Netflix is a subscription-based streaming service that allows its members to watch TV shows and movies on an internet-connected device. It is available on platforms such as the Web, iOS, Android, TV, etc."},{header:"Requirements",slug:"requirements-3",content:"Our system should meet the following requirements:"},{header:"Functional requirements",slug:"functional-requirements-4",content:`Users should be able to stream and share videos.
The content team (or users in YouTube's case) should be able to upload new videos (movies, tv shows episodes, and other content).
Users should be able to search for videos using titles or tags.
Users should be able to comment on a video similar to YouTube.`},{header:"Non-Functional requirements",slug:"non-functional-requirements-4",content:`High availability with minimal latency.
High reliability, no uploads should be lost.
The system should be scalable and efficient.`},{header:"Extended requirements",slug:"extended-requirements-4",content:`Certain content should be geo-blocked.
Resume video playback from the point user left off.
Record metrics and analytics of videos.`},{header:"Estimation and Constraints",slug:"estimation-and-constraints-4",content:`Let's start with the estimation and constraints.
Note: Make sure to check any scale or traffic-related assumptions with your interviewer.`},{header:"Traffic",slug:"traffic-3",content:`This will be a read-heavy system, let us assume we have 1 billion total users with 200 million daily active users (DAU), and on average each user watches 5 videos a day. This gives us 1 billion videos watched per day.
$$
200 \\space million \\times 5 \\space videos = 1 \\space billion/day
$$
Assuming a 200:1 read/write ratio, about 50 million videos will be uploaded every day.
$$
\\frac{1}{200} \\times 1 \\space billion = 50 \\space million/day
$$
What would be Requests Per Second (RPS) for our system?
1 billion requests per day translate into 12K requests per second.
$$
\\frac{1 \\space billion}{(24 \\space hrs \\times 3600 \\space seconds)} = \\sim 12K \\space requests/second
$$`},{header:"Storage",slug:"storage-5",content:`If we assume each video is 100 MB on average, we will require about 5 PB of storage every day.
$$
50 \\space million \\times 100 \\space MB = 5 \\space PB/day
$$
And for 10 years, we will require an astounding 18,250 PB of storage.
$$
5 \\space PB \\times 365 \\space days \\times 10 \\space years = \\sim 18,250 \\space PB
$$`},{header:"Bandwidth",slug:"bandwidth-3",content:`As our system is handling 5 PB of ingress every day, we will require a minimum bandwidth of around 58 GB per second.
$$
\\frac{5 \\space PB}{(24 \\space hrs \\times 3600 \\space seconds)} = \\sim 58 \\space GB/second
$$`},{header:"High-level estimate",slug:"high-level-estimate-3",content:`Here is our high-level estimate: Type
Estimate Daily active users (DAU)
200 million Requests per second (RPS)
12K/s Storage (per day)
~5 PB Storage (10 years)
~18,250 PB Bandwidth
~58 GB/s`},{header:"Data model design",slug:"data-model-design-4",content:`This is the general data model which reflects our requirements.
netflix-datamodel
We have the following tables:
users
This table will contain a user's information such as name, email, dob, and other details.
videos
As the name suggests, this table will store videos and their properties such as title, streamURL, tags, etc. We will also store the corresponding userID.
tags
This table will simply store tags associated with a video.
views
This table helps us to store all the views received on a video.
comments
This table stores all the comments received on a video (like YouTube).`},{header:"What kind of database should we use?",slug:"what-kind-of-database-should-we-use-3",content:`While our data model seems quite relational, we don't necessarily need to store everything in a single database, as this can limit our scalability and quickly become a bottleneck.
We will split the data between different services each having ownership over a particular table. Then we can use a relational database such as PostgreSQL or a distributed NoSQL database such as Apache Cassandra for our use case.`},{header:"API design",slug:"api-design-4",content:"Let us do a basic API design for our services:"},{header:"Upload a video",slug:"upload-a-video",content:`Given a byte stream, this API enables video to be uploaded to our service.
uploadVideo(title: string, description: string, data: Stream<byte>, tags?: string[]): boolean Parameters
Title (string): Title of the new video.
Description (string): Description of the new video.
Data (Byte[]): Byte stream of the video data.
Tags (string[]): Tags for the video (optional).
Returns
Result (boolean): Represents whether the operation was successful or not.`},{header:"Streaming a video",slug:"streaming-a-video",content:`This API allows our users to stream a video with the preferred codec and resolution.
streamVideo(videoID: UUID, codec: Enum<string>, resolution: Tuple<int>, offset?: int): VideoStream Parameters
Video ID (UUID): ID of the video that needs to be streamed.
Codec (Enum<string>): Required codec of the requested video, such as h.265, h.264, VP9, etc.
Resolution (Tuple<int>): Resolution of the requested video.
Offset (int): Offset of the video stream in seconds to stream data from any point in the video (optional).
Returns
Stream (VideoStream): Data stream of the requested video.`},{header:"Search for a video",slug:"search-for-a-video",content:`This API will enable our users to search for a video based on its title or tags.
searchVideo(query: string, nextPage?: string): Video[] Parameters
Query (string): Search query from the user.
Next Page (string): Token for the next page, this can be used for pagination (optional).
Returns
Videos (Video[]): All the videos available for a particular search query.`},{header:"Add a comment",slug:"add-a-comment",content:`This API will allow our users to post a comment on a video (like YouTube).
comment(videoID: UUID, comment: string): boolean Parameters
VideoID (UUID): ID of the video user wants to comment on.
Comment (string): The text content of the comment.
Returns
Result (boolean): Represents whether the operation was successful or not.`},{header:"High-level design",slug:"high-level-design-3",content:"Now let us do a high-level design of our system."},{header:"Architecture",slug:"architecture-2",content:`We will be using microservices architecture since it will make it easier to horizontally scale and decouple our services. Each service will have ownership of its own data model. Let's try to divide our system into some core services.
User Service
This service handles user-related concerns such as authentication and user information.
Stream Service
The tweet service will handle video streaming-related functionality.
Search Service
The service is responsible for handling search-related functionality. It will be discussed in detail separately.
Media service
This service will handle the video uploads and processing. It will be discussed in detail separately.
Analytics Service
This service will be used for metrics and analytics use cases.
What about inter-service communication and service discovery?
Since our architecture is microservices-based, services will be communicating with each other as well. Generally, REST or HTTP performs well but we can further improve the performance using gRPC which is more lightweight and efficient.
Service discovery is another thing we will have to take into account. We can also use a service mesh that enables managed, observable, and secure communication between individual services.
Note: Learn more about REST, GraphQL, gRPC and how they compare with each other.`},{header:"Video processing",slug:"video-processing",content:`video-processing-pipeline
There are so many variables in play when it comes to processing a video. For example, an average data size of two-hour raw 8K footage from a high-end camera can easily be up to 4 TB, thus we need to have some kind of processing to reduce both storage and delivery costs.
Here's how we can process videos once they're uploaded by the content team (or users in YouTube's case) and are queued for processing in our message queue.
Let's discuss how this works: File Chunker file-chunking
This is the first step of our processing pipeline. File chunking is the process of splitting a file into smaller pieces called chunks. It can help us eliminate duplicate copies of repeating data on storage, and reduces the amount of data sent over the network by only selecting changed chunks.
Usually, a video file can be split into equal size chunks based on timestamps but Netflix instead splits chunks based on scenes. This slight variation becomes a huge factor for a better user experience since whenever the client requests a chunk from the server, there is a lower chance of interruption as a complete scene will be retrieved. Content Filter This step checks if the video adheres to the content policy of the platform. This can be pre-approved as in the case of Netflix according to content rating of the media or can be strictly enforced like by YouTube.
This entire process is done by a machine learning model which performs copyright, piracy, and NSFW checks. If issues are found, we can push the task to a dead-letter queue (DLQ) and someone from the moderation team can do further inspection. Transcoder Transcoding is a process in which the original data is decoded to an intermediate uncompressed format, which is then encoded into the target format. This process uses different codecs to perform bitrate adjustment, image downsampling, or re-encoding the media.
This results in a smaller size file and a much more optimized format for the target devices. Standalone solutions such as FFmpeg or cloud-based solutions like AWS Elemental MediaConvert can be used to implement this step of the pipeline. Quality Conversion This is the last step of the processing pipeline and as the name suggests, this step handles the conversion of the transcoded media from the previous step into different resolutions such as 4K, 1440p, 1080p, 720p, etc.
It allows us to fetch the desired quality of the video as per the user's request, and once the media file finishes processing, it gets uploaded to a distributed file storage such as HDFS, GlusterFS, or an object storage such as Amazon S3 for later retrieval during streaming.
Note: We can add additional steps such as subtitles and thumbnails generation as part of our pipeline.
Why are we using a message queue?
Processing videos as a long-running task and using a message queue makes much more sense. It also decouples our video processing pipeline from the upload functionality. We can use something like Amazon SQS or RabbitMQ to support this.`},{header:"Video streaming",slug:"video-streaming",content:`Video streaming is a challenging task from both the client and server perspectives. Moreover, internet connection speeds vary quite a lot between different users. To make sure users don't re-fetch the same content, we can use a Content Delivery Network (CDN).
Netflix takes this a step further with its Open Connect program. In this approach, they partner with thousands of Internet Service Providers (ISPs) to localize their traffic and deliver their content more efficiently.
What is the difference between Netflix's Open Connect and a traditional Content Delivery Network (CDN)?
Netflix Open Connect is a purpose-built Content Delivery Network (CDN) responsible for serving Netflix's video traffic. Around 95% of the traffic globally is delivered via direct connections between Open Connect and the ISPs their customers use to access the internet.
Currently, they have Open Connect Appliances (OCAs) in over 1000 separate locations around the world. In case of issues, Open Connect Appliances (OCAs) can failover, and the traffic can be re-routed to Netflix servers.
Additionally, we can use Adaptive bitrate streaming protocols such as HTTP Live Streaming (HLS) which is designed for reliability and it dynamically adapts to network conditions by optimizing playback for the available speed of the connections.
Lastly, for playing the video from where the user left off (part of our extended requirements), we can simply use the offset property we stored in the views table to retrieve the scene chunk at that particular timestamp and resume the playback for the user.`},{header:"Searching",slug:"searching",content:`Sometimes traditional DBMS are not performant enough, we need something which allows us to store, search, and analyze huge volumes of data quickly and in near real-time and give results within milliseconds. Elasticsearch can help us with this use case.
Elasticsearch is a distributed, free and open search and analytics engine for all types of data, including textual, numerical, geospatial, structured, and unstructured. It is built on top of Apache Lucene.
How do we identify trending content?
Trending functionality will be based on top of the search functionality. We can cache the most frequently searched queries in the last N seconds and update them every M seconds using some sort of batch job mechanism.`},{header:"Sharing",slug:"sharing",content:`Sharing content is an important part of any platform, for this, we can have some sort of URL shortener service in place that can generate short URLs for the users to share.
For more details, refer to the URL Shortener system design.`},{header:"Detailed design",slug:"detailed-design-4",content:"It's time to discuss our design decisions in detail."},{header:"Data Partitioning",slug:"data-partitioning-4",content:`To scale out our databases we will need to partition our data. Horizontal partitioning (aka Sharding) can be a good first step. We can use partitions schemes such as: Hash-Based Partitioning
List-Based Partitioning
Range Based Partitioning
Composite Partitioning The above approaches can still cause uneven data and load distribution, we can solve this using Consistent hashing.
For more details, refer to Sharding and Consistent Hashing.`},{header:"Geo-blocking",slug:"geo-blocking",content:`Platforms like Netflix and YouTube use Geo-blocking to restrict content in certain geographical areas or countries. This is primarily done due to legal distribution laws that Netflix has to adhere to when they make a deal with the production and distribution companies. In the case of YouTube, this will be controlled by the user during the publishing of the content.
We can determine the user's location either using their IP or region settings in their profile then use services like Amazon CloudFront which supports a geographic restrictions feature or a geolocation routing policy with Amazon Route53 to restrict the content and re-route the user to an error page if the content is not available in that particular region or country.`},{header:"Recommendations",slug:"recommendations",content:`Netflix uses a machine learning model which uses the user's viewing history to predict what the user might like to watch next, an algorithm like Collaborative Filtering can be used.
However, Netflix (like YouTube) uses its own algorithm called Netflix Recommendation Engine which can track several data points such as: User profile information like age, gender, and location.
Browsing and scrolling behavior of the user.
Time and date a user watched a title.
The device which was used to stream the content.
The number of searches and what terms were searched. For more detail, refer to Netflix recommendation research.`},{header:"Metrics and Analytics",slug:"metrics-and-analytics-2",content:"Recording analytics and metrics is one of our extended requirements. We can capture the data from different services and run analytics on the data using Apache Spark which is an open-source unified analytics engine for large-scale data processing. Additionally, we can store critical metadata in the views table to increase data points within our data."},{header:"Caching",slug:"caching-4",content:`In a streaming platform, caching is important. We have to be able to cache as much static media content as possible to improve user experience. We can use solutions like Redis or Memcached but what kind of cache eviction policy would best fit our needs?
Which cache eviction policy to use?
Least Recently Used (LRU) can be a good policy for our system. In this policy, we discard the least recently used key first.
How to handle cache miss?
Whenever there is a cache miss, our servers can hit the database directly and update the cache with the new entries.
For more details, refer to Caching.`},{header:"Media streaming and storage",slug:"media-streaming-and-storage",content:`As most of our storage space will be used for storing media files such as thumbnails and videos. Per our discussion earlier, the media service will be handling both the upload and processing of media files.
We will use distributed file storage such as HDFS, GlusterFS, or an object storage such as Amazon S3 for storage and streaming of the content.`},{header:"Content Delivery Network (CDN)",slug:"content-delivery-network-cdn-3",content:"Content Delivery Network (CDN) increases content availability and redundancy while reducing bandwidth costs. Generally, static files such as images, and videos are served from CDN. We can use services like Amazon CloudFront or Cloudflare CDN for this use case."},{header:"Identify and resolve bottlenecks",slug:"identify-and-resolve-bottlenecks-4",content:`netflix-advanced-design
Let us identify and resolve bottlenecks such as single points of failure in our design: "What if one of our services crashes?"
"How will we distribute our traffic between our components?"
"How can we reduce the load on our database?"
"How to improve the availability of our cache?" To make our system more resilient we can do the following: Running multiple instances of each of our services.
Introducing load balancers between clients, servers, databases, and cache servers.
Using multiple read replicas for our databases.
Multiple instances and replicas for our distributed cache.`},{header:"Uber",slug:"uber",content:"Let's design an Uber like ride-hailing service, similar to services like Lyft, OLA Cabs, etc."},{header:"What is Uber?",slug:"what-is-uber",content:"Uber is a mobility service provider, allowing users to book rides and a driver to transport them in a way similar to a taxi. It is available on the web and mobile platforms such as Android and iOS."},{header:"Requirements",slug:"requirements-4",content:"Our system should meet the following requirements:"},{header:"Functional requirements",slug:"functional-requirements-5",content:`We will design our system for two types of users: Customers and Drivers.
Customers Customers should be able to see all the cabs in the vicinity with an ETA and pricing information.
Customers should be able to book a cab to a destination.
Customers should be able to see the location of the driver. Drivers Drivers should be able to accept or deny the customer-requested ride.
Once a driver accepts the ride, they should see the pickup location of the customer.
Drivers should be able to mark the trip as complete on reaching the destination.`},{header:"Non-Functional requirements",slug:"non-functional-requirements-5",content:`High reliability.
High availability with minimal latency.
The system should be scalable and efficient.`},{header:"Extended requirements",slug:"extended-requirements-5",content:`Customers can rate the trip after it's completed.
Payment processing.
Metrics and analytics.`},{header:"Estimation and Constraints",slug:"estimation-and-constraints-5",content:`Let's start with the estimation and constraints.
Note: Make sure to check any scale or traffic-related assumptions with your interviewer.`},{header:"Traffic",slug:"traffic-4",content:`Let us assume we have 100 million daily active users (DAU) with 1 million drivers and on average our platform enables 10 million rides daily.
If on average each user performs 10 actions (such as request a check available rides, fares, book rides, etc.) we will have to handle 1 billion requests daily.
$$
100 \\space million \\times 10 \\space actions = 1 \\space billion/day
$$
What would be Requests Per Second (RPS) for our system?
1 billion requests per day translate into 12K requests per second.
$$
\\frac{1 \\space billion}{(24 \\space hrs \\times 3600 \\space seconds)} = \\sim 12K \\space requests/second
$$`},{header:"Storage",slug:"storage-6",content:`If we assume each message on average is 400 bytes, we will require about 400 GB of database storage every day.
$$
1 \\space billion \\times 400 \\space bytes = \\sim 400 \\space GB/day
$$
And for 10 years, we will require about 1.4 PB of storage.
$$
400 \\space GB \\times 10 \\space years \\times 365 \\space days = \\sim 1.4 \\space PB
$$`},{header:"Bandwidth",slug:"bandwidth-4",content:`As our system is handling 400 GB of ingress every day, we will require a minimum bandwidth of around 4 MB per second.
$$
\\frac{400 \\space GB}{(24 \\space hrs \\times 3600 \\space seconds)} = \\sim 5 \\space MB/second
$$`},{header:"High-level estimate",slug:"high-level-estimate-4",content:`Here is our high-level estimate: Type
Estimate Daily active users (DAU)
100 million Requests per second (RPS)
12K/s Storage (per day)
~400 GB Storage (10 years)
~1.4 PB Bandwidth
~5 MB/s`},{header:"Data model design",slug:"data-model-design-5",content:`This is the general data model which reflects our requirements.
uber-datamodel
We have the following tables:
customers
This table will contain a customer's information such as name, email, and other details.
drivers
This table will contain a driver's information such as name, email, dob and other details.
trips
This table represents the trip taken by the customer and stores data such as source, destination, and status of the trip.
cabs
This table stores data such as the registration number, and type (like Uber Go, Uber XL, etc.) of the cab that the driver will be driving.
ratings
As the name suggests, this table stores the rating and feedback for the trip.
payments
The payments table contains the payment-related data with the corresponding tripID.`},{header:"What kind of database should we use?",slug:"what-kind-of-database-should-we-use-4",content:`While our data model seems quite relational, we don't necessarily need to store everything in a single database, as this can limit our scalability and quickly become a bottleneck.
We will split the data between different services each having ownership over a particular table. Then we can use a relational database such as PostgreSQL or a distributed NoSQL database such as Apache Cassandra for our use case.`},{header:"API design",slug:"api-design-5",content:"Let us do a basic API design for our services:"},{header:"Request a Ride",slug:"request-a-ride",content:`Through this API, customers will be able to request a ride.
requestRide(customerID: UUID, source: Tuple<float>, destination: Tuple<float>, cabType: Enum<string>, paymentMethod: Enum<string>): Ride Parameters
Customer ID (UUID): ID of the customer.
Source (Tuple<float>): Tuple containing the latitude and longitude of the trip's starting location.
Destination (Tuple<float>): Tuple containing the latitude and longitude of the trip's destination.
Returns
Result (Ride): Associated ride information of the trip.`},{header:"Cancel the Ride",slug:"cancel-the-ride",content:`This API will allow customers to cancel the ride.
cancelRide(customerID: UUID, reason?: string): boolean Parameters
Customer ID (UUID): ID of the customer.
Reason (UUID): Reason for canceling the ride (optional).
Returns
Result (boolean): Represents whether the operation was successful or not.`},{header:"Accept or Deny the Ride",slug:"accept-or-deny-the-ride",content:`This API will allow the driver to accept or deny the trip.
acceptRide(driverID: UUID, rideID: UUID): boolean
denyRide(driverID: UUID, rideID: UUID): boolean Parameters
Driver ID (UUID): ID of the driver.
Ride ID (UUID): ID of the customer requested ride.
Returns
Result (boolean): Represents whether the operation was successful or not.`},{header:"Start or End the Trip",slug:"start-or-end-the-trip",content:`Using this API, a driver will be able to start and end the trip.
startTrip(driverID: UUID, tripID: UUID): boolean
endTrip(driverID: UUID, tripID: UUID): boolean Parameters
Driver ID (UUID): ID of the driver.
Trip ID (UUID): ID of the requested trip.
Returns
Result (boolean): Represents whether the operation was successful or not.`},{header:"Rate the Trip",slug:"rate-the-trip",content:`This API will enable customers to rate the trip.
rateTrip(customerID: UUID, tripID: UUID, rating: int, feedback?: string): boolean Parameters
Customer ID (UUID): ID of the customer.
Trip ID (UUID): ID of the completed trip.
Rating (int): Rating of the trip.
Feedback (string): Feedback about the trip by the customer (optional).
Returns
Result (boolean): Represents whether the operation was successful or not.`},{header:"High-level design",slug:"high-level-design-4",content:"Now let us do a high-level design of our system."},{header:"Architecture",slug:"architecture-3",content:`We will be using microservices architecture since it will make it easier to horizontally scale and decouple our services. Each service will have ownership of its own data model. Let's try to divide our system into some core services.
Customer Service
This service handles customer-related concerns such as authentication and customer information.
Driver Service
This service handles driver-related concerns such as authentication and driver information.
Ride Service
This service will be responsible for ride matching and quadtree aggregation. It will be discussed in detail separately.
Trip Service
This service handles trip-related functionality in our system.
Payment Service
This service will be responsible for handling payments in our system.
Notification Service
This service will simply send push notifications to the users. It will be discussed in detail separately.
Analytics Service
This service will be used for metrics and analytics use cases.
What about inter-service communication and service discovery?
Since our architecture is microservices-based, services will be communicating with each other as well. Generally, REST or HTTP performs well but we can further improve the performance using gRPC which is more lightweight and efficient.
Service discovery is another thing we will have to take into account. We can also use a service mesh that enables managed, observable, and secure communication between individual services.
Note: Learn more about REST, GraphQL, gRPC and how they compare with each other.`},{header:"How is the service expected to work?",slug:"how-is-the-service-expected-to-work",content:`Here's how our service is expected to work:
uber-working Customer requests a ride by specifying the source, destination, cab type, payment method, etc.
Ride service registers this request, finds nearby drivers, and calculates the estimated time of arrival (ETA).
The request is then broadcasted to the nearby drivers for them to accept or deny.
If the driver accepts, the customer is notified about the live location of the driver with the estimated time of arrival (ETA) while they wait for pickup.
The customer is picked up and the driver can start the trip.
Once the destination is reached, the driver will mark the ride as complete and collect payment.
After the payment is complete, the customer can leave a rating and feedback for the trip if they like.`},{header:"Location Tracking",slug:"location-tracking",content:`How do we efficiently send and receive live location data from the client (customers and drivers) to our backend? We have two different options:
Pull model
The client can periodically send an HTTP request to servers to report its current location and receive ETA and pricing information. This can be achieved via something like Long polling.
Push model
The client opens a long-lived connection with the server and once new data is available it will be pushed to the client. We can use WebSockets or Server-Sent Events (SSE) for this.
The pull model approach is not scalable as it will create unnecessary request overhead on our servers and most of the time the response will be empty, thus wasting our resources. To minimize latency, using the push model with WebSockets is a better choice because then we can push data to the client once it's available without any delay, given the connection is open with the client. Also, WebSockets provide full-duplex communication, unlike Server-Sent Events (SSE) which are only unidirectional.
Additionally, the client application should have some sort of background job mechanism to ping GPS location while the application is in the background.
Note: Learn more about Long polling, WebSockets, Server-Sent Events (SSE).`},{header:"Ride Matching",slug:"ride-matching",content:`We need a way to efficiently store and query nearby drivers. Let's explore different solutions we can incorporate into our design.
SQL
We already have access to the latitude and longitude of our customers, and with databases like PostgreSQL and MySQL we can perform a query to find nearby driver locations given a latitude and longitude (X, Y) within a radius (R).
SELECT * FROM locations WHERE lat BETWEEN X-R AND X+R AND long BETWEEN Y-R AND Y+R However, this is not scalable, and performing this query on large datasets will be quite slow.
Geohashing
Geohashing is a geocoding method used to encode geographic coordinates such as latitude and longitude into short alphanumeric strings. It was created by Gustavo Niemeyer in 2008.
Geohash is a hierarchical spatial index that uses Base-32 alphabet encoding, the first character in a geohash identifies the initial location as one of the 32 cells. This cell will also contain 32 cells. This means that to represent a point, the world is recursively divided into smaller and smaller cells with each additional bit until the desired precision is attained. The precision factor also determines the size of the cell.
geohashing
For example, San Francisco with coordinates 37.7564, -122.4016 can be represented in geohash as 9q8yy9mf.
Now, using the customer's geohash we can determine the nearest available driver by simply comparing it with the driver's geohash. For better performance, we will index and store the geohash of the driver in memory for faster retrieval.
Quadtrees
A Quadtree is a tree data structure in which each internal node has exactly four children. They are often used to partition a two-dimensional space by recursively subdividing it into four quadrants or regions. Each child or leaf node stores spatial information. Quadtrees are the two-dimensional analog of Octrees which are used to partition three-dimensional space.
quadtree
Quadtrees enable us to search points within a two-dimensional range efficiently, where those points are defined as latitude/longitude coordinates or as cartesian (x, y) coordinates.
We can save further computation by only subdividing a node after a certain threshold.
quadtree-subdivision
Quadtree seems perfect for our use case, we can update the Quadtree every time we receive a new location update from the driver. To reduce the load on the quadtree servers we can use an in-memory datastore such as Redis to cache the latest updates. And with the application of mapping algorithms such as the Hilbert curve, we can perform efficient range queries to find nearby drivers for the customer.
What about race conditions?
Race conditions can easily occur when a large number of customers will be requesting rides simultaneously. To avoid this, we can wrap our ride matching logic in a Mutex to avoid any race conditions. Furthermore, every action should be transactional in nature.
For more details, refer to Transactions and Distributed Transactions.
How to find the best drivers nearby?
Once we have a list of nearby drivers from the Quadtree servers, we can perform some sort of ranking based on parameters like average ratings, relevance, past customer feedback, etc. This will allow us to broadcast notifications to the best available drivers first.
Dealing with high demand
In cases of high demand, we can use the concept of Surge Pricing. Surge pricing is a dynamic pricing method where prices are temporarily increased as a reaction to increased demand and mostly limited supply. This surge price can be added to the base price of the trip.
For more details, learn how surge pricing works with Uber.`},{header:"Payments",slug:"payments",content:"Handling payments at scale is challenging, to simplify our system we can use a third-party payment processor like Stripe or PayPal. Once the payment is complete, the payment processor will redirect the user back to our application and we can set up a webhook to capture all the payment-related data."},{header:"Notifications",slug:"notifications-2",content:`Push notifications will be an integral part of our platform. We can use a message queue or a message broker such as Apache Kafka with the notification service to dispatch requests to Firebase Cloud Messaging (FCM) or Apple Push Notification Service (APNS) which will handle the delivery of the push notifications to user devices.
For more details, refer to the WhatsApp system design where we discuss push notifications in detail.`},{header:"Detailed design",slug:"detailed-design-5",content:"It's time to discuss our design decisions in detail."},{header:"Data Partitioning",slug:"data-partitioning-5",content:`To scale out our databases we will need to partition our data. Horizontal partitioning (aka Sharding) can be a good first step. We can shard our database either based on existing partition schemes or regions. If we divide the locations into regions using let's say zip codes, we can effectively store all the data in a given region on a fixed node. But this can still cause uneven data and load distribution, we can solve this using Consistent hashing.
For more details, refer to Sharding and Consistent Hashing.`},{header:"Metrics and Analytics",slug:"metrics-and-analytics-3",content:"Recording analytics and metrics is one of our extended requirements. We can capture the data from different services and run analytics on the data using Apache Spark which is an open-source unified analytics engine for large-scale data processing. Additionally, we can store critical metadata in the views table to increase data points within our data."},{header:"Caching",slug:"caching-5",content:`In a location services-based platform, caching is important. We have to be able to cache the recent locations of the customers and drivers for fast retrieval. We can use solutions like Redis or Memcached but what kind of cache eviction policy would best fit our needs?
Which cache eviction policy to use?
Least Recently Used (LRU) can be a good policy for our system. In this policy, we discard the least recently used key first.
How to handle cache miss?
Whenever there is a cache miss, our servers can hit the database directly and update the cache with the new entries.
For more details, refer to Caching.`},{header:"Identify and resolve bottlenecks",slug:"identify-and-resolve-bottlenecks-5",content:`uber-advanced-design
Let us identify and resolve bottlenecks such as single points of failure in our design: "What if one of our services crashes?"
"How will we distribute our traffic between our components?"
"How can we reduce the load on our database?"
"How to improve the availability of our cache?"
"How can we make our notification system more robust?" To make our system more resilient we can do the following: Running multiple instances of each of our services.
Introducing load balancers between clients, servers, databases, and cache servers.
Using multiple read replicas for our databases.
Multiple instances and replicas for our distributed cache.
Exactly once delivery and message ordering is challenging in a distributed system, we can use a dedicated message broker such as Apache Kafka or NATS to make our notification system more robust.`},{header:"Next Steps",slug:"next-steps",content:`Congratulations, you've finished the course!
Now that you know the fundamentals of System Design, here are some additional resources: Distributed Systems (by Dr. Martin Kleppmann)
System Design Interview: An Insider's Guide
Microservices (by Chris Richardson)
Serverless computing
Kubernetes It is also recommended to actively follow engineering blogs of companies putting what we learned in the course into practice at scale: Microsoft Engineering
Google Research Blog
Netflix Tech Blog
AWS Blog
Facebook Engineering
Uber Engineering Blog
Airbnb Engineering
GitHub Engineering Blog
Intel Software Blog
LinkedIn Engineering
Paypal Developer Blog
Twitter Engineering Last but not least, volunteer for new projects at your company, and learn from senior engineers and architects to further improve your system design skills.
I hope this course was a great learning experience. I would love to hear feedback from you.
Wishing you all the best for further learning!`},{header:"References",slug:"references",content:`Here are the resources that were referenced while creating this course. Cloudflare learning center
IBM Blogs
Fastly Blogs
NS1 Blogs
Grokking the System Design Interview
System Design Primer
AWS Blogs
Martin Fowler
PagerDuty resources
VMWare Blogs All the diagrams were made using Excalidraw and are available here.`}]},{path:"/Basic/os/",title:"操作系统",pathLocale:"/",contents:[{header:"操作系统",slug:"操作系统",content:""},{header:"进程与线程",slug:"进程与线程",content:`对于有线程系统： 进程是资源分配的独立单位
线程是资源调度的独立单位 对于无线程系统： 进程是资源调度、分配的独立单位`},{header:"进程之间的通信方式以及优缺点",slug:"进程之间的通信方式以及优缺点",content:`管道（PIPE) 有名管道：一种半双工的通信方式，它允许无亲缘关系进程间的通信 优点：可以实现任意关系的进程间的通信
缺点： 长期存系统中，使用不当容易出错
缓冲区有限 无名管道：一种半双工的通信方式，只能在具有亲缘关系的进程间使用（父子进程） 优点：简单方便
缺点： 局限于单向通信
只能创建在它的进程以及其有亲缘关系的进程之间
缓冲区有限 信号量（Semaphore）：一个计数器，可以用来控制多个线程对共享资源的访问 优点：可以同步进程
缺点：信号量有限 信号（Signal）：一种比较复杂的通信方式，用于通知接收进程某个时间已经发生 消息队列（Message Queue）：是消息的链表，存放在内核中并由消息队列标识符标识 优点：可以实现任意进程间的通信，并通过系统调用函数来实现消息发送和接收之间的同步，无需考虑同步问题，方便
缺点：信息的肤质需要额外消耗CPU的时间，不适宜于信息量大或操作频繁的场合 共享内存（Shared Memory）：映射一端能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问 优点：无须复制，快捷，信息量大
缺点： 通信是通过将共享空间缓冲区直接附加到进程的虚拟地址空间中来实现的，因此进程间的读写操作的同步问题
利用内存缓冲区直接交换信息，内存的实体存在于计算机中，只能同一个计算机系统中的诸多进程共享，不方便网络通信 套接字（Socket）：可以用于同计算机间的进程通信 优点： 传输数据为字节级，传输数据可自定义，数据量小效率高
传输数据时间段，性能高
适合于客户端和服务器端之间信息实时交互
可以加密，数据安全性强 缺点：需对传输的数据进行解析，转化成应用级的数据`},{header:"线程之间的通信方式",slug:"线程之间的通信方式",content:`锁机制： 互斥锁/量（mutex）：提供了以排他方式防止数据结构被并发修改的方法
读写锁（reader-writer lock）：允许多个线程同事读共享数据，而对写操作是互斥的
自旋锁（spin lock）：与互斥锁类似，都是为了保护共享资源。互斥锁是当资源被占用，申请者进入睡眠状态；而自旋锁则循环检测保持者是否已经释放锁
条件变量（condition）：可以以原子的方式阻塞进程，知道某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用 信号量机制（Semaphore） 无名线程信号量
命名线程信号量 信号机制（SIgnal）：类似进程间的信号处理 屏障（Barrier）：屏障允许每个线程等待，知道所有的合作线程都达到某一点，然后从该点继续执行 线程间的通信目的主要是用于线程同步，所以线程没有像进程通信中的同于数据交换的通信机制`},{header:"进程之间私有和共享的资源",slug:"进程之间私有和共享的资源",content:`私有：地址空间、堆、全局变量、栈、寄存器
共享：代码段、公共数据、进程目录、进程ID`},{header:"线程之间私有和共享的资源",slug:"线程之间私有和共享的资源",content:`私有：线程栈、寄存器、程序计数器
共享：堆、地址空间、全局变量、静态变量`},{header:"多进程与多线程间的对比、优劣与选择",slug:"多进程与多线程间的对比、优劣与选择",content:""},{header:"对比",slug:"对比",content:`对比维度
多进程
多线程
总结 数据共享、同步
数据共享复杂，需要用 IPC；数据是分开的，同步简单
因为共享进程数据，数据共享简单，但也是因为这个原因导致同步复杂
各有优势 内存、CPU
占用内存多，切换复杂，CPU 利用率低
占用内存少，切换简单，CPU 利用率高
线程占优 创建销毁、切换
创建销毁、切换复杂，速度慢
创建销毁、切换简单，速度很快
线程占优 编程、调试
编程简单，调试简单
编程复杂，调试复杂
进程占优 可靠性
进程间不会互相影响
一个线程挂掉将导致整个进程挂掉
进程占优 分布式
适应于多核、多机分布式；如果一台机器不够，扩展到多台机器比较简单
适应于多核分布式
进程占优`},{header:"优劣",slug:"优劣",content:`优劣
多进程
多线程 优点
编程、调试简单，可靠性较高
创建、销毁、切换速度快，内存、资源占用小 缺点
创建、销毁、切换速度慢，内存、资源占用大
编程、调试复杂，可靠性较差`},{header:"选择",slug:"选择",content:`需要频繁创建销毁的优先用线程
需要进行大量计算的优先使用线程
强相关的处理用线程，弱相关的处理用进程
可能要扩展到多机分布的用进程，多核分布的用线程
都满足需求的情况下，用你最熟悉、最拿手的方式`},{header:"死锁",slug:"死锁",content:""},{header:"原因",slug:"原因",content:`系统资源不足
资源分配不当
进程运行推进顺序不合适`},{header:"产生条件",slug:"产生条件",content:`互斥
请求和保持
不剥夺
环路`},{header:"预防",slug:"预防",content:`打破互斥条件：改造独占性资源为虚拟资源，大部分资源已无法改造
打破不可抢占条件：当一进程占有一独占性资源后又申请一独占性资源而无法满足，则退出原占有的资源
打破占有且申请条件：采用资源预先分配策略，即进程运行前申请全部资源，满足则运行，不然就等待，这样就不会占有且申请
打破循环等待条件：实现资源有序分配策略，对所有设备实现分类编号，所有进程只能采用按序号递增的形式申请资源
有序资源分配法
银行家算法`},{header:"文件系统",slug:"文件系统",content:`Windows：FCB 表 + FAT + 位图
Unix：inode + 混合索引 + 成组链接`},{header:"主机字节序与网络字节序",slug:"主机字节序与网络字节序",content:""},{header:"主机字节序（CPU字节序）",slug:"主机字节序-cpu字节序",content:""},{header:"概念",slug:"概念",content:`主机字节序又叫CPU字节序，其不是由操作系统决定的，而是由CPU指令集架构决定的。主机字节序分为两种： 大端字节序（Big Endian）：高序字节存储在低位地址，低序字节存储在高位地址
小端字节序（Little Endian）：高序字节存储在高位地址，低序字节存储在低位地址`},{header:"存储方式",slug:"存储方式",content:`32位整数 0x12345678 是从起始位置位 0x00 的地址开始存放，则： 内存地址
0x00
0x01
0x02
0x03 大端
12
34
56
78 小端
78
56
34
12 大端小端图片`},{header:"大小端实例",slug:"大小端实例",content:`我们知道在计算机中所有数据都是用二进制表示的，举个例子，如果用16位二进制表示数字 258 ，它的二进制是 0000000100000010 ，转换成16进制是 0x0102 。
假如使用大端模式存入内存，内存数据如图： 还原这个数字的步骤是： 拿到第1个字节的数据 00000001，乘以进制位256（2的8次方），得到256，即第1个字节（低地址）代表了十进制数字256；
拿到第2个字节的数据 00000010 ，它代表十进制数字2，乘以进制位1，得到2；
将前两步得到的数字相加，即256+2，得到258，还原出数字。 假如使用小端模式存入内存，内存数据如图： 还原这个数字的步骤是： 拿到第1个字节的数据 00000010 ，它代表十进制数字2，乘以进制位1，得到2；
拿到第2个字节的数据 00000001，乘以进制位256（2的8次方），得到256，即第1个字节（低地址）代表了十进制数字256；
将前两步得到的数字相加，即256+2，得到258，还原出数字。 常用的X86结构是小端模式，很多的ARM、DSP都为小端模式，但KEIL C51则为大端模式，有些ARM处理器还可以由硬件来选择是大端模式还是小端模式。也就是说市面上的手机有些采用大端，有些采用小端模式。`},{header:"判断大端小端",slug:"判断大端小端",content:`可以这样判断自己 CPU 字节序是大端还是小端：
#include <iostream>
using namespace std; int main()
{ int i = 0x12345678; if (*((char*)&i) == 0x12) cout << "大端" << endl; else cout << "小端" << endl; return 0;
}`},{header:"各架构处理器的字节序",slug:"各架构处理器的字节序",content:`x86（Intel、AMD）、MOS Technology 6502、Z80、VAX、PDP-11 等处理器为小端序
Motorola 6800、Motorola 68000、PowerPC 970、System/370、SPARC（除 V9 外）等处理器为大端序
ARM（默认小端序）、PowerPC（除 PowerPC 970 外）、DEC Alpha、SPARC V9、MIPS、PA-RISC 及 IA64 的字节序是可配置的`},{header:"网络字节序",slug:"网络字节序",content:"网络字节顺序是TCP/IP中规定好的一种数据表示格式，它与具体的CPU类型、操作系统等无关，从而可以保证数据在不同主机之间传输时能够被正确解释。"},{header:"页面置换算法",slug:"页面置换算法",content:"在地址映射过程中，若在页面中发现所要访问的页面不在内存中，则产生缺页中断。当发生缺页中断时，如果操作系统内存中没有空闲页面，则操作系统必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。而用来选择淘汰哪一页的规则叫做页面置换算法。"},{header:"分类",slug:"分类",content:`全局置换：在整个内存空间置换
局部置换：在本进程中进行置换`},{header:"算法",slug:"算法",content:`全局： 工作集算法
缺页率置换算法 局部： 最佳置换算法（OPT）
先进先出置换算法（FIFO）
最近最久未使用（LRU）算法
时钟（Clock）置换算法`},{header:"内存管理",slug:"内存管理",content:""},{header:"虚拟内存",slug:"虚拟内存",content:`虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。
虚拟内存是指把磁盘的一部分作为假想的内存来使用。
通过借助虚拟内存，在内存不足时也可以运行程序。例如，造只剩下5MB内存空间的情况下也能运行10MB大小的程序。不过，CPU只能执行加载到内存中的程序。虚拟内存虽说是把磁盘作为内存的一部分来使用，但实际上正在运行的程序部分，在这个时间点上是必须在内存中的。也就是说，为了实现虚拟内存，就必须把实际内存（也可称物理内存）的内容和磁盘的虚拟内存的内容进行部分置换，并同时运行程序。
虚拟内存的方法分为两种： 分页式：在不考虑程序构造的情况下，把运行的程序按照一定大小的页（Page）进行分割，并以页为单位在内存和磁盘建进行置换。
分段式：把要运行的程序分割成以处理集合及数据集合等为单位的段落，然后再以分割后的段落为单位在内存和磁盘之间进行数据置换。 Windows使用的是分页式`},{header:"分页系统地址映射",slug:"分页系统地址映射",content:`内存管理单元（MMU）管理着地址空间和物理内存的转换，其中的页表（Page table）存储着页（程序地址空间）和页框（物理内存空间）的映射表。
一个虚拟地址分成两个部分，一部分存储页面号，一部分存储偏移量。
下图的页表存放着16个页，这16页需要用4个比特为来进行索引定位。例如对于虚拟地址（0010 000000000100），前4位是存储页面号2，读取表向内容为（1101），页表顶最后一位表示是否存在于内存中，1表示存在。后12位存储偏移量。这个页对应的页框的地址为（110 000000000100）。`},{header:"页面置换算法",slug:"页面置换算法-1",content:`在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。
页面置换算法和缓存淘汰策略类似，可以将内存看成磁盘的缓存。在缓存系统中，缓存的大小有限，当有新的缓存到达时，需要淘汰一部分已经存在的缓存，这样才有空间存放新的缓存数据。
页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。`},{header:"1.最佳 OPT, Optimal replacement algorithm",slug:"_1-最佳-opt-optimal-replacement-algorithm",content:`所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。
是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。
举例：一个系统为某进程分配了三个物理块，并有如下页面引用序列：
7，0，1，2，0，3，0，4，2，3，0，3，2，1，2，0，1，7，0，1 开始运行时，先将7，0，,三个页面装入内存。当进程要访问页面2时，产生缺页中断，会将页面7换出，因为页面7再次被访问的时间最长。`},{header:"2.最近最久未使用 LRU, Least Recently Used",slug:"_2-最近最久未使用-lru-least-recently-used",content:`虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。LRU 将最近最久未使用的页面换出。
为了实现 LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。
因为每次访问都需要更新链表，因此这种方式实现的 LRU 代价很高。
4，7，0，7，1，0，1，2，1，2，6`},{header:"3.最近未使用 NRU, Not Recently Used",slug:"_3-最近未使用-nru-not-recently-used",content:`每个页面都有两个状态位：R 与 M，当页面被访问时设置页面的 R=1，当页面被修改时设置 M=1。其中 R 位会定时被清零。可以将页面分成以下四类： R=0，M=0
R=0，M=1
R=1，M=0
R=1，M=1 当发生缺页中断时，NRU 算法随机地从类编号最小的非空类中挑选一个页面将它换出。
NRU 优先换出已经被修改的脏页面（R=0，M=1），而不是被频繁使用的干净页面（R=1，M=0）`},{header:"4.先进先出 FIFO, First In First Out",slug:"_4-先进先出-fifo-first-in-first-out",content:`选择换出的页面是最先进入的页面。
该算法会将那些经常被访问的页面换出，导致缺页率升高。`},{header:"5.第二次机会算法",slug:"_5-第二次机会算法",content:`FIFO 算法可能会把经常使用的页面置换出去，为了避免这一问题，对该算法做一个简单的修改：
当页面被访问 (读或写) 时设置该页面的 R 位为 1。需要替换的时候，检查最老页面的 R 位。如果 R 位是 0，那么这个页面既老又没有被使用，可以立刻置换掉；如果是 1，就将 R 位清 0，并把该页面放到链表的尾端，修改它的装入时间使它就像刚装入的一样，然后继续从链表的头部开始搜索。`},{header:"6.时钟 Clock",slug:"_6-时钟-clock",content:"第二次机会算法需要在链表中移动页面，降低了效率。时钟算法使用环形链表将页面连接起来，再使用一个指针指向最老的页面。"},{header:"分段",slug:"分段",content:`虚拟内存采用的是分页技术，也就是将地址空间划分成固定大小的页，每一页再与内存进行映射。
下图为一个编译器在编译过程中建立的多个表，有 4 个表是动态增长的，如果使用分页系统的一维地址空间，动态增长的特点会导致覆盖问题的出现。 分段的做法是把每个表分成段，一个段构成一个独立的地址空间。每个段的长度可以不同，并且可以动态增长。`},{header:"段页式",slug:"段页式",content:"程序的地址空间划分成多个拥有独立地址空间的段，每个段上的地址空间划分成大小相同的页。这样既拥有分段系统的共享和保护，又拥有分页系统的虚拟内存功能。"},{header:"分页与分段的比较",slug:"分页与分段的比较",content:"对程序员的透明性：分页透明，但是分段需要程序员显式划分每个段。 地址空间的维度：分页是一维地址空间，分段是二维的。 大小是否可以改变：页的大小不可变，段的大小可以动态改变。 出现的原因：分页主要用于实现虚拟内存，从而获得更大的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护。"}]},{path:"/Basic/os/memory.html",title:"Memory",pathLocale:"/",contents:[{header:"Memory",slug:"memory",content:""},{header:"Modern Cpp Memory Management",slug:"modern-cpp-memory-management",content:"https://www.udemy.com/course/modern-cpp-memory-management-learn-to-write-good-code-fast/"},{header:"Introduction to memory management",slug:"introduction-to-memory-management",content:"https://www.memorymanagement.org/mmref/index.html#mmref-intro"},{header:"Introduction memory allocator",slug:"introduction-memory-allocator",content:"https://github.com/mtrebi/memory-allocators"},{header:"Memory Allocation Strategies",slug:"memory-allocation-strategies",content:"https://www.gingerbill.org/series/memory-allocation-strategies/"}]},{path:"/Basic/os/thread.html",title:"Thread",pathLocale:"/",contents:[{header:"Thread",slug:"thread",content:""},{header:"C++ Concurrency in Action 2nd.pdf",slug:"c-concurrency-in-action-2nd-pdf",content:"https://livebook.manning.com/book/c-plus-plus-concurrency-in-action/chapter-1/"},{header:"Async Execution",slug:"async-execution",content:""},{header:"Async tutorial example",slug:"async-tutorial-example",content:`https://thispointer.com/c11-multithreading-part-9-stdasync-tutorial-example/
https://solarianprogrammer.com/2012/10/17/cpp-11-async-tutorial/`},{header:"Async loading data example",slug:"async-loading-data-example",content:"https://www.youtube.com/watch?v=2eJm6tA4y2U"},{header:"Learn Multithreading in C++",slug:"learn-multithreading-in-c",content:"https://www.udemy.com/course/cplusplus-multithreading/"},{header:"C# async await explained",slug:"c-async-await-explained",content:"https://blog.ndepend.com/c-async-await-explained/"},{header:"Concurrency",slug:"concurrency",content:"https://www.udemy.com/course/modern-cpp-concurrency-in-depth/"},{header:"Coroutines",slug:"coroutines",content:`A tutorial on C++ 20 Coroutines https://www.scs.stanford.edu/~dm/blog/c++-coroutines.html
https://en.cppreference.com/w/cpp/language/coroutines#co_yield C++ Coroutines https://www.incredibuild.com/blog/cpp-coroutines-lets-play-with-them Understanding C++ Coroutines by example https://youtu.be/1Wy5sq3s2rg
https://github.com/lewissbaker/cppcoro Debugging C++ Coroutines https://clang.llvm.org/docs/DebuggingCoroutines.html`},{header:"Fibers",slug:"fibers",content:"Introduction to fibers in c++ https://www.romange.com/2018/12/15/introduction-to-fibers-in-c-/ https://graphitemaster.github.io/fibers/"},{header:"Job system",slug:"job-system",content:""},{header:"Simple job system using standard C++",slug:"simple-job-system-using-standard-c",content:"https://wickedengine.net/2018/11/24/simple-job-system-using-standard-c/"},{header:"Job system: Lock-free",slug:"job-system-lock-free",content:"https://blog.molecular-matters.com/2015/08/24/job-system-2-0-lock-free-work-stealing-part-1-basics/"},{header:"C# Job System in Unity",slug:"c-job-system-in-unity",content:`https://www.intel.com/content/www/us/en/developer/articles/guide/get-started-with-the-unity-entity-component-system-ecs-c-sharp-job-system-and-burst-compiler.html
https://docs.unity3d.com/Manual/JobSystem.html
https://blog.unity.com/engine-platform/what-is-a-job-system`},{header:"Lock-free Programming",slug:"lock-free-programming",content:""},{header:"Async tutorial example",slug:"async-tutorial-example-1",content:`https://thispointer.com/c11-multithreading-part-9-stdasync-tutorial-example/
https://solarianprogrammer.com/2012/10/17/cpp-11-async-tutorial/`},{header:"Async loading data example",slug:"async-loading-data-example-1",content:"https://www.youtube.com/watch?v=2eJm6tA4y2U"},{header:"Multi-thread Renderingthread",slug:"multi-thread-renderingthread",content:""}]},{path:"/GameEngine/Godot/Debugging.html",title:"Debugging",pathLocale:"/",contents:[{header:"Debugging",slug:"debugging",content:""},{header:"Viusal Studio",slug:"viusal-studio",content:"需要设置一下调试，如下操作： 设置一下，引擎路径即可。"}]},{path:"/GameEngine/Unreal/References.html",title:"References",pathLocale:"/",contents:[{header:"References",slug:"references",content:`代码规范
资源命名规范 类与结构体 http://jollymonsterstudio.com/2018/12/07/ue4-c-fundamentals-structs/
https://iq.opengenus.org/structure-vs-class-in-cpp/ Deattach后再Attach无法调试的问题。可以使用UE编辑器编译一次，需要关闭Live Coding。
https://dev.epicgames.com/documentation/en-us/unreal-engine/animation-blueprint-blend-nodes-in-unreal-engine`}]},{path:"/Career/interview/interview.html",title:"面试",pathLocale:"/",contents:[{header:"面试",slug:"面试",content:""},{header:"你负责的业务是什么？(学会发现问题)",slug:"你负责的业务是什么-学会发现问题",content:"业务最核心的要素是业务本身的价值"},{header:"可以开始写代码了？(学会思考的方式)",slug:"可以开始写代码了-学会思考的方式",content:""},{header:"图，是思想的结晶",slug:"图-是思想的结晶",content:`第一步，先想明白这张图要表达什么？
第二步，图里的每一个大块必须是同一个领域或类似概念的，每一个框都有意义
第三步，画完回顾一下是否描述清楚了第一步里的核心逻辑`},{header:"知道原理有什么用？(技术如何赋能)",slug:"知道原理有什么用-技术如何赋能",content:`知其然，而后使其然
任务的拆解`},{header:"从1到10能做什么？(思考方式的抽象)",slug:"从1到10能做什么-思考方式的抽象",content:"业务/技术思考 => 发现痛点 => 产出方案 => 拆解实现"}]},{path:"/Career/interview/last.html",title:"反向面试",pathLocale:"/",contents:[{header:"反向面试",slug:"反向面试",content:`大部分翻译自：https://github.com/viraptor/reverse-interview ，亦有其他网友补充。 译者总结的一份适合突击记忆的简洁版 LeetCode 题解和面试问题，也欢迎 Star。https://github.com/yifeikong/interview 下面列表里的问题对于参加技术面试的人来说可能有些用。
列表里的问题并不一定适用于某个特定的职位或者工作类型，也没有排序
最开始的时候这只是我自己的问题列表，但是慢慢地添加了一些我觉得可能让我对这家公司亮红牌的问题。
我也注意到被我面试的人提问我的问题太少了，感觉他们挺浪费机会的。
如果你问过的问题没有被列出来，请提交一个 PR。
翻译：
English
Korean
Portuguese`},{header:"预期使用方式",slug:"预期使用方式",content:`检查一下哪些问题你感兴趣
检查一下哪些是你可以自己在网上找到答案的
找不到的话就向面试官提问 绝对不要想把这个列表里的每个问题都问一遍。（尊重面试官的时间，而且你可以通过查找已经发布的答案来显示
你的主动性）
请记住事情总是灵活的，组织的结构调整也会经常发生。拥有一个 bug 追踪系统并不会保证高效处理 bug。
CI/CD （持续集成系统） 也不一定保证交付时间会很短。`},{header:"职责",slug:"职责",content:`On-call （电话值班）的计划或者规定是什么？值班或者遇到问题加班时候有加班费吗？
我的日常工作是什么？
有给我设定的特定目标吗？
团队里面初级和高级工程师的比例是多少？（有计划改变吗）
入职培训 (onboarding) 会是什么样的？
每个开发者有多大的自由来做出决定？
在你看来，这个工作做到什么程度算成功？
你期望我在最初的一个月 / 三个月能够完成什么？
试用期结束的时候，你会怎么样衡量我的绩效？
自己单独的开发活动和按部就班工作的比例大概是怎样的？
一个典型的一天或者一周的工作是怎样安排的？
对我的申请你有什么疑虑么？
在这份工作上，我将会和谁紧密合作？
我的直接上级他们的上级都是什么样的管理风格？（事无巨细还是着眼宏观）
我在这个岗位上应该如何发展？会有哪些机会？
每天预期 / 核心工作时间是多少小时？
我入职的岗位是新增还是接替之前离职的同事？（是否有技术债需要还）？(zh)
入职之后在哪个项目组，项目是新成立还是已有的？(zh)`},{header:"技术",slug:"技术",content:`公司常用的技术栈是什么？
你们怎么使用源码控制系统？
你们怎么测试代码？
你们怎么追踪 bug?
你们怎样监控项目？
你们怎么集成和部署代码改动？是使用持续集成和持续部署吗 (CI/CD)？
你们的基础设施搭建在版本管理系统里吗？或者是代码化的吗？
从计划到完成一项任务的工作流是什么样的？
你们如何准备故障恢复？
有标准的开发环境吗？是强制的吗？
你们需要花费多长时间来给产品搭建一个本地测试环境？（分钟 / 小时 / 天）
你们需要花费多长时间来响应代码或者依赖中的安全问题？
所有的开发者都可以使用他们电脑的本地管理员权限吗？
介绍一下你们的技术原则或者展望。
你们的代码有开发文档吗？有没有单独的供消费者阅读的文档？
你们有更高层次的文档吗？比如说 ER 图，数据库范式
你们使用静态代码分析吗？
你们如何管理内部和外部的数字资产？
你们如何管理依赖？
公司是否有技术分享交流活动？有的话，多久一次呢？(zh)
你们的数据库是怎么进行版本控制的？(zh)
业务需求有没有文档记录？是如何记录的？(zh)`},{header:"团队",slug:"团队",content:`工作是怎么组织的？
团队内 / 团队间的交流通常是怎样的？
你们使用什么工具来做项目组织？你的实际体会是什么？
如果遇到不同的意见怎样处理？
谁来设定优先级 / 计划？
如果团队没能赶上预期发布日期怎么办？
每周都会开什么类型的会议？
会有定期的和上级的一对一谈话吗？
产品 / 服务的规划是什么样的？（n 周一发布 / 持续部署 / 多个发布流 / ...)
生产环境发生事故了怎么办？是否有不批评人而分析问题的文化？
有没有一些团队正在经历还尚待解决的挑战？
你们如何跟踪进度？
预期和目标是如何设定的？谁来设定？
Code Review 如何实施？
给我介绍下团队里一个典型的 sprint
你们如何平衡技术和商业目标？
你们如何共享知识？
团队有多大？
公司技术团队的架构和人员组成？(zh)
团队内开发、产品、运营哪一方是需求的主要提出方？哪一方更强势？(zh)`},{header:"问未来的同事",slug:"问未来的同事",content:`开发者倾向于从哪里学习？
你对在这里工作最满意的地方是？
最不满意的呢？
如果可以的话，你想改变哪里？
团队最老的成员在这里多久了？
在小团队中，有没有出现成员性格互相冲突的情况？最后是如何解决的？`},{header:"公司",slug:"公司",content:`公司为什么在招人？（产品发展 / 新产品 / 波动...)
有没有会议 / 旅行预算？使用的规定是什么？
晋升流程是怎样的？要求 / 预期是怎样沟通的？
绩效评估流程是怎样的？
技术和管理两条职业路径是分开的吗？
对于多元化招聘的现状或者观点是什么？
有公司级别的学习资源吗？比如电子书订阅或者在线课程？
有获取证书的预算吗？
公司的成熟度如何？（早期寻找方向 / 有内容的工作 / 维护中 / ...)
我可以为开源项目做贡献吗？是否需要审批？
你认为公司未来五年或者十年会发展成什么样子？
公司的大多数员工是如何看待整洁代码的？
你上次注意到有人成长是什么时候？他们在哪方面成长了？
在这里成功的定义是什么？如何衡量成功？
有体育活动或者团建么？
有内部的黑客马拉松活动吗？
公司支持开源项目吗？
有竞业限制或者保密协议需要签吗？
你们认为公司文化中的空白是什么？
能够跟我说一公司处于不良情况，以及如何处理的故事吗？
您在这工作了多久了？您觉得体验如何？(zh)
大家为什么会喜欢这里？(zh)
公司的调薪制度是如何的？(zh)`},{header:"社会问题",slug:"社会问题",content:`你们关于多元化招聘什么看法？
你们的公司文化如何？你认为有什么空白么？
这里的工作生活平衡地怎么样？
公司对气候变化有什么态度吗？`},{header:"冲突",slug:"冲突",content:`不同的意见如何处理？
如果被退回了会怎样？（“这个在预计的时间内做不完”）
当团队有压力并且在超负荷工作的时候怎么处理？
如果有人注意到了在流程或者技术等其他方面又改进的地方，怎么办？
当管理层的预期和工程师的绩效之间有差距的时候如何处理？
能给我讲一个公司深处有毒环境以及如何处理的故事吗？
如果在公司内你的同事因涉嫌性侵犯他人而被调查，请问你会如何处理？
假设我自己很不幸是在公司内被性侵的受害者，在公司内部有没有争取合法权益的渠道？`},{header:"商业",slug:"商业",content:`你们现在盈利吗？
如果没有的话，还需要多久？
公司的资金来源是什么？谁影响或者制定高层计划或方向？
你们如何挣钱？
什么阻止了你们挣更多的钱？
公司未来一年的增长计划怎样？五年呢？
你们认为什么是你们的竞争优势？
你们的竞争优势是什么？
公司未来的商业规划是怎样的？有上市的计划吗？(zh)`},{header:"远程工作",slug:"远程工作",content:`远程工作和办公室工作的比例是多少？
公司提供硬件吗？更新计划如何？
使用自己的硬件办公可以吗？现在有政策吗？
额外的附件和家具可以通过公司购买吗？这方面是否有预算？
有共享办公或者上网的预算吗？
多久需要去一次办公室？
公司的会议室是否一直是视频会议就绪的？`},{header:"办公室布局",slug:"办公室布局",content:`办公室的布局如何？（开放的 / 小隔间 / 独立办公室）
有没有支持 / 市场 / 或者其他需要大量打电话的团队在我的团队旁边办公？`},{header:"终极问题",slug:"终极问题",content:`该职位为何会空缺？
公司如何保证人才不流失？
这份工作 / 团队 / 公司最好和最坏的方面是？
你最开始为什么选择了这家公司？
你为什么留在这家公司？`},{header:"待遇",slug:"待遇",content:`如果有奖金计划的话，奖金如何分配？
如果有奖金计划的话，过去的几年里通常会发百分之多少的奖金？
有五险一金(zh)/401k(us)或者其他退休养老金等福利吗？
五险一金中，补充公积金一般交多少比例？/401k一般交多少比例？我可以自己选择这一比例吗？
有什么医疗保险吗？如果有的话何时开始？
有额外商业保险吗？例如人寿保险和额外的养老/医疗保险？
更换工作地点，公司付费吗？`},{header:"休假",slug:"休假",content:`带薪休假时间有多久？
病假和事假是分开的还是一起算？
我可以提前使用假期时间吗？也就是说应休假期是负的？
假期的更新策略是什么样的？也就是说未休的假期能否滚入下一周期
照顾小孩的政策如何？
无薪休假政策是什么样的？
学术性休假政策是怎么样的？`},{header:"其他资源",slug:"其他资源",content:`Find more inspiration for questions in: The Joel Test: 12 Steps to Better Code by Joel Spolsky
Questions I'm asking in interviews by Julia Evans`},{header:"License",slug:"license",content:`Creative Commons License
This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.`}]},{path:"/Gameplay/AI/GameAIModel.html",title:"游戏AI模型",pathLocale:"/",contents:[{header:"游戏AI模型",slug:"游戏ai模型",content:`一般游戏中的AI模块我们都可以它分为三个小块： 移动
行为决策
策略 前两个都是对于单个AI角色的操作，策略则是对多个AI角色的操作。当然也有某些游戏没有其中的某一个小块。`},{header:"移动 MOVEMENT",slug:"移动-movement",content:"移动是指使用算法去决定角色进入某种运动，或者更简单的理解就是寻路系统。当AI角色想要执行某个特定的行为时，如攻击，但是AI角色想要攻击的对象并不在AI角色的攻击范围内，所以就需要让这个角色走到让攻击对象在他攻击范围内。当然这个移动的这个过程中需要避开障碍物。"},{header:"行为决策 DECISION MAKING",slug:"行为决策-decision-making",content:"行为决策是指我们的角色下一步需要做什么。我们的角色有很多不同的行为，我们需要根据当前的环境筛选出最适合在当前执行的行为的一个过程。我们经常听到的行为树他的功能范围就是这个。"},{header:"策略 STRATEGY",slug:"策略-strategy",content:"这是并不是控制某一个单位的行为，而是控制多个单位，把他们看做一个整体来控制，在moba游戏里像是团战怎么打或者是rts游戏中一队小兵集体做什么。"},{header:"基础设施 INFRASTRUCTURE",slug:"基础设施-infrastructure",content:"指的是游戏的基本运行组件，比如说是我们要使一个角色自动从A点移动B点，怎么走到B点，走那一条路是AI程序需要计算的，这个角色的走的前提是它具备走这个能力，我们需要使用动画、位移、物理等使这个角色拥有这个能力，这个就属于是基础设施。这个部分也有让我们的AI角色感受到周围世界，从中获取信息从而根据这些信息去执行我们的AI逻辑。"},{header:"基于代理的AI AGENT-BASED AI",slug:"基于代理的ai-agent-based-ai",content:`指我们在设计AI功能时，我们是以自底向上的方式还是自顶向下的方式设计。
自底向上：你需要从每一个角色的行为是什么和通过AI程序去支持什么，把这些小的实现合并在一起了，就是一个游戏的AI系统。换句话说就是我有一个角色，我知道他的所有的数据，把这些数据传入一个公用或者工具方法中，这个角色就去执行AI需要做的行为。这种方式就是基于代理的AI系统。
自顶向下：我们需要总结出一个完整的角色体系，在这个体系中去实现模拟我们的角色行为。`}]},{path:"/Gameplay/AI/",title:"Game AI",pathLocale:"/",contents:[{header:"Game AI",slug:"game-ai",content:"Game AI PRO"}]},{path:"/Gameplay/AI/RTSAI.html",title:"RTS Game AI",pathLocale:"/",contents:[{header:"RTS Game AI",slug:"rts-game-ai",content:"是一个自底向上的设计方式做的。"},{header:"移动",slug:"移动",content:""},{header:"导航",slug:"导航",content:`两层导航：空中、地面
主要策略为走最少的点`},{header:"世界转换",slug:"世界转换",content:`可视化点，预先配置建筑的转角点与地形的转角点。 量化是在有建筑创建或是销毁是就会执行
这里执行的重建 GridChangesVisibilityGraphHelper.ModifyVisibilityGraph
转角会根据寻路单位的体型改变，防止单位被卡住和不能通过。`},{header:"流程",slug:"流程",content:`先使用射线探测是否可以直接到达目的，不能就是启动寻路，能就直接走到目标点
PathfindingProcessor.EvaluatePathWork
添加寻路计算到Job线程中执行
PathfindingProcessor.DoPathingWork
PathfindingProcessor.PathfindingJobDelegate
主要使用了 A*算法，先把之前射线检测到的障碍物的转角点先加入Open列表。
VisibilityGraph.FindPath
然后选出最小预计总花销的节点作为当前节点。
VisibilityGraph.DoPathFind
判断当前节点是否可以到达起始节点,如果可以则实际使用射线检测判断当前节点是否可以直接到达起始节点。
如果可以直接到达起始节点则把当前节点的上一个节点修改为起点。
VisibilityGraph.CheckOriginConnection
判断当前节点是否可以直接到达目的地，使用射线检测判断，如果不能直接到达，也就是当前节点与目标点有障碍物，如果有碰撞就更新碰撞的障碍物的转角节点的信息并加入Open列表。
VisibilityGraph.HandleRaycastObstacleHit
如果当前节点可以直接到达目的地，就直接返回当前节点。不能直接到达则将当前节点移除Open列表，并加入Closed列表。
根据当前点是在起点的左边还是右边更新当前节点对应的所有连接的节点信息，
VisibilityGraph.AccumulateNeighbours
且找出与当前节点所有相连的节点最小总预计花销的点。
VisibilityGraph.ExpandNeighbours
判断该节点与Open列表中最小的节点，如果新的节点小于Open中的，那么就不需要把所有新发现的节点加入到Open列表中。
否则在新节点加入Open列表后，找到最小花销点，再次循环更新当前节点。`},{header:"细节实现",slug:"细节实现",content:""},{header:"节点计算信息：",slug:"节点计算信息",content:`Cost-so-far: 两个节点距离
Heuristic: 当前节点到目的节点距离
Open,Closed: 寻路节点状态
StatusToPathOrigin：位于起点左方右方
StatusToPathDestination：：位于终点点左方右方
NeighboursInRightRegion: 右边的连接点
NeighboursInLeftRegion: 左边的连接点`},{header:"左右判断",slug:"左右判断",content:"这里的左右是使用的转角两边做判断。 这个转角是90度圆锥，方向是由中心点到转角点的方向决定。只需要使用起点与圆锥两边分别做点乘即可得到当前转角位于起始点的左边还是右边。"},{header:"碰撞检测",slug:"碰撞检测",content:`先把地图网格化，如果格子上有建筑，那么这个格子就会被定义为障碍物，再判断由起点到终点连线上是否有已经被定义为障碍物的格子。
但是有这种情况，障碍物只有半在格子中 我们只需要计算三角形与射线是否相交，即只需要判断射线与三角形任意两个边是否相交就可以了。在即就是判断线段的两个端点是否在边的两侧。`},{header:"特殊处理",slug:"特殊处理",content:""},{header:"行为制定",slug:"行为制定",content:""},{header:"建筑 & 生产单位",slug:"建筑-生产单位",content:""},{header:"单位行为树",slug:"单位行为树",content:""},{header:"单位技能",slug:"单位技能",content:`在AIGroupAbilityActivationAttributes配置当前阵营的所有单位的技能，
同样是规则系统，满足执行条件就分配行为树中去执行`},{header:"任务系统",slug:"任务系统",content:""},{header:"策略",slug:"策略",content:""},{header:"团队行为",slug:"团队行为",content:""},{header:"Influence Map",slug:"influence-map",content:""}]},{path:"/Gameplay/ECS/SampleECS.html",title:"一个简单实体框架",pathLocale:"/",contents:[{header:"一个简单实体框架",slug:"一个简单实体框架",content:""},{header:"是什么？",slug:"是什么",content:`我们经常会听到ECS这个名词，最近Unity也在推动他的ECS框架。那到底什么呢?
我们从字面上来解释就是Entity-Component-System，也就是实体-组件-系统。
分别解释一下： Entity ：一个对象
Component ：存储数据的容器
System ：处理对象数据的运行器 我们可以从《游戏编程模式》中看到一个叫作组件模式，我认为ECS就是该模式的变种。`},{header:"为什么用ECS",slug:"为什么用ecs",content:""},{header:"解耦",slug:"解耦",content:`我们在游戏里所有不同的系统被杂糅进一团乱麻的代码，如我们设计一个人物类：
if (collidingWithFloor() && (getRenderState() != INVISIIBLE))
{ playSound(HIT_FLOOR);
} 这样耦合的设计在任何游戏中都是一种糟糕的设计，并且在使用并发性时会更加的不好。好的并发性是希望把游戏的各个模块在各自的线程运行，如AI计算在一个核中完成，生效在另一个核，渲染在第三个核等。
如果想要修改以上代码，就需要程序员了解物理、图像以及声音相关知识。
我们将这个人物类根据域边界切分成相互独立的部分。如，我们将所有用户的输入的代码放到一个单独的类InputComponent中。完成切分后，我们几乎把这个人物类中所有的东西都清空了，这样这个人物类就只剩下一个空壳，那么这个空壳我们就叫Entity。`},{header:"轻量对象",slug:"轻量对象",content:"当我们使用面向对象编程的时候，继承总是最实用的工具。它被视为代码重用的终极武器。然而我们发现这个武器很多时候是块绊脚石，继承有它的用途，但是对某些对象中的父类逻辑，该对象可能永远不会用到，这会使这个设计存在冗余。"},{header:"简单的设计",slug:"简单的设计",content:"我们先来看看整个的框架的流程，如下图： 我们在系统模块中去搜索我们需要处理的实体，搜索条件是拥有或者是不拥有某个特定的组件。然后遍历找到的所有实体，检测数据或者修改数据，再做特定的行为。这里的数据就是组件。"},{header:"实体组件管理",slug:"实体组件管理",content:`我们在设一个 EntityContext 类来管理所有的实际与组件，其中使用两个数组来管理所有的实体与组件，使用索引来做每个实体与组件的映射。使用这种方式，我们需要固定每个实体的组件数量。具体的映射图如下： 这样设计才使得我们的实体是真正意义上是一个空壳。
我们这样设计就需要为每个组件设置固定的索引去映射到组件数组中去，所以我们在ECS启动时，为每个组件分配唯一的索引，也可以叫做组件ID。
这样我们可以通过实体的索引与组件的ID来获取到某个组件,计算如下：
int componentIndex = entity.index * maxComponentsPerEntity + Component.ID;
Component com = components[componentIndex];`},{header:"索引池",slug:"索引池",content:`这里我们就需要设计一个索引池来维护实体的索引，其实实体的索引也可以认为就是实体的ID，索引与ID都需要是唯一的。
我们申请一个数组来作为索引池，以这个数组的索引来最为实体的索引也就是ID。`},{header:"实体筛选",slug:"实体筛选",content:`我们需要获取特定的实例，比如我们需要获取所有含有PositionComponent这个组件的实体，按照正常的想法就是对所有的实体遍历，判断每一个实体是否拥有该组件。
再具体的做法就是获得该组件的ID，根据实体的索引获得该组件的对象，判断其是否为空就可以了。
这里我们可以不去关注组件对象本身，我们可以使用一个更为直观简单高效的方式来判断一个实体是否拥有一个组件。
使用一个数字的二进制的每一位 0/1 表示是否有当前位数的组件，我们的组件的ID是动态分配的，从0开始，我们可以把ID看做数字的二进制的多少位。这样我们可以把这个问题转为这个数字的第多少位是否是1。如果是1,说明实体拥有该组件。
但是这样做会有一个弊端就是越界，我们数字的长度是有限的，当一个数字不足时，我们可以使用两个数字来存储，一个数字左移，一个数字右移。
但是这个都不是万全之策。但是从我们的实际使用来看设计一个可以存储128为的数字即可，使用两个Int64数字组合。`},{header:"Entity",slug:"entity",content:`Entity ：我们的实体就是一个空壳，里面只需要一个ID字段即可。
EntityType ：实体类型的接口来区别表现层与逻辑层的实体。`},{header:"Component",slug:"component",content:`ComponentID ： 组件的ID，需要在系统开始时注册到一个集中的地方，然后分别动态分配数值。
ComponentBase ： 注册与销毁组件ID。`},{header:"System",slug:"system",content:`ProcessBase ：逻辑处理器，一般一个组件对应一个处理器。
EntityProcess ：含有所有逻辑处理器且驱动它们。`},{header:"源码",slug:"源码",content:"GitHub"}]},{path:"/Gameplay/design/card.html",title:"卡牌",pathLocale:"/",contents:[{header:"卡牌",slug:"卡牌",content:""},{header:"3D",slug:"_3d",content:`https://store.steampowered.com/app/1265820/Fights_in_Tight_Spaces/
https://store.steampowered.com/app/1709050/Nitro_Kid/
https://store.steampowered.com/app/1260590/_Hadean_Tactics/
https://store.steampowered.com/app/780290/Gloomhaven/`},{header:"2D",slug:"_2d",content:`https://store.steampowered.com/app/2146170/__HD_Remaster/
https://store.steampowered.com/app/2088160/_Traveler_of_Wuxia/
https://store.steampowered.com/app/2113040/_/
https://store.steampowered.com/app/1915780/Tendryll/
https://store.steampowered.com/app/2920970/2_MetaCard2__Prologue/
https://store.steampowered.com/app/1824580/_/
https://store.steampowered.com/app/1449070/_/`}]},{path:"/Gameplay/design/",title:"参考",pathLocale:"/",contents:[{header:"参考",slug:"参考",content:`https://www.romsgames.net/gameboy-advance-rom-chocobo-land---game-de-dice/
https://www.romsgames.net/gameboy-advance-rom-choh-makai-mura-r-eurasia/
https://www.romsgames.net/gameboy-advance-rom-sennen-kazoku-supplex/`}]},{path:"/Gameplay/design/simulation.html",title:"Simulation",pathLocale:"/",contents:[{header:"Simulation",slug:"simulation",content:""},{header:"陀螺游戏",slug:"陀螺游戏",content:`https://www.romsgames.net/gameboy-advance-rom-beyblade-g-revolution/
https://www.romsgames.net/roms/gameboy-advance/?letter=all&page=12&sort=alphabetical
数值模拟向`},{header:"钓鱼模拟",slug:"钓鱼模拟",content:"https://www.romsgames.net/gameboy-advance-rom-kawa-no-nushi-tsuri-3-4/"}]},{path:"/Gameplay/network/GameServerGuide.html",title:"游戏网络通信浅析",pathLocale:"/",contents:[{header:"游戏网络通信浅析",slug:"游戏网络通信浅析",content:""},{header:"服务器三问",slug:"服务器三问",content:"我们都知道现在游戏可以分为单机游戏和网络游戏，简单区别就是一个独自快乐，一个是多人快乐。"},{header:"什么是服务器",slug:"什么是服务器",content:`简单地说就是一台电脑。在那台电脑上运行一些特定程序，这些程序主要的功能： 游戏和玩家的数据存储
玩家交互数据进行广播和同步
重要逻辑要在服务器上运算，做好验证，防止外挂`},{header:"为啥要服务器",slug:"为啥要服务器",content:"因为玩家不想让他很牛逼这个事情，只有他知道，他想告诉全世界。当然对开发者来说，是一个比较简单防破解的方式。"},{header:"怎么用服务器",slug:"怎么用服务器",content:`我们从编程的角度来看看单机游戏和网络游戏的区别： 单机游戏设计思路如下图 在游戏开始时，需要加载一些资源，这些资源包括地图信息、模型、配置表等。加载完成之后，选择角色进入有即可。
从编码的角度来说，游戏一旦开始，运行的就是一个无限循环，就像是Unity中Monobehavior的Update，我们可以认为它是一个 while（true）{...}，除非离开游戏，否则这个循环会一直执行下去。循环的每一次执行称为一帧。在一帧中包括三个主要操作： 检测玩家输入
根据输入更新内存数据，刷新场景、人物模型、界面等。
捕捉退出请求，如果有退出请求，这个循环就会被打破，游戏结束。 理论上来讲，一秒能产生的循环数越大，程序的反应就越灵敏，玩家看到就是越流畅。 网络游戏设计思路如下图 网络游戏和单机游戏一样也有一个循环，只是多了一个网络层的处理。简单的理解就是把以前一个人完成的任务，分成两个人来做。因为是两个人做事，所以就会出现异步这个概念。也就是一个人需要另一个人的支持，所以就会出现一个人等待另一个人的支持。
我们以登录为例来展示一下具体不同之处，登录流程： 在登录界面输入账号和密码之后，要经历一个异步的操作，客户端向服务端发送协议，等待服务端返回数据，由此来判断登录成功或者失败。网络游戏yum的哭护短发出命令，只有等到服务端给它结果，它才会做出反应。客户端向服务端请求账号验证，这个请求数据不是一个函数可以完成的，这就是一个异步的过程。`},{header:"网络基础",slug:"网络基础",content:`计算机网络体系结构
我们可以把网络使用不同的数据模型分层，我通常使用五层协议来对网络理解。`},{header:"数据流程",slug:"数据流程",content:"这里我们使用发一个微信消息给好友来简单解释一下数据的流向。"},{header:"使用",slug:"使用",content:`我们游戏服务器与客户端使用到的就是运输层中的TCP与UPD协议，我们一般使用套接字（socket）创建
我们可以使用套接字（Socket)来对不同主机上的应用进程进行通信。一个套接字就是网络上进程通信的一端，提供了应用层进程利用网络协议交换数据的机制。从所处的地位来讲，套接字上联应用进程，下联网络协议栈，是应用程序通过网络协议进行通信的接口，是应用程序与网络协议根进行交互的接口。
Api： 连接 socket.Connect
发送 socket.Send
接收 socket.Receive
关闭 socket.Close 当收到对端（服务器或客户端）数据时，操作系统会将数据存入到Socket的接收缓冲区中，接收缓冲区存有数据的TCP Socket示意图如下： 上图可以看到，接收缓冲区有4个字节数据，分别是1、2、3、4。操作系统层面上的缓冲区完全由操作系统操作，程序不能直接操作它们，只能通过socket.Receive、socket.Send等方法来间接操作。
Socket的Receive方法只是把接收缓冲区的数据提取出来，比如调用 Receive(readBuff,0,2) ，接收2个字节的数据到readbuff。上图例子中，调用后操作系统接收缓冲区只剩下了2个字节数据，用户缓冲区readBuff保存了接收到的2字节数据，形成下图： 当系统的接收缓冲区为空，Receive方法会被阻塞，知道里面有数据。
同样地，Socket的Send方法只是把数据写入到发送缓冲区里，具体的发送过程由操作系统负责。当操作系统的发送缓冲区满了，Send方法将会阻塞。`},{header:"网络模型",slug:"网络模型",content:`我们知道可以使用计算机网络中的Socket来传输信息。那么我们是以什么角色来使用这个工具呢？这里就引出我们常说几个名词： 客户端
服务器
我们使用排列组合，就可以列出两种常见的网络模型`},{header:"客户端-服务器",slug:"客户端-服务器",content:`我们从名字（Client-Server）可以看出这个模型中是有两个不同的角色。这种网络模型也是最常用的。我们看看他们各自的定义： 服务器：一个具有高性能可以存储数据和信息的机器
客户端：一个让用户可以访问远程数据的机器 系统管理员在服务器上管理数据。客户端与服务器通过网络连接。客户端可以访问数据，即使客户端机器离服务器机器很远在物理距离上。
客户端向服务器发送请求，服务器接收到请求后，处理数据，再向客户端回复信息。
所有的服务都是由中心服务器提供，所以这个模型会出现瓶颈的问题。`},{header:"点对点",slug:"点对点",content:"不同于客户端-服务器模型，在点对点（Peer to Peer — P2P）并没有特别定义哪个是服务器那个是客户端。每一个节点都可以作为客户端和服务器。 在P2P网络环境中，彼此连接的多台计算机之间都处于对等的地位，各台计算机有相同的功能，无主从之分，一台计算既可作为服务器，设定共享资源供网络中其他计算机所使用，又可以作为工作站，整个网络一般来说不依赖专用的集中服务器，也没有专用的工作站。网络中的每一台计算机既能充当网络服务的请求者，又对其他计算机的请求做出响应，提供资源、服务和内容。通常这些资源和服务包括：信息的共享和交换、计算资源（如CPU计算能力共享）、存储共享（如缓存和磁盘空间的使用）、网络共享、打印机共享等。"},{header:"区别",slug:"区别",content:`内容
服务器 - 客户端
点对点 基础
有一个服务器与多个连接到服务器的客户端
没有定义服务器与客户端，每一个节点都可以是客户端或服务器 服务
客户端发出请求，服务器响应请求
每个节点都可以发出请求也可以提供服务 聚焦
共享信息
连接 数据
数据存在中心服务器
没有端都有自己的数据 服务器
当多个客户端向一个服务器发出请求，这个服务器会出现瓶颈
由于服务是由分布在对等系统中的多个服务器提供的，因此服务器不会出现瓶颈 价格
贵
不是那么贵 稳定性
很稳
节点越多稳定减少`},{header:"同步理论",slug:"同步理论",content:`在客户端——服务端架构中，无论是用什么样的同步方法，都始终遵循着下图所示的过程： 客户端1向服务端发送一条消息，服务端收到后稍作处理，把它广播给所需的客户端（客户端1、客户端2和客户端3）。
所传递的消息可以是角色的位置、旋转这样的状态值，也可以是“向前走”这样的指令值。前者称之为状态同步，后者称之为指令同步。`},{header:"同步的难题",slug:"同步的难题",content:`由于存在网络延迟和抖动，往往很难做到精确的同步。
例如：下图左边展示的是理想的网络情况，服务端定时发送消息给客户端，客户端立刻就能够收到。 而实际的网络情况并非如此，更像右边的情况，这里出现了两个问题： 消息的传播需要时间，会有延迟
消息的倒带时间并不稳定，有时候两条消息会像个较长时间，有时候却相隔很短 传播时间长了，也就是我们常说的延迟高了，就会出现卡顿的现象。
看一个实例：
玩家1控制的坦克从A点走向C点，玩家2看到的坦克总是延迟了一小段时间，所以玩家1和玩家2看到的战场不会完全一致。 网络颜值问题基本无解，只能权衡。比如： 尽量发送更少的数据，数据越少，发生数据丢失并重传的概率就越小，平均速度越快。
在客户端上做些“障眼法”，让玩家感受不到延迟。`},{header:"状态同步",slug:"状态同步",content:`状态同步是同步状态信息。如在坦克游戏中，客户端把坦克的位置坐标、旋转发给服务端，服务端再做广播。
我们都以坦克的位置同步来讲解几种不同的状态同步方式。前提条件都为：
玩家1位发送位置信息的一方，玩家2为同步方，网络延迟为250毫秒。`},{header:"直接状态同步",slug:"直接状态同步",content:""},{header:"是什么",slug:"是什么",content:"最直接的同步方案就是客户端定时向服务器报告位置，其他玩家收到转发的消息后，直接将对方坦克移动到指定位置。"},{header:"分析",slug:"分析",content:"当玩家1在经过B点时发送同步信息，经过一定的网络延迟，当玩家1的坦克走到C点时，玩家B才收到消息。这时两个客户端的误差为“速度*延迟”。 如果网络延迟是固定的，那么两个客户端虽然有着不同的状态，但是最终结果会是一样的。实际上网络是波动的，假设玩家1到C点时又发送了位置信息，这时没有网络延迟，玩家2看到的同步坦克瞬移的，从B直接跳到C，很不自然。所以我们一般不这样同步位置。"},{header:"跟随算法",slug:"跟随算法",content:""},{header:"是什么",slug:"是什么-1",content:"为了解决“直接状态同步”的瞬移问题，人们引入了一种障眼法————“跟随算法”。在收到同步消息后，客户端不直接将坦克到目的地，而是让坦克以一定的速度移动。"},{header:"分析",slug:"分析-1",content:"玩家1经过B点发送同步信息，玩家2收到后，将坦克以同样的速度从A点移动到B点。此种情况下，误差更大了，因为在玩家1从B点移动到C点的过程中，玩家2看到的坦克才从A点移向B点。 然而很多时候，游戏并不需要非常精确的同步，只要同步频率足够高（玩家每1秒发送位置的次数，比如每秒发送30次），误差就可以忽略"},{header:"预测算法",slug:"预测算法",content:""},{header:"是什么",slug:"是什么-2",content:"跟随算法的一大缺陷就是误差会变得很大，在某些有规律可循的条件下，比如坦克匀速运动，或者匀加速运动，我们能够预测坦克在接下来某个时间点的位置，让坦克提前走到预测的位置上去。这就是预测算法。"},{header:"分析",slug:"分析-2",content:"假设坦克匀速前进。玩家1经过B点时发送位置信息，玩家2根据 “距离=速度*时间” 可以计算出下一次收到同步信息时，坦克应移动到C点。于是玩家2让同步坦克移向C点，玩家1和玩家2之间的误差会很小。 然而玩家1操控的坦克不可能一直保持匀速。当玩家1突然停下，玩家2看到的坦克会向前移动一段距离，又再向后移动一段距离。 跟随算法和预测算法各有优缺点，具体使用哪种算法，应当视项目需求而定。"},{header:"帧同步",slug:"帧同步",content:"帧同步是指令同步的一种，即同步操作信息。基本上所有指令同步方法都结合了帧同步，两者可以视为一体。这里 “帧” 的概念与Unity中 “每一帧执行一次Update” “30FPS（每秒传输帧数，Frames Per Second）” 里的 “Unity帧” 有所不同，我们会实现独立于 “Unity帧” 的另外一种 “同步帧”。"},{header:"指令同步",slug:"指令同步",content:""},{header:"是什么",slug:"是什么-3",content:"状态同步所同步的是状态消息，如果要同步坦克的位置和旋转，那就需要同步六个值（三个坐标值和三个旋转值）。上面提到，缓解网络延迟的一个办法是减少传输的数据量，如果只传输玩家的操作指令，数据量就会减少很多。"},{header:"分析",slug:"分析-3",content:"当玩家1要移动坦克，按下键盘上的 “上” 键时，玩家1会发送 “往前走” 的消息给服务端，经由转发，玩家2收到后，让同步坦克向前移动。当玩家1要定制移动坦克，会放开按键，发送 “停止” 指令，玩家2收到后，让坦克停止移动。"},{header:"缺点",slug:"缺点",content:"上诉过程的一大缺点是误差的累积。有些电脑速度快，有些电脑速度慢，尽管玩家2收到了玩家1的指令，但只要两者的电脑运行速度不同，可能有人看到坦克走了很远，有人看到的却只移动了一点点的距离。为了解决这个问题，人们操作同步的基础上，引入了 “同步帧” 的概念。"},{header:"从Update说起",slug:"从update说起",content:`如果有一种办法，让不同的电脑有一致的运行效果，便可以解决指令同步中的误差累积问题。
我们看看坦克移动的代码 ：
public void MoveUpdate(){ //在Unity的Update中调用 …… float y = Input.GetAxis("Vertical"); // 如果是 SyncTank ，改为由网络传播的指令 Vector3 s = y＊transform.forward ＊ speed ＊ Time.deltaTime; transform.transform.position += s;
} 由于采用了 “ 速度*时间” 的公式，理论上说，无论电脑运行速度快慢，坦克移动的路径都能够保持一致。因为当电脑很慢时，Update的执行次数会变少，但 Time.deltaTime 的值变大，反之一样，但坦克移动的路径不变。
尽管如此，我们还不能够保证经由网络同步的坦克能够有一致的行为。因为网络延迟的存在，从发出 “前进” 到 “停止” 指令之间的时间可能不一致，坦克移动的路径也就不同。一种解决办法是，在发送命令的时候附带时间信息，客户端根据指令的时间信息区修正路程的计算方式，使所有客户端表现一致。人们定义了 “帧” 的概念，来表示时间（为和Unity本身的帧区分，这里称为 “同步帧”）。`},{header:"什么是同步帧",slug:"什么是同步帧",content:`假如我们自己实现一个类似 Update 的方法，称之为 FrameUpdate，程序会固定每隔0.1秒调用它一次。每一次调用 FrameUpdate 称之为一帧，第1次调用称为第一帧，第二次调用称为第2帧，以此类推。 上图展示了一种理想情况，现实往往很残酷。比如在执行第2帧的时候，系统突然卡顿了一下，这一帧的执行时间变长了，就超过0.1秒，这会导致第3帧无法按时执行。 为了保证后面的帧能够按时执行，程序需要做出调整，即减少第2帧和第3帧之间、第3帧和第4帧之间的时间间隔，保证程序在第0.5秒是，执行到第5帧。
同步帧的具体实现如下：
int frame = 0; // 当前执行到第几帧 float interval = 0.1f; // 两帧之间的理想间隔时间 public void Update(){ while(Time.time < frame＊interval){ FrameUpdate(); frame++; }
} 上述程序中，如果某几帧的执行时间太长，程序就会立即调用下一帧（注意使用到while循环），间隔时间为0。程序尽量保证在第N秒的时候，执行到第10*N帧。FrameUpdate 每执行一次，即表示执行一次同步帧。如果程序运行了较长时间，FrameUpdate 的执行频率会相对稳定。
帧同步所保证的，就是各个客户端在执行到同一个 “同步帧” 时，表现效果完全一样。如果将移动坦克的逻辑在 FrameUpdate 里，无论这一帧的执行时间多长，每一帧移动的距离都设定为 “速度*0.1秒” ，只要执行相同的帧数，移动的距离必然相同。`},{header:"指令",slug:"指令",content:`比起操作同步，在指令同步中，客户端向服务端发送的指令包含了具体的指令和时间信息，即是在哪一帧（特指同步帧）做了哪些操作。例如：在第10帧发出了“前进”指令（按下“上”键），在第20帧发出了“后退”指令（按下“下”键）。
指令同步的协议形式如下：
// 同步协议 public class MsgFrameSync:MsgBase { public MsgFrameSync() {protoName = "MsgFrameSync"; } // 指令， 0- 前进 1- 后退 2- 左转 3- 右转 4- 停止 ... public int cmd = 0; // 在第几帧发生事件 public int frame = 0;
}`},{header:"指令的执行",slug:"指令的执行",content:`为了保持所有客户端有一样的表现，往往要做一些妥协，有两种常见的妥协方案： 有的客户端运行速度快，有运行速度慢，如果要让它们表现一致，那只能让快的客户端区等待慢的客户端，所有客户端和最慢的客户端保持一致，才有可能表现一致，毕竟，慢的客户端无论如何都快不了。这种方案对速度快的客户端较为不利。达成此方案的一个方法称为延迟执行，如果客户端1在第3帧发出向前的指令，由于网络延迟，客户端2可能在第5帧才收到，所以客户端1的坦克也只能在第5帧（或之后的某一帧）才开始前进。
对于速度慢客户端所发送的，丢弃安歇已经过时的指令，知道它赶上来。此种方案也称之乐观帧同步，对速度慢的玩家较为不利，因为某些操作指令会被丢弃。比如发出“前进”指令，但该指令被丢弃了，坦克不会移动。 所以，帧同步是一种为了保证多个客户端表现一致，让某些客户端做妥协的方案。而且如果启用了延迟执行，在玩家发出“前进”指令之后，要隔一小段时间坦克才能移动，玩家会感受到延迟。但无论如何，只要帧率（每秒执行多少帧）足够高，玩家就不会感觉到明显的延迟。
在方案一中，为了让各个客户端知道对方是否执行完某一帧，我们假定客户端每一帧都需要向服务端发送指令，没有操作也要发一个代表“没有操作”的指令。服务端要收集各个客户端的指令，收集满时，才在接下的某一帧广播出去。而客户端也只有在收到服务端的消息时，才执行下一帧。此时客户端的帧调用完全由服务端控制。 上图展示了一种帧同步的执行情况。在第1帧时（0.1s）客户端1和客户端2都向服务端发送指令，由于网络延迟，指令到达的时间也不同。服务端收集两个客户端的指令后将两条指令都广播出去，两个客户端会根据指令去执行，比如让坦克向前移动。如果某一个客户端执行很慢，另一个客户端也要等待很久才能收到服务端的指令，才会执行新的一帧，相当于等待慢的客户端。 按照每秒执行30帧的频率，客户端和服务端之间的信息交流也许太过频繁，会带来较大的网络负担。于是人们把多个帧合成为一轮（比如4帧组成一轮），每一轮向服务端同步一次指令。
帧同步还可以配合投票法来防止作弊。例如在坦克游戏中，某个玩家击中另外一个玩家，由于所有客户端的运行结果严格一致，它们都可以向服务端发送“谁击中了谁”的消息。服务端可以收集这些信息，如果半数以上的玩家都发送了击中消息，才认为有效。`},{header:"传输问题",slug:"传输问题",content:""},{header:"沾包半包",slug:"沾包半包",content:""},{header:"问题：",slug:"问题",content:`如果发送端快速发送多条数据，接收端没有及时调用Receive，那么数据便会在接收端的缓冲区中积累，如下图： 客户端先发送 “1、2、3、4” 四个字节的数据，紧接着又发送 “5、6、7、8” 四个字节的数据。等到服务端调用Receive时，服务端操作系统已经将接收到的数据全部写入缓冲区，共接收到8个数据。
我们举个例子：在聊天软件中，客户端依次发送 “LSP” 和 “_is_handsome” ，期望其他客户端也展示出 “LSP” 和 “_is_handsome” 两条信息，但由于Receive可能把两条信息当做一条信息处理，有可能只展示 “LSP_is_handsome” 一条信息，如下图： Receive方法返回多少个数据，取决于操作系统接收缓冲区中存放的内容。
发送端发送的数据还有可能被拆分，如发送 “HelloWorld”，如下图： 但在接收端调用Receive时，操作系统只接收到了部分数据，如 “Hel” ，在等待一小段时间后再次调用Receive才接收到另一部分数据 “loWord” 。`},{header:"解决 ：",slug:"解决",content:`我们可以效仿网络协议包体，为我们的数据包加一个包头，这个包头中存放该数据包长度，当然这个包头还可以放入其他的自定义信息，但是我们的包头长度需要固定。
游戏程序的包头只包含了数据包长度，这个长度一般使用16位整数或32位整数来存放。
16位消息长度的格式如下图： 32位消息长度的格式如下图：`},{header:"大端小端",slug:"大端小端",content:""},{header:"问题：",slug:"问题-1",content:`我们读取接收到的字节流时，可以按照来类型来读取，比如我们要先读取消息长度，规定消息长度为16位整数，使用API BitConverter.ToInt16(buffer,offset) 来读取。这个方法的底层是怎么实现的呢？我们看看 .Net的源码：
// Converts an array of bytes into a short. public static unsafe short ToInt16(byte[] value, int startIndex) { if( value == null) { ThrowHelper.ThrowArgumentNullException(ExceptionArgument.value); } if ((uint) startIndex >= value.Length) { ThrowHelper.ThrowArgumentOutOfRangeException(ExceptionArgument.startIndex, ExceptionResource.ArgumentOutOfRange_Index); } if (startIndex > value.Length -2) { ThrowHelper.ThrowArgumentException(ExceptionResource.Arg_ArrayPlusOffTooSmall); } Contract.EndContractBlock(); fixed( byte * pbyte = &value[startIndex]) { if( startIndex % 2 == 0) { // data is aligned return *((short *) pbyte); } else { if(IsLittleEndian) { return (short)((*pbyte) | (*(pbyte + 1) << 8)) ; } else { return (short)((*pbyte << 8) | (*(pbyte + 1))); } } } } 我们看到代码中有一个变量 IsLittleEndian，它代表这台计算机是大端编码还是小端编码，不同的计算机编码方式会有不同。所以问题就是，不同编码方式下，计算方法不同，那对与不同的计算机，读取出来的数据长度肯定是不同的，这个是需要我们处理。`},{header:"什么是大端小端？",slug:"什么是大端小端",content:`我们知道在计算机中所有数据都是用二进制表示的，举个例子，如果用16位二进制表示数字 258 ，它的二进制是 0000000100000010 ，转换成16进制是 0x0102 。
假如使用大端模式存入内存，内存数据如图： 还原这个数字的步骤是： 拿到第1个字节的数据 00000001，乘以进制位256（2的8次方），得到256，即第1个字节（低地址）代表了十进制数字256；
拿到第2个字节的数据 00000010 ，它代表十进制数字2，乘以进制位1，得到2；
将前两步得到的数字相加，即256+2，得到258，还原出数字。 假如使用小端模式存入内存，内存数据如图： 还原这个数字的步骤是： 拿到第1个字节的数据 00000010 ，它代表十进制数字2，乘以进制位1，得到2；
拿到第2个字节的数据 00000001，乘以进制位256（2的8次方），得到256，即第1个字节（低地址）代表了十进制数字256；
将前两步得到的数字相加，即256+2，得到258，还原出数字。 常用的X86结构是小端模式，很多的ARM、DSP都为小端模式，但KEIL C51则为大端模式，有些ARM处理器还可以由硬件来选择是大端模式还是小端模式。也就是说市面上的手机有些采用大端，有些采用小端模式。`},{header:"解决",slug:"解决-1",content:`在不确定的问题出现了，我们的解决方案就是把它确定就好了，就可以规定都以小端的方式发送即可。以发送代码为例，就可以写成：
public void Send()
{ string sendStr = InputFeld.text; // 组装协议 byte[] bodyBytes = System.Text.Encoding.Default.GetBytes(sendStr); Int16 len = (Int16)bodyBytes.Length; byte[] lenBytes = BitConverter.GetBytes(len); // 大小端编码 if(!BitConverter.IsLittleEndian){ Log("[Send] Reverse lenBytes"); lenBytes.Reverse(); } // 拼接字节 byte[] sendBytes = lenBytes.Concat(bodyBytes).ToArray(); socket.Send(sendBytes);
}`},{header:"完整发送数据",slug:"完整发送数据",content:""},{header:"问题",slug:"问题-2",content:`回忆一下Send方法，该方法会把要发的数据存入操作系统的发送缓冲区，然后返回成功写入的字节数。简单的解释是，对于那些没有成功发送的数据，程序需要把他们保存起来，在适当的时机再次发送。由于在网络通畅的环境下，Send只发送部分数据的概率并不高，所以很多商业游戏也没有处理这种情况。
我们以异步聊天客户端为例，假设操作系统缓冲区被设置得很小，只有8个字节，再假设网络环境很差，缓冲区的数据没能及时的发出去。我们看下图： 在客户端步骤： 假设客户端发送字符串 hero ，发送后，Send返回6（包含两字节的长度），数据全部存入操作系统缓冲区中。但此时网络拥堵，TCP尚未把数据发给服务器。
客户端又发送了字符串 cat ，由于操作系统的发送缓冲区只剩下2字节空位，只有把代表数据长度 03 写入缓冲区。
此时网络环境有所改善，TCP成功把缓冲区的数据发送给服务器，操作系统缓冲区被清空。
客户端又发送了字符串 hi ,数据发送成功 服务器收到的数据 04hero0302hi ,第一个字符串 hero 可以被解析，但对于后续 0302hi ，服务端会解析成一串3个字节的数据 02h，以及不完整的长度信息 i。04hero 往后的数据全部无法解析，通讯失败。`},{header:"解决",slug:"解决-2",content:`我们使用 Sokect.BeginSend 方法可以传入一个异步回调方法。
public IAsyncResult BeginSend(IList<ArraySegment<byte>> buffers, SocketFlags socketFlags, AsyncCallback callback, object state) 我们可以在这个回调中加入检测我们此次发送的数据是否发送完整。简单的实例代码：
//定义发送缓冲区
byte[] sendBytes = new byte[1024];
//缓冲区偏移值
int readIdx = 0;
//缓冲区剩余长度
int length = 0; //点击发送按钮
public void Send()
{ sendBytes = 要发送的数据； length = sendBytes.Length; //数据长度 readIdx = 0; socket.BeginSend(sendBytes, 0, length, 0, SendCallback, socket);
} //Send回调
public void SendCallback(IAsyncResult ar){ //获取state Socket socket = (Socket) ar.AsyncState; //EndSend的处理 int count = socket.EndSend(ar); readIdx + =count; length -= count; //继续发送 if(length > 0){ socket.BeginSend(sendBytes,readIdx, length, 0, SendCallback, socket); }
} 在检测到未发送完成后，我们在发送一次即可。
这里发送缓冲区设置的是一个长度为1024的数组，这个会有潜在的一些风险。我们可以简单的封装一个数据结构ByteArray，然后把这个数据结构使用队列来存储。
ByteArray的简单实现如下：
using System; public class ByteArray { //缓冲区 public byte[] bytes; //读写位置 public int readIdx = 0; public int writeIdx = 0; //数据长度 public int length { get { return writeIdx-readIdx; }} //构造函数 public ByteArray(byte[] defaultBytes){ bytes = defaultBytes; readIdx = 0; writeIdx = defaultBytes.Length; }
} 最终我们需要把上面发送缓冲区换成队列的实例如下：
// 发送缓冲区 Queue<ByteArray> writeQueue = new Queue<ByteArray>();
// 点击发送按钮 public void Send()
{ // 拼接字节，省略组装 sendBytes 的代码 byte[] sendBytes = 要发送的数据 ； ByteArray ba = new ByteArray(sendBytes); int count = 0; lock(writeQueue){ writeQueue.Enqueue(ba); count = writeQueue.Count; } // send if(count == 1){ socket.BeginSend(sendBytes, 0, sendBytes.Length, 0, SendCallback, socket); } Debug.Log("[Send]" + BitConverter.ToString(sendBytes));
} // Send 回调 public void SendCallback(IAsyncResult ar){ // 获取 state、EndSend 的处理 Socket socket = (Socket) ar.AsyncState; int count = socket.EndSend(ar); ByteArray ba; lock(writeQueue){ ba = writeQueue.First(); } ba.readIdx+=count; if(count == ba.length){ lock(writeQueue){ writeQueue.Dequeue(); ba = writeQueue.First(); } } if(ba ! = null){ socket.BeginSend(ba.bytes, ba.readIdx, ba.length, 0, SendCallback, socket); }
} 这里我们对缓冲队列做了加锁的操作，因为在发送回调中极可能会是多个线程操作。所以我们需要保证这个队列只能被修改一次。`},{header:"客户端网络模块",slug:"客户端网络模块",content:`我们客户端网络模块的架构如下图： 工作流程： 初始化，使用 Networkmanager 创建一个 NetworkChannel,
当需要发消息时，我们使用特定的序列化工具把对象转化为bytes，再把bytes交给协议栈
当收到消息时，我们使用特定的序列化工具把bytes 转化为对象，再把对象内容由事件传递出去。 我们可以使用一个 Networkmanager 去管理多个 NetworkChannel 。`},{header:"Networkmanager",slug:"networkmanager",content:`网络管理器，管理，驱动多个连接。其中主要的方法： CreateNetworkChannel : 创建一个连接
GetNetworkChannel ：获得一个连接
DestroyNetworkChannel ： 销毁一个连接 类图`},{header:"NetworkChannel",slug:"networkchannel",content:`管理一个Socket连接。其中主要方法： Connect ：连接服务器
Send ：发送消息
ReceiveCallback ： 处理接收消息
Close ：关闭连接 类图`},{header:"NetworkChannelHelper",slug:"networkchannelhelper",content:`序列化与反序列化消息包。主要方法： Serialize : 序列化消息包
DeserializePacketHeader : 反序列化消息包头
DeserializePacket : 反序列化消息包 类图`},{header:"EventManager",slug:"eventmanager",content:`事件分发器，负责分发消息包到执行，使用这个可以控制线程处理，可以把其他线程的运行的抛到主线程执行。主要方法： Subscribe ：订阅事件处理函数
Unsubscribe ：取消订阅事件处理函数
Fire ：抛出事件 类图`},{header:"Packet",slug:"packet",content:"消息包体，封装字节流，用于逻辑层使用。主要内容有： Id ：消息ID 类图"},{header:"通用服务器网络模块",slug:"通用服务器网络模块",content:`我们服务器的网络模块框架如下： 可以看出跟客户端的网络模块没有啥区别，很多就是换了个名字而已。这里跟客户端不同的是这里既有Server对象又有Client的对象。
这里的Client并不是连接这个服务器的客户端的意思，而是当该服务器去作为客户端去连接别的服务器时。
我们在游戏中实现一些跨服的功能（如跨服交易）时，就需要一个公共服务器来转发一些数据，或者是设计分布式服务器。我们当前的服务器都会作为客户端去连接别的服务器。`},{header:"Server",slug:"server",content:`负责作为服务器时，驱动多个Session的适配器，其中主要方法： ListenAccept : 监听新的连接
NewServer ： 启动服务器
Update ：轮询服务器，处理发送与接收数据流`},{header:"Client",slug:"client",content:`负责处理作为客户端时，驱动一个Session的适配器。其中主要方法 Send ： 发送消息到Session层
Update ：轮询客户端，处理发送与接收数据流
NewClient ： 新建一个连接到服务器`},{header:"Session",slug:"session",content:`控制每一个连接的收发消息。主要方法有： Write ： 发送消息到协议栈
Read ： 读取协议栈消息
NewSession ： 新建一个连接的管理器`},{header:"Router",slug:"router",content:`转发接收到的消息到逻辑层。主要方法有： Register ：注册路由
Handle ： 处理路由`},{header:"PacketPaser",slug:"packetpaser",content:`消息的解码器。主要方法有： Encode ：序列化对象到bytes
Decode ：反序列化bytes到对象`},{header:"Packet",slug:"packet-1",content:`消息包体，可以分为： SendPacket
ReceivePacket`},{header:"参考",slug:"参考",content:`https://developer.valvesoftware.com/wiki/Source_Multiplayer_Networking
https://www.zhihu.com/question/41498780/answer/1537480110
https://www.zhihu.com/question/433768405/answer/1700193198
https://gameinstitute.qq.com/community/detail/117210
https://zhuanlan.zhihu.com/p/28447002
https://www.cnblogs.com/panchanggui/p/9841768.html
https://unitylist.com/p/j35/Unity-Lockstep
https://unitylist.com/p/bmi/Unity-texture-curve
https://unitylist.com/p/k9s/Unity-ECS-RTS
https://techdifferences.com/difference-between-client-server-and-peer-to-peer-network.html`}]},{path:"/Gameplay/network/OrcaOnlineServices.html",title:"Project Online Layer",pathLocale:"/",contents:[{header:"Project Online Layer",slug:"project-online-layer",content:`顶层使用： Game.Online 基础接口： Carbon.Network
Carbon.Online 实现： System.Online.Steam
System.Online.Epic
System.Online.Null API: Steamworks.NET
Epic.OnlineServices`}]},{path:"/Graphic/DirectX/D3D9.html",title:"D3D9",pathLocale:"/",contents:[{header:"D3D9",slug:"d3d9",content:`SDK下载：https://www.microsoft.com/en-us/download/details.aspx?id=6812
安装：https://blog.csdn.net/dragoo1/article/details/121946520
VS 设置：https://blog.csdn.net/wo16pao/article/details/104240846`}]},{path:"/Graphic/DirectX/Note.html",title:"Note",pathLocale:"/",contents:[{header:"Note",slug:"note",content:""},{header:"关于编辑错误 ： C2102",slug:"关于编辑错误-c2102",content:"https://blog.csdn.net/WhoisPo/article/details/112689870"}]},{path:"/Graphic/basic/References.html",title:"资料",pathLocale:"/",contents:[{header:"资料",slug:"资料",content:""},{header:"大纲",slug:"大纲",content:`两种算法：光栅化、光线追踪
数学
光栅化
着色
光追
使用像素来替换物体，
定义一个几何体在内存中：用三个浮点数表示一个点，然后链接起来。
使用三角形来代表几何表面，三角形是最简单的几何形状`},{header:"书籍",slug:"书籍",content:`3D数学基础：图形与游戏开发 Unity Shader入门精要 Fundamentals of Computer Graphics, Fourth Edition by Marschner, Steve Shirley, Peter Introduction to 3D Game Programming with DirectX 12 Jim Blinn’s Corner: A Trip Down the Graphics Pipeline (J. Blinn, 1996)
3D Game Engine Design (Eberly, 2000)
Real-TimeRendering (Akenine-M ¨oller et al., 2008)`},{header:"课程",slug:"课程",content:""},{header:"GAMES101: 现代计算机图形学入门主页",slug:"games101-现代计算机图形学入门主页",content:`主页
视频`},{header:"仓库",slug:"仓库",content:"测试代码GitHub"},{header:"参考博客",slug:"参考博客",content:`Scratch
免费下载一些图形书
线性代数
https://scarletsky.github.io/
https://github.com/ssloy`}]},{path:"/Graphic/bgfx/debug_draw.html",title:"Debug Draw",pathLocale:"/",contents:[{header:"Debug Draw",slug:"debug-draw",content:"路径： modules/bgfx.cmake/bgfx/examples/common/debugdraw/debugdraw.cpp"},{header:"drawLineList",slug:"drawlinelist",content:"视为连个为一组"}]},{path:"/Graphic/bgfx/how_to_select_platform.html",title:"How to select the platform",pathLocale:"/",contents:[{header:"How to select the platform",slug:"how-to-select-the-platform",content:"在初始化bgfx时，可以设置bgfx::init.type来控制渲染使用的API。"}]},{path:"/Graphic/bgfx/uniform_render_flow.html",title:"Uniform Render Flow",pathLocale:"/",contents:[{header:"Uniform Render Flow",slug:"uniform-render-flow",content:""},{header:"bgfx::setUniform",slug:"bgfx-setuniform",content:"Params:(UniformHandle _handle, const void* _value, uint16_t _num = 1)"},{header:"Encoder::setUniform",slug:"encoder-setuniform",content:"Params:(UniformHandle _handle, const void* _value, uint16_t _num = 1)"},{header:"EncoderImpl::setUniform",slug:"encoderimpl-setuniform",content:`Write value to UniformBuffer
Params:(UniformType::Enum _type, UniformHandle _handle, const void* _value, uint16_t _num)
File: bgfx_p.h`},{header:"EncoderImpl::submit",slug:"encoderimpl-submit",content:`Set RenderDraw uniformIDx, uniformBegain, UniformEnd
Params: (ViewId _id, ProgramHandle _program, OcclusionQueryHandle _occlusionQuery, uint32_t _depth, uint8_t _flags);
File: bgfx.cpp`},{header:"RendererContext::submit",slug:"renderercontext-submit",content:`Params: (Frame* _render, ClearQuad& /_clearQuad/, TextVideoMemBlitter& _textVideoMemBlitter)
File: Platform Renderer(renderer_d3d12.cpp)`},{header:"bgfx::rendererUpdateUniforms",slug:"bgfx-rendererupdateuniforms",content:`Copy/Move uniform buffer to renderer native uniform buffer
Params: (RendererContextI* _renderCtx, UniformBuffer* _uniformBuffer, uint32_t _begin, uint32_t _end)
File: bgfx.cpp`},{header:"RendererContext::updateUniform",slug:"renderercontext-updateuniform",content:`Cache uniform buffer in local m_uniforms. Make up constant buffer.
Params: (uint16_t _loc, const void* _data, uint32_t _size)
File: Platform Renderer(renderer_d3d12.cpp)`},{header:"RendererContext::commit",slug:"renderercontext-commit",content:`Set m_uniforms data to m_fsCcratch/m_vsScratch array by uniform type
File: Platform Renderer(renderer_d3d12.cpp)`},{header:"RendererContext::commit",slug:"renderercontext-commit-1",content:`Write m_vsScratch/m_fsScratch to m_scratchBUffer
File: Platform Renderer(renderer_d3d12.cpp)`}]},{path:"/Graphic/bgfx/windows_launch_flow.html",title:"Example Windows Launch Flow",pathLocale:"/",contents:[{header:"Example Windows Launch Flow",slug:"example-windows-launch-flow",content:""},{header:"Create Window",slug:"create-window",content:"文件为：bgfx.cmake\\bgfx\\examples\\common\\entry\\entry_windows.cpp，入口函数如下： 在 Context::run 函数中创建Windows的窗口以及监听窗口事件，与此同时创建一个线程来开启 bgfx::entry::main 方法。"},{header:"bgfx::entry::main",slug:"bgfx-entry-main",content:`该方法首先初始化以下模块： cmdInit
input inputInit
inputAddBindings windows info 然后启动entry::AppI程序。`},{header:"Launch entry::AppI",slug:"launch-entry-appi",content:`在自己的脚本里必须实现，以下函数：
int _main_(int _argc, char** _argv)
{ return 0;
} 可以直接在该函数里实例化一个应用，然后调用entry::runApp，来启动应用。
如果已经实例化AppI对象，启动AppI有两种方式： 多个应用，使用命令行传入App名字来判断启动那个
一个时，直接运行entry::runApp`},{header:"entry::AppI::init",slug:"entry-appi-init",content:`初始化宽度，调试等级...
bgfx::init(init)
bgfx::setViewClear(0...)
imguiCreate()`},{header:"entry::AppI::shutdown",slug:"entry-appi-shutdown",content:`imguiDestroy()
bgfx::shutdown()`},{header:"entry::AppI::update",slug:"entry-appi-update",content:`entry::processEvents(...)
bgfx::setViewRect(..)
bgfx::touch(...): submit an empty primitive for rendering.
commit frame buffer...
bgfx::frame(): advance to next frame
imguiBeginFrame()
custom imgui...
imguiEndFrame()`}]},{path:"/Graphic/simple_shader/",title:"unity simple shader",pathLocale:"/",contents:[{header:"unity simple shader",slug:"unity-simple-shader",content:`Tips
一些简单的unity shader https://github.com/BanMing/BanMingShaderLab`}]},{path:"/Tools/Windows/AccessIsDenied.html",title:"How to fix - Error 5: Access is Denied in Windows 10",pathLocale:"/",contents:[{header:"How to fix - Error 5: Access is Denied in Windows 10",slug:"how-to-fix-error-5-access-is-denied-in-windows-10",content:`Error indicates that you wont have required privileges to install the application to that particular system drive. Right-click on the application(.exe) file and select Run as administrator installing the same. Do follow the below mentioned steps and heck if it helps.
Method 1:
Open the properties of the main User Profile folder where the files are located (such as Documents, Pictures, etc.). You can open the properties of a particular folder by Right-clicking on it and select Properties from context menu.
Go to the Security tab and click Advanced. Check the box at the bottom of this window. It is labeled "Replace all child object permissions with inheritable permissions from this object" and then click Ok.
This does a one-time action that replaces the security on all the files/subfolders. It’s one-time, so you won’t find that box checked if you peek at it later. Please let us know if it’s working
Method 2: Press Windows Key + R, type netplwiz Click and highlight the User profile, which you want to make administrator Click on Properties, then select the Group Membership tab Select the Administrator, Click apply/ok`}]},{path:"/Tools/Windows/",title:"Windows",pathLocale:"/",contents:[{header:"Windows",slug:"windows",content:""},{header:"强制关闭exe的命令",slug:"强制关闭exe的命令",content:"Start taskkill /im exe_name.exe /f"},{header:"因为在此系统上禁止运行脚本”解决办法",slug:"因为在此系统上禁止运行脚本-解决办法",content:'我们通过管理员权限运行power shell，然后输入命令 set-ExecutionPolicy RemoteSigned 如果执行了操作后，还出现了 "未对文件 xxxxx 进行数字签名", 需要选择xxx.ps1文件右键 -> 属性 -> 点击 "解除锁定" 框框'}]},{path:"/Tools/Windows/SmallTool.html",title:"自制小工具",pathLocale:"/",contents:[{header:"自制小工具",slug:"自制小工具",content:""},{header:"声音控制",slug:"声音控制",content:`https://www.py.cn/faq/python/19079.html
实际设置的音量大小和设置值之间有个对应关系
{0: -65.25, 1: -56.99, 2: -51.67, 3: -47.74, 4: -44.62, 5: -42.03, 6: -39.82, 7: -37.89, 8: -36.17, 9: -34.63, 10: -33.24, 11: -31.96, 12: -30.78, 13: -29.68, 14: -28.66, 15: -27.7, 16: -26.8, 17: -25.95, 18: -25.15, 19: -24.38, 20: -23.65, 21: -22.96, 22: -22.3, 23: -21.66, 24: -21.05, 25: -20.46, 26: -19.9, 27: -19.35, 28: -18.82, 29: -18.32, 30: -17.82, 31: -17.35, 32: -16.88, 33: -16.44, 34: -16.0, 35: -15.58, 36: -15.16, 37: -14.76, 38: -14.37, 39: -13.99, 40: -13.62, 41: -13.26, 42: -12.9, 43: -12.56, 44: -12.22, 45: -11.89, 46: -11.56, 47: -11.24, 48: -10.93, 49: -10.63, 50: -10.33, 51: -10.04, 52: -9.75, 53: -9.47, 54: -9.19, 55: -8.92, 56: -8.65, 57: -8.39, 58: -8.13, 59: -7.88, 60: -7.63, 61: -7.38, 62: -7.14, 63: -6.9, 64: -6.67, 65: -6.44, 66: -6.21, 67: -5.99, 68: -5.76, 69: -5.55, 70: -5.33, 71: -5.12, 72: -4.91, 73: -4.71, 74: -4.5, 75: -4.3, 76: -4.11, 77: -3.91, 78: -3.72, 79: -3.53, 80: -3.34, 81: -3.15, 82: -2.97, 83: -2.79, 84: -2.61, 85: -2.43, 86: -2.26, 87: -2.09, 88: -1.91, 89: -1.75, 90: -1.58, 91: -1.41, 92: -1.25, 93: -1.09, 94: -0.93, 95: -0.77, 96: -0.61, 97: -0.46, 98: -0.3, 99: -0.15, 100: 0.0}`}]},{path:"/Tools/Windows/win32.html",title:"Note",pathLocale:"/",contents:[{header:"Note",slug:"note",content:`WNDCLASSEX, RegisterClassEx, CreateWindowEx 与 WNDCLASSEXA, RegisterClassExA, CreateWindowExA
前者是显示的创建一个窗口，后者是隐藏创建一个窗口。`}]},{path:"/Web/Project/shop.html",title:"Shop",pathLocale:"/",contents:[{header:"Shop",slug:"shop",content:""},{header:"优选",slug:"优选",content:`https://github.com/linlinjava/litemall
https://github.com/HelloZouYou/easy-mall`},{header:"全套",slug:"全套",content:`https://github.com/hxrui/youlai-mall
https://github.com/stavyan/TinyShop-UniApp`},{header:"前端",slug:"前端",content:`https://github.com/linlinjava/litemall
https://github.com/dyq086/wepy-mall`},{header:"后端&后台",slug:"后端-后台",content:""},{header:"golang",slug:"golang",content:`https://github.com/silenceper/wechat
https://github.com/medivhzhan/miniapp`},{header:"PHP",slug:"php",content:"https://github.com/jianyan74/rageframe2"},{header:"后台",slug:"后台",content:"https://github.com/macrozheng/mall-admin-web"}]},{path:"/Basic/algorithm/leetcode/",title:"Some algorithm",pathLocale:"/",contents:[{header:"Some algorithm",slug:"some-algorithm",content:""}]},{path:"/Basic/language/CSharp/CodeConvention.html",title:"编码规范",pathLocale:"/",contents:[{header:"编码规范",slug:"编码规范",content:""},{header:"文件",slug:"文件",content:""},{header:"文件名字和类名字应该一致",slug:"文件名字和类名字应该一致",content:"MyClass.cs public class MyClass { … }"},{header:"布局",slug:"布局",content:""},{header:"1. 避免在一个文件中写多个命名空间或者类",slug:"_1-避免在一个文件中写多个命名空间或者类",content:"这可以让你代码更具有可读性，让他更容易的被找到根据文件名称"},{header:"2. 命名空间",slug:"_2-命名空间",content:`// .NET namespaces first
using System;
using System.Collections;
// Then any other namespaces in alphabetical order
using Company.Business;
using Company.Standard;
using Telerik.Ajax;
using Telerik.WebControls;`},{header:"3.每个类布局顺序",slug:"_3-每个类布局顺序",content:`内部枚举、结构体、类
成员变量和属性
构造、初始化、销毁方法
公有方法
私有方法`},{header:"缩进",slug:"缩进",content:""},{header:"1. 基础为4个空格",slug:"_1-基础为4个空格",content:`// A Hello World! program in C#.
using System;
namespace HelloWorld
{ class Hello { static void Main() {
Console.WriteLine("Hello World!"); } }
}`},{header:"2. 一行最多130个字符",slug:"_2-一行最多130个字符",content:`当一行放不下了，用下面的规则： 在逗号之后换行
在操作符之后换行
新一行对齐前一行同样的表达式级别 方法调用换行实例：
优质：
LongMethodCall(expr1, expr2,
expr3, expr4, expr5); 劣质：
LongMethodCall(expr1, expr2 ,expr3, expr4, expr5); 表达式换行实例：
优质：
var result = a * b / (c - g + f) + 4 * z; 劣质：
var result = a * b / (c - g + f) + 4 * z;`},{header:"3. 行末的花括号需要放在新的一行",slug:"_3-行末的花括号需要放在新的一行",content:`while (x == y)
{ FirstMethod(); SecondMethod();
} LastMethod();`},{header:"4. 必须使用花括号即使不需要",slug:"_4-必须使用花括号即使不需要",content:`即使只有一行的 if 判断句，也需要添加。
if (x == y)
{ DoSomething();
}`},{header:"空格",slug:"空格",content:`规则： 关键字后有一个空格：if,while
for循环的分号后有一个空格
逗号后面有一个空格
操作符后有一个空格：+,-,-- 等
不需要加空格在 ( 之后与 ) 之前 实例：
a = (b + c) * d;
while (true) DoSomething(a, b, c, d)
for (i = 0; i < 10; i++)`},{header:"命名",slug:"命名",content:""},{header:"1. 所有命名应该是英语",slug:"_1-所有命名应该是英语",content:"在国际合作开发中英语更有优势"},{header:"2. 对语言元素使用适当的大小写",slug:"_2-对语言元素使用适当的大小写",content:`Tips
帕斯卡命名法（Pascal casing）：一句文本中的每个单词的首字母为大写
驼峰命名法（Camel casing）：一句文本中的每个单词的首字母为大写，除了文本的首字母 语言元素
命名法
样例 Class, Struct
Pascal
AppDomain Interface
Pascal
IBusinessService Enumeration
Pascal
ErrorLevel Enumeration values
UPPER_CASE
FATAL_ERROR Event
Pascal
Click Public field
Camel
listItem Private field
Camel
_listItem Protected field
Camel
mListItem Constant field
UPPER_CASE
MAXIMUM_ITEM_NUMBER Constant local variable
UPPER_CASE
MAXIMUM_ITEM_NUMBER Read-only static field
Pascal
ReadValue Local variable
Camel
listOfValues Method
Pascal
ToString Namespace
Pascal
System.Drawing Parameter
Camel
typeName Type parameter
Pascal
TView Property
Pascal
BackColor`},{header:"3.避免使用缩略语",slug:"_3-避免使用缩略语",content:`除非全名过长： 避免缩略超过5个字符
缩略语必须是广泛的被知道的
使用2个字符的大写缩略，使用Pascal命名方式对于长的缩略 优质：
UIControl
HtmlSource 劣质：
UiControl
HTMLSource`},{header:"4. 布尔类型参数前缀",slug:"_4-布尔类型参数前缀",content:`Can
Is
Has Tips
避免使用布尔参数作代表反面的性质，例如： 使用 IsInitialized ，而不是 IsNotInitialized`},{header:"5. 在参数或属性中不要包含该类的名字",slug:"_5-在参数或属性中不要包含该类的名字",content:`优质：
Customer.Name 劣质：
Customer.CustomerNam`},{header:"注释",slug:"注释",content:`在注释定界符（//）和注释文本之间插入一个空格。
使用 //
使用内联注释来解释假设，已知问题和算法见解
不要使用内联注释来解释明显的代码。 编写良好的代码可以自我记录。
使用 // TODO
重构建议使用 // TODO :Refactor(username_optional)`},{header:"语言规范",slug:"语言规范",content:""},{header:"1. 不要忽略写访问权限",slug:"_1-不要忽略写访问权限",content:"需要在声明时，写全访问权限"},{header:"2. 使用C#内置的数据类型名字，而不是用.NET通用类型",slug:"_2-使用c-内置的数据类型名字-而不是用-net通用类型",content:`优质：
short
int
long
string 劣质：
Int16
Int32
Int64
String`},{header:"3. 不要使用var",slug:"_3-不要使用var",content:"容易不知道变量类型，不易阅读。"},{header:"4.使用默认初始化器赋值，而不是单独写赋值",slug:"_4-使用默认初始化器赋值-而不是单独写赋值",content:`优质：
ProcessStartInfo startInfo = new ProcessStartInfo("myapp.exe")
{ StandardOutput = Console.Output, UseShellExecute = true
}; 劣质：
ProcessStartInfo startInfo = new ProcessStartInfo("myapp.exe"); startInfo.StandardOutput = Console.Output;
startInfo.UseShellExecute = true;`},{header:"5. 代码用法",slug:"_5-代码用法",content:`代码
形式 变量
每一个声明一个变量 属性
不要加前缀 Get 和 Set 不想要额外变量，简单的声明public int MyVariable { get; private set; } 方法
最多7个参数 base 和 this
只在构造方法或override中使用 三元表达式
避免复杂的条件 迭代
不要在foreach语句中修改枚举项 异常
不要将异常用于流控制只抛出你能处理的使用验证来避免异常从Execption派生而不是ApplicationException 事件
在触发是需要检测是否为空 锁
使用lock()而不是Monitor.Enter()不要锁对象的类型或者this锁一个私有的对象 Dispose() & Close()
如果它提供了，就要使用时常记得声明 类
避免放多个类在一个文件中 Finalizers
不要用使用C#的析构函数不要创建Finalize()方法`},{header:"6. 变量与类型",slug:"_6-变量与类型",content:`尽量初始化值在定义变量时
尽量选择最简单的数据类型
避免使用数字在代码里，使用常数或是枚举代替
声明 readonly 和 static readonly 的变量而不是复杂的 常数类型
只对简单的类型声明常数
避免直接转化，使用 as 操作符然后检测是否为空object dataObject = LoadData();
DataSet dataSet = dataObject as DataSet; if(dataSet != null)
{...} 始终使用for循环显式初始化引用类型的数组
避免对值类型装箱与拆箱int count = 1;
object refCount = count; // Implicitly boxed.
int newCount = (int)refCount; // Explicitly unboxed. 尝试对字符串文字使用@前缀，而不是转义的字符串
使用StringBuilder连接大量字符串（在循环内）
不要使用""或者string.Empty来判断空字符串，而是用string.IsNullOrEmpty()方法
避免在循环中分配隐藏的字符串。 使用String.Compare()区分大小写 // Bad!
int id = -1;
string name = "lance hunt"; for(int i=0; i < customerList.Count; i++)
{ if(customerList[i].Name.ToLower() == name) { id = customerList[i].ID; } } // Good!
int id = -1;
string name = "lance hunt"; for(int i=0; i < customerList.Count; i++)
{ // The "ignoreCase = true" argument performs a // case-insensitive compare without new allocation. if(String.Compare(customerList[i].Name, name, true) == 0) { id = customerList[i].ID; }
}`},{header:"7. 流程控制",slug:"_7-流程控制",content:`避免在条件表达式中调用方法
避免使用递归，使用循环代替
避免使用foreach遍历不可变的值类型集合。 例如：字符串数组
在foreach中不要修改枚举项
仅将三元条件运算符用于简单条件。避免复杂的或复合的三元运算。示例：int result = isValid ? 9：4;
避免在if判断时，使用布尔值再加判断：// Bad!
if (isValid == true)
{...} // Good!
if (isValid)
{...} 避免在条件语句中赋值。示例 ：if((i=2)==2){...}
避免使用复合条件表达式,使用布尔变量将零件拆分为多个可管理的表达式// Bad!
if (((value > _highScore) && (value != _highScore)) && (value < _maxScore))
{...} // Good!
isHighScore = (value >= _highScore);
isTiedHigh = (value == _highScore);
isValid = (value < _maxValue); if ((isHighScore && ! isTiedHigh) && isValid) {...} 仅将switch/case语句用于具有并行条件逻辑的简单操作
对于简短的条件序列和复杂的条件，优先使用嵌套if/else而不是switch/case
使用多态或委托来替换switch/case语句`},{header:"8. 对象模型与API设计",slug:"_8-对象模型与api设计",content:`避免过早的使用泛型
当设计已经很清晰了，才创建抽象类
做最简单的实现，这样重构才有意义
尽量使对象的生命周期是对用户是不可见的
始终把表现层和逻辑层分离
优先使用接口而不是抽象类
当使用设计模式时，在类名中加入设计模式名字后缀，如：Brdge、Adpter、Factory
经常重构`},{header:"参考",slug:"参考",content:`https://google.github.io/styleguide/csharp-style.html
https://docs.microsoft.com/en-us/dotnet/standard/design-guidelines/naming-guidelines`}]},{path:"/Basic/language/CSharp/ForLoop.html",title:"并行循环效率",pathLocale:"/",contents:[{header:"并行循环效率",slug:"并行循环效率",content:`基本可以放弃使用
https://www.c-sharpcorner.com/UploadFile/efa3cf/parallel-foreach-vs-foreach-loop-in-C-Sharp/
https://blog.csdn.net/li315171406/article/details/78450534`}]},{path:"/Basic/language/CSharp/Interview.html",title:"Some Questions",pathLocale:"/",contents:[{header:"Some Questions",slug:"some-questions",content:""},{header:"C#的编译过程",slug:"c-的编译过程",content:"C#->IL->机器码"},{header:"什么是IL代码",slug:"什么是il代码",content:"IL-> Intermediate Language，它是一个部分编译的代码"},{header:"什么是JIT",slug:"什么是jit",content:"JIT-> Just in time compiler，使用JIT来编译IL代码到机器码"},{header:"为啥么要用IL",slug:"为啥么要用il",content:"因为开发环境和运行环境会有不同，根据运行环境JIT会来编译不同平带的机器码。同样在开发时，速度会更加的快了。"},{header:"什么是CLR",slug:"什么是clr",content:`CLR-> Common Language Runtime CLR 触发JIT来编译IL代码
清理任何没有使用的对象通过GC`},{header:"什么是托管代码和非托管代码",slug:"什么是托管代码和非托管代码",content:`托管代码激活在CLR激活环境
非托管代码激活在CLR边界意外，简单的说就是一些引用的dll。`},{header:"GC可以清理非托管代码",slug:"gc可以清理非托管代码",content:"不行"}]},{path:"/Basic/language/CSharp/Optimize.html",title:"优化",pathLocale:"/",contents:[{header:"优化",slug:"优化",content:""},{header:"字典GC",slug:"字典gc",content:`当枚举和结构体为字典索引时，调用Contain方法是会拆箱装箱，则会出现GC。解决方案： 把枚举转成int类型
结构体继承IEquatable接口，然后在创建一个继承IEqualityComparer的类用来对结构体作比较。把比较类实例化一个全局变量，在字典初始化时把全局比较工具对象传入字典即可。 https://blog.csdn.net/qq_36576410/article/details/87909947
https://answer.uwa4d.com/question/59f716c0727b4a5d10c6dfef
https://stackoverflow.com/questions/50303424/why-is-dictionary-containskey-tostring-causing-gc-alloc
https://forum.unity.com/threads/solved-question-about-dictionary-any-vs-dictionary-containskey.589939/`}]},{path:"/Basic/language/CSharp/",title:"C#",pathLocale:"/",contents:[{header:"C#",slug:"c",content:`类与结构体 微软文档搜索：
https://docs.microsoft.com/zh-cn/
.net 源码查看 ： https://referencesource.microsoft.com/
微软.net 博客 ：https://docs.microsoft.com/en-us/archive/msdn-magazine/msdn-magazine-issues`},{header:".net framework vs .net core vs .net standard",slug:"net-framework-vs-net-core-vs-net-standard",content:"https://code-maze.com/differences-between-net-framework-net-core-and-net-standard/"}]},{path:"/Basic/language/CSharp/StringFormat.html",title:"字符串格式化测试",pathLocale:"/",contents:[{header:"字符串格式化测试",slug:"字符串格式化测试",content:"我们知道使用字符串优化的方式，就是尽量使用StringBuilder来处理需要经常修改的字符串。但是我们平时用到字符串格式化的时候呢？我做了一个测试。"},{header:"测试代码",slug:"测试代码",content:`我们使用 StringBuilder、Static StringBuilder、$、string.Format ，分别调用100000 Format 次查看profile。 测试代码 public class ProfileTest : MonoBehaviour
{ private System.Text.StringBuilder _sb = new System.Text.StringBuilder(); private const string kFormator = "2222 {0}"; private string _test = string.Empty; private void OnGUI() { if (GUILayout.Button("GC Collect")) { System.GC.Collect(); } if (GUILayout.Button("StringBuilder")) { for (int i = 0; i < 100000; i++) { _sb.Clear(); _sb.Length = 0; _sb.AppendFormat("in {0}", i); _test = _sb.ToString(); } UnityEditor.EditorApplication.isPaused = true; } if (GUILayout.Button("StringBuilder Const")) { for (int i = 0; i < 100000; i++) { _sb.Clear(); _sb.Length = 0; _sb.AppendFormat(kFormator, i); _test = _sb.ToString(); } UnityEditor.EditorApplication.isPaused = true; } if (GUILayout.Button("Insert")) { for (int i = 0; i < 100000; i++) { _test = $"sssss{i}"; } UnityEditor.EditorApplication.isPaused = true; } if (GUILayout.Button("Format")) { for (int i = 0; i < 100000; i++) { _test = string.Format("sss {0}", i); } UnityEditor.EditorApplication.isPaused = true; } if (GUILayout.Button("Format Const")) { for (int i = 0; i < 100000; i++) { _test = string.Format(kFormator, i); } UnityEditor.EditorApplication.isPaused = true; } }
}`},{header:"测试截图",slug:"测试截图",content:""},{header:"StringBuilder",slug:"stringbuilder",content:""},{header:"StringBuilder Const",slug:"stringbuilder-const",content:""},{header:"Interpolation",slug:"interpolation",content:""},{header:"String Format",slug:"string-format",content:""},{header:"String Format Const",slug:"string-format-const",content:""},{header:"测试结论",slug:"测试结论",content:`Test
GC Alloc
Time ms
Self ms StringBuilder
9.3MB
2235.08
59.78 StringBuilder Const
9.7MB
2282.98
61.95 Interpolation
9.7MB
2371.47
34.99 String Format
9.5MB
2368.92
34.66 String Format Const
9.7MB
2404.02
35.21 我们看到最后一个数据Unity调用的花去的时间，直接使用格式化或者内插花去的时间少于StringBuilder花的时间少一半。但是所有的时间其实差距不是特别大。再从分配堆内存中看StringBuilder最少，但是差距也不是特别大。
所以： 最求极致就使用StringBuilder
一般直接使用string.Format`}]},{path:"/Basic/language/Cplusplus/BuidError.html",title:"编译报错",pathLocale:"/",contents:[{header:"编译报错",slug:"编译报错",content:`Severity	Code	Description	Project	File	Line	Suppression State
Error	LNK2019	unresolved external symbol _main referenced in function "int __cdecl invoke_main(void)" (?invoke_main@@YAHXZ)	C 缺少main函数，加入
int main(int argc, const char** argv)
{ return 0;
} 即可`}]},{path:"/Basic/language/Cplusplus/Complie.html",title:"编译",pathLocale:"/",contents:[{header:"编译",slug:"编译",content:""},{header:"编译步骤",slug:"编译步骤",content:""},{header:"预编译",slug:"预编译",content:`使用 #define，#include，#if等以#开始的语句，来设置预编译。读取指定文件，把该文件读取到当前文件。
设置该选项可以查看预处理后的代码文件，打开该选项就不会生成obj文件了。 文件在对应的输出文件夹中，以.i为后缀的文件。`},{header:"实际编译",slug:"实际编译",content:"该过程就是把文本文件转化为机器码。生成的obj文件是二进制文件，如图： 可以设置编译后的文件为可读性更高的汇编文件，将输出设置为汇编，如图： 这样就可以在输出文件夹中看到.arm文件，其中存储是汇编代码： 设置编译优化："}]},{path:"/Basic/language/Cplusplus/Concurrency.html",title:"Concurrency",pathLocale:"/",contents:[{header:"Concurrency",slug:"concurrency",content:""},{header:"Hello Concurrent World",slug:"hello-concurrent-world",content:""},{header:"Approaches to concurrency",slug:"approaches-to-concurrency",content:`有两种方式实现并发： 多个进程，使用信号，套接字，文件等作为信息传递媒介。 两个处理器之间交流比较缓慢且难开始，因为操作系统会限制一个进程突然修改另一个进程使用到的数据。
操作系统在开启一个进程时，消耗比较大，需要单独准备资源。
安全的编写并行代码。
通过网络连接可以在不同的物理机器上跑并行，再好的设计下，很好的提高并行度和性能。 单个处理器，多线程 更小的开销
共享内存，交流方便
管理共享内存复杂 #include <iostream>
#include <thread> void hello()
{ std::cout << "Hello Concurrent World" << std::endl;
} int main()
{ std::thread t(hello); t.join();
}`},{header:"Managing threads",slug:"managing-threads",content:""},{header:"join",slug:"join",content:"该方法使启动线程等启动的线程执行结束。"},{header:"detach",slug:"detach",content:`使线程后台运行且不能在对他做join的监听工作了。
std::thread t(do_background_work);
t.detach();
assert(!t.joinable());`},{header:"Passing argument",slug:"passing-argument",content:`在传递传输参数时，传递的对象是会被复制的，或者传递至常引用。直接传递引用对象编译是不会通过的。
传递成员函数时，需要传递对象过去，实例如下：
class X
{
public: void do_lengthy_work();
}; X my_x;
std::thread t(&X::do_lengthy_work,&my_x);`},{header:"Transferring ownership of a thread",slug:"transferring-ownership-of-a-thread",content:"使用std::move()来转移线程的所有权。在被赋予新的所有权时，之前有线程任务，该任务会被终结。"},{header:"Choosing the number of threads at runtime",slug:"choosing-the-number-of-threads-at-runtime",content:`使用std::thread::hardware_concurrency()可以获得当前硬件支持线程的数量。
使用std::this_thread:: get_id()辨别线程，如下判断是否时主线程：
std::thread::id master_thread;
void some_core_part_of_algorithm()
{ if(std::this_thread::get_id()==master_thread) { do_master_thread_work(); } do_common_work();
}`},{header:"Sharing data between threads",slug:"sharing-data-between-threads",content:""},{header:"Avoiding problematic race conditions",slug:"avoiding-problematic-race-conditions",content:`避免资源竞争有几种方式如下： 以保护的机制缓存数据，只有修改数据的线程可以看到变量被修改的中间状态，访问线程只知道修改没开始或者已经完成。
无锁编程，修改数据结构。
以交易的方式来访问数据，使用中间层控制数据访问的情况。`},{header:"Protecting shared data with mutexes",slug:"protecting-shared-data-with-mutexes",content:"使用mutex来锁住数据，当一个线程锁住一个互斥变量，其他所有线程需要等待那个线程访问结束。"},{header:"Using mutexes in C++",slug:"using-mutexes-in-c",content:`使用std::mutex声明一个互斥的变量，当需要锁住互斥值时，使用std::lock_guard创建一个警卫对象，创建这个对象时，传入互斥值，并锁定该值；在这个对象被销毁时，互斥值会被解锁。该对象是创建在栈上，所以函数结束后就会被销毁。在C++17中std::lock_guard名字被修改为std::scoped_lock
#include <list>
#include <mutex>
#include <algorithm> std::list<int> some_list;
std::mutex some_mutex; void add_to_list(int new_value)
{ std::lock_guard<std::mutex> guard(some_mutex); some_list.push_back(new_value);
} bool list_contains(int value_to_find)
{ std::lock_guard<std::mutex> guard(some_mutex); return std::find(some_list.begin(), some_list.end(), value_to_find) != some_list.end();
}`},{header:"Structuring code for protecting shared data",slug:"structuring-code-for-protecting-shared-data",content:`当使用std::lock_guard锁住互斥变量时，此时把需要保护的数据以指针或引用的方式传出，这样很大的可能不能保护数据。如以下示例代码，把需要保护的数据传出并缓存到其他地方，后续直接使用缓存的数据都会出现一定的问题。
#include <string>
#include <thread> class some_data
{
private: int a; std::string b; public: void do_something() { std::cout << b << std::endl; }
}; class data_wrapper
{
private: some_data data; std::mutex m; public: template <typename Function> void process_data(Function func) { std::lock_guard<std::mutex>(m); // Pass "protected" data to user-supplied function func(data); }
}; some_data *unprotected;
void malicious_function(some_data &protected_data)
{ unexpected = &protected_data;
} data_wrapper x;
void Run()
{ // Pass in a malicious function x.process_data(malicious_function); // Unprotected access to protected data unprotected->do_something();
}`},{header:"Spotting race conditions inherent in interfaces",slug:"spotting-race-conditions-inherent-in-interfaces",content:`当一个结构体内部出现了竞争，比如说操作一个栈时，多线程都在控制该数据结构，执行以下代码：
std::stack<int> some_stack; void do_someting(int value)
{ std::cout << value << std::endl;
} void test1()
{ if (!some_stack.empty()) { int const value = some_stack.top(); some_stack.pop(); do_someting(value); }
} 会出现很多顺序上的问题，比如线程A刚执行完pop()函数，但是线程B正常执行top()函数，那么线程B这里就不能获得正确的值。有以下三个基础的原则可以设置来避免这种情况： 把栈中的数据转存到列表中来操作。该方法最大的缺点就是在转存时，会调用复制构造函数，如果数据比较复杂，这会很消耗。
使用移动构造函数或者使用会抛异常的复制构造函数
对栈中的元素创建指针，并且对该指针进行内存管理，使用智能指针std::shared_ptr 最终结合这三点可以编写一个线程安全的栈：
#include <exception>
#include <memory>
#include <mutex>
#include <stack>
struct empty_stack : std::exception
{ const char *what() const noexcept;
}; template <typename T>
class threadsafe_stack
{
private: std::stack<T> data; mutable std::mutex m; public: threadsafe_stack(){}; threadsafe_stack(const threadsafe_stack &other) { std::lock_guard<std::mutex> lock(other.m); data = other.data; } threadsafe_stack &operator=(const threadsafe_stack &) = delete; void push(T new_value) { std::lock_guard<std::mutex> lock(m); data.push(new_value); } std::shared_ptr<T> pop() { std::lock_guard<std::mutex> lock(m); // Check for empty before trying to pop value if (data.empty()) { throw empty_stack(); } // Allocate return value before modifying stack std::shared_ptr<T> const res(std::make_shared<T>(data.top())); data.pop(); return res; } void pop(T &value) { std::lock_guard<std::mutex> lock(m); // Check for empty before trying to pop value if (data.empty()) { throw empty_stack(); } value = data.top(); data.pop(); } bool empty() const { std::lock_guard<std::mutex> lock(m); return data.empty(); }
} 除此之外，还需要注意互斥变量的个数，需要申请多个互斥变量来把锁的颗粒度变小。比如，当全局只一个互斥量时，有四个线程在运行，会出现三个线程都在等待该互斥量。可以根据数据分不同的互斥量，这样多个线程在同一时刻可以访问不同的数据。`},{header:"Deadlock: the problem and a solution",slug:"deadlock-the-problem-and-a-solution",content:`当两线程A、B同时去访问一段数据时，这段数据有两个子数据data1、data2。A访问并锁住data1，B访问并锁住data2。然后A需要访问data2，B需要访问data1。这样就造成了相互等待的情况，也叫做死锁。
std::lock
std::adopt_lock: 表示一个互斥量已经被锁住，使用公用的拥有关系，并不需要再次锁定。
std::recursive_mutex`}]},{path:"/Basic/language/Cplusplus/DefineClass.html",title:"宏定义类",pathLocale:"/",contents:[{header:"宏定义类",slug:"宏定义类",content:`发现一个宏定义类，被后面声明的类所替换。实例是：UniqueNetIdNull Redpoint插件\\Engine\\Plugins\\EpicOnlineSubsystem\\OnlineSubsystemRedpointEOS\\Source\\OnlineSubsystemRedpointEOS\\Private\\NullOSS\\UniqueNetIdNull.h
EOS插件:\\Engine\\Engine\\Plugins\\Online\\OnlineSubsystemNull\\Source\\Private\\OnlineSubsystemNullTypes.h 这两个文件中都有同样的声明，EOS中的是宏定义的类。但是在EOS中使用该类型时，却被指定为Redpoint插件中类型了。`}]},{path:"/Basic/language/Cplusplus/DisableFunctionOptimization.html",title:"Disable Function Optimization with Attribute",pathLocale:"/",contents:[{header:"Disable Function Optimization with Attribute",slug:"disable-function-optimization-with-attribute",content:""},{header:"Single function definition",slug:"single-function-definition",content:""},{header:"Clang",slug:"clang",content:`// Clang
// GNU-style attribute
__attribute__((optnone))
int foo(){}
// C++11 attribute
[[clang::optnone]]
int foo(){}`},{header:"GCC",slug:"gcc",content:`__attribute__((optimize("O0")))
int foo(){}`},{header:"Multiply function definition",slug:"multiply-function-definition",content:""},{header:"Clang",slug:"clang-1",content:`#pragma clang optimize off
// This function will be decorated with optnone.
int foo() {} // optnone conflicts with always_inline, so bar() will not be decorated.
__attribute__((always_inline)) int bar(){}
#pragma clang optimize on`},{header:"Visual Studio",slug:"visual-studio",content:`#pragma optimize( "", off )
/* unoptimized code section */
#pragma optimize( "", on )`},{header:"GCC",slug:"gcc-1",content:`#pragma GCC push_options
#pragma GCC optimize("O0")
/* unoptimized code section */
#pragma GCC pop_options`},{header:"Reference",slug:"reference",content:`Clang Language Extensions — Clang 8 documentation (bcain-llvm.readthedocs.io)
optimize pragma | Microsoft Learn
[Tutorial] GCC Optimization Pragmas - Codeforces`}]},{path:"/Basic/language/Cplusplus/Emstripten.html",title:"Emscripten",pathLocale:"/",contents:[{header:"Emscripten",slug:"emscripten",content:"把c++打包为WebAssembly...."},{header:"Install",slug:"install",content:""},{header:"Windows",slug:"windows",content:`# 下载工具
git clone https://github.com/emscripten-core/emsdk.git cd emsdk # 安装 需要科学上网
./emsdk install latest
./emsdk activate latest # 更新环境变量
./emsdk_env.bat 运行后所有需要的文件都在emsdk/upstream/文件夹中，需要把emsdk/upstream/bin设置到环境变量。
值得注意的是：upstream\\emscripten\\.emscripten文件记录的是需要使用到的其他模块的执行文件位置。需要手动设置以下两个地方：
# 如果安装了LLVM会自动检测到安装的版本
# 但是推荐这样配置，在upstream中也有llvm的执行文件
# 同时版本也是smsdk匹配的，减少编译警告
LLVM_ROOT = 'D:\\\\Code\\emsdk\\\\upstream\\\\bin' # 在使用该变量时，后面会自动补齐bin\\。使用wsam等执行文件
BINARYEN_ROOT = 'D:\\\\Code\\\\emsdk\\\\upstream\\\\' 最后需要安装MinGW。`},{header:"Mac",slug:"mac",content:`命令安装：
brew install emscripten`},{header:"Command",slug:"command",content:`指定编译文件：
# 一种
em++ bgfx.cpp -std=c++11 -O2 -s ALLOW_MEMORY_GROWTH=1 -s MAX_WEBGL_VERSION=2 -s MIN_WEBGL_VERSION=2 -s USE_LIBPING=1 test.cpp -o page.html --preload-file .\\assets # 两种
em++ main.cpp -std=c++11 -s WASM=1 -s MAX_WEBGL_VERSION=2 -s MIN_WEBGL_VERSION=2 -O2 -o main.html
em++ WindowsProject1.cpp -std=c++11 -s WASM=1 -s MAX_WEBGL_VERSION=2 -s MIN_WEBGL_VERSION=2 -O2 -o main.html`},{header:"Cmake",slug:"cmake",content:'在使用cmake命令前加上emcmake字段，该字段会自动设置编译工具等。如执行以下命令：\nemcmake cmake .. 转义后的命令为： cmake .. -DCMAKE_TOOLCHAIN_FILE=D:\\Code\\emsdk\\upstream\\emscripten\\cmake\\Modules\\Platform\\Emscripten.cmake "-DCMAKE_CROSSCOMPILING_EMULATOR=C:\\Program Files\\nodejs\\node.exe" -G "MinGW Makefiles" 在CMakeLists.txt文件中可以设置：\nadd_executable(${OutputExecutable} ${SOURCE_CXX_FILES}) ######################################################################\n# Emscripten\n######################################################################\nif (EMSCRIPTEN) # Generate an HTML file set(CMAKE_EXECUTABLE_SUFFIX .html) # Build Cache: SDL2_mixer, libpng, zlib execute_process(COMMAND "${EMSCRIPTEN_ROOT_PATH}/embuilder${EMCC_SUFFIX}" build sdl2_mixer libpng zlib) if(EXISTS "${SOURCE_DATA_DIR}" AND IS_DIRECTORY "${SOURCE_DATA_DIR}") target_link_options( ${OutputExecutable} PRIVATE -sALLOW_MEMORY_GROWTH=1 -sMAX_WEBGL_VERSION=2 -sMIN_WEBGL_VERSION=2 -sUSE_LIBPNG=1 -sUSE_SDL_MIXER=2 # thanks for the s, cstd -sLLD_REPORT_UNDEFINED --preload-file ${SOURCE_DATA_DIR}@assets) else() target_link_options( ${OutputExecutable} PRIVATE -sALLOW_MEMORY_GROWTH=1 -sMAX_WEBGL_VERSION=2 -sMIN_WEBGL_VERSION=2 -sUSE_LIBPNG=1 -sUSE_SDL_MIXER=2 # thanks for the s, cstd -sLLD_REPORT_UNDEFINED) endif() endif() # Emscripten 其中EMSCRIPTEN字段在Emscripten.cmake文件中定义的。\n在vscode中配置\nhttps://blog.evernightfireworks.com/emscripten_config/'},{header:"Example Project",slug:"example-project",content:"Project Respiratory： https://github.com/Moros1138/pge-template-project"},{header:"Refence",slug:"refence",content:`https://emscripten.org/index.html
https://www.youtube.com/watch?v=1xFny-BkkR4
https://github.com/emscripten-core/emscripten/issues/10412`}]},{path:"/Basic/language/Cplusplus/Link.html",title:"链接",pathLocale:"/",contents:[{header:"链接",slug:"链接",content:"把编译好的文件，合成到一个可执行的文件中去。并定位每个函数在哪里。"}]},{path:"/Basic/language/Cplusplus/Note.html",title:"Tips",pathLocale:"/",contents:[{header:"Tips",slug:"tips",content:`标准库中的vector与string，在清除时，不仅需要调用clear，还需要调用shrink_to_fit
https://en.cppreference.com/w/cpp/string/basic_string/shrink_to_fit const vs constexpr:
对于变量来说最大的区别是初始化，const能延迟初始化到运行时，constexpr在编译时就需要对其初始化。
https://learn.microsoft.com/en-us/cpp/cpp/constexpr-cpp?view=msvc-170 在头文件中使用class标注某个类型，这样的写法可以不用在头文件中添加include的引用。同样作用有点像typename。`}]},{path:"/Basic/language/Cplusplus/",title:"C++",pathLocale:"/",contents:[{header:"C++",slug:"c",content:""},{header:"学习地址",slug:"学习地址",content:`https://light-city.club/sc/
https://theboostcpplibraries.com/
https://software.intel.com/content/www/us/en/develop/articles/lessons-on-development-of-64-bit-cc-applications.html`},{header:"文档",slug:"文档",content:"https://www.onlineinterviewquestions.com/c-plus-plus-interview-questions/#question20"}]},{path:"/Basic/language/Cplusplus/Scope.html",title:"作用域",pathLocale:"/",contents:[{header:"作用域",slug:"作用域",content:""},{header:"作用域指针",slug:"作用域指针",content:`作用域中声明的变量都是存在栈中的。
#include <iostream> class Entity
{
public: int x; Entity() { std::cout << "Created Entity" << std::endl; } ~Entity() { std::cout << "Destroyed Entity" << std::endl; }
}; class ScopePtr
{
public: Entity *entityPtr; ScopePtr(Entity *e) : entityPtr(e) {} ~ScopePtr() { delete entityPtr; }
}; void Run()
{ { // 离开作用域当前值会被销毁 // Entity e; // 离开作用域指针不会被销毁 // Entity *e = new Entity(); // 离开作用域指针会被销毁 ScopePtr e = new Entity(); } std::cin.get();
}`}]},{path:"/Basic/language/Cplusplus/SmartPtr.html",title:"智能指针",pathLocale:"/",contents:[{header:"智能指针",slug:"智能指针",content:""},{header:"unique_ptr",slug:"unique-ptr",content:"脱离作用域，该指针就会被释放。不能复制这个指针。"},{header:"weak_ptr",slug:"weak-ptr",content:`std::weak_ptr 是 C++11 标准库中的一个智能指针类型，用于解决 std::shared_ptr 循环引用的问题。std::weak_ptr 不控制所指向对象的生命周期，它只是观察一个由 std::shared_ptr 管理的对象。这意味着 std::weak_ptr 不会增加所指向对象的引用计数。
std::weak_ptr 的主要特点如下： 不控制对象的生命周期：与 std::shared_ptr 不同，std::weak_ptr 不拥有所指向对象的所有权。当最后一个 std::shared_ptr 被销毁或重置时，无论是否有 std::weak_ptr 指向该对象，对象都会被删除。 避免循环引用：在复杂的对象结构中，两个或多个对象相互持有对方的 std::shared_ptr 可能导致循环引用，从而使这些对象无法被正确删除。通过使用 std::weak_ptr 代替其中一个或多个 std::shared_ptr，可以打破循环引用，确保对象在不再需要时能够被正确删除。 访问对象前需要锁定：由于 std::weak_ptr 不保证所指向的对象仍然存在（因为该对象可能已经被 std::shared_ptr 删除），所以在访问对象之前，通常需要先将其转换为 std::shared_ptr。这可以通过调用 std::weak_ptr::lock 方法实现，该方法会尝试获取一个指向对象的 std::shared_ptr。如果对象仍然存在，lock 方法会返回一个有效的 std::shared_ptr；否则，返回一个空的 std::shared_ptr。 下面是一个简单的示例，展示了如何使用 std::weak_ptr 来避免循环引用：
#include <iostream>
#include <memory> class Parent; class Child {
public: std::weak_ptr<Parent> parent; ~Child() { std::cout << "Child destroyed\\n"; }
}; class Parent {
public: std::shared_ptr<Child> child; ~Parent() { std::cout << "Parent destroyed\\n"; }
}; int main() { { auto parent = std::make_shared<Parent>(); auto child = std::make_shared<Child>(); parent->child = child; child->parent = parent; // 此时，parent 和 child 对象相互持有对方的引用，但由于 child 使用的是 weak_ptr， // 因此不会造成循环引用。当离开这个作用域时，parent 和 child 都会被正确删除。 } return 0;
} 在这个例子中，Parent 类持有一个指向 Child 的 std::shared_ptr，而 Child 类持有一个指向 Parent 的 std::weak_ptr。当 parent 和 child 对象离开作用域时，它们都会被正确删除，即使它们相互引用。这是因为 std::weak_ptr 不增加引用计数，所以不会阻止对象的删除。`}]},{path:"/Basic/language/Cplusplus/Template.html",title:"模板与泛型编程",pathLocale:"/",contents:[{header:"模板与泛型编程",slug:"模板与泛型编程",content:""},{header:"定义模板",slug:"定义模板",content:""},{header:"函数模板",slug:"函数模板",content:`在模板定义中，模板参数列表不能为空 template<typename T>
模板程序应该尽量减少对实参类型的要求，减少特定使用，如调用泛型类中某个函数。
函数模板和类模板成员函数的定义通常放在头文件中。
保证传递给模板的实参支持模板所要求的操作，以及这些操作在模板中能正确工作，是调用者的责任。 示例代码`},{header:"类模板",slug:"类模板",content:`一个类模板的每个实例都形成一个独立的类。类型Blob<string>与任何其他Blob类型都没有关联，也不会对任何其他Blob类型的成员有特殊访问权限
我们既可以在类模板内部，也可以在类模板外部为其定义成员函数，且定义在类模板内的成员函数被隐式声明为内联函数
声明：
ret-type StrBlob::member-name(parm-list) 定义：
template <typename T>
ret-type Blob<T>::member-name(parm-list) 默认情况下，对于一个实例化了的类模板，其成员只有在使用时才被实例化。
C++11中可以直接设置别名
template <typename T>
using BlobT = Blob<T>;
BlobT<std::string> a; 与任何其他static数据成员相同，模板类的每个static数据成员必须有且仅有一个定义。
类似任何其他成员函数，一个static成员函数只有在使用时才会实例化 示例代码`}]},{path:"/Basic/language/Cplusplus/vector.html",title:"Vector",pathLocale:"/",contents:[{header:"Vector",slug:"vector",content:""},{header:"emplace_back",slug:"emplace-back",content:`使用 emplace_back 添加数列中的元数可以减少复制构造函数的调用。但是前提是传入的是该数组类型构造函数的参数。例如：
class Vertex
{
private: int x, y, z; public: Vertex(int a, int b, int c) : x(a), y(b), z(c) {} Vertex(const Vertex &other) { std::cout << "Copy!!!" << std::endl; }
}; void Run()
{ std::vector<Vertex> vertices; // 该方式复制6次 // vertices.push_back(Vertex(1, 2, 3)); // vertices.push_back(Vertex(4, 5, 6)); // vertices.push_back(Vertex(7, 8, 9)); // 以下方式无复制 vertices.reserve(3); vertices.emplace_back(1, 2, 3); vertices.emplace_back(4, 2, 3); vertices.emplace_back(5, 2, 3);
}`}]},{path:"/Basic/language/Golang/Build.html",title:"Build",pathLocale:"/",contents:[{header:"Build",slug:"build",content:"go build -v -o test.exe main.go"}]},{path:"/Basic/language/Golang/buildversion.html",title:"打包版本",pathLocale:"/",contents:[{header:"打包版本",slug:"打包版本",content:"https://www.cnblogs.com/zz962/p/14414970.html"}]},{path:"/Basic/language/Golang/httpserver.html",title:"Http Server",pathLocale:"/",contents:[{header:"Http Server",slug:"http-server",content:`http包包含：请求行line，头文件Header，主体Body
get与post区别：
1.get把需要传输的数据直接放在url中，直接加上？参数，&分隔参数，
post中的数据是放在http包中的body中。
2.get传输的数据是有限的，URL长度有限。post传输的数据是无限。
3.post比get更加安全一些。get参数是在URL中，可以让别人看见。
https://juejin.cn/post/6844903998869209095
https://zhuanlan.zhihu.com/p/135315419`}]},{path:"/Basic/language/Golang/mail.html",title:"Mail",pathLocale:"/",contents:[{header:"Mail",slug:"mail",content:`tls:
https://forum.golangbridge.org/t/sending-office-365-email/21043`}]},{path:"/Basic/language/Golang/recveiver.html",title:"Receviver vs Pointer Receviver",pathLocale:"/",contents:[{header:"Receviver vs Pointer Receviver",slug:"receviver-vs-pointer-receviver",content:`官方指导: 如果接收者是 map,func,chan 这些类型，不要使用指针类型。
如果接收者是切片或者该方法不会重新分配或切片就不用指针类型。
如果方法需要改变接收者，接收者必须是一个指针。
如果接收者是一个含有 sync.Mutex 或者有同步类型的数据结构，那么接收者必须是一个指针，去避免被复制。
如果接收者是一个大的结构体或者数组，就是使用指针。多大算大？大概是把接收者的所有属性都当参数传递到该方法中。这些参数过多过大就算大。
当一个方法被调用时，一个值类型的接收者是会被复制传入，所以外部的更新并不会应用到接收者中。如果需要修改源接收者，那么就需要把接收者设置为指针。
如果接收者是一个 struct,array 或者 slice 其中所有元素都是指针，这些指针可能会被修改。所以接收者最好是指针。
如果接收者是一个小数组或结构，它自然是一个值类型（例如，类似 time.Time 类型的东西），没有可变字段和指针，或者只是一个简单的基本类型，例如 int 或 string， 值类型接收者是有道理的。 一个值接收者可以减少可以产生的垃圾量； 如果将值传递给值方法，则可以使用堆栈上副本而不是在堆上分配。 （编译器试图巧妙地避免这种分配，但它不可能总是成功。）不要在没有首先分析的情况下选择值接收器类型。
不要混着用指针和类型传入，在同一个类型中
最后，当你不知道用啥的时候，就用指针`}]},{path:"/Basic/language/Java/Maven.html",title:"Maven",pathLocale:"/",contents:[{header:"Maven",slug:"maven",content:""},{header:"安装",slug:"安装",content:"https://blog.csdn.net/qq_38190185/article/details/115921070"}]},{path:"/Basic/language/Java/mall.html",title:"Mall",pathLocale:"/",contents:[{header:"Mall",slug:"mall",content:""},{header:"文档",slug:"文档",content:"docments"},{header:"错误",slug:"错误",content:`mvn 安装报错No compiler is provided in this environment. Perhaps you are running on a JRE rather than a JDK?
https://blog.csdn.net/LJFPHP/article/details/89341345`},{header:"software",slug:"software",content:"HeidiSQL_11.2.0.6213_Setup.exe"},{header:"发布",slug:"发布",content:`宝塔
https://www.cyril.vip/blog/note/installation-of-wechat-applet-litemall/`}]},{path:"/GameEngine/Unity/manual/Interview.html",title:"面试题整理(附答案)",pathLocale:"/",contents:[{header:"面试题整理(附答案)",slug:"面试题整理-附答案",content:""},{header:"lua相关",slug:"lua相关",content:`lua深拷贝和浅拷贝的区别？如何实现深拷贝？ A:http://ju.outofmemory.cn/entry/212960
lua中ipairs和pairs的区别？ A: https://blog.csdn.net/wwlcsdn000/article/details/81291756
lua中的userdata是什么？有什么作用？
A: https://blog.csdn.net/adam040606/article/details/56484488
https://blog.csdn.net/zhang197093/article/details/77109674
解释下lua中的元表元方法？ A:https://www.cnblogs.com/msxh/p/7745553.html
说说lua中如何实现面向对象？A:https://www.cnblogs.com/msxh/p/8469340.html
如何实现一个lua table的迭代器？A:https://www.jb51.net/article/86840.htm
lua和C++、C#交互原理？ A:https://www.cnblogs.com/slysky/p/7919114.html
cstolua的底层原理？A:https://www.cnblogs.com/msxh/p/9813147.html
C#与Lua交互原理? A:https://blog.csdn.net/UnityHUI/article/details/79752296
说说lua中的闭包？ A:https://www.cnblogs.com/msxh/p/8283865.html
在lua中有俩字符串，内容都是"Hello"，说一下他们指向的内存空间是否是同一块？ A:https://blog.csdn.net/ft1874478a/article/details/95307214
lua是如何实现热更新的？ A: 考察Package.loaded`},{header:"C#相关",slug:"c-相关",content:`用过协程吗？应用场景是什么？协程与线程的区别？协程的底层实现原理？ A:https://www.cnblogs.com/iwiniwin/p/14878498.html
值类型和引用类型的区别？ A:https://www.cnblogs.com/u3ddjw/p/11065189.html
堆和栈的区别？内存分配时地址有什么不同？ A:https://www.cnblogs.com/u3ddjw/p/11065189.html
GC的原理？Unity中Mono的GC和.net原生的GC算法有什么区别？ A:https://www.cnblogs.com/u3ddjw/p/11065189.html
List的底层实现原理？如何实现扩容？删除时占用内存空间会释放吗？
String与StringBuilder的区别？StringBuilder底层原理？A:https://www.cnblogs.com/oralig/p/7766566.html
C#中字符串的内存分配与暂存池? A:https://blog.csdn.net/xiaouncle/article/details/87832198
Dictionary的内部实现原理？ A:https://www.cnblogs.com/InCerry/p/10325290.html
HashTable与Dictionary的区别？ A:https://blog.csdn.net/mpegfour/article/details/78725768
抽象类与接口的区别？什么时候使用抽象类，什么时候使用接口？
C# 内存分配&&垃圾回收解析？ A:https://www.jianshu.com/p/53439af1eb00
谈谈.net对象生命周期 A:https://www.cnblogs.com/MaMaNongNong/p/11945161.html`},{header:"C++ 相关",slug:"c-相关-1",content:`智能指针有了解吗？ A:https://www.baidu.com/link?url=zPuC-0F5PLZMiHgVeo3YUcaL1YC5BDIV3a-rOmr8vWIsK0CwCrzh5C2EMAzakXoh&wd=&eqid=a22323c0000ba41a000000025d5e8cf2
https://blog.csdn.net/k346k346/article/details/81478223
https://blog.csdn.net/flowing_wind/article/details/81301001
https://www.cnblogs.com/wuyepeng/p/9741241.html
C++11里面一些常用的新特性？ A:https://www.cnblogs.com/msxh/p/5869992.html
重载与多态？
C++是如何实现多态的？底层原理？（考察虚函数表和虚指针） A:https://blog.csdn.net/yuanchunsi/article/details/78833345
https://www.cnblogs.com/zhxmdefj/p/11594459.html
浅谈C++虚函数机制 A:https://www.cnblogs.com/backnullptr/p/12047900.html
说说C++中的内存对齐？一个空类、空结构体占用几个字节？
C++ 为什么会在内存溢出或者越界的时候导致程序崩溃？ A:https://blog.csdn.net/u014426939/article/details/80374207
类与对象的区别？
类编译后，没有实例化前会占用内存空间吗？如果占用的话它存储在哪里？
C++ 的内存分配？ A:https://blog.csdn.net/qq_22238021/article/details/79533711
静态变量和全局变量的区别？ A:https://blog.csdn.net/qq_22238021/article/details/79533711
了解STL标准模板库吗？挑两个你最熟悉的说说他们的特点、用法和实现原理？
指针与引用的区别？ A:https://www.cnblogs.com/msxh/p/5557546.html`},{header:"Unity相关",slug:"unity相关",content:`MonoBehavior的生命周期 A:https://docs.unity3d.com/Manual/ExecutionOrder.html
图片压缩格式（PC，Android，iOS平台） A:https://www.jianshu.com/p/f7c3741f22af
https://blog.csdn.net/a133900029/article/details/80698783
https://blog.csdn.net/u013746357/article/details/89457616
https://blog.csdn.net/biospc/article/details/78077159
纹理加载进内存以后占用内存如何计算？比如一个1024 * 1204的RGBA 32bit的纹理占用多大内存？ A: 纹理加载进内存后，大小计算公式如下：
纹理内存大小（字节） = 纹理宽度 x 纹理高度 x 像素字节
像素字节 = 像素通道数（R/G/B/A） x 通道大小（1字节/半字节）
1024 * 1024 * 4 * 4byte
UGUI原理与常用优化技巧？ A:https://www.jianshu.com/p/9bd461de19a7
合批的原理与优化？
Unity如何实现跨平台的？
当我们自定义一个脚本继承自MonoBehavior以后，Start()、Update()方法并不是重写父类的方法，那么Unity在底层是如何调用到他们的呢？A:https://www.zhihu.com/question/27752591
有读过UGUI源码嘛？
浅述项目中的资源管理方案？ A:建议读一下xAsset的源码，然后就会对资源管理有个大致的了解了，传送门
在项目中有做过性能优化吗？从哪些方面入手？
Unity 使用UGUI创建可重用TableView思路？ A:https://blog.csdn.net/tmac3380809/article/details/51290387
算法与数据结构和3D数学
讲一下KMP字符串匹配算法？
将一下DP动态规划的思想？
说一下快排的思想以及手写代码 A:https://github.com/XINCGer/AlgorithmTraining/tree/master/sort/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F
链表相关(求长度，求倒数第N个，删除倒数第N个，判断是否有环，链表逆置等)
快排是稳定排序吗？什么是稳定排序？ A:https://www.jianshu.com/p/abe27f16b7b5
table.sort()的内部实现源码和List.Sort的内部实现源码？ A:https://docs.microsoft.com/en-us/dotnet/api/system.collections.generic.list-1.sort?redirectedfrom=MSDN&view=netframework-4.8#System_Collections_Generic_List_1_Sort_System_Comparison__0__
http://www.csharp411.com/c-stable-sort/
https://www.cnblogs.com/bitzhuwei/archive/2012/10/27/smilewei_sort.html
二分查找算法？
一个地图中假如说有100个怪，如何快速地获取到你周围一定范围内的怪？ A:百度一下AOI算法。https://www.cnblogs.com/persistentsnail/p/3294842.html https://www.cnblogs.com/rond/p/6114919.html
http://www.cppblog.com/jaxe/archive/2011/06/20/148998.html
https://blog.codingnow.com/2012/03/dev_note_13.html
如何判断技能的打击范围？
已知入射向量和法向量如何求出反射向量？
说说Hash算法与HashTable？
实现一个简单的线性插值算法？ A: value = to + (from - to)* progress
判断一个图中任意两个节点的连通性？A:通过BFS或者DFS直接搜索就可以
写出斐波那契数列的实现并进行优化 A:1.最普通的递归版|2.ACM竞赛数组打表版|3.尾递归优化版|4.DP思想，增加记忆化避免重复计算
实现一个比较好的洗牌算法？ A:直接上Fisher-Yates shuffle洗牌算法
https://blog.csdn.net/u012604810/article/details/82177726
https://blog.csdn.net/bitcarmanlee/article/details/52206847
从二叉查找树到B+树中间的各种树复习 A:https://www.cnblogs.com/godoforange/p/11618643.html`},{header:"网络相关",slug:"网络相关",content:`简述一下TCP三次握手和四次挥手的过程？A:https://www.cnblogs.com/pretty-guy/p/11457706.html
说一下Socket编程中的一些常见API和客户端服务器端的函数调用顺序？A:https://www.cnblogs.com/msxh/p/4989883.html
在浏览器上打开www.baidu.com这个网站，背后都发生了哪些事情？ A:https://blog.csdn.net/ZhangQiye1993/article/details/82693304
讲一讲Http协议，http和https有什么区别？ A:https://www.cnblogs.com/lingyejun/p/7148756.html?utm_source=itdadao&utm_medium=referral
什么是粘包，如何处理？ A: https://www.cnblogs.com/msxh/p/10822516.html
关于网络的一些基本知识点汇总 A:网络编程之TCP/IP各层详解
从零开始的计算机网络基础（图文并茂，1.8w字，面试复习必备）`},{header:"设计模式相关",slug:"设计模式相关",content:`说一下设计模式的六大设计原则 A: https://www.cnblogs.com/msxh/p/6921679.html
工厂模式考察 A:https://github.com/XINCGer/Unity3DTraining/tree/master/DesignPatterns/Factory
单例模式考察 A:https://github.com/XINCGer/Unity3DTraining/tree/master/DesignPatterns/Singleton
中介者模式考察 A:https://github.com/XINCGer/Unity3DTraining/tree/master/DesignPatterns/MediatorPattern
观察者模式考察 A:https://github.com/XINCGer/Unity3DTraining/tree/master/DesignPatterns/ObserverPattern
说一说MVC架构，各层分别负责做什么？MVC模式优点、缺点是什么？ A: https://www.cnblogs.com/JustRun1983/p/3679827.html
http://www.cnblogs.com/JustRun1983/p/3727560.html
https://www.cnblogs.com/aspwebchh/p/8853659.html
说一下MVVM架构，对比MVC架构有和优点？ A:解答同上面的问题`},{header:"考察一般的unity高级程序就这几块：",slug:"考察一般的unity高级程序就这几块",content:`（1）数据结构和算法，刷好leetcode 就行了
（2）图形学渲染管线 建议 从opengl 学起，熟悉基本的渲染管线
（3）一些unity特殊技巧。比如 mesh的定点的属性列表。ugui的动静分离 。assetbundle的 加载和卸载，ui 渲染3d 模型，别提 雨凇的策略。那策略基本上没用
（4）lua 比如：for 空洞的 table。寄存器语言特性, lua vm 一些基本的概念`}]},{path:"/GameEngine/Unity/somecode/Framework%20Test.html",title:"Framework Test",pathLocale:"/",contents:[{header:"Framework Test",slug:"framework-test",content:""},{header:"代码放哪里？",slug:"代码放哪里",content:`在项目中代码是直接新建一个C#的solution，直接生成dll导入unity工程中，这样可以把代码和资源彻底分开，这样也非常适合分远程库。但是有一个致命的问题就是IL2CPP，这样就需要自己接入IL2CPP到C#工程里去。暂时还没有找到相应的教程指导我们生成IL2CPP文件。这里有个最差的想法就是在打包的时候，把代码复制到unity工程中去，这样就可以使用IL2CPP。
第二个方案可以使用: ScriptCompilationAssemblyDefinitionFiles，官方的程序集分包。
经过实验室，使用.net standard 2.1创建的C#解决方案，生成的dll。在unity选择il2cpp时，会自动打包到cpp文件中去。
所以前面的问题就解决了。
接下来就可以添加vs的配置了。可以看这一篇文章： 使用C#动态库开发unity游戏
经过测试，并不需要mdb文件了，如果在unity端设置.net standard 2.1。直接复制pdb文件到unity工程下即可。
最后再设置一下define，添加defines文件即可。`},{header:"单例测试",slug:"单例测试",content:`https://learn.microsoft.com/en-us/visualstudio/test/getting-started-with-unit-testing?toc=%2Fvisualstudio%2Fget-started%2Fcsharp%2Ftoc.json&bc=%2Fvisualstudio%2Fget-started%2Fcsharp%2Fbreadcrumb%2Ftoc.json&view=vs-2022&tabs=dotnet%2Cmstest
直接在VS中创建Nunit的工程，`}]},{path:"/GameEngine/Unreal/animation/ControlRig.html",title:"Control Rig Resources",pathLocale:"/",contents:[{header:"Control Rig Resources",slug:"control-rig-resources",content:""},{header:"Courses",slug:"courses",content:`Intro to Creating and Modifying Control Rig
Animating in Unreal Engine 5.1 | Unreal Fest 2022`},{header:"UE 5 Documentation",slug:"ue-5-documentation",content:`Control Rig Quick Start
Animating with Control Rig
Animation Mode- describes some animation tools like Motion Trails, Pose Library, and more`},{header:"Videos, Blogs, and Talks",slug:"videos-blogs-and-talks",content:`Video: UE 5.0 Control Rig Features at a Glance
Blog: Control Rig Function Libraries
Blog: Animating and Rigging the Robot in Valley of the Ancient
Talk: Puppeteering in UE
Talk: Evolving Animating`},{header:"Projects",slug:"projects",content:`BungeeMan | Project
BungeeMan | Tutorials
Content Examples`}]},{path:"/GameEngine/Unreal/animation/MotionWarping.html",title:"Motion Warping",pathLocale:"/",contents:[{header:"Motion Warping",slug:"motion-warping",content:"这是可以动态的调整角色Root Motion的结果的一种技术。在UE中是以插件的方式集成。 使用该功能的动画一定要开启Root Motion"},{header:"资料",slug:"资料",content:`UE5 Motion Warping 原理剖析
https://homes.cs.washington.edu/—zoran/warpage/warpage.pdf
https://dev.epicgames.com/documentation/en-us/unreal-engine/motion-warping-in-unreal-engine?application_version=5.3
Player Traversal Mechanics in the Vast World of Horizon Zero Dawn`}]},{path:"/GameEngine/Unreal/animation/PlayerMove.html",title:"Player Move",pathLocale:"/",contents:[{header:"Player Move",slug:"player-move",content:`指引
https://docs.unrealengine.com/4.27/zh-CN/InteractiveExperiences/HowTo/CharacterMovement/`}]},{path:"/GameEngine/Unreal/animation/ProceduralAniamtionForHumans.html",title:"Procedural Animation for humans",pathLocale:"/",contents:[{header:"Procedural Animation for humans",slug:"procedural-animation-for-humans",content:"Udemy:https://www.udemy.com/course/procedural-animation/"}]},{path:"/GameEngine/Unreal/course/rpg.html",title:"Unreal Engine 5 Gas Top Down RPG",pathLocale:"/",contents:[{header:"Unreal Engine 5 Gas Top Down RPG",slug:"unreal-engine-5-gas-top-down-rpg",content:"https://www.udemy.com/course/unreal-engine-5-gas-top-down-rpg/learn/lecture/37324564?start=525#overview"},{header:"Notes",slug:"notes",content:`关闭 Live Code， 直接使用VS编译即可。
关闭 Automaticlly Complie Newly Added C++ Classes
VS设置插件,在安装后需要手动设置一下uproject文件，文档。需要在商城里下载或者直接在插件中心打开。 ,{ "Name": "VisualStudioTools", "Enabled": true } 如果发现编译出来的效果不对，删除动态链接库，重新加载即可。`},{header:"Enhanced Input",slug:"enhanced-input",content:"[]"},{header:"Gameplay Ability System",slug:"gameplay-ability-system",content:""},{header:"UI",slug:"ui",content:"HUD -> Controller - > View"}]},{path:"/GameEngine/Unreal/manual/AutomatedTestingFramework.html",title:"Automated Testing Framework",pathLocale:"/",contents:[{header:"Automated Testing Framework",slug:"automated-testing-framework",content:`IMPLEMENT_SIMPLE_AUTOMATION_TEST(FPlaceholderTest, "TestGroup.TestSubgroupPlaceholder Test", EAutomationTestFlags::EditorContext | EAutomationTestFlags::EngineFilter) bool FPlaceholderTest::RunTest(const FString& Parameters)
{ // 通过返回"真（true）"使测试通过，或者返回"假（false）"使测试失败。 return true;
} 控制面板在Tools->Session Frontend->Automation`},{header:"Reference",slug:"reference",content:`https://dev.epicgames.com/documentation/en-us/unreal-engine/automation-test-framework-in-unreal-engine
https://dev.epicgames.com/documentation/en-us/unreal-engine/automation-spec-in-unreal-engine
https://dev.epicgames.com/documentation/zh-cn/unreal-engine/write-cplusplus-tests-in-unreal-engine?application_version=5.4`}]},{path:"/GameEngine/Unreal/manual/BP2C__.html",title:"蓝图转C++",pathLocale:"/",contents:[{header:"蓝图转C++",slug:"蓝图转c",content:`可以设置蓝图转化成C++，来解决一些性能上的问题。标记需要生成C++的蓝图就不会打到pak包中。
一般是在打包的时候就会让标记的蓝图转化为C++，手动转化就直接打开蓝图，点击File -> Developer -> Generate Native Code即可。
相关代码可以查看：
FGeneratedCodeData.Save FBlueprintNativeCodeGenModule::GenerateSingleAsset FBlueprintNativeCodeGenUtils::GenerateCppCode`},{header:"引用",slug:"引用",content:`https://docs.unrealengine.com/4.27/zh-CN/Resources/SampleGames/ARPG/BalancingBlueprintAndCPP/
https://www.unrealengine.com/en-US/onlinelearning-courses/converting-blueprints-to-c`}]},{path:"/GameEngine/Unreal/manual/Build.html",title:"Build",pathLocale:"/",contents:[{header:"Build",slug:"build",content:`UE 打包时使用的是BuildUAT.bat这个批处理来启动的。具体的代码可以参看Engine\\Engine\\Source\\Programs\\AutomationTool这里的。
如果想要在打包完后做一些处理可以在Engine\\Engine\\Source\\Programs\\AutomationTool\\Scripts\\ArchiveCommand.Automation.cs这个文件中出一些处理。
估计还可以不用修改引擎代码来实现，比如说修改批处理的执行、监听某些事件来处理。应该是重写Engine\\Engine\\Source\\Programs\\AutomationTool\\AutomationUtils\\Platform.cs这个类来实现。`}]},{path:"/GameEngine/Unreal/manual/Camera.html",title:"Camera",pathLocale:"/",contents:[{header:"Camera",slug:"camera",content:"Six ingredients for a dynamic third person camera"},{header:"Camera Shake",slug:"camera-shake",content:""},{header:"UCameraShakePattern",slug:"ucamerashakepattern",content:`UWaveOscillatorCameraShakePattern：A camera shake that uses oscillations to move the camera.
UPerlinNoiseCameraShakePattern：A camera shake that uses Perlin noise to shake the camera. 设置循环抖动时间Timing为0。 unreal-engine-how-to-add-camera-shake-to-animations
master-camera-shake-in-unreal-engine-5-4
unreal-engine-using-camera-shake`}]},{path:"/GameEngine/Unreal/manual/Commandline.html",title:"Command Line",pathLocale:"/",contents:[{header:"Command Line",slug:"command-line",content:""},{header:"读取启动命令行命令",slug:"读取启动命令行命令",content:'FString ParameterValue; if (FParse::Value(FCommandLine::Get(), TEXT("-LocalClientIndex="), ParameterValue)) { LocalUserIndex = FCString::Atoi((*ParameterValue)); UE_LOG(LogBalor, Log, TEXT("Command Line LocalUserIndex@@@@@@: %s "), *ParameterValue); }'},{header:"控制台命令行调用",slug:"控制台命令行调用",content:`直接在方法属性中添加Exec即可，在控制台直接使用函数名调用。
UFUNCTION( Exec )
void Test(const FString TestStr) 多人模式下，服务器可以直接使用函数名调用，客户端需要在函数名前加上ServerExec来调用。`}]},{path:"/GameEngine/Unreal/manual/Component.html",title:"Component",pathLocale:"/",contents:[{header:"Component",slug:"component",content:""},{header:"GetComponentByClass and FindCompoentByClass",slug:"getcomponentbyclass-and-findcompoentbyclass",content:`GetComponentByClass是给蓝图调用的，底层就是用FindCompoentByClass
UActorComponent* AActor::GetComponentByClass(TSubclassOf<UActorComponent> ComponentClass) const
{ return FindComponentByClass(ComponentClass);
}`}]},{path:"/GameEngine/Unreal/manual/DataTable.html",title:"Data Table",pathLocale:"/",contents:[{header:"Data Table",slug:"data-table",content:""},{header:"参考",slug:"参考",content:"https://docs.unrealengine.com/4.27/en-US/InteractiveExperiences/DataDriven/"}]},{path:"/GameEngine/Unreal/manual/DebugTips.html",title:"Debug Tips",pathLocale:"/",contents:[{header:"Debug Tips",slug:"debug-tips",content:""},{header:"VS连接编辑器",slug:"vs连接编辑器",content:"使用vs打开ue编辑器后，可以使用death process关闭调试，后面需要调试就使用attach process，这里需要选择Native Code。"},{header:"蓝图调试器",slug:"蓝图调试器",content:"Alt text"},{header:"蓝图异常",slug:"蓝图异常",content:""},{header:"自动中断",slug:"自动中断",content:`编辑器偏好设置->通用-实验性功能->蓝图->异常时中断蓝图
DefaultEditorPerProjectUserSettings.ini: [/Script/UnrealEd.EditorExperimentalSettings]
bBreakOnExceptions=True`},{header:"显示蓝图脚本调用堆栈",slug:"显示蓝图脚本调用堆栈",content:`DefaultEngine.ini：[Kismet] ScriptStackOnWarnings=true
添加启动参数：-ScriptStackOnWarning`},{header:"在编辑器中调用函数/事件",slug:"在编辑器中调用函数-事件",content:""},{header:"编辑器中调用",slug:"编辑器中调用",content:`仅针对无形参的函数/事件有效
C++ 函数在UFUNCTION声明中添加标记符CallinEditor UFUNCTION(BlueprintCallable, CallInEditor, Category = "Default") void TestFunction(); Alt text`},{header:"编辑器工具控件 / 编辑器工具蓝图",slug:"编辑器工具控件-编辑器工具蓝图",content:"蓝图函数库（BlueprintFunctionLibrary）"},{header:"Python",slug:"python",content:""},{header:"打印字符串",slug:"打印字符串",content:`固定屏幕打印字符串的位置： 使用Key属性替换HUD中已有的Log
C++下：GEngine->AddOnScreenDebugMessage
仅非Shipping下有效果 Alt text`},{header:"画线",slug:"画线",content:`在需要进行射线碰撞的地方，使用 DrawDebugLine 函数来绘制射线：
#include "DrawDebugHelpers.h" FVector StartLocation = PlayerCamera->GetComponentLocation();
FVector EndLocation = StartLocation + PlayerCamera->GetForwardVector() * MaxRaycastDistance; // 绘制射线
DrawDebugLine(GetWorld(), StartLocation, EndLocation, FColor::Green, false, -1, 0, 1); GetWorld()：获取当前场景的世界对象。
StartLocation 和 EndLocation：射线的起点和终点。
FColor::Green：指定绘制射线的颜色。 在 DrawDebugLine 函数中，你还可以设置其他的参数，例如绘制持续时间、线条宽度等。`},{header:"日志",slug:"日志",content:`保存在Saved/Logs
仅Dev/Debug下有效 Shipping开启：bUseLoggingInShipping=true (adb log中不显示) 启动参数 -log：在命令行中显示日志
声明和定义日志类别： DECLARE_LOG_CATEGORY_EXTERN
DEFINE_LOG_CATEGORY 控制台命令 log LogName NewVerbosity:运行时修改日志的显示级别 控制台命令：log global error
配置文件参数：DefaultEngine.ini: [Core.log] global=error
启动参数：-ini.Engine:[Core.Log]:global=error 在VS中可以打开Unreal Engine Log窗口：
Alt text
需要安装VS对UE的支持模块：`},{header:"可视化记录器（Visual Logger）",slug:"可视化记录器-visual-logger",content:"可视化记录器 是一款强大的调试工具，可以创建记录游戏状态的视觉表示，并提供子啊编辑器中查看此数据的功能。 https://www.unrealengine.com/zh-CN/blog/using-the-ue4-visual-logger"},{header:"作弊管理器（Cheat Manager）",slug:"作弊管理器-cheat-manager",content:`引擎提供了内置的作弊管理器对象 代码位于CheatManager.h/cpp
使用Exec标记声明函数，例如： UFUNCTION(exec,BlueprintCallable)
ENGINE_API virtural void God(); Shipping开启：UE_WITH_CHEAT_MANAGER=1
定义你自己的作弊管理器（Player Controller的成员）`},{header:"调试相机（Debug Camera）",slug:"调试相机-debug-camera",content:`快捷键开启 默认快捷键为“分号”
可以在BaseInput.ini中修改默认快捷/或在UserInput.ini中重载 [/Script/Engine.PlayerInput]
+DebugExecBindings=(Key=Semicolon,Command="ToggleDebugCamera")
+DebugExecBindings=(Key=Apostrophe,Command="ToggleForceDefaultMaterial") 控制台命令 ToggleDebugCamera
控制台命令 Teleport: 将角色移动到debug相机注视处
控制台命令 slomo 0.1：所有运动逻辑放缓10倍 Alt text`},{header:"obj 命令",slug:"obj-命令",content:`该命令最好在版本中运行，在编辑器下很多对象不会被释放。 obj list package=X 查看x资产内所有的 UObjects obj list outer=X 按outer(直接)分组查看所有UObjects obj mem class=X 查看所有X类型对象的内存占用 obj dump /Path/To.Obj 打印一个对象的所有 UPROPERTY obj refs name=/Path/To.Obj 列出该对象被引用的堆栈 obj gc 强制出发一次垃圾回收
更多查看UEngine::HandleObjCommand`},{header:"Viual Studio 配置",slug:"viual-studio-配置",content:`设置配置栏宽度 多个分支叫做 UE5.sln 设置环境变量UE_NAME_PROJECT_AFTER_FOLDER=1
解决方案会被命名为UE5_<文件夹名>.sln
该设置可在\\Engine\\Source\\Programs\\UnrealBuildTool\\ProjectFiles\\ProjectFileGenerator.cs : GenerateProjectFiles函数修改逻辑 调试速度慢，单步执行耗时久 选项->调试->通用 关闭 “调试时启用诊断工具”（Enable Diagostic Tools while debugging）
关闭 “调试过程中显示运行时间”（Show elapsed time PerfTip while debugging）`},{header:"构建配置 （Build Configurations）",slug:"构建配置-build-configurations",content:`Debug
Development
Test
Shipping IDE中调试
√
√
√
√ 代码优化
×
√
√
√ 调试符号
√
√
√
×(unless IncludeDebugFiles=true) 控制台命令
√
√
√
×(unless ALLOW_CONSOLE_IN_SHIPPING=true) 作弊管理器
√
√
√
×(unless UE_WITH_CHEAT_MANAGER=true) Insights&可视化日志
√
√
√
×(unless UE_TRACE_ENABLED=true) checks / ensures
Show & normal
Normal
×(unless bUseChecksInShpping=true)
×(unless bUseChecksInShpping=true) 日志
√
√
×(unless bUseLoggingInShpping=true)
×(unless bUseLoggingInShpping=true) 绘制调试图形
√
√
×(unless UE_ENABLE_DEBUG_DRAWING=1)
×(unless UE_ENABLE_DEBUG_DRAWING=1) DebugGame : 游戏模块使用 Debug，引擎模块使用 Development`},{header:"取消代码优化",slug:"取消代码优化",content:`独立的C++文件： Checkout（使用P4）或修改文件（使用git），C++文件会因为adaptive unity build的机制单独编译 BuildConfiguration.xml: <BuildConfiguration><bAdaptiveUnityDisableOptimizations>true</..>
Target.cs: bAdaptiveUnityDisablesOptimizations = true; 单个模块： BuildConfiguration.xml:<ModuleConfiguration><DisableOptimizeCode><Item>ModuleName</..>
Build.cs: OptimizeCode = CodeOptimization.InShippingBuildsOnly or CodeOptimization.Never
Target.cs: DisableOptimizeCodeForModules 数组 代码块： UE_DISABLE_OPTIMIZATION / UE_ENABLE_OPTIMIZATION
UE_ENABLE_OPTIMIZATION_SHIP / UE_DISABLE_OPTIMIZATION_SHIP (shipping)
Target.cs: UE_CHECK_DISABLE_OPTIMIZATION=1 在打包机上设置，避免包含代码为优化
PC: #pragma optimize( "", off ) / #pragma optimize( "", on )
Clang: #pragma clang optimize off / #pragma clang optimize on`},{header:"条件断点",slug:"条件断点",content:'FString条件断点 wcsstr((wchar_t*)MyString.Data.AllocatorInstance.Data,L"Search substring") FName条件断点 strstr(((FNameEntry&)GNameBlocksDebug[MyFName.DisplayIndex.Value >> FNameDebugVisualizer::OffsetBits][FNameDebugVisualizer::EntryStride * (MyFName.DisplayIndex.Value & FNameDebugVisualizer::OffsetMask)]).AnsiName,"Search substring")'},{header:"查看全局变量",slug:"查看全局变量",content:`在监视窗口中使用ModuleName!VariableName查看全局变量，在Monolithic builds中可以省略ModuleName UnrealEditor-Core!GConfig
UnrealEditor-Engine!GPlayInEditorContextString
UnrealEditor-Core!GFrameCounter`},{header:"Natvis",slug:"natvis",content:`Visual Studio Natvis 框架可以自定数据类型在调试器变量窗口中显示的方式
Unreal 的Natvis实现：Engine\\Extras\\VisualStudioDebugging\\Unreal.Natvis 安装方法：将Unreal.Natvis复制到C:\\Users\\<user>\\Documents\\Visual Studio 2022\\Visualizers\\
修改立即生效`},{header:"启动参数",slug:"启动参数",content:`阻塞游戏进程直到调试器挂载：-WaitForAttach / -WaitForDebugger
从已有的打包程序中启动调试：-basedir=E:\\path\\to\\GameName\\Binaries\\Win64
使用-ini参数覆盖ini文件中的配置参数：ini:File:[SectionName]:Key=Value
使用-DPCVars覆盖DeviceProfile CVar：-DPCVars="r.cvarname=foo,anothercvar=bar
使用-execcmds在启动后自动执行控制台命令：-exccmds="log global error"`},{header:"Cook确定性",slug:"cook确定性",content:`未修改任何资源多次Cook产物不一致
第二次Cook时添加参数-DiffOnly Alt text`},{header:"内存分析",slug:"内存分析",content:`控制台命令：memreport -full [-csv|-name=X] 生成完整内存报告，保存至Engine/Saved/Profiling/MemReports 启动参数：-LLM -LLMcsv 生成LLM记录，保存至Engine/Saved/Profiling/LLM
CsvTools: csvtosvg -csv xxx.csv -stats * 特定内存问题：-stompmalloc或ASAN
Unreal Insights`},{header:"崩溃分析",slug:"崩溃分析",content:`崩溃后游戏会创建一个文件Saved/Crashes UEMinidump.dmp (MiniDumpWriteDump)
CrashContext.runtime-xml: 额外上下文的信息（-CrashReproter）
GameName.Log 模拟产生崩溃 控制台命令： Debug Crash RenderCrash / ThreadCrash / GPUCrash /...
Abort / Stall / OOM / StackOverflow / Sleep /... -将dmp和pdb文件放在同一个路径下
- 打包时隐藏符号：-nodebuginfo`},{header:"调试工具",slug:"调试工具",content:""},{header:"FPS Chart",slug:"fps-chart",content:`在命令行中运行Start FPSChart和Stop FPSChart，可以记录出运行的一个数据。再用Excel转成图表更直观。
https://www.youtube.com/watch?v=4HOmXzwfFaY`},{header:"Unreal Insights",slug:"unreal-insights",content:`启动方式： -trace=default,task,memory,cook -tracehost=127.0.0.1
-tracehost=127.0.0.1 -> -tracefile 文档： https://docs.unrealengine.com/5.3/zh-CN/unreal-insights-in-unreal-engine/`},{header:"RenderDoc",slug:"renderdoc",content:`启动方式： 开启RenderDoc软件
并在项目设置->插件->RenderDoc中勾选 启动时自动附加
点击Viewport右上角图标/控制台命令Renderdoc.CaptureFrame
调试Shader额外操作： 修改 Engine/Config/ConsoleVariables.ini r.Shaders.Optimize=0
r.Shaders.Symbols=1 默认RHI切换为D3D11`},{header:"GPU调试 - PIX",slug:"gpu调试-pix",content:"Alt text"},{header:"GPU调试 - Xcode",slug:"gpu调试-xcode",content:`GPU Trace
Instruments Alt text`},{header:"GPU调试 - DumpGPU",slug:"gpu调试-dumpgpu",content:"Alt text"}]},{path:"/GameEngine/Unreal/manual/EnemyAI.html",title:"Enemy AI",pathLocale:"/",contents:[{header:"Enemy AI",slug:"enemy-ai",content:`Create an AI Controller class
Create a BlackBoard and Behavior Tree
Add a Blackboard Component and Behavior Tree Component to the AI Controller
Add a Behavior Tree to the Enemy
Run the Behavior Tree`},{header:"Behaior Tree",slug:"behaior-tree",content:"behavior-tree-in-unreal-engine---overview"},{header:"Environment Query System",slug:"environment-query-system",content:"当敌人想远程攻击玩家时，但是两者之间是由一堵墙的，这种情况如何让敌人攻击玩家呢？ 最直接想到的就是让敌人移动以下，移动到障碍物两侧，哪有如何让敌人移动到正确的位置呢？ 这里就可以使用环境查询系统，其中最简单的方式就是在敌人周围生成多个点位，然后从这些点位发射射线，直接碰撞到玩家的点就是可以远程攻击的位置。然后找符合条件点中离玩家最近的点即可。 environment-query-system-overview-in-unreal-engine"}]},{path:"/GameEngine/Unreal/manual/EnhancedInput.html",title:"Enhanced Input",pathLocale:"/",contents:[{header:"Enhanced Input",slug:"enhanced-input",content:""},{header:"Enable",slug:"enable",content:`在Build.cs中的PublicDependencyModuleNames添加EnhancedInput。
且需要在Project Setting中确认默认的输入类型是Enhanced Input:
Alt text`},{header:"Core",slug:"core",content:`主要有6大模块组成： UInputAction，输入动作，按键转换为游戏内的数值。 IA
UInputModifier，输入修改器，对输入动作中的数值做出特定修改。IM
UInputTrigger，输入触发器，什么时候触发按键后的函数。IT
UInputMappingContext，输入映射上下文环境，绑定输入动作到按键和执行的函数。IMC
UEnhancedPlayerInput，输入处理，把按键关联上输入动作。
UEnhancedInputComponent，输入组件，把输入动作关联上执行函数。`},{header:"How To Use",slug:"how-to-use",content:`Alt text
Alt text`},{header:"Input Action",slug:"input-action",content:"Alt text"},{header:"Input Modifier",slug:"input-modifier",content:`Alt text
在UInputAction和UInputMappingContext中都可以对一个输入动作设置修改器，在IMC中是全局配置。如果两个同时都配置了，两个都会生效，先执行IMC，在执行IA。`},{header:"Input Trigger",slug:"input-trigger",content:"Alt text"},{header:"Input Mapping Context",slug:"input-mapping-context",content:"Alt text"},{header:"Framework",slug:"framework",content:`在UE中的收到按键指令后执行流程如下：先压入Pawn，再压入关卡蓝图，接着PlayerController最后EnableInput的Actors。
框架
在UEnhancedPlayerInput中通过UInputMappingContext来触发按键和输入动作。
Alt text
在EnhancedInputComponent中存储InputAction和回调的映射，使用BindAction来实现绑定。
Alt text
总体流程如下：
Alt text
Alt text
AddMappingContext流程：
Alt text`},{header:"Debug",slug:"debug",content:`调试命令：
showdebug enhancedinput`},{header:"Notes",slug:"notes",content:`https://docs.unrealengine.com/5.0/zh-CN/enhanced-input-in-unreal-engine/
https://zhuanlan.zhihu.com/p/470949422
https://zhuanlan.zhihu.com/p/668048398
https://zhuanlan.zhihu.com/p/640271313
https://www.bilibili.com/video/BV14r4y1r7nz/`}]},{path:"/GameEngine/Unreal/manual/EventSystem.html",title:"EventSystem",pathLocale:"/",contents:[{header:"EventSystem",slug:"eventsystem",content:""},{header:"C++ DELEGATES",slug:"c-delegates",content:`This system allows you to call member functions on C++ objects in a generic, yet type-safe way.
Using delegates, you can dynamically bind to a member function of an arbitrary object, then call functions on the object, even if the caller doesnt know the objects type.
The system predefines various combinations of generic function signatures with which you can
declare a delegate type from, filling in the type names for return value and parameters with
whichever types you need.
Both single-cast and multi-cast delegates are supported, as well as "dynamic" delegates which
can be serialized to disk and accessed from blueprints. Additionally, delegates may define
"payload" data which will be stored and passed directly to bound functions.`},{header:"DELEGATE FEATURES",slug:"delegate-features",content:`Currently we support delegate signatures using any combination of the following: Functions returning a value Up to four "payload" variables Multiple function parameters depending on macro/template declaration
Functions declared as const Multi-cast delegates are also supported, using the DECLARE_MULTICAST_DELEGATE... macros.
Multi-cast delegates allow you to attach multiple function delegates, then execute them all at once by calling a single "Broadcast()" function.
Multi-cast delegate signatures are not allowed to use a return value.
Unlike other types, dynamic delegates are integrated into the UObject reflection system and can be
bound to blueprint-implemented functions or serialized to disk. You can also bind native functions,
but the native functions need to be declared with UFUNCTION markup. You do not need to use UFUNCTION for
functions bound to other types of delegates.
You can assign "payload data" to your delegates! These are arbitrary variables that will be passed
directly to any bound function when it is invoked. This is really useful as it allows you to store
parameters within the delegate it self at bind-time. All delegate types (except for "dynamic") supports
payload variables automatically!
When binding to a delegate, you can pass payload data along. This example passes two custom variables,
a bool and an int32 to a delegate. Then when the delegate is invoked, these parameters will be passed
to your bound function. The extra variable arguments must always be accepted after the delegate
type parameter arguments.
MyDelegate.BindStatic( &MyFunction, true, 20 ); Remember to look at the signature table at the bottom of this documentation comment for the macro names
to use for each function signature type, and the binding table to see options and concerns for binding.`},{header:"DELEGATES EXAMPLE",slug:"delegates-example",content:`Suppose you have a class with a method that you\`d like to be able to call from anywhere:
class FLogWriter
{ void WriteToLog( FString );
}; To call the WriteToLog function, well need to create a delegate type for that functions signature.
To do this, you will first declare the delegate using one of the macros below. For example, here
is a simple delegate type:
DECLARE_DELEGATE_OneParam( FStringDelegate, FString ); This creates a delegate type called FStringDelegate that takes a single parameter of type FString.
Heres an example of how youd use this FStringDelegate in a class:
class FMyClass
{ FStringDelegate WriteToLogDelegate;
}; This allows your class to hold a pointer to a method in an arbitrary class. The only thing the
class really knows about this delegate is it\`s function signature.
Now, to assign the delegate, simply create an instance of your delegate class, passing along the
class that owns the method as a template parameter. Youll also pass the instance of your object and the actual function address of the method. So, here well create an instance of our FLogWriter
class, then create a delegate for the WriteToLog method of that object instance:
FSharedRef< FLogWriter > LogWriter( new FLogWriter() ); WriteToLogDelegate.BindSP( LogWriter, &FLogWriter::WriteToLog ); You\`ve just dynamically bound a delegate to a method of a class! Pretty simple, right?
Note that the SP part of BindSP stands for shared pointer, because were binding to an object thats owned by a shared pointer. There are versions for different object types,
such as BindRaw() and BindUObject(). You can bind to global function pointers with BindStatic().
Now, your WriteToLog method can be called by FMyClass without it even knowing anything about
the FLogWriter class! To call a your delegate, just use the Execute() method:
WriteToLogDelegate.Execute( TEXT( "Delegates are spiffy!" ) ); If you call Execute() before binding a function to the delegate, an assertion will be triggered. In
many cases, you\`ll instead want to do this:
WriteToLogDelegate.ExecuteIfBound( TEXT( "Only executes if a function was bound!" ) ); That\`s pretty much all there is to it!! You can read below for a bit more information.`},{header:"MORE INFORMATION",slug:"more-information",content:`The delegate system understands certain types of objects, and additional features are enabled when
using these objects. If you bind a delegate to a member of a UObject or shared pointer class, the
delegate system can keep a weak reference to the object, so that if the object gets destroyed out
from underneath the delegate, you\`ll be able to handle these cases by calling IsBound() or
ExecuteIfBound() functions. Note the special binding syntax for the various types of supported objects.
It\`s perfectly safe to copy delegate objects. Delegates can be passed around by value but this is
generally not recommended since they do have to allocate memory on the heap. Pass them by reference
when possible!
Delegate signature declarations can exist at global scope, within a namespace or even within a class
declaration (but not function bodies.)`},{header:"FUNCTION SIGNATURES",slug:"function-signatures",content:`Use this table to find the declaration macro to use to declare your delegate.
The full list is defined in DelegateCombinations.h Function signature
Declaration macro void Function()
DECLARE_DELEGATE( DelegateName ) void Function( <Param1> )
DECLARE_DELEGATE_OneParam( DelegateName, Param1Type ) void Function( <Param1>, <Param2> )
DECLARE_DELEGATE_TwoParams( DelegateName, Param1Type, Param2Type ) void Function( <Param1>, <Param2>, ... )
DECLARE_DELEGATE_<Num>Params( DelegateName, Param1Type, Param2Type, ... ) <RetVal> Function()
DECLARE_DELEGATE_RetVal( RetValType, DelegateName ) <RetVal> Function( <Param1> )
DECLARE_DELEGATE_RetVal_OneParam( RetValType, DelegateName, Param1Type ) <RetVal> Function( <Param1>, <Param2> )
DECLARE_DELEGATE_RetVal_TwoParams( RetValType, DelegateName, Param1Type, Param2Type ) <RetVal> Function( <Param1>, <Param2>, ... )
DECLARE_DELEGATE_RetVal_<Num>Params( RetValType, DelegateName, Param1Type, Param2Type, ... ) Remember, there are three different delegate types you can define (any of the above signatures will work): Single-cast delegates: DECLARE_DELEGATE...()
Multi-cast delegates: DECLARE_MULTICAST_DELEGATE...()
Dynamic (UObject, serializable) delegates: DECLARE_DYNAMIC_DELEGATE...()`},{header:"BINDING AND SAFETY",slug:"binding-and-safety",content:`Once a delegate has been declared, it can be bound to functions stored in different places.
Because delegates are often called long after they are bound, extra attention must be paid to
avoid crashes. This list is for single-cast, for multi-cast delegates, replace Bind in the table
below with Add. Also for multi-cast delegates, Add will return a handle that can then be used to
later remove the binding. All multi-cast delegates have an ::FDelegate subtype defining an equivalent
single-cast version, that can be Created one place and then added later. Bind function
Usage BindStatic(&GlobalFunctionName)
Call a static function, can either be globally scoped or a class static BindUObject(UObject, &UClass::Function)
Call a UObject class member function via a TWeakObjectPtr, will not be called if object is invalid BindSP(SharedPtr, &FClass::Function)
Call a native class member function via a TWeakPtr, will not be called if shared pointer is invalid BindThreadSafeSP(SharedPtr, &FClass::Function)
Call a native class member function via a TWeakPtr, will not be called if shared pointer is invalid BindRaw(RawPtr, &FClass::Function)
Call a native class member function with no safety checks. You MUST call Unbind or Remove when object dies to avoid crashes! BindLambda(Lambda)
Call a lambda function with no safety checks. You MUST make sure all captures will be safe at a later point to avoid crashes! BindSPLambda(SharedPtr, Lambda)
Call a lambda function only if shared pointer is still valid. Captured this will always be valid but any other captures may not be BindWeakLambda(UObject, Lambda)
Call a lambda function only if UObject is still valid. Captured this will always be valid but any other captures may not be BindUFunction(UObject, FName("FunctionName"))
Usable for both native and dynamic delegates, will call a UFUNCTION with specified name BindDynamic(UObject, &UClass::FunctionName)
Convenience wrapper only available for dynamic delegates, FunctionName must be declared as a UFUNCTION`},{header:"Reference",slug:"reference",content:"C:\\Program Files\\Epic Games\\UE_5.4\\Engine\\Source\\Runtime\\Core\\Public\\Delegates\\Delegate.h"}]},{path:"/GameEngine/Unreal/manual/GASDocumentation.html",title:"GASDocumentation",pathLocale:"/",contents:[{header:"GASDocumentation",slug:"gasdocumentation",content:`原地址
My understanding of Unreal Engine 5's GameplayAbilitySystem plugin (GAS) with a simple multiplayer sample project. This is not official documentation and neither this project nor myself are affiliated with Epic Games. I make no guarantee for the accuracy of this information.
The goal of this documentation is to explain the major concepts and classes in GAS and provide some additional commentary based on my experience with it. There is a lot of 'tribal knowledge' of GAS among users in the community and I aim to share all of mine here.
The Sample Project and documentation are current with Unreal Engine 5.3 (UE5). There are branches of this documentation for older versions of Unreal Engine, but they are no longer supported and are liable to have bugs or out of date information. Please use the branch that matches your engine version.
GASShooter is a sister Sample Project demonstrating advanced techniques with GAS for a multiplayer FPS/TPS.
The best documentation will always be the plugin source code.`},{header:"1. Intro to the GameplayAbilitySystem Plugin",slug:"_1-intro-to-the-gameplayabilitysystem-plugin",content:`From the Official Documentation: The Gameplay Ability System is a highly-flexible framework for building abilities and attributes of the type you might find in an RPG or MOBA title. You can build actions or passive abilities for the characters in your games to use, status effects that can build up or wear down various attributes as a result of these actions, implement "cooldown" timers or resource costs to regulate the usage of these actions, change the level of the ability and its effects at each level, activate particle or sound effects, and more. Put simply, this system can help you to design, implement, and efficiently network in-game abilities as simple as jumping or as complex as your favorite character's ability set in any modern RPG or MOBA title. The GameplayAbilitySystem plugin is developed by Epic Games and comes with Unreal Engine. It has been battle tested in AAA commercial games such as Paragon and Fortnite among others.
The plugin provides an out-of-the-box solution in single and multiplayer games for: Implementing level-based character abilities or skills with optional costs and cooldowns (GameplayAbilities)
Manipulating numerical Attributes belonging to actors (Attributes)
Applying status effects to actors (GameplayEffects)
Applying GameplayTags to actors (GameplayTags)
Spawning visual or sound effects (GameplayCues)
Replication of everything mentioned above In multiplayer games, GAS provides support for client-side prediction of: Ability activation
Playing animation montages
Changes to Attributes
Applying GameplayTags
Spawning GameplayCues
Movement via RootMotionSource functions connected to the CharacterMovementComponent. GAS must be set up in C++, but GameplayAbilities and GameplayEffects can be created in Blueprint by the designers.
Current issues with GAS: GameplayEffect latency reconciliation (can't predict ability cooldowns resulting in players with higher latencies having lower rate of fire for low cooldown abilities compared to players with lower latencies).
Cannot predict the removal of GameplayEffects. We can however predict adding GameplayEffects with the inverse effects, effectively removing them. This is not always appropriate or feasible and still remains an issue.
Lack of boilerplate templates, multiplayer examples, and documentation. Hopefully this helps with that!`},{header:"2. Sample Project",slug:"_2-sample-project",content:`A multiplayer third person shooter sample project is included with this documentation aimed at people new to the GameplayAbilitySystem Plugin but not new to Unreal Engine. Users are expected to know C++, Blueprints, UMG, Replication, and other intermediate topics in UE. This project provides an example of how to set up a basic third person shooter multiplayer-ready project with the AbilitySystemComponent (ASC) on the PlayerState class for player/AI controlled heroes and the ASC on the Character class for AI controlled minions.
The goal is to keep this project simple while showing the GAS basics and demonstrating some commonly requested abilities with well-commented code. Because of its beginner focus, the project does not show advanced topics like predicting projectiles.
Concepts demonstrated: ASC on PlayerState vs Character
Replicated Attributes
Replicated animation montages
GameplayTags
Applying and removing GameplayEffects inside of and externally from GameplayAbilities
Applying damage mitigated by armor to change health of a character
GameplayEffectExecutionCalculations
Stun effect
Death and respawn
Spawning actors (projectiles) from an ability on the server
Predictively changing the local player's speed with aim down sights and sprinting
Constantly draining stamina to sprint
Using mana to cast abilities
Passive abilities
Stacking GameplayEffects
Targeting actors
GameplayAbilities created in Blueprint
GameplayAbilities created in C++
Instanced per Actor GameplayAbilities
Non-Instanced GameplayAbilities (Jump)
Static GameplayCues (FireGun projectile impact particle effect)
Actor GameplayCues (Sprint and Stun particle effects) The hero class has the following abilities: Ability
Input Bind
Predicted
C++ / Blueprint
Description Jump
Space Bar
Yes
C++
Makes the hero jump. Gun
Left Mouse Button
No
C++
Fires a projectile from the hero's gun. The animation is predicted but the projectile is not. Aim Down Sights
Right Mouse Button
Yes
Blueprint
While the button is held, the hero will walk slower and the camera will zoom in to allow more precise shots with the gun. Sprint
Left Shift
Yes
Blueprint
While the button is held, the hero will run faster draining stamina. Forward Dash
Q
Yes
Blueprint
The hero dashes forward at the cost of stamina. Passive Armor Stacks
Passive
No
Blueprint
Every 4 seconds the hero gains a stack of armor up to a maximum of 4 stacks. Receiving damage removes one stack of armor. Meteor
R
No
Blueprint
Player targets a location to drop a meteor on the enemies causing damage and stunning them. The targeting is predicted while spawning the meteor is not. It does not matter if GameplayAbilities are created in C++ or Blueprint. A mixture of the two were used here for example of how to do them in each language.
Minions do not come with any predefined GameplayAbilities. The Red Minions have more health regen while the Blue Minions have higher starting health.
For GameplayAbility naming, I used the suffix _BP to denote the GameplayAbility's logic was created in Blueprint. The lack of suffix means the logic was created in C++.
Blueprint Asset Naming Prefixes Prefix
Asset Type GA_
GameplayAbility GC_
GameplayCue GE_
GameplayEffect`},{header:"3. Setting Up a Project Using GAS",slug:"_3-setting-up-a-project-using-gas",content:`Basic steps to set up a project using GAS: Enable GameplayAbilitySystem plugin in the Editor
Edit YourProjectName.Build.cs to add "GameplayAbilities", "GameplayTags", "GameplayTasks" to your PrivateDependencyModuleNames
Refresh/Regenerate your Visual Studio project files
Starting with 4.24, it is now mandatory to call UAbilitySystemGlobals::Get().InitGlobalData() to use TargetData. The Sample Project does this in UAssetManager::StartInitialLoading(). See InitGlobalData() for more information. That's all that you have to do to enable GAS. From here, add an ASC and AttributeSet to your Character or PlayerState and start making GameplayAbilities and GameplayEffects!`},{header:"4. GAS Concepts",slug:"_4-gas-concepts",content:""},{header:"Sections",slug:"sections",content:`4.1 Ability System Component
4.2 Gameplay Tags
4.3 Attributes
4.4 Attribute Set
4.5 Gameplay Effects
4.6 Gameplay Abilities
4.7 Ability Tasks
4.8 Gameplay Cues
4.9 Ability System Globals
4.10 Prediction`},{header:"4.1 Ability System Component",slug:"_4-1-ability-system-component",content:`The AbilitySystemComponent (ASC) is the heart of GAS. It's a UActorComponent (UAbilitySystemComponent) that handles all interactions with the system. Any Actor that wishes to use GameplayAbilities, have Attributes, or receive GameplayEffects must have one ASC attached to them. These objects all live inside of and are managed and replicated by (with the exception of Attributes which are replicated by their AttributeSet) the ASC. Developers are expected but not required to subclass this.
The Actor with the ASC attached to it is referred to as the OwnerActor of the ASC. The physical representation Actor of the ASC is called the AvatarActor. The OwnerActor and the AvatarActor can be the same Actor as in the case of a simple AI minion in a MOBA game. They can also be different Actors as in the case of a player controlled hero in a MOBA game where the OwnerActor is the PlayerState and the AvatarActor is the hero's Character class. Most Actors will have the ASC on themselves. If your Actor will respawn and need persistence of Attributes or GameplayEffects between spawns (like a hero in a MOBA), then the ideal location for the ASC is on the PlayerState.
Note: If your ASC is on your PlayerState, then you will need to increase the NetUpdateFrequency of your PlayerState. It defaults to a very low value on the PlayerState and can cause delays or perceived lag before changes to things like Attributes and GameplayTags happen on the clients. Be sure to enable Adaptive Network Update Frequency, Fortnite uses it.
Both, the OwnerActor and the AvatarActor if different Actors, should implement the IAbilitySystemInterface. This interface has one function that must be overriden, UAbilitySystemComponent* GetAbilitySystemComponent() const, which returns a pointer to its ASC. ASCs interact with each other internally to the system by looking for this interface function.
The ASC holds its current active GameplayEffects in FActiveGameplayEffectsContainer ActiveGameplayEffects.
The ASC holds its granted Gameplay Abilities in FGameplayAbilitySpecContainer ActivatableAbilities. Any time that you plan to iterate over ActivatableAbilities.Items, be sure to add ABILITYLIST_SCOPE_LOCK(); above your loop to lock the list from changing (due to removing an ability). Every ABILITYLIST_SCOPE_LOCK(); in scope increments AbilityScopeLockCount and then decrements when it falls out of scope. Do not try to remove an ability inside the scope of ABILITYLIST_SCOPE_LOCK(); (the clear ability functions check AbilityScopeLockCount internally to prevent removing abilities if the list is locked).`},{header:"4.1.1 Replication Mode",slug:"_4-1-1-replication-mode",content:`The ASC defines three different replication modes for replicating GameplayEffects, GameplayTags, and GameplayCues - Full, Mixed, and Minimal. Attributes are replicated by their AttributeSet. Replication Mode
When to Use
Description Full
Single Player
Every GameplayEffect is replicated to every client. Mixed
Multiplayer, player controlled Actors
GameplayEffects are only replicated to the owning client. Only GameplayTags and GameplayCues are replicated to everyone. Minimal
Multiplayer, AI controlled Actors
GameplayEffects are never replicated to anyone. Only GameplayTags and GameplayCues are replicated to everyone. Note: Mixed replication mode expects the OwnerActor's Owner to be the Controller. PlayerState's Owner is the Controller by default but Character's is not. If using Mixed replication mode with the OwnerActor not the PlayerState, then you need to call SetOwner() on the OwnerActor with a valid Controller.
Starting with 4.24, PossessedBy() now sets the owner of the Pawn to the new Controller.`},{header:"4.1.2 Setup and Initialization",slug:"_4-1-2-setup-and-initialization",content:`ASCs are typically constructed in the OwnerActor's constructor and explicitly marked replicated. This must be done in C++.
AGDPlayerState::AGDPlayerState()
{ // Create ability system component, and set it to be explicitly replicated AbilitySystemComponent = CreateDefaultSubobject<UGDAbilitySystemComponent>(TEXT("AbilitySystemComponent")); AbilitySystemComponent->SetIsReplicated(true); //...
} The ASC needs to be initialized with its OwnerActor and AvatarActor on both the server and the client. You want to initialize after the Pawn's Controller has been set (after possession). Single player games only need to worry about the server path.
For player controlled characters where the ASC lives on the Pawn, I typically initialize on the server in the Pawn's PossessedBy() function and initialize on the client in the PlayerController's AcknowledgePossession() function.
void APACharacterBase::PossessedBy(AController * NewController)
{ Super::PossessedBy(NewController); if (AbilitySystemComponent) { AbilitySystemComponent->InitAbilityActorInfo(this, this); } // ASC MixedMode replication requires that the ASC Owner's Owner be the Controller. SetOwner(NewController);
} void APAPlayerControllerBase::AcknowledgePossession(APawn* P)
{ Super::AcknowledgePossession(P); APACharacterBase* CharacterBase = Cast<APACharacterBase>(P); if (CharacterBase) { CharacterBase->GetAbilitySystemComponent()->InitAbilityActorInfo(CharacterBase, CharacterBase); } //...
} For player controlled characters where the ASC lives on the PlayerState, I typically initialize the server in the Pawn's PossessedBy() function and initialize on the client in the Pawn's OnRep_PlayerState() function. This ensures that the PlayerState exists on the client.
// Server only
void AGDHeroCharacter::PossessedBy(AController * NewController)
{ Super::PossessedBy(NewController); AGDPlayerState* PS = GetPlayerState<AGDPlayerState>(); if (PS) { // Set the ASC on the Server. Clients do this in OnRep_PlayerState() AbilitySystemComponent = Cast<UGDAbilitySystemComponent>(PS->GetAbilitySystemComponent()); // AI won't have PlayerControllers so we can init again here just to be sure. No harm in initing twice for heroes that have PlayerControllers. PS->GetAbilitySystemComponent()->InitAbilityActorInfo(PS, this); } //...
} // Client only
void AGDHeroCharacter::OnRep_PlayerState()
{ Super::OnRep_PlayerState(); AGDPlayerState* PS = GetPlayerState<AGDPlayerState>(); if (PS) { // Set the ASC for clients. Server does this in PossessedBy. AbilitySystemComponent = Cast<UGDAbilitySystemComponent>(PS->GetAbilitySystemComponent()); // Init ASC Actor Info for clients. Server will init its ASC when it possesses a new Actor. AbilitySystemComponent->InitAbilityActorInfo(PS, this); } // ...
} If you get the error message LogAbilitySystem: Warning: Can't activate LocalOnly or LocalPredicted ability %s when not local! then you did not initialize your ASC on the client.`},{header:"4.2 Gameplay Tags",slug:"_4-2-gameplay-tags",content:`FGameplayTags are hierarchical names in the form of Parent.Child.Grandchild... that are registered with the GameplayTagManager. These tags are incredibly useful for classifying and describing the state of an object. For example, if a character is stunned, we could give it a State.Debuff.Stun GameplayTag for the duration of the stun.
You will find yourself replacing things that you used to handle with booleans or enums with GameplayTags and doing boolean logic on whether or not objects have certain GameplayTags.
When giving tags to an object, we typically add them to its ASC if it has one so that GAS can interact with them. UAbilitySystemComponent implements the IGameplayTagAssetInterface giving functions to access its owned GameplayTags.
Multiple GameplayTags can be stored in an FGameplayTagContainer. It is preferable to use a GameplayTagContainer over a TArray<FGameplayTag> since the GameplayTagContainers add some efficiency magic. While tags are standard FNames, they can be efficiently packed together in FGameplayTagContainers for replication if Fast Replication is enabled in the project settings. Fast Replication requires that the server and the clients have the same list of GameplayTags. This generally shouldn't be a problem so you should enable this option. GameplayTagContainers can also return a TArray<FGameplayTag> for iteration.
GameplayTags stored in FGameplayTagCountContainer have a TagMap that stores the number of instances of that GameplayTag. A FGameplayTagCountContainer may still have the GameplayTag in it but its TagMapCount is zero. You may encounter this while debugging if an ASC still has a GameplayTag. Any of the HasTag() or HasMatchingTag() or similar functions will check the TagMapCount and return false if the GameplayTag is not present or its TagMapCount is zero.
GameplayTags must be defined ahead of time in the DefaultGameplayTags.ini. The Unreal Engine Editor provides an interface in the project settings to let developers manage GameplayTags without needing to manually edit the DefaultGameplayTags.ini. The GameplayTag editor can create, rename, search for references, and delete GameplayTags.
GameplayTag Editor in Project Settings
Searching for GameplayTag references will bring up the familiar Reference Viewer graph in the Editor showing all the assets that reference the GameplayTag. This will not however show any C++ classes that reference the GameplayTag.
Renaming GameplayTags creates a redirect so that assets still referencing the original GameplayTag can redirect to the new GameplayTag. I prefer if possible to instead create a new GameplayTag, update all the references manually to the new GameplayTag, and then delete the old GameplayTag to avoid creating a redirect.
In addition to Fast Replication, the GameplayTag editor has an option to fill in commonly replicated GameplayTags to optimize them further.
GameplayTags are replicated if they're added from a GameplayEffect. The ASC allows you to add LooseGameplayTags that are not replicated and must be managed manually. The Sample Project uses a LooseGameplayTag for State.Dead so that the owning clients can immediately respond to when their health drops to zero. Respawning manually sets the TagMapCount back to zero. Only manually adjust the TagMapCount when working with LooseGameplayTags. It is preferable to use the UAbilitySystemComponent::AddLooseGameplayTag() and UAbilitySystemComponent::RemoveLooseGameplayTag() functions than manually adjusting the TagMapCount.
Getting a reference to a GameplayTag in C++:
FGameplayTag::RequestGameplayTag(FName("Your.GameplayTag.Name")) For advanced GameplayTag manipulation like getting the parent or children GameplayTags, look at the functions offered by the GameplayTagManager. To access the GameplayTagManager, include GameplayTagManager.h and call it with UGameplayTagManager::Get().FunctionName. The GameplayTagManager actually stores the GameplayTags as relational nodes (parent, child, etc) for faster processing than constant string manipulation and comparisons.
GameplayTags and GameplayTagContainers can have the optional UPROPERTY specifier Meta = (Categories = "GameplayCue") that filters the tags in the Blueprint to show only GameplayTags that have the parent tag of GameplayCue. This is useful when you know the GameplayTag or GameplayTagContainer variable should only be used for GameplayCues.
Alternatively, there's a separate structure called FGameplayCueTag that encapsulates a FGameplayTag and also automatically filters GameplayTags in Blueprint to only show those tags with the parent tag of GameplayCue.
If you want to filter a GameplayTag parameter in a function, use the UFUNCTION specifier Meta = (GameplayTagFilter = "GameplayCue"). GameplayTagContainer parameters in functions can not be filtered. If you would like to edit your engine to allow this, look at how SGameplayTagGraphPin::ParseDefaultValueData() from Engine\\Plugins\\Editor\\GameplayTagsEditor\\Source\\GameplayTagsEditor\\Private\\SGameplayTagGraphPin.cpp calls FilterString = UGameplayTagsManager::Get().GetCategoriesMetaFromField(PinStructType); and passes FilterString to SGameplayTagWidget in SGameplayTagGraphPin::GetListContent(). The GameplayTagContainer version of these functions in Engine\\Plugins\\Editor\\GameplayTagsEditor\\Source\\GameplayTagsEditor\\Private\\SGameplayTagContainerGraphPin.cpp do not check for the meta field properties and pass along the filter.
The Sample Project extensively uses GameplayTags.`},{header:"4.2.1 Responding to Changes in Gameplay Tags",slug:"_4-2-1-responding-to-changes-in-gameplay-tags",content:`The ASC provides a delegate for when GameplayTags are added or removed. It takes in a EGameplayTagEventType that can specify only to fire when the GameplayTag is added/removed or for any change in the GameplayTag's TagMapCount.
AbilitySystemComponent->RegisterGameplayTagEvent(FGameplayTag::RequestGameplayTag(FName("State.Debuff.Stun")), EGameplayTagEventType::NewOrRemoved).AddUObject(this, &AGDPlayerState::StunTagChanged); The callback function has a parameter for the GameplayTag and the new TagCount.
virtual void StunTagChanged(const FGameplayTag CallbackTag, int32 NewCount);`},{header:"4.2.2 Loading Gameplay Tags from Plugin .ini Files",slug:"_4-2-2-loading-gameplay-tags-from-plugin-ini-files",content:`If you create a plugin with its own .ini files with GameplayTags, you can load that plugin's GameplayTag .ini directory in your plugin's StartupModule() function.
For example, this is how the CommonConversation plugin that comes with Unreal Engine does it:
void FCommonConversationRuntimeModule::StartupModule()
{ TSharedPtr<IPlugin> ThisPlugin = IPluginManager::Get().FindPlugin(TEXT("CommonConversation")); check(ThisPlugin.IsValid()); UGameplayTagsManager::Get().AddTagIniSearchPath(ThisPlugin->GetBaseDir() / TEXT("Config") / TEXT("Tags")); //...
} This would look for the directory Plugins\\CommonConversation\\Config\\Tags and load any .ini files with GameplayTags in them into your project when the Engine starts up if the plugin is enabled.`},{header:"4.3 Attributes",slug:"_4-3-attributes",content:""},{header:"4.3.1 Attribute Definition",slug:"_4-3-1-attribute-definition",content:`Attributes are float values defined by the struct FGameplayAttributeData. These can represent anything from the amount of health a character has to the character's level to the number of charges that a potion has. If it is a gameplay-related numerical value belonging to an Actor, you should consider using an Attribute for it. Attributes should generally only be modified by GameplayEffects so that the ASC can predict the changes.
Attributes are defined by and live in an AttributeSet. The AttributeSet is responsible for replicating Attributes that are marked for replication. See the section on AttributeSets for how to define Attributes.
Tip: If you don't want an Attribute to show up in the Editor's list of Attributes, you can use the Meta = (HideInDetailsView) property specifier.`},{header:"4.3.2 BaseValue vs CurrentValue",slug:"_4-3-2-basevalue-vs-currentvalue",content:`An Attribute is composed of two values - a BaseValue and a CurrentValue. The BaseValue is the permanent value of the Attribute whereas the CurrentValue is the BaseValue plus temporary modifications from GameplayEffects. For example, your Character may have a movespeed Attribute with a BaseValue of 600 units/second. Since there are no GameplayEffects modifying the movespeed yet, the CurrentValue is also 600 u/s. If she gets a temporary 50 u/s movespeed buff, the BaseValue stays the same at 600 u/s while the CurrentValue is now 600 + 50 for a total of 650 u/s. When the movespeed buff expires, the CurrentValue reverts back to the BaseValue of 600 u/s.
Often beginners to GAS will confuse BaseValue with a maximum value for an Attribute and try to treat it as such. This is an incorrect approach. Maximum values for Attributes that can change or are referenced in abilities or UI should be treated as separate Attributes. For hardcoded maximum and minimum values, there is a way to define a DataTable with FAttributeMetaData that can set maximum and minimum values, but Epic's comment above the struct calls it a "work in progress". See AttributeSet.h for more information. To prevent confusion, I recommend that maximum values that can be referenced in abilities or UI be made as separate Attributes and hardcoded maximum and minimum values that are only used for clamping Attributes be defined as hardcoded floats in the AttributeSet. Clamping of Attributes is discussed in PreAttributeChange() for changes to the CurrentValue and PostGameplayEffectExecute() for changes to the BaseValue from GameplayEffects.
Permanent changes to the BaseValue come from Instant GameplayEffects whereas Duration and Infinite GameplayEffects change the CurrentValue. Periodic GameplayEffects are treated like instant GameplayEffects and change the BaseValue.`},{header:"4.3.3 Meta Attributes",slug:"_4-3-3-meta-attributes",content:`Some Attributes are treated as placeholders for temporary values that are intended to interact with Attributes. These are called Meta Attributes. For example, we commonly define damage as a Meta Attribute. Instead of a GameplayEffect directly changing our health Attribute, we use a Meta Attribute called damage as a placeholder. This way the damage value can be modified with buffs and debuffs in an GameplayEffectExecutionCalculation and can be further manipulated in the AttributeSet, for example subtracting the damage from a current shield Attribute, before finally subtracting the remainder from the health Attribute. The damage Meta Attribute has no persistence between GameplayEffects and is overriden by every one. Meta Attributes are not typically replicated.
Meta Attributes provide a good logical separation for things like damage and healing between "How much damage did we do?" and "What do we do with this damage?". This logical separation means our Gameplay Effects and Execution Calculations don't need to know how the Target handles the damage. Continuing our damage example, the Gameplay Effect determines how much damage and then the AttributeSet decides what to do with that damage. Not all characters may have the same Attributes, especially if you use subclassed AttributeSets. The base AttributeSet class may only have a health Attribute, but a subclassed AttributeSet may add a shield Attribute. The subclassed AttributeSet with the shield Attribute would distribute the damage received differently than the base AttributeSet class.
While Meta Attributes are a good design pattern, they are not mandatory. If you only ever have one Execution Calculation used for all instances of damage and one Attribute Set class shared by all characters, then you may be fine doing the damage distribution to health, shields, etc. inside of the Execution Calculation and directly modifying those Attributes. You'll only be sacrificing flexibility, but that may be okay for you.`},{header:"4.3.4 Responding to Attribute Changes",slug:"_4-3-4-responding-to-attribute-changes",content:`To listen for when an Attribute changes to update the UI or other gameplay, use UAbilitySystemComponent::GetGameplayAttributeValueChangeDelegate(FGameplayAttribute Attribute). This function returns a delegate that you can bind to that will be automatically called whenever an Attribute changes. The delegate provides a FOnAttributeChangeData parameter with the NewValue, OldValue, and FGameplayEffectModCallbackData. Note: The FGameplayEffectModCallbackData will only be set on the server.
AbilitySystemComponent->GetGameplayAttributeValueChangeDelegate(AttributeSetBase->GetHealthAttribute()).AddUObject(this, &AGDPlayerState::HealthChanged); virtual void HealthChanged(const FOnAttributeChangeData& Data); The Sample Project binds to the Attribute value changed delegates on the GDPlayerState to update the HUD and to respond to player death when health reaches zero.
A custom Blueprint node that wraps this into an ASyncTask is included in the Sample Project. It is used in the UI_HUD UMG Widget to update the health, mana, and stamina values. This AsyncTask will live forever until manually called EndTask(), which we do in the UMG Widget's Destruct event. See AsyncTaskAttributeChanged.h/cpp.
Listen for Attribute Change BP Node`},{header:"4.3.5 Derived Attributes",slug:"_4-3-5-derived-attributes",content:`To make an Attribute that has some or all of its value derived from one or more other Attributes, use an Infinite GameplayEffect with one or more Attribute Based or MMC Modifiers. The Derived Attribute will update automatically when an Attribute that it depends on is updated.
The final formula for all the Modifiers on a Derived Attribute is the same formula for Modifier Aggregators. If you need calculations to happen in a certain order, do it all inside of an MMC.
((CurrentValue + Additive) * Multiplicitive) / Division Note: If playing with multiple clients in PIE, you need to disable Run Under One Process in the Editor Preferences otherwise the Derived Attributes will not update when their independent Attributes update on clients other than the first.
In this example, we have an Infinite GameplayEffect that derives the value of TestAttrA from the Attributes, TestAttrB and TestAttrC, in the formula TestAttrA = (TestAttrA + TestAttrB) * ( 2 * TestAttrC). TestAttrA recalculates its value automatically whenever any of the Attributes update their values.
Derived Attribute Example`},{header:"4.4 Attribute Set",slug:"_4-4-attribute-set",content:""},{header:"4.4.1 Attribute Set Definition",slug:"_4-4-1-attribute-set-definition",content:"The AttributeSet defines, holds, and manages changes to Attributes. Developers should subclass from UAttributeSet. Creating an AttributeSet in an OwnerActor's constructor automatically registers it with its ASC. This must be done in C++."},{header:"4.4.2 Attribute Set Design",slug:"_4-4-2-attribute-set-design",content:`An ASC may have one or many AttributeSets. AttributeSets have negligible memory overhead so how many AttributeSets to use is an organizational decision left up to the developer.
It is acceptable to have one large monolithic AttributeSet shared by every Actor in your game and only use attributes if needed while ignoring unused attributes.
Alternatively, you may choose to have more than one AttributeSet representing groupings of Attributes that you selectively add to your Actors as needed. For example, you could have an AttributeSet for health related Attributes, an AttributeSet for mana related Attributes, and so on. In a MOBA game, heroes might need mana but minions might not. Therefore the heroes would get the mana AttributeSet and minions would not.
Additionally, AttributeSets can be subclassed as another means of selectively choosing which Attributes an Actor has. Attributes are internally referred to as AttributeSetClassName.AttributeName. When you subclass an AttributeSet, all of the Attributes from the parent class will still have the parent class's name as the prefix.
While you can have more than one AttributeSet, you should not have more than one AttributeSet of the same class on an ASC. If you have more than one AttributeSet from the same class, it won't know which AttributeSet to use and will just pick one.`},{header:"4.4.2.1 Subcomponents with Individual Attributes",slug:"_4-4-2-1-subcomponents-with-individual-attributes",content:`In the scenario where you have multiple damageable components on a Pawn like individually damageable armor pieces, I recommend that if you know the maximum number of damageable components that a Pawn could have to make that many health Attributes on one AttributeSet - DamageableCompHealth0, DamageableCompHealth1, etc. to represent logical 'slots' for those damageable components. In your damageable component class instance, assign the slot number Attribute that can be read by GameplayAbilities or Executions to know which Attribute to apply damage to. Pawns that have less than the maximum number or zero of damageable components are fine. Just because a AttributeSet has an Attribute, doesn't mean that you have to use it. Unused Attributes take up trivial amount of memory.
If your subcomponents need many Attributes each, there's potentially an unbounded number of subcomponents, the subcomponents can detach and be used by other players (e.g. weapons), or for any other reason this approach doesn't work for you, I'd recommend switching away from Attributes and instead store plain old floats on the components. See Item Attributes.`},{header:"4.4.2.2 Adding and Removing AttributeSets at Runtime",slug:"_4-4-2-2-adding-and-removing-attributesets-at-runtime",content:`AttributeSets can be added and removed from an ASC at runtime; however, removing AttributeSets can be dangerous. For example, if an AttributeSet is removed on a client before the server and an Attribute value change is replicated to client, the Attribute won't find its AttributeSet and crash the game.
On weapon add to inventory:
AbilitySystemComponent->GetSpawnedAttributes_Mutable().AddUnique(WeaponAttributeSetPointer);
AbilitySystemComponent->ForceReplication(); On weapon remove from inventory:
AbilitySystemComponent->GetSpawnedAttributes_Mutable().Remove(WeaponAttributeSetPointer);
AbilitySystemComponent->ForceReplication();`},{header:"4.4.2.3 Item Attributes (Weapon Ammo)",slug:"_4-4-2-3-item-attributes-weapon-ammo",content:`There's a few ways to implement equippable items with Attributes (weapon ammo, armor durability, etc). All of these approaches store values directly on the item. This is necessary for items that can be equipped by more than one player over its lifetime. Use plain floats on the item (Recommended)
Separate AttributeSet on the item
Separate ASC on the item`},{header:"4.4.2.3.1 Plain Floats on the Item",slug:"_4-4-2-3-1-plain-floats-on-the-item",content:`Instead of Attributes, store plain float values on the item class instance. Fortnite and GASShooter handle gun ammo this way. For a gun, store the max clip size, current ammo in clip, reserve ammo, etc directly as replicated floats (COND_OwnerOnly) on the gun instance. If weapons share reserve ammo, you would move the reserve ammo onto the character as an Attribute in a shared ammo AttributeSet (reload abilities can use a Cost GE to pull from reserve ammo into the gun's float clip ammo). Since you're not using Attributes for current clip ammo, you will need to override some functions in UGameplayAbility to check and apply cost against the floats on the gun. Making the gun the SourceObject in the GameplayAbilitySpec when granting the ability means you'll have access to the gun that granted the ability inside the ability.
To prevent the gun from replicating back the ammo amount and clobbering the local ammo amount during automatic fire, disable replication while the player has a IsFiring GameplayTag in PreReplication(). You're essentially doing your own local prediction here.
void AGSWeapon::PreReplication(IRepChangedPropertyTracker& ChangedPropertyTracker)
{ Super::PreReplication(ChangedPropertyTracker); DOREPLIFETIME_ACTIVE_OVERRIDE(AGSWeapon, PrimaryClipAmmo, (IsValid(AbilitySystemComponent) && !AbilitySystemComponent->HasMatchingGameplayTag(WeaponIsFiringTag))); DOREPLIFETIME_ACTIVE_OVERRIDE(AGSWeapon, SecondaryClipAmmo, (IsValid(AbilitySystemComponent) && !AbilitySystemComponent->HasMatchingGameplayTag(WeaponIsFiringTag)));
} Benefits: Avoids limitations of using AttributeSets (see below) Limitations: Can not use existing GameplayEffect workflow (Cost GEs for ammo use, etc)
Requires work to override key functions on UGameplayAbility to check and apply ammo costs against the gun's floats`},{header:"4.4.2.3.2 AttributeSet on the Item",slug:"_4-4-2-3-2-attributeset-on-the-item",content:`Using a separate AttributeSet on the item that gets added to the player's ASC on adding it to the player's inventory can work, but it has some major limitations. I had this working in early versions of GASShooter for the weapon ammo. The weapon stores its Attributes such as max clip size, current ammo in clip, reserve ammo, etc in an AttributeSet that lives on the weapon class. If weapons share reserve ammo, you would move the reserve ammo onto the character in a shared ammo AttributeSet. When a weapon is added to the player's inventory on the server, the weapon would add its AttributeSet to the player's ASC::SpawnedAttributes. The server would then replicate this down to the client. If the weapon is removed from the inventory, it would remove its AttributeSet from the ASC::SpawnedAttributes.
When the AttributeSet lives on something other than the OwnerActor (say a weapon), you'll initially get some compilation errors in the AttributeSet. The fix is to construct the AttributeSet in BeginPlay() instead of in the constructor and to implement IAbilitySystemInterface (set the pointer to the ASC when you add the weapon to the player inventory) on the weapon.
void AGSWeapon::BeginPlay()
{ if (!AttributeSet) { AttributeSet = NewObject<UGSWeaponAttributeSet>(this); } //...
} You can see it in practice by checking out this older version of GASShooter.
Benefits: Can use existing GameplayAbility and GameplayEffect workflow (Cost GEs for ammo use, etc)
Simple to setup for a very small set of items Limitations: You have to make a new AttributeSet class for every weapon type. ASCs can only functionally have one AttributeSet instance of a class since changes to an Attribute look for the first instance of their AttributeSet class in the ASCs SpawnedAttributes array. Additional instances of the same AttributeSet class are ignored.
You can only have one of each type of weapon in the player's inventory due to previous reason of one AttributeSet instance per AttributeSet class.
Removing an AttributeSet is dangerous. In GASShooter if the player killed himself from a rocket, the player would immediately remove the rocket launcher from his inventory (including its AttributeSet from the ASC). When the server replicated that the rocket launcher's ammo Attribute changed, the AttributeSet no longer existed on the client's ASC and the game crashed.`},{header:"4.4.2.3.3 ASC on the Item",slug:"_4-4-2-3-3-asc-on-the-item",content:`Putting a whole AbilitySystemComponent on each item is an extreme approach. I have not personally done this nor have I seen it in the wild. It would take a lot of engineering to make it work. Is it viable to have several AbilitySystemComponents which have the same owner but different avatars (e.g. on pawn and weapon/items/projectiles with Owner set to PlayerState)?
The first problem I see there would be implementing the IGameplayTagAssetInterface and IAbilitySystemInterface on the owning actor. The former may be possible: just aggregate the tags from all all ASCs (but watch out -HasAllMatchingGameplayTags may be met only via cross ASC aggregation. It wouldn't be enough to just forward that calls to each ASC and OR the results together). But the later is even trickier: which ASC is the authoritative one? If someone wants to apply a GE -which one should receive it? Maybe you can work these out but this side of the problem will be the hardest: owners will have multiple ASCs beneath them.
Separate ASCs on the pawn and the weapon can make sense on its own though. E.g, distinguishing between tags that describe the weapon vs those that describe the owning pawn. Maybe it does make sense that tags granted to the weapon also “apply” to the owner and nothing else (e.g, attributes and GEs are independent but the owner will aggregate the owned tags like I describe above). This could work out, I am sure. But having multiple ASCs with the same owner may get dicey. Dave Ratti from Epic's answer to community questions #6
Benefits: Can use existing GameplayAbility and GameplayEffect workflow (Cost GEs for ammo use, etc)
Can reuse AttributeSet classes (one on each weapon's ASC) Limitations: Unknown engineering cost
Is it even possible?`},{header:"4.4.3 Defining Attributes",slug:"_4-4-3-defining-attributes",content:`Attributes can only be defined in C++ in the AttributeSet's header file. It is recommended to add this block of macros to the top of every AttributeSet header file. It will automatically generate getter and setter functions for your Attributes.
// Uses macros from AttributeSet.h
#define ATTRIBUTE_ACCESSORS(ClassName, PropertyName) \\ GAMEPLAYATTRIBUTE_PROPERTY_GETTER(ClassName, PropertyName) \\ GAMEPLAYATTRIBUTE_VALUE_GETTER(PropertyName) \\ GAMEPLAYATTRIBUTE_VALUE_SETTER(PropertyName) \\ GAMEPLAYATTRIBUTE_VALUE_INITTER(PropertyName) A replicated health attribute would be defined like this:
UPROPERTY(BlueprintReadOnly, Category = "Health", ReplicatedUsing = OnRep_Health)
FGameplayAttributeData Health;
ATTRIBUTE_ACCESSORS(UGDAttributeSetBase, Health) Also define the OnRep function in the header:
UFUNCTION()
virtual void OnRep_Health(const FGameplayAttributeData& OldHealth); The .cpp file for the AttributeSet should fill in the OnRep function with the GAMEPLAYATTRIBUTE_REPNOTIFY macro used by the prediction system:
void UGDAttributeSetBase::OnRep_Health(const FGameplayAttributeData& OldHealth)
{ GAMEPLAYATTRIBUTE_REPNOTIFY(UGDAttributeSetBase, Health, OldHealth);
} Finally, the Attribute needs to be added to GetLifetimeReplicatedProps:
void UGDAttributeSetBase::GetLifetimeReplicatedProps(TArray<FLifetimeProperty>& OutLifetimeProps) const
{ Super::GetLifetimeReplicatedProps(OutLifetimeProps); DOREPLIFETIME_CONDITION_NOTIFY(UGDAttributeSetBase, Health, COND_None, REPNOTIFY_Always);
} REPNOTIFY_Always tells the OnRep function to trigger if the local value is already equal to the value being repped down from the Server (due to prediction). By default it won't trigger the OnRep function if the local value is the same as the value being repped down from the Server.
If the Attribute is not replicated like a Meta Attribute, then the OnRep and GetLifetimeReplicatedProps steps can be skipped.`},{header:"4.4.4 Initializing Attributes",slug:"_4-4-4-initializing-attributes",content:`There are multiple ways to initialize Attributes (set their BaseValue and consequently their CurrentValue to some initial value). Epic recommends using an instant GameplayEffect. This is the method used in the Sample Project too.
See GE_HeroAttributes Blueprint in the Sample Project for how to make an instant GameplayEffect to initialize Attributes. Application of this GameplayEffect happens in C++.
If you used the ATTRIBUTE_ACCESSORS macro when you defined your Attributes, an initialization function will automatically be generated on the AttributeSet for each Attribute that you can call at your leisure in C++.
// InitHealth(float InitialValue) is an automatically generated function for an Attribute 'Health' defined with the \`ATTRIBUTE_ACCESSORS\` macro
AttributeSet->InitHealth(100.0f); See AttributeSet.h for more ways to initialize Attributes.
Note: Prior to 4.24, FAttributeSetInitterDiscreteLevels did not work with FGameplayAttributeData. It was created when Attributes were raw floats and will complain about FGameplayAttributeData not being Plain Old Data (POD). This is fixed in 4.24 https://issues.unrealengine.com/issue/UE-76557.`},{header:"4.4.5 PreAttributeChange()",slug:"_4-4-5-preattributechange",content:`PreAttributeChange(const FGameplayAttribute& Attribute, float& NewValue) is one of the main functions in the AttributeSet to respond to changes to an Attribute's CurrentValue before the change happens. It is the ideal place to clamp incoming changes to CurrentValue via the reference parameter NewValue.
For example to clamp movespeed modifiers the Sample Project does it like so:
if (Attribute == GetMoveSpeedAttribute())
{ // Cannot slow less than 150 units/s and cannot boost more than 1000 units/s NewValue = FMath::Clamp<float>(NewValue, 150, 1000);
} The GetMoveSpeedAttribute() function is created by the macro block that we added to the AttributeSet.h (Defining Attributes).
This is triggered from any changes to Attributes, whether using Attribute setters (defined by the macro block in AttributeSet.h (Defining Attributes)) or using GameplayEffects.
Note: Any clamping that happens here does not permanently change the modifier on the ASC. It only changes the value returned from querying the modifier. This means anything that recalculates the CurrentValue from all of the modifiers like GameplayEffectExecutionCalculations and ModifierMagnitudeCalculations need to implement clamping again.
Note: Epic's comments for PreAttributeChange() say not to use it for gameplay events and instead use it mainly for clamping. The recommended place for gameplay events on Attribute change is UAbilitySystemComponent::GetGameplayAttributeValueChangeDelegate(FGameplayAttribute Attribute) (Responding to Attribute Changes).`},{header:"4.4.6 PostGameplayEffectExecute()",slug:"_4-4-6-postgameplayeffectexecute",content:`PostGameplayEffectExecute(const FGameplayEffectModCallbackData & Data) only triggers after changes to the BaseValue of an Attribute from an instant GameplayEffect. This is a valid place to do more Attribute manipulation when they change from a GameplayEffect.
For example, in the Sample Project we subtract the final damage Meta Attribute from the health Attribute here. If there was a shield Attribute, we would subtract the damage from it first before subtracting the remainder from health. The Sample Project also uses this location to apply hit react animations, show floating Damage Numbers, and assign experience and gold bounties to the killer. By design, the damage Meta Attribute will always come through an instant GameplayEffect and never the Attribute setter.
Other Attributes that will only have their BaseValue changed from instant GameplayEffects like mana and stamina can also be clamped to their maximum value counterpart Attributes here.
Note: When PostGameplayEffectExecute() is called, changes to the Attribute have already happened, but they have not replicated back to clients yet so clamping values here will not cause two network updates to clients. Clients will only receive the update after clamping.`},{header:"4.4.7 OnAttributeAggregatorCreated()",slug:"_4-4-7-onattributeaggregatorcreated",content:`OnAttributeAggregatorCreated(const FGameplayAttribute& Attribute, FAggregator* NewAggregator) triggers when an Aggregator is created for an Attribute in this set. It allows custom setup of FAggregatorEvaluateMetaData. AggregatorEvaluateMetaData is used by the Aggregator in evaluating the CurrentValue of an Attribute based on all the Modifiers applied to it. By default, AggregatorEvaluateMetaData is only used by the Aggregator to determine which Modifiers qualify with the example of MostNegativeMod_AllPositiveMods which allows all positive Modifiers but restricts negative Modifiers to only the most negative one. This was used by Paragon to only allow the most negative move speed slow effect to apply to a player regardless of how many slow effects where on them at any one time while applying all positive move speed buffs. Modifiers that don't qualify still exist on the ASC, they just aren't aggregated into the final CurrentValue. They can potentially qualify later once conditions change, like in the case if the most negative Modifier expires, the next most negative Modifier (if one exists) then qualifies.
To use AggregatorEvaluateMetaData in the example of only allowing the most negative Modifier and all positive Modifiers:
virtual void OnAttributeAggregatorCreated(const FGameplayAttribute& Attribute, FAggregator* NewAggregator) const override; void UGSAttributeSetBase::OnAttributeAggregatorCreated(const FGameplayAttribute& Attribute, FAggregator* NewAggregator) const
{ Super::OnAttributeAggregatorCreated(Attribute, NewAggregator); if (!NewAggregator) { return; } if (Attribute == GetMoveSpeedAttribute()) { NewAggregator->EvaluationMetaData = &FAggregatorEvaluateMetaDataLibrary::MostNegativeMod_AllPositiveMods; }
} Your custom AggregatorEvaluateMetaData for qualifiers should be added to FAggregatorEvaluateMetaDataLibrary as static variables.`},{header:"4.5 Gameplay Effects",slug:"_4-5-gameplay-effects",content:""},{header:"4.5.1 Gameplay Effect Definition",slug:"_4-5-1-gameplay-effect-definition",content:`GameplayEffects (GE) are the vessels through which abilities change Attributes and GameplayTags on themselves and others. They can cause immediate Attribute changes like damage or healing or apply long term status buff/debuffs like a movespeed boost or stunning. The UGameplayEffect class is a meant to be a data-only class that defines a single gameplay effect. No additional logic should be added to GameplayEffects. Typically designers will create many Blueprint child classes of UGameplayEffect.
GameplayEffects change Attributes through Modifiers and Executions (GameplayEffectExecutionCalculation).
GameplayEffects have three types of duration: Instant, Duration, and Infinite.
Additionally, GameplayEffects can add/execute GameplayCues. An Instant GameplayEffect will call Execute on the GameplayCue GameplayTags whereas a Duration or Infinite GameplayEffect will call Add and Remove on the GameplayCue GameplayTags. Duration Type
GameplayCue Event
When to use Instant
Execute
For immediate permanent changes to Attribute's BaseValue. GameplayTags will not be applied, not even for a frame. Duration
Add & Remove
For temporary changes to Attribute's CurrentValue and to apply GameplayTags that will be removed when the GameplayEffect expires or is manually removed. The duration is specified in the UGameplayEffect class/Blueprint. Infinite
Add & Remove
For temporary changes to Attribute's CurrentValue and to apply GameplayTags that will be removed when the GameplayEffect is removed. These will never expire on their own and must be manually removed by an ability or the ASC. Duration and Infinite GameplayEffects have the option of applying Periodic Effects that apply its Modifiers and Executions every X seconds as defined by its Period. Periodic Effects are treated as Instant GameplayEffects when it comes to changing the Attribute's BaseValue and Executing GameplayCues. These are useful for damage over time (DOT) type effects. Note: Periodic Effects cannot be predicted.
Duration and Infinite GameplayEffects can be temporarily turned off and on after application if their Ongoing Tag Requirements are not met/met (Gameplay Effect Tags). Turning off a GameplayEffect removes the effects of its Modifiers and applied GameplayTags but does not remove the GameplayEffect. Turning the GameplayEffect back on reapplies its Modifiers and GameplayTags.
If you need to manually recalculate the Modifiers of a Duration or Infinite GameplayEffect (say you have an MMC that uses data that doesn't come from Attributes), you can call UAbilitySystemComponent::ActiveGameplayEffects.SetActiveGameplayEffectLevel(FActiveGameplayEffectHandle ActiveHandle, int32 NewLevel) with the same level that it already has using UAbilitySystemComponent::ActiveGameplayEffects.GetActiveGameplayEffect(ActiveHandle).Spec.GetLevel(). Modifiers that are based on backing Attributes automatically update when those backing Attributes update. The key functions of SetActiveGameplayEffectLevel() to update the Modifiers are:
MarkItemDirty(Effect);
Effect.Spec.CalculateModifierMagnitudes();
// Private function otherwise we'd call these three functions without needing to set the level to what it already is
UpdateAllAggregatorModMagnitudes(Effect); GameplayEffects are not typically instantiated. When an ability or ASC wants to apply a GameplayEffect, it creates a GameplayEffectSpec from the GameplayEffect's ClassDefaultObject. Successfully applied GameplayEffectSpecs are then added to a new struct called FActiveGameplayEffect which is what the ASC keeps track of in a special container struct called ActiveGameplayEffects.`},{header:"4.5.2 Applying Gameplay Effects",slug:"_4-5-2-applying-gameplay-effects",content:`GameplayEffects can be applied in many ways from functions on GameplayAbilities and functions on the ASC and usually take the form of ApplyGameplayEffectTo. The different functions are essentially convenience functions that will eventually call UAbilitySystemComponent::ApplyGameplayEffectSpecToSelf() on the Target.
To apply GameplayEffects outside of a GameplayAbility for example from a projectile, you need to get the Target's ASC and use one of its functions to ApplyGameplayEffectToSelf.
You can listen for when any Duration or Infinite GameplayEffects are applied to an ASC by binding to its delegate:
AbilitySystemComponent->OnActiveGameplayEffectAddedDelegateToSelf.AddUObject(this, &APACharacterBase::OnActiveGameplayEffectAddedCallback); The callback function:
virtual void OnActiveGameplayEffectAddedCallback(UAbilitySystemComponent* Target, const FGameplayEffectSpec& SpecApplied, FActiveGameplayEffectHandle ActiveHandle); The server will always call this function regardless of replication mode. The autonomous proxy will only call this for replicated GameplayEffects in Full and Mixed replication modes. Simulated proxies will only call this in Full replication mode.`},{header:"4.5.3 Removing Gameplay Effects",slug:"_4-5-3-removing-gameplay-effects",content:`GameplayEffects can be removed in many ways from functions on GameplayAbilities and functions on the ASC and usually take the form of RemoveActiveGameplayEffect. The different functions are essentially convenience functions that will eventually call FActiveGameplayEffectsContainer::RemoveActiveEffects() on the Target.
To remove GameplayEffects outside of a GameplayAbility, you need to get the Target's ASC and use one of its functions to RemoveActiveGameplayEffect.
You can listen for when any Duration or Infinite GameplayEffects are removed from an ASC by binding to its delegate:
AbilitySystemComponent->OnAnyGameplayEffectRemovedDelegate().AddUObject(this, &APACharacterBase::OnRemoveGameplayEffectCallback); The callback function:
virtual void OnRemoveGameplayEffectCallback(const FActiveGameplayEffect& EffectRemoved); The server will always call this function regardless of replication mode. The autonomous proxy will only call this for replicated GameplayEffects in Full and Mixed replication modes. Simulated proxies will only call this in Full replication mode.`},{header:"4.5.4 Gameplay Effect Modifiers",slug:"_4-5-4-gameplay-effect-modifiers",content:`Modifiers change an Attribute and are the only way to predictively change an Attribute. A GameplayEffect can have zero or many Modifiers. Each Modifier is responsible for changing only one Attribute via a specified operation. Operation
Description Add
Adds the result to the Modifier's specified Attribute. Use a negative value for subtraction. Multiply
Multiplies the result to the Modifier's specified Attribute. Divide
Divides the result against the Modifier's specified Attribute. Override
Overrides the Modifier's specified Attribute with the result. The CurrentValue of an Attribute is the aggregate result of all of its Modifiers added to its BaseValue. The formula for how Modifiers are aggregated is defined as follows in FAggregatorModChannel::EvaluateWithBase in GameplayEffectAggregator.cpp:
((InlineBaseValue + Additive) * Multiplicitive) / Division Any Override Modifiers will override the final value with the last applied Modifier taking precedence.
Note: For percentage based changes, make sure to use the Multiply operation so that it happens after addition.
Note: Prediction has trouble with percentage changes.
There are four types of Modifiers: Scalable Float, Attribute Based, Custom Calculation Class, and Set By Caller. They all generate some float value that is then used to change the specified Attribute of the Modifier based on its operation. Modifier Type
Description Scalable Float
FScalableFloats are a structure that can point to a Data Table that has the variables as rows and levels as columns. The Scalable Floats will automatically read the value of the specified table row at the ability's current level (or different level if overriden on the GameplayEffectSpec). This value can further be manipulated by a coefficient. If no Data Table/Row is specified, it treats the value as a 1 so the coefficient can be used to hard code in a single value at all levels. Attribute Based
Attribute Based Modifiers take the CurrentValue or BaseValue of a backing Attribute on the Source (who created the GameplayEffectSpec) or Target (who received the GameplayEffectSpec) and further modifies it with a coefficient and pre and post coefficient additions. Snapshotting means the backing Attribute is captured when the GameplayEffectSpec is created whereas no snapshotting means the Attribute is captured when the GameplayEffectSpec is applied. Custom Calculation Class
Custom Calculation Class provides the most flexibility for complex Modifiers. This Modifier takes a ModifierMagnitudeCalculation class and can further manipulate the resulting float value with a coefficient and pre and post coefficient additions. Set By Caller
SetByCaller Modifiers are values that are set outside of the GameplayEffect at runtime by the ability or whoever made the GameplayEffectSpec on the GameplayEffectSpec. For example, you would use a SetByCaller if you want to set the damage to be based on how long the player held down a button to charge the ability. SetByCallers are essentially TMap<FGameplayTag, float> that live on the GameplayEffectSpec. The Modifier is just telling the Aggregator to look for a SetByCaller value associated with the supplied GameplayTag. The SetByCallers used by Modifiers can only use the GameplayTag version of the concept. The FName version is disabled here. If the Modifier is set to SetByCaller but a SetByCaller with the correct GameplayTag does not exist on the GameplayEffectSpec, the game will throw a runtime error and return a value of 0. This might cause issues in the case of a Divide operation. See SetByCallers for more information on how to use SetByCallers.`},{header:"4.5.4.1 Multiply and Divide Modifiers",slug:"_4-5-4-1-multiply-and-divide-modifiers",content:`By default, all Multiply and Divide Modifiers are added together before multiplying or dividing them into the Attribute's BaseValue.
float FAggregatorModChannel::EvaluateWithBase(float InlineBaseValue, const FAggregatorEvaluateParameters& Parameters) const
{ ... float Additive = SumMods(Mods[EGameplayModOp::Additive], GameplayEffectUtilities::GetModifierBiasByModifierOp(EGameplayModOp::Additive), Parameters); float Multiplicitive = SumMods(Mods[EGameplayModOp::Multiplicitive], GameplayEffectUtilities::GetModifierBiasByModifierOp(EGameplayModOp::Multiplicitive), Parameters); float Division = SumMods(Mods[EGameplayModOp::Division], GameplayEffectUtilities::GetModifierBiasByModifierOp(EGameplayModOp::Division), Parameters); ... return ((InlineBaseValue + Additive) * Multiplicitive) / Division; ...
} float FAggregatorModChannel::SumMods(const TArray<FAggregatorMod>& InMods, float Bias, const FAggregatorEvaluateParameters& Parameters)
{ float Sum = Bias; for (const FAggregatorMod& Mod : InMods) { if (Mod.Qualifies()) { Sum += (Mod.EvaluatedMagnitude - Bias); } } return Sum;
} from GameplayEffectAggregator.cpp
Both Multiply and Divide Modifiers have a Bias value of 1 in this formula (Addition has a Bias of 0). So it would look something like:
1 + (Mod1.Magnitude - 1) + (Mod2.Magnitude - 1) + ... This formula leads to some unexpected results. Firstly, this formula adds all the modifiers together before multiplying or dividing them into the BaseValue. Most people would expect it to multiply or divide them together. For example, if you have two Multiply modifiers of 1.5, most people would expect the BaseValue to be multiplied by 1.5 x 1.5 = 2.25. Instead, this adds the 1.5s together to multiply the BaseValue by 2 (50% increase + another 50% increase = 100% increase). This was for the example from GameplayPrediction.h of a 10% speed buff on 500 base speed would be 550. Add another 10% speed buff and it will be 600.
Secondly, this formula has some undocumented rules about what values can be used as it was designed with Paragon in mind.
Rules for Multiply and Divide multiplication addition formula: (No more than one value < 1) AND (Any number of values [1, 2))
OR (One value >= 2) The Bias in the formula basically subtracts out the integer digit of numbers in the range [1, 2). The first Modifier's Bias subtracts out from the starting Sum value (set to the Bias before the loop) which is why any value by itself works and why one value < 1 will work with the numbers in the range [1, 2).
Some examples with Multiply:
Multipliers: 0.5
1 + (0.5 - 1) = 0.5, correct
Multipliers: 0.5, 0.5
1 + (0.5 - 1) + (0.5 - 1) = 0, incorrect expected 1? Multiple values less than 1 don't make sense for adding multipliers. Paragon was designed to only use the greatest negative value for Multiply Modifiers so there would only ever be at most one value less than 1 multiplying into the BaseValue.
Multipliers: 1.1, 0.5
1 + (0.5 - 1) + (1.1 - 1) = 0.6, correct
Multipliers: 5, 5
1 + (5 - 1) + (5 - 1) = 9, incorrect expected 10. Will always be the sum of the Modifiers - number of Modifiers + 1.
Many games will want their Multiply and Divide Modifiers to multiply and divide together before applying to the BaseValue. To achieve this, you will need to change the engine code for FAggregatorModChannel::EvaluateWithBase().
float FAggregatorModChannel::EvaluateWithBase(float InlineBaseValue, const FAggregatorEvaluateParameters& Parameters) const
{ ... float Multiplicitive = MultiplyMods(Mods[EGameplayModOp::Multiplicitive], Parameters); float Division = MultiplyMods(Mods[EGameplayModOp::Division], Parameters); ... return ((InlineBaseValue + Additive) * Multiplicitive) / Division;
} float FAggregatorModChannel::MultiplyMods(const TArray<FAggregatorMod>& InMods, const FAggregatorEvaluateParameters& Parameters)
{ float Multiplier = 1.0f; for (const FAggregatorMod& Mod : InMods) { if (Mod.Qualifies()) { Multiplier *= Mod.EvaluatedMagnitude; } } return Multiplier;
}`},{header:"4.5.4.2 Gameplay Tags on Modifiers",slug:"_4-5-4-2-gameplay-tags-on-modifiers",content:`SourceTags and TargetTags can be set for each Modifier. They work the same like the Application Tag requirements of a GameplayEffect. So the tags are considered only when the effect is applied. I.e. when having a periodic, infinite effect, they are only taken into consideration on the first application of the effect but not on each periodic execution.
Attribute Based Modifiers can also set SourceTagFilter and TargetTagFilter. When determining the magnitude of the attribute which is the source of the Attribute Based Modifier, these filters are used to exclude certain Modifiers to that attribute. Modifiers which source or target didn't have all of the tags of the filter are excluded.
This means in detail: The tags of the source ASC and the target ASC are captured by GameplayEffects. The source ASC tags are captured, when the GameplayEffectSpec is created, the target ASC tags are captured on execution of the effect. When determining, if a Modifier of an infinite or duration effect "qualifies" to be applied (i.e. its Aggregator qualifies) and those filters are set, the captured tags are compared against the filters.`},{header:"4.5.5 Stacking Gameplay Effects",slug:"_4-5-5-stacking-gameplay-effects",content:`GameplayEffects by default will apply new instances of the GameplayEffectSpec that don't know or care about previously existing instances of the GameplayEffectSpec on application. GameplayEffects can be set to stack where instead of a new instance of the GameplayEffectSpec is added, the currently existing GameplayEffectSpec's stack count is changed. Stacking only works for Duration and Infinite GameplayEffects.
There are two types of stacking: Aggregate by Source and Aggregate by Target. Stacking Type
Description Aggregate by Source
There is a separate instance of stacks per Source ASC on the Target. Each Source can apply X amount of stacks. Aggregate by Target
There is only one instance of stacks on the Target regardless of Source. Each Source can apply a stack up to the shared stack limit. Stacks also have policies for expiration, duration refresh, and period reset. They have helpful hover tooltips in the GameplayEffect Blueprint.
The Sample Project includes a custom Blueprint node that listens for GameplayEffect stack changes. The HUD UMG Widget uses it to update the amount of passive armor stacks that the player has. This AsyncTask will live forever until manually called EndTask(), which we do in the UMG Widget's Destruct event. See AsyncTaskEffectStackChanged.h/cpp.
Listen for GameplayEffect Stack Change BP Node`},{header:"4.5.6 Granted Abilities",slug:"_4-5-6-granted-abilities",content:`GameplayEffects can grant new GameplayAbilities to ASCs. Only Duration and Infinite GameplayEffects can grant abilities.
A common usecase for this is when you want to force another player to do something like moving them from a knockback or pull. You would apply a GameplayEffect to them that grants them an automatically activating ability (see Passive Abilities for how to automatically activate an ability when it is granted) that does the desired action to them.
Designers can choose which abilities a GameplayEffect grants, what level to grant them at, what input to bind them at and the removal policy for the granted ability. Removal Policy
Description Cancel Ability Immediately
The granted ability is canceled and removed immediately when the GameplayEffect that granted it is removed from the Target. Remove Ability on End
The granted ability is allowed to finish and then is removed from the Target. Do Nothing
The granted ability is not affected by the removal of the granting GameplayEffect from the Target. The Target has the ability permanently until it is manually removed later.`},{header:"4.5.7 Gameplay Effect Tags",slug:"_4-5-7-gameplay-effect-tags",content:`GameplayEffects carry multiple GameplayTagContainers. Designers will edit the Added and Removed GameplayTagContainers for each category and the result will show up in the Combined GameplayTagContainer on compilation. Added tags are new tags that this GameplayEffect adds that its parents did not previously have. Removed tags are tags that parent classes have but this subclass does not have. Category
Description Gameplay Effect Asset Tags
Tags that the GameplayEffect has. They do not do any function on their own and serve only the purpose of describing the GameplayEffect. Granted Tags
Tags that live on the GameplayEffect but are also given to the ASC that the GameplayEffect is applied to. They are removed from the ASC when the GameplayEffect is removed. This only works for Duration and Infinite GameplayEffects. Ongoing Tag Requirements
Once applied, these tags determine whether the GameplayEffect is on or off. A GameplayEffect can be off and still be applied. If a GameplayEffect is off due to failing the Ongoing Tag Requirements, but the requirements are then met, the GameplayEffect will turn on again and reapply its modifiers. This only works for Duration and Infinite GameplayEffects. Application Tag Requirements
Tags on the Target that determine if a GameplayEffect can be applied to the Target. If these requirements are not met, the GameplayEffect is not applied. Remove Gameplay Effects with Tags
GameplayEffects on the Target that have any of these tags in their Asset Tags or Granted Tags will be removed from the Target when this GameplayEffect is successfully applied.`},{header:"4.5.8 Immunity",slug:"_4-5-8-immunity",content:`GameplayEffects can grant immunity, effectively blocking the application of other GameplayEffects, based on GameplayTags. While immunity can be effectively achieved through other means like Application Tag Requirements, using this system provides a delegate for when GameplayEffects are blocked due to immunity UAbilitySystemComponent::OnImmunityBlockGameplayEffectDelegate.
GrantedApplicationImmunityTags checks if the Source ASC (including tags from the Source ability's AbilityTags if there was one) has any of the specified tags. This is a way to provide immunity from all GameplayEffects from certain characters or sources based on their tags.
Granted Application Immunity Query checks the incoming GameplayEffectSpec if it matches any of the queries to block or allow its application.
The queries have helpful hover tooltips in the GameplayEffect Blueprint.`},{header:"4.5.9 Gameplay Effect Spec",slug:"_4-5-9-gameplay-effect-spec",content:`The GameplayEffectSpec (GESpec) can be thought of as the instantiations of GameplayEffects. They hold a reference to the GameplayEffect class that they represent, what level it was created at, and who created it. These can be freely created and modified at runtime before application unlike GameplayEffects which should be created by designers prior to runtime. When applying a GameplayEffect, a GameplayEffectSpec is created from the GameplayEffect and that is actually what is applied to the Target.
GameplayEffectSpecs are created from GameplayEffects using UAbilitySystemComponent::MakeOutgoingSpec() which is BlueprintCallable. GameplayEffectSpecs do not have to be immediately applied. It is common to pass a GameplayEffectSpec to a projectile created from an ability that the projectile can apply to the target it hits later. When GameplayEffectSpecs are successfully applied, they return a new struct called FActiveGameplayEffect.
Notable GameplayEffectSpec Contents: The GameplayEffect class that this GameplayEffect was created from.
The level of this GameplayEffectSpec. Usually the same as the level of the ability that created the GameplayEffectSpec but can be different.
The duration of the GameplayEffectSpec. Defaults to the duration of the GameplayEffect but can be different.
The period of the GameplayEffectSpec for periodic effects. Defaults to the period of the GameplayEffect but can be different.
The current stack count of this GameplayEffectSpec. The stack limit is on the GameplayEffect.
The GameplayEffectContextHandle tells us who created this GameplayEffectSpec.
Attributes that were captured at the time of the GameplayEffectSpec's creation due to snapshotting.
DynamicGrantedTags that the GameplayEffectSpec grants to the Target in addition to the GameplayTags that the GameplayEffect grants.
DynamicAssetTags that the GameplayEffectSpec has in addition to the AssetTags that the GameplayEffect has.
SetByCaller TMaps.`},{header:"4.5.9.1 SetByCallers",slug:"_4-5-9-1-setbycallers",content:`SetByCallers allow the GameplayEffectSpec to carry float values associated with a GameplayTag or FName around. They are stored in their respective TMaps: TMap<FGameplayTag, float> and TMap<FName, float> on the GameplayEffectSpec. These can be used as Modifiers on the GameplayEffect or as generic means of ferrying floats around. It is common to pass numerical data generated inside of an ability to GameplayEffectExecutionCalculations or ModifierMagnitudeCalculations via SetByCallers. SetByCaller Use
Notes Modifiers
Must be defined ahead of time in the GameplayEffect class. Can only use the GameplayTag version. If one is defined on the GameplayEffect class but the GameplayEffectSpec does not have the corresponding tag and float value pair, the game will have a runtime error on application of the GameplayEffectSpec and return 0. This is a potential problem for a Divide operation. See Modifiers. Elsewhere
Does not need to be defined ahead of time anywhere. Reading a SetByCaller that does not exist on a GameplayEffectSpec can return a developer defined default value with optional warnings. To assign SetByCaller values in Blueprint, use the Blueprint node for the version that you need (GameplayTag or FName):
Assigning SetByCaller
To read a SetByCaller value in Blueprint, you will need to make custom nodes in your Blueprint Library.
To assign SetByCaller values in C++, use the version of the function that you need (GameplayTag or FName):
void FGameplayEffectSpec::SetSetByCallerMagnitude(FName DataName, float Magnitude); void FGameplayEffectSpec::SetSetByCallerMagnitude(FGameplayTag DataTag, float Magnitude); To read a SetByCaller value in C++, use the version of the function that you need (GameplayTag or FName):
float GetSetByCallerMagnitude(FName DataName, bool WarnIfNotFound = true, float DefaultIfNotFound = 0.f) const; float GetSetByCallerMagnitude(FGameplayTag DataTag, bool WarnIfNotFound = true, float DefaultIfNotFound = 0.f) const; I recommend using the GameplayTag version over the FName version. This can prevent spelling errors in Blueprint.`},{header:"4.5.10 Gameplay Effect Context",slug:"_4-5-10-gameplay-effect-context",content:`The GameplayEffectContext structure holds information about a GameplayEffectSpec's instigator and TargetData. This is also a good structure to subclass to pass arbitrary data around between places like ModifierMagnitudeCalculations / GameplayEffectExecutionCalculations, AttributeSets, and GameplayCues.
To subclass the GameplayEffectContext: Subclass FGameplayEffectContext
Override FGameplayEffectContext::GetScriptStruct()
Override FGameplayEffectContext::Duplicate()
Override FGameplayEffectContext::NetSerialize() if your new data needs to be replicated
Implement TStructOpsTypeTraits for your subclass, like the parent struct FGameplayEffectContext has
Override AllocGameplayEffectContext() in your AbilitySystemGlobals class to return a new object of your subclass GASShooter uses a subclassed GameplayEffectContext to add TargetData which can be accessed in GameplayCues, specifically for the shotgun since it can hit more than one enemy.`},{header:"4.5.11 Modifier Magnitude Calculation",slug:"_4-5-11-modifier-magnitude-calculation",content:`ModifierMagnitudeCalculations (ModMagCalc or MMC) are powerful classes used as Modifiers in GameplayEffects. They function similarly to GameplayEffectExecutionCalculations but are less powerful and most importantly they can be predicted. Their sole purpose is to return a float value from CalculateBaseMagnitude_Implementation(). You can subclass and override this function in Blueprint and C++.
MMCs can be used in any duration of GameplayEffects - Instant, Duration, Infinite, or Periodic.
MMCs' strength lies in their capability to capture the value of any number of Attributes on the Source or the Target of GameplayEffect with full access to the GameplayEffectSpec to read GameplayTags and SetByCallers. Attributes can either be snapshotted or not. Snapshotted Attributes are captured when the GameplayEffectSpec is created whereas non snapshotted Attributes are captured when the GameplayEffectSpec is applied and automatically update when the Attribute changes for Infinite and Duration GameplayEffects. Capturing Attributes recalculates their CurrentValue from existing mods on the ASC. This recalculation will not run PreAttributeChange() in the AbilitySet so any clamping must be done here again. Snapshot
Source or Target
Captured on GameplayEffectSpec
Automatically updates when Attribute changes for Infinite or Duration GE Yes
Source
Creation
No Yes
Target
Application
No No
Source
Application
Yes No
Target
Application
Yes The resultant float from an MMC can further be modified in the GameplayEffect's Modifier by a coefficient and a pre and post coefficient addition.
An example MMC that captures the Target's mana Attribute reduces it from a poison effect where the amount reduced changes depending on how much mana the Target has and a tag that the Target might have:
UPAMMC_PoisonMana::UPAMMC_PoisonMana()
{ //ManaDef defined in header FGameplayEffectAttributeCaptureDefinition ManaDef; ManaDef.AttributeToCapture = UPAAttributeSetBase::GetManaAttribute(); ManaDef.AttributeSource = EGameplayEffectAttributeCaptureSource::Target; ManaDef.bSnapshot = false; //MaxManaDef defined in header FGameplayEffectAttributeCaptureDefinition MaxManaDef; MaxManaDef.AttributeToCapture = UPAAttributeSetBase::GetMaxManaAttribute(); MaxManaDef.AttributeSource = EGameplayEffectAttributeCaptureSource::Target; MaxManaDef.bSnapshot = false; RelevantAttributesToCapture.Add(ManaDef); RelevantAttributesToCapture.Add(MaxManaDef);
} float UPAMMC_PoisonMana::CalculateBaseMagnitude_Implementation(const FGameplayEffectSpec & Spec) const
{ // Gather the tags from the source and target as that can affect which buffs should be used const FGameplayTagContainer* SourceTags = Spec.CapturedSourceTags.GetAggregatedTags(); const FGameplayTagContainer* TargetTags = Spec.CapturedTargetTags.GetAggregatedTags(); FAggregatorEvaluateParameters EvaluationParameters; EvaluationParameters.SourceTags = SourceTags; EvaluationParameters.TargetTags = TargetTags; float Mana = 0.f; GetCapturedAttributeMagnitude(ManaDef, Spec, EvaluationParameters, Mana); Mana = FMath::Max<float>(Mana, 0.0f); float MaxMana = 0.f; GetCapturedAttributeMagnitude(MaxManaDef, Spec, EvaluationParameters, MaxMana); MaxMana = FMath::Max<float>(MaxMana, 1.0f); // Avoid divide by zero float Reduction = -20.0f; if (Mana / MaxMana > 0.5f) { // Double the effect if the target has more than half their mana Reduction *= 2; } if (TargetTags->HasTagExact(FGameplayTag::RequestGameplayTag(FName("Status.WeakToPoisonMana")))) { // Double the effect if the target is weak to PoisonMana Reduction *= 2; } return Reduction;
} If you don't add the FGameplayEffectAttributeCaptureDefinition to RelevantAttributesToCapture in the MMC's constructor and try to capture Attributes, you will get an error about a missing Spec while capturing. If you don't need to capture Attributes, then you don't have to add anything to RelevantAttributesToCapture.`},{header:"4.5.12 Gameplay Effect Execution Calculation",slug:"_4-5-12-gameplay-effect-execution-calculation",content:`GameplayEffectExecutionCalculations (ExecutionCalculation, Execution (you will often see this term in the plugin's source code), or ExecCalc) are the most powerful way for GameplayEffects to make changes to an ASC. Like ModifierMagnitudeCalculations, these can capture Attributes and optionally snapshot them. Unlike MMCs, these can change more than one Attribute and essentially do anything else that the programmer wants. The downside to this power and flexibility is that they can not be predicted and they must be implemented in C++.
ExecutionCalculations can only be used with Instant and Periodic GameplayEffects. Anything with the word 'Execute' in it typically refers to these two types of GameplayEffects.
Snapshotting captures the Attribute when the GameplayEffectSpec is created whereas not snapshotting captures the Attribute when the GameplayEffectSpec is applied. Capturing Attributes recalculates their CurrentValue from existing mods on the ASC. This recalculation will not run PreAttributeChange() in the AbilitySet so any clamping must be done here again. Snapshot
Source or Target
Captured on GameplayEffectSpec Yes
Source
Creation Yes
Target
Application No
Source
Application No
Target
Application To set up Attribute capture, we follow a pattern set by Epic's ActionRPG Sample Project by defining a struct holding and defining how we capture the Attributes and creating one copy of it in the struct's constructor. You will have a struct like this for every ExecCalc. Note: Each struct needs a unique name as they share the same namespace. Using the same name for the structs will cause incorrect behavior in capturing your Attributes (mostly capturing the values of the wrong Attributes).
For Local Predicted, Server Only, and Server Initiated GameplayAbilities, the ExecCalc only calls on the Server.
Calculating damage received based on a complex formula reading from many attributes on the Source and the Target is the most common example of an ExecCalc. The included Sample Project has a simple ExecCalc for calculating damage that reads the value of damage from the GameplayEffectSpec's SetByCaller and then mitigates that value based on the armor Attribute captured from the Target. See GDDamageExecCalculation.cpp/.h.`},{header:"4.5.12.1 Sending Data to Execution Calculations",slug:"_4-5-12-1-sending-data-to-execution-calculations",content:"There are a few ways to send data to an ExecutionCalculation in addition to capturing Attributes."},{header:"4.5.12.1.1 SetByCaller",slug:"_4-5-12-1-1-setbycaller",content:`Any SetByCallers set on the GameplayEffectSpec can be directly read in the ExecutionCalculation.
const FGameplayEffectSpec& Spec = ExecutionParams.GetOwningSpec();
float Damage = FMath::Max<float>(Spec.GetSetByCallerMagnitude(FGameplayTag::RequestGameplayTag(FName("Data.Damage")), false, -1.0f), 0.0f);`},{header:"4.5.12.1.2 Backing Data Attribute Calculation Modifier",slug:"_4-5-12-1-2-backing-data-attribute-calculation-modifier",content:`If you want to hardcode values to a GameplayEffect, you can pass them in using a CalculationModifier that uses one of the captured Attributes as the backing data.
In this screenshot example, we're adding 50 to the captured Damage Attribute. You could also set this to Override to just take in only the hardcoded value.
Backing Data Attribute Calculation Modifier
The ExecutionCalculation reads this value in when it captures the Attribute.
float Damage = 0.0f;
// Capture optional damage value set on the damage GE as a CalculationModifier under the ExecutionCalculation
ExecutionParams.AttemptCalculateCapturedAttributeMagnitude(DamageStatics().DamageDef, EvaluationParameters, Damage);`},{header:"4.5.12.1.3 Backing Data Temporary Variable Calculation Modifier",slug:"_4-5-12-1-3-backing-data-temporary-variable-calculation-modifier",content:`If you want to hardcode values to a GameplayEffect, you can pass them in using a CalculationModifier that uses a Temporary Variable or Transient Aggregator as it's called in C++. The Temporary Variable is associated with a GameplayTag.
In this screenshot example, we're adding 50 to a Temporary Variable using the Data.Damage GameplayTag.
Backing Data Temporary Variable Calculation Modifier
Add backing Temporary Variables to your ExecutionCalculation's constructor:
ValidTransientAggregatorIdentifiers.AddTag(FGameplayTag::RequestGameplayTag("Data.Damage")); The ExecutionCalculation reads this value in using special capture functions similar to the Attribute capture functions.
float Damage = 0.0f;
ExecutionParams.AttemptCalculateTransientAggregatorMagnitude(FGameplayTag::RequestGameplayTag("Data.Damage"), EvaluationParameters, Damage);`},{header:"4.5.12.1.4 Gameplay Effect Context",slug:"_4-5-12-1-4-gameplay-effect-context",content:`You can send data to the ExecutionCalculation via a custom GameplayEffectContext on the GameplayEffectSpec.
In the ExecutionCalculation you can access the EffectContext from the FGameplayEffectCustomExecutionParameters.
const FGameplayEffectSpec& Spec = ExecutionParams.GetOwningSpec();
FGSGameplayEffectContext* ContextHandle = static_cast<FGSGameplayEffectContext*>(Spec.GetContext().Get()); If you need change something on the GameplayEffectSpec or the EffectContext:
FGameplayEffectSpec* MutableSpec = ExecutionParams.GetOwningSpecForPreExecuteMod();
FGSGameplayEffectContext* ContextHandle = static_cast<FGSGameplayEffectContext*>(MutableSpec->GetContext().Get()); Use caution if modifying the GameplayEffectSpec in the ExecutionCalculation. See the comment for GetOwningSpecForPreExecuteMod().
/** Non const access. Be careful with this, especially when modifying a spec after attribute capture. */
FGameplayEffectSpec* GetOwningSpecForPreExecuteMod() const;`},{header:"4.5.13 Custom Application Requirement",slug:"_4-5-13-custom-application-requirement",content:`CustomApplicationRequirement (CAR) classes give the designers advanced control over whether a GameplayEffect can be applied versus the simple GameplayTag checks on the GameplayEffect. These can be implemented in Blueprint by overriding CanApplyGameplayEffect() and in C++ by overriding CanApplyGameplayEffect_Implementation().
Examples of when to use CARs: Target needs to have a certain amount of an Attribute
Target needs to have a certain number of stacks of a GameplayEffect CARs can also do more advanced things like checking if an instance of this GameplayEffect is already on the Target and changing the duration of the existing instance instead of applying a new instance (return false for CanApplyGameplayEffect()).`},{header:"4.5.14 Cost Gameplay Effect",slug:"_4-5-14-cost-gameplay-effect",content:`GameplayAbilities have an optional GameplayEffect specifically designed to use as the cost of the ability. Costs are how much of an Attribute an ASC needs to have to be able to activate the GameplayAbility. If a GA cannot afford the Cost GE, then they will not be able to activate. This Cost GE should be an Instant GameplayEffect with one or more Modifiers that subtract from Attributes. By default, Cost GEs are meant to be predicted and it is recommended to maintain that capability meaning do not use ExecutionCalculations. MMCs are perfectly acceptable and encouraged for complex cost calculations.
When starting out, you will most likely have one unique Cost GE per GA that has a cost. A more advanced technique is to reuse one Cost GE for multiple GAs and just modify the GameplayEffectSpec created from the Cost GE with the GA-specific data (the cost value is defined on the GA). This only works for Instanced abilities.
Two techniques for reusing the Cost GE: Use an MMC. This is the easiest method. Create an MMC that reads the cost value from the GameplayAbility instance which you can get from the GameplayEffectSpec. float UPGMMC_HeroAbilityCost::CalculateBaseMagnitude_Implementation(const FGameplayEffectSpec & Spec) const
{ const UPGGameplayAbility* Ability = Cast<UPGGameplayAbility>(Spec.GetContext().GetAbilityInstance_NotReplicated()); if (!Ability) { return 0.0f; } return Ability->Cost.GetValueAtLevel(Ability->GetAbilityLevel());
} In this example the cost value is an FScalableFloat on the GameplayAbility child class that I added to it.
UPROPERTY(BlueprintReadOnly, EditAnywhere, Category = "Cost")
FScalableFloat Cost; Cost GE With MMC Override UGameplayAbility::GetCostGameplayEffect(). Override this function and create a GameplayEffect at runtime that reads the cost value on the GameplayAbility.`},{header:"4.5.15 Cooldown Gameplay Effect",slug:"_4-5-15-cooldown-gameplay-effect",content:`GameplayAbilities have an optional GameplayEffect specifically designed to use as the cooldown of the ability. Cooldowns determine how long after activation the ability can be activated again. If a GA is still on cooldown, it cannot activate. This Cooldown GE should be a Duration GameplayEffect with no Modifiers and a unique GameplayTag per GameplayAbility or per ability slot (if your game has interchangeable abilities assigned to slots that share a cooldown) in the GameplayEffect's GrantedTags ("Cooldown Tag"). The GA actually checks for the presence of the Cooldown Tag instead of the presence of the Cooldown GE. By default, Cooldown GEs are meant to be predicted and it is recommended to maintain that capability meaning do not use ExecutionCalculations. MMCs are perfectly acceptable and encouraged for complex cooldown calculations.
When starting out, you will most likely have one unique Cooldown GE per GA that has a cooldown. A more advanced technique is to reuse one Cooldown GE for multiple GAs and just modify the GameplayEffectSpec created from the Cooldown GE with the GA-specific data (the cooldown duration and the Cooldown Tag are defined on the GA). This only works for Instanced abilities.
Two techniques for reusing the Cooldown GE: Use a SetByCaller. This is the easiest method. Set the duration of your shared Cooldown GE to SetByCaller with a GameplayTag. On your GameplayAbility subclass, define a float / FScalableFloat for the duration, a FGameplayTagContainer for the unique Cooldown Tag, and a temporary FGameplayTagContainer that we will use as the return pointer of the union of our Cooldown Tag and the Cooldown GE's tags. UPROPERTY(BlueprintReadOnly, EditAnywhere, Category = "Cooldown")
FScalableFloat CooldownDuration; UPROPERTY(BlueprintReadOnly, EditAnywhere, Category = "Cooldown")
FGameplayTagContainer CooldownTags; // Temp container that we will return the pointer to in GetCooldownTags().
// This will be a union of our CooldownTags and the Cooldown GE's cooldown tags.
UPROPERTY(Transient)
FGameplayTagContainer TempCooldownTags; Then override UGameplayAbility::GetCooldownTags() to return the union of our Cooldown Tags and any existing Cooldown GE's tags.
const FGameplayTagContainer * UPGGameplayAbility::GetCooldownTags() const
{ FGameplayTagContainer* MutableTags = const_cast<FGameplayTagContainer*>(&TempCooldownTags); MutableTags->Reset(); // MutableTags writes to the TempCooldownTags on the CDO so clear it in case the ability cooldown tags change (moved to a different slot) const FGameplayTagContainer* ParentTags = Super::GetCooldownTags(); if (ParentTags) { MutableTags->AppendTags(*ParentTags); } MutableTags->AppendTags(CooldownTags); return MutableTags;
} Finally, override UGameplayAbility::ApplyCooldown() to inject our Cooldown Tags and to add the SetByCaller to the cooldown GameplayEffectSpec.
void UPGGameplayAbility::ApplyCooldown(const FGameplayAbilitySpecHandle Handle, const FGameplayAbilityActorInfo * ActorInfo, const FGameplayAbilityActivationInfo ActivationInfo) const
{ UGameplayEffect* CooldownGE = GetCooldownGameplayEffect(); if (CooldownGE) { FGameplayEffectSpecHandle SpecHandle = MakeOutgoingGameplayEffectSpec(CooldownGE->GetClass(), GetAbilityLevel()); SpecHandle.Data.Get()->DynamicGrantedTags.AppendTags(CooldownTags); SpecHandle.Data.Get()->SetSetByCallerMagnitude(FGameplayTag::RequestGameplayTag(FName( OurSetByCallerTag )), CooldownDuration.GetValueAtLevel(GetAbilityLevel())); ApplyGameplayEffectSpecToOwner(Handle, ActorInfo, ActivationInfo, SpecHandle); }
} In this picture, the cooldown's duration Modifier is set to SetByCaller with a Data Tag of Data.Cooldown. Data.Cooldown would be OurSetByCallerTag in the code above.
Cooldown GE with SetByCaller Use an MMC. This has the same setup as above except for setting the SetByCaller as the duration on the Cooldown GE and in ApplyCooldown. Instead, set the duration to be a Custom Calculation Class and point to the new MMC that we will make. UPROPERTY(BlueprintReadOnly, EditAnywhere, Category = "Cooldown")
FScalableFloat CooldownDuration; UPROPERTY(BlueprintReadOnly, EditAnywhere, Category = "Cooldown")
FGameplayTagContainer CooldownTags; // Temp container that we will return the pointer to in GetCooldownTags().
// This will be a union of our CooldownTags and the Cooldown GE's cooldown tags.
UPROPERTY(Transient)
FGameplayTagContainer TempCooldownTags; Then override UGameplayAbility::GetCooldownTags() to return the union of our Cooldown Tags and any existing Cooldown GE's tags.
const FGameplayTagContainer * UPGGameplayAbility::GetCooldownTags() const
{ FGameplayTagContainer* MutableTags = const_cast<FGameplayTagContainer*>(&TempCooldownTags); MutableTags->Reset(); // MutableTags writes to the TempCooldownTags on the CDO so clear it in case the ability cooldown tags change (moved to a different slot) const FGameplayTagContainer* ParentTags = Super::GetCooldownTags(); if (ParentTags) { MutableTags->AppendTags(*ParentTags); } MutableTags->AppendTags(CooldownTags); return MutableTags;
} Finally, override UGameplayAbility::ApplyCooldown() to inject our Cooldown Tags into the cooldown GameplayEffectSpec.
void UPGGameplayAbility::ApplyCooldown(const FGameplayAbilitySpecHandle Handle, const FGameplayAbilityActorInfo * ActorInfo, const FGameplayAbilityActivationInfo ActivationInfo) const
{ UGameplayEffect* CooldownGE = GetCooldownGameplayEffect(); if (CooldownGE) { FGameplayEffectSpecHandle SpecHandle = MakeOutgoingGameplayEffectSpec(CooldownGE->GetClass(), GetAbilityLevel()); SpecHandle.Data.Get()->DynamicGrantedTags.AppendTags(CooldownTags); ApplyGameplayEffectSpecToOwner(Handle, ActorInfo, ActivationInfo, SpecHandle); }
} float UPGMMC_HeroAbilityCooldown::CalculateBaseMagnitude_Implementation(const FGameplayEffectSpec & Spec) const
{ const UPGGameplayAbility* Ability = Cast<UPGGameplayAbility>(Spec.GetContext().GetAbilityInstance_NotReplicated()); if (!Ability) { return 0.0f; } return Ability->CooldownDuration.GetValueAtLevel(Ability->GetAbilityLevel());
} Cooldown GE with MMC`},{header:"4.5.15.1 Get the Cooldown Gameplay Effect's Remaining Time",slug:"_4-5-15-1-get-the-cooldown-gameplay-effect-s-remaining-time",content:`bool APGPlayerState::GetCooldownRemainingForTag(FGameplayTagContainer CooldownTags, float & TimeRemaining, float & CooldownDuration)
{ if (AbilitySystemComponent && CooldownTags.Num() > 0) { TimeRemaining = 0.f; CooldownDuration = 0.f; FGameplayEffectQuery const Query = FGameplayEffectQuery::MakeQuery_MatchAnyOwningTags(CooldownTags); TArray< TPair<float, float> > DurationAndTimeRemaining = AbilitySystemComponent->GetActiveEffectsTimeRemainingAndDuration(Query); if (DurationAndTimeRemaining.Num() > 0) { int32 BestIdx = 0; float LongestTime = DurationAndTimeRemaining[0].Key; for (int32 Idx = 1; Idx < DurationAndTimeRemaining.Num(); ++Idx) { if (DurationAndTimeRemaining[Idx].Key > LongestTime) { LongestTime = DurationAndTimeRemaining[Idx].Key; BestIdx = Idx; } } TimeRemaining = DurationAndTimeRemaining[BestIdx].Key; CooldownDuration = DurationAndTimeRemaining[BestIdx].Value; return true; } } return false;
} Note: Querying the cooldown's time remaining on clients requires that they can receive replicated GameplayEffects. This will depend on their ASC's replication mode.`},{header:"4.5.15.2 Listening for Cooldown Begin and End",slug:"_4-5-15-2-listening-for-cooldown-begin-and-end",content:`To listen for when a cooldown begins, you can either respond to when the Cooldown GE is applied by binding to AbilitySystemComponent->OnActiveGameplayEffectAddedDelegateToSelf or when the Cooldown Tag is added by binding to AbilitySystemComponent->RegisterGameplayTagEvent(CooldownTag, EGameplayTagEventType::NewOrRemoved). I recommend listening for when the Cooldown GE is added because you also have access to the GameplayEffectSpec that applied it. From this you can determine if the Cooldown GE is the locally predicted one or the Server's correcting one.
To listen for when a cooldown ends, you can either respond to when the Cooldown GE is removed by binding to AbilitySystemComponent->OnAnyGameplayEffectRemovedDelegate() or when the Cooldown Tag is removed by binding to AbilitySystemComponent->RegisterGameplayTagEvent(CooldownTag, EGameplayTagEventType::NewOrRemoved). I recommend listening for when the Cooldown Tag is removed because when the Server's corrected Cooldown GE comes in, it will remove our locally predicted one causing the OnAnyGameplayEffectRemovedDelegate() to fire even though we're still on cooldown. The Cooldown Tag will not change during the removal of the predicted Cooldown GE and the application of the Server's corrected Cooldown GE.
Note: Listening for a GameplayEffect to be added or removed on clients requires that they can receive replicated GameplayEffects. This will depend on their ASC's replication mode.
The Sample Project includes a custom Blueprint node that listens for cooldowns beginning and ending. The HUD UMG Widget uses it to update the amount of time remaining on the Meteor's cooldown. This AsyncTask will live forever until manually called EndTask(), which we do in the UMG Widget's Destruct event. See AsyncTaskCooldownChanged.h/cpp.
Listen for Cooldown Change BP Node`},{header:"4.5.15.3 Predicting Cooldowns",slug:"_4-5-15-3-predicting-cooldowns",content:`Cooldowns cannot really be predicted currently. We can start UI cooldown timer's when the locally predicted Cooldown GE is applied but the GameplayAbility's actual cooldown is tied to the server's cooldown's time remaining. Depending on the player's latency, the locally predicted cooldown could expire but the GameplayAbility would still be on cooldown on the server and this would prevent the GameplayAbility's immediate re-activation until the server's cooldown expires.
The Sample Project handles this by graying out the Meteor ability's UI icon when the locally predicted cooldown begins and then starting the cooldown timer once the server's corrected Cooldown GE comes in.
A gameplay consequence of this is that players with high latencies have a lower rate of fire on short cooldown abilities than players with lower latencies putting them at a disadvantage. Fortnite avoids this by their weapons having custom bookkeeping that do not use cooldown GameplayEffects.
Allowing for true predicted cooldowns (player could activate a GameplayAbility when the local cooldown expires but the server is still on cooldown) is something that Epic would like to implement someday in a future iteration of GAS.`},{header:"4.5.16 Changing Active Gameplay Effect Duration",slug:"_4-5-16-changing-active-gameplay-effect-duration",content:`To change the time remaining for a Cooldown GE or any Duration GameplayEffect, we need to change the GameplayEffectSpec's Duration, update its StartServerWorldTime, update its CachedStartServerWorldTime, update its StartWorldTime, and rerun the check on the duration with CheckDuration(). Doing this on the server and marking the FActiveGameplayEffect dirty will replicate the changes to clients.
Note: This does involve a const_cast and may not be Epic's intended way of changing durations, but it seems to work well so far.
bool UPAAbilitySystemComponent::SetGameplayEffectDurationHandle(FActiveGameplayEffectHandle Handle, float NewDuration)
{ if (!Handle.IsValid()) { return false; } const FActiveGameplayEffect* ActiveGameplayEffect = GetActiveGameplayEffect(Handle); if (!ActiveGameplayEffect) { return false; } FActiveGameplayEffect* AGE = const_cast<FActiveGameplayEffect*>(ActiveGameplayEffect); if (NewDuration > 0) { AGE->Spec.Duration = NewDuration; } else { AGE->Spec.Duration = 0.01f; } AGE->StartServerWorldTime = ActiveGameplayEffects.GetServerWorldTime(); AGE->CachedStartServerWorldTime = AGE->StartServerWorldTime; AGE->StartWorldTime = ActiveGameplayEffects.GetWorldTime(); ActiveGameplayEffects.MarkItemDirty(*AGE); ActiveGameplayEffects.CheckDuration(Handle); AGE->EventSet.OnTimeChanged.Broadcast(AGE->Handle, AGE->StartWorldTime, AGE->GetDuration()); OnGameplayEffectDurationChange(*AGE); return true;
}`},{header:"4.5.17 Creating Dynamic Gameplay Effects at Runtime",slug:"_4-5-17-creating-dynamic-gameplay-effects-at-runtime",content:`Creating Dynamic GameplayEffects at runtime is an advanced topic. You shouldn't have to do this too often.
Only Instant GameplayEffects can be created at runtime from scratch in C++. Duration and Infinite GameplayEffects cannot be created dynamically at runtime because when they replicate they look for the GameplayEffect class definition that does not exist. To achieve this functionality, you should instead make an archetype GameplayEffect class like you would normally do in the Editor. Then customize the GameplayEffectSpec instance with what you need at runtime.
Instant GameplayEffects created at runtime can also be called from within a local predicted GameplayAbility. However, it is unknown yet if the dynamic creation can have side effects.`},{header:"Examples",slug:"examples",content:`The Sample Project creates one to send the gold and experience points back to the killer of a character when it takes the killing blow in its AttributeSet.
// Create a dynamic instant Gameplay Effect to give the bounties
UGameplayEffect* GEBounty = NewObject<UGameplayEffect>(GetTransientPackage(), FName(TEXT("Bounty")));
GEBounty->DurationPolicy = EGameplayEffectDurationType::Instant; int32 Idx = GEBounty->Modifiers.Num();
GEBounty->Modifiers.SetNum(Idx + 2); FGameplayModifierInfo& InfoXP = GEBounty->Modifiers[Idx];
InfoXP.ModifierMagnitude = FScalableFloat(GetXPBounty());
InfoXP.ModifierOp = EGameplayModOp::Additive;
InfoXP.Attribute = UGDAttributeSetBase::GetXPAttribute(); FGameplayModifierInfo& InfoGold = GEBounty->Modifiers[Idx + 1];
InfoGold.ModifierMagnitude = FScalableFloat(GetGoldBounty());
InfoGold.ModifierOp = EGameplayModOp::Additive;
InfoGold.Attribute = UGDAttributeSetBase::GetGoldAttribute(); Source->ApplyGameplayEffectToSelf(GEBounty, 1.0f, Source->MakeEffectContext()); A second example shows a runtime GameplayEffect created within a local predicted GameplayAbility. Use at your own risk (see comments in code)!
UGameplayAbilityRuntimeGE::UGameplayAbilityRuntimeGE()
{ NetExecutionPolicy = EGameplayAbilityNetExecutionPolicy::LocalPredicted;
} void UGameplayAbilityRuntimeGE::ActivateAbility(const FGameplayAbilitySpecHandle Handle, const FGameplayAbilityActorInfo* ActorInfo, const FGameplayAbilityActivationInfo ActivationInfo, const FGameplayEventData* TriggerEventData)
{ if (HasAuthorityOrPredictionKey(ActorInfo, &ActivationInfo)) { if (!CommitAbility(Handle, ActorInfo, ActivationInfo)) { EndAbility(Handle, ActorInfo, ActivationInfo, true, true); } // Create the GE at runtime. UGameplayEffect* GameplayEffect = NewObject<UGameplayEffect>(GetTransientPackage(), TEXT("RuntimeInstantGE")); GameplayEffect->DurationPolicy = EGameplayEffectDurationType::Instant; // Only instant works with runtime GE. // Add a simple scalable float modifier, which overrides MyAttribute with 42. // In real world applications, consume information passed via TriggerEventData. const int32 Idx = GameplayEffect->Modifiers.Num(); GameplayEffect->Modifiers.SetNum(Idx + 1); FGameplayModifierInfo& ModifierInfo = GameplayEffect->Modifiers[Idx]; ModifierInfo.Attribute.SetUProperty(UMyAttributeSet::GetMyModifiedAttribute()); ModifierInfo.ModifierMagnitude = FScalableFloat(42.f); ModifierInfo.ModifierOp = EGameplayModOp::Override; // Apply the GE. // Create the GESpec here to avoid the behavior of ASC to create GESpecs from the GE class default object. // Since we have a dynamic GE here, this would create a GESpec with the base GameplayEffect class, so we // would lose our modifiers. Attention: It is unknown, if this "hack" done here can have drawbacks! // The spec prevents the GE object being collected by the GarbageCollector, since the GE is a UPROPERTY on the spec. FGameplayEffectSpec* GESpec = new FGameplayEffectSpec(GameplayEffect, {}, 0.f); // "new", since lifetime is managed by a shared ptr within the handle ApplyGameplayEffectSpecToOwner(Handle, ActorInfo, ActivationInfo, FGameplayEffectSpecHandle(GESpec)); } EndAbility(Handle, ActorInfo, ActivationInfo, false, false);
}`},{header:"4.5.18 Gameplay Effect Containers",slug:"_4-5-18-gameplay-effect-containers",content:`Epic's Action RPG Sample Project implements a structure called FGameplayEffectContainer. These are not in vanilla GAS but are extremely handy for containing GameplayEffects and TargetData. It automates some of the effort like creating GameplayEffectSpecs from GameplayEffects and setting default values in its GameplayEffectContext. Making a GameplayEffectContainer in a GameplayAbility and passing it to spawned projectiles is very easy and straightforward. I opted not to implement the GameplayEffectContainers in the included Sample Project to show how you would work without them in vanilla GAS, but I highly recommend looking into them and considering adding them to your project.
To access the GESpecs inside of the GameplayEffectContainers to do things like adding SetByCallers, break the FGameplayEffectContainer and access the GESpec reference by its index in the array of GESpecs. This requires that you know the index ahead of time of the GESpec that you want to access.
SetByCaller with a GameplayEffectContainer
GameplayEffectContainers also contain an optional efficient means of targeting.`},{header:"4.6 Gameplay Abilities",slug:"_4-6-gameplay-abilities",content:""},{header:"4.6.1 Gameplay Ability Definition",slug:"_4-6-1-gameplay-ability-definition",content:`GameplayAbilities (GA) are any actions or skills that an Actor can do in the game. More than one GameplayAbility can be active at one time for example sprinting and shooting a gun. These can be made in Blueprint or C++.
Examples of GameplayAbilities: Jumping
Sprinting
Shooting a gun
Passively blocking an attack every X number of seconds
Using a potion
Opening a door
Collecting a resource
Constructing a building Things that should not be implemented with GameplayAbilities: Basic movement input
Some interactions with UIs - Don't use a GameplayAbility to purchase an item from a store. These are not rules, just my recommendations. Your design and implementations may vary.
GameplayAbilities come with default functionality to have a level to modify the amount of change to attributes or to change the GameplayAbility's functionality.
GameplayAbilities run on the owning client and/or the server depending on the Net Execution Policy but not simulated proxies. The Net Execution Policy determines if a GameplayAbility will be locally predicted. They include default behavior for optional cost and cooldown GameplayEffects. GameplayAbilities use AbilityTasks for actions that happen over time like waiting for an event, waiting for an attribute change, waiting for players to choose a target, or moving a Character with Root Motion Source. Simulated clients will not run GameplayAbilities. Instead, when the server runs the ability, anything that visually needs to play on the simulated proxies (like animation montages) will be replicated or RPC'd through AbilityTasks or GameplayCues for cosmetic things like sounds and particles.
All GameplayAbilities will have their ActivateAbility() function overriden with your gameplay logic. Additional logic can be added to EndAbility() that runs when the GameplayAbility completes or is canceled.
Flowchart of a simple GameplayAbility: Flowchart of a more complex GameplayAbility: Complex abilities can be implemented using multiple GameplayAbilities that interact (activate, cancel, etc) with each other.`},{header:"4.6.1.1 Replication Policy",slug:"_4-6-1-1-replication-policy",content:"Don't use this option. The name is misleading and you don't need it. GameplayAbilitySpecs are replicated from the server to the owning client by default. As mentioned above, GameplayAbilities don't run on simulated proxies. They use AbilityTasks and GameplayCues to replicate or RPC visual changes to the simulated proxies. Dave Ratti from Epic has stated his desire to remove this option in the future."},{header:"4.6.1.2 Server Respects Remote Ability Cancellation",slug:"_4-6-1-2-server-respects-remote-ability-cancellation",content:"This option causes trouble more often than not. It means if the client's GameplayAbility ends either due to cancellation or natural completion, it will force the server's version to end whether it completed or not. The latter issue is the important one, especially for locally predicted GameplayAbilities used by players with high latencies. Generally you will want to disable this option."},{header:"4.6.1.3 Replicate Input Directly",slug:"_4-6-1-3-replicate-input-directly",content:`Setting this option will always replicate input press and release events to the server. Epic recommends not using this and instead relying on the Generic Replicated Events that are built into the existing input related AbilityTasks if you have your input bound to your ASC.
Epic's comment:
/** Direct Input state replication. These will be called if bReplicateInputDirectly is true on the ability and is generally not a good thing to use. (Instead, prefer to use Generic Replicated Events). */
UAbilitySystemComponent::ServerSetInputPressed()`},{header:"4.6.2 Binding Input to the ASC",slug:"_4-6-2-binding-input-to-the-asc",content:`The ASC allows you to directly bind input actions to it and assign those inputs to GameplayAbilities when you grant them. Input actions assigned to GameplayAbilities automatically activate those GameplayAbilities when pressed if the GameplayTag requirements are met. Assigned input actions are required to use the built-in AbilityTasks that respond to input.
In addition to input actions assigned to activate GameplayAbilities, the ASC also accepts generic Confirm and Cancel inputs. These special inputs are used by AbilityTasks for confirming things like Target Actors or canceling them.
To bind input to an ASC, you must first create an enum that translates the input action name to a byte. The enum name must match exactly to the name used for the input action in the project settings. The DisplayName does not matter.
From the Sample Project:
UENUM(BlueprintType)
enum class EGDAbilityInputID : uint8
{ // 0 None None UMETA(DisplayName = "None"), // 1 Confirm Confirm UMETA(DisplayName = "Confirm"), // 2 Cancel Cancel UMETA(DisplayName = "Cancel"), // 3 LMB Ability1 UMETA(DisplayName = "Ability1"), // 4 RMB Ability2 UMETA(DisplayName = "Ability2"), // 5 Q Ability3 UMETA(DisplayName = "Ability3"), // 6 E Ability4 UMETA(DisplayName = "Ability4"), // 7 R Ability5 UMETA(DisplayName = "Ability5"), // 8 Sprint Sprint UMETA(DisplayName = "Sprint"), // 9 Jump Jump UMETA(DisplayName = "Jump")
}; If your ASC lives on the Character, then in SetupPlayerInputComponent() include the function for binding to the ASC:
// Bind to AbilitySystemComponent
FTopLevelAssetPath AbilityEnumAssetPath = FTopLevelAssetPath(FName("/Script/GASDocumentation"), FName("EGDAbilityInputID"));
AbilitySystemComponent->BindAbilityActivationToInputComponent(PlayerInputComponent, FGameplayAbilityInputBinds(FString("ConfirmTarget"), FString("CancelTarget"), AbilityEnumAssetPath, static_cast<int32>(EGDAbilityInputID::Confirm), static_cast<int32>(EGDAbilityInputID::Cancel))); If your ASC lives on the PlayerState, there is a potential race condition inside of SetupPlayerInputComponent() where the PlayerState may not have replicated to the client yet. Therefore, I recommend attempting to bind to input in SetupPlayerInputComponent() and OnRep_PlayerState(). OnRep_PlayerState() is not sufficient by itself because there could be a case where the Actor's InputComponent could be null when PlayerState replicates before the PlayerController tells the client to call ClientRestart() which creates the InputComponent. The Sample Project demonstrates attempting to bind in both locations with a boolean gating the process so it only actually binds the input once.
Note: In the Sample Project Confirm and Cancel in the enum don't match the input action names in the project settings (ConfirmTarget and CancelTarget), but we supply the mapping between them in BindAbilityActivationToInputComponent(). These are special since we supply the mapping and they don't have to match, but they can match. All other inputs in the enum must match the input action names in the project settings.
For GameplayAbilities that will only ever be activated by one input (they will always exist in the same "slot" like a MOBA), I prefer to add a variable to my UGameplayAbility subclass where I can define their input. I can then read this from the ClassDefaultObject when granting the ability.`},{header:"4.6.2.1 Binding to Input without Activating Abilities",slug:"_4-6-2-1-binding-to-input-without-activating-abilities",content:`If you don't want your GameplayAbilities to automatically activate when an input is pressed but still bind them to input to use with AbilityTasks, you can add a new bool variable to your UGameplayAbility subclass, bActivateOnInput, that defaults to true and override UAbilitySystemComponent::AbilityLocalInputPressed().
void UGSAbilitySystemComponent::AbilityLocalInputPressed(int32 InputID)
{ // Consume the input if this InputID is overloaded with GenericConfirm/Cancel and the GenericConfim/Cancel callback is bound if (IsGenericConfirmInputBound(InputID)) { LocalInputConfirm(); return; } if (IsGenericCancelInputBound(InputID)) { LocalInputCancel(); return; } // --------------------------------------------------------- ABILITYLIST_SCOPE_LOCK(); for (FGameplayAbilitySpec& Spec : ActivatableAbilities.Items) { if (Spec.InputID == InputID) { if (Spec.Ability) { Spec.InputPressed = true; if (Spec.IsActive()) { if (Spec.Ability->bReplicateInputDirectly && IsOwnerActorAuthoritative() == false) { ServerSetInputPressed(Spec.Handle); } AbilitySpecInputPressed(Spec); // Invoke the InputPressed event. This is not replicated here. If someone is listening, they may replicate the InputPressed event to the server. InvokeReplicatedEvent(EAbilityGenericReplicatedEvent::InputPressed, Spec.Handle, Spec.ActivationInfo.GetActivationPredictionKey()); } else { UGSGameplayAbility* GA = Cast<UGSGameplayAbility>(Spec.Ability); if (GA && GA->bActivateOnInput) { // Ability is not active, so try to activate it TryActivateAbility(Spec.Handle); } } } } }
}`},{header:"4.6.3 Granting Abilities",slug:"_4-6-3-granting-abilities",content:`Granting a GameplayAbility to an ASC adds it to the ASC's list of ActivatableAbilities allowing it to activate the GameplayAbility at will if it meets the GameplayTag requirements.
We grant GameplayAbilities on the server which then automatically replicates the GameplayAbilitySpec to the owning client. Other clients / simulated proxies do not receive the GameplayAbilitySpec.
The Sample Project stores a TArray<TSubclassOf<UGDGameplayAbility>> on the Character class that it reads from and grants when the game starts:
void AGDCharacterBase::AddCharacterAbilities()
{ // Grant abilities, but only on the server if (Role != ROLE_Authority || !AbilitySystemComponent.IsValid() || AbilitySystemComponent->bCharacterAbilitiesGiven) { return; } for (TSubclassOf<UGDGameplayAbility>& StartupAbility : CharacterAbilities) { AbilitySystemComponent->GiveAbility( FGameplayAbilitySpec(StartupAbility, GetAbilityLevel(StartupAbility.GetDefaultObject()->AbilityID), static_cast<int32>(StartupAbility.GetDefaultObject()->AbilityInputID), this)); } AbilitySystemComponent->bCharacterAbilitiesGiven = true;
} When granting these GameplayAbilities, we're creating GameplayAbilitySpecs with the UGameplayAbility class, the ability level, the input that it is bound to, and the SourceObject or who gave this GameplayAbility to this ASC.`},{header:"4.6.4 Activating Abilities",slug:"_4-6-4-activating-abilities",content:`If a GameplayAbility is assigned an input action, it will be automatically activated if the input is pressed and it meets its GameplayTag requirements. This may not always be the desirable way to activate a GameplayAbility. The ASC provides four other methods of activating GameplayAbilities: by GameplayTag, GameplayAbility class, GameplayAbilitySpec handle, and by an event. Activating a GameplayAbility by event allows you to pass in a payload of data with the event.
UFUNCTION(BlueprintCallable, Category = "Abilities")
bool TryActivateAbilitiesByTag(const FGameplayTagContainer& GameplayTagContainer, bool bAllowRemoteActivation = true); UFUNCTION(BlueprintCallable, Category = "Abilities")
bool TryActivateAbilityByClass(TSubclassOf<UGameplayAbility> InAbilityToActivate, bool bAllowRemoteActivation = true); bool TryActivateAbility(FGameplayAbilitySpecHandle AbilityToActivate, bool bAllowRemoteActivation = true); bool TriggerAbilityFromGameplayEvent(FGameplayAbilitySpecHandle AbilityToTrigger, FGameplayAbilityActorInfo* ActorInfo, FGameplayTag Tag, const FGameplayEventData* Payload, UAbilitySystemComponent& Component); FGameplayAbilitySpecHandle GiveAbilityAndActivateOnce(const FGameplayAbilitySpec& AbilitySpec, const FGameplayEventData* GameplayEventData); To activate a GameplayAbility by event, the GameplayAbility must have its Triggers set up in the GameplayAbility. Assign a GameplayTag and pick an option for GameplayEvent. To send the event, use the function UAbilitySystemBlueprintLibrary::SendGameplayEventToActor(AActor* Actor, FGameplayTag EventTag, FGameplayEventData Payload). Activating a GameplayAbility by event allows you to pass in a payload with data.
GameplayAbility Triggers also allow you to activate the GameplayAbility when a GameplayTag is added or removed.
Note: When activating a GameplayAbility from event in Blueprint, you must use the ActivateAbilityFromEvent node.
Note: Don't forget to call EndAbility() when the GameplayAbility should terminate unless you have a GameplayAbility that will always run like a passive ability.
Activation sequence for locally predicted GameplayAbilities: Owning client calls TryActivateAbility()
Calls InternalTryActivateAbility()
Calls CanActivateAbility() and returns whether GameplayTag requirements are met, if the ASC can afford the cost, if the GameplayAbility is not on cooldown, and if no other instances are currently active
Calls CallServerTryActivateAbility() and passes it the Prediction Key that it generates
Calls CallActivateAbility()
Calls PreActivate() Epic refers to this as "boilerplate init stuff"
Calls ActivateAbility() finally activating the ability Server receives CallServerTryActivateAbility() Calls ServerTryActivateAbility()
Calls InternalServerTryActivateAbility()
Calls InternalTryActivateAbility()
Calls CanActivateAbility() and returns whether GameplayTag requirements are met, if the ASC can afford the cost, if the GameplayAbility is not on cooldown, and if no other instances are currently active
Calls ClientActivateAbilitySucceed() if successful telling it to update its ActivationInfo that its activation was confirmed by the server and broadcasting the OnConfirmDelegate delegate. This is not the same as input confirmation.
Calls CallActivateAbility()
Calls PreActivate() Epic refers to this as "boilerplate init stuff"
Calls ActivateAbility() finally activating the ability If at any time the server fails to activate, it will call ClientActivateAbilityFailed(), immediately terminating the client's GameplayAbility and undoing any predicted changes.`},{header:"4.6.4.1 Passive Abilities",slug:"_4-6-4-1-passive-abilities",content:`To implement passive GameplayAbilities that automatically activate and run continuously, override UGameplayAbility::OnAvatarSet() which is automatically called when a GameplayAbility is granted and the AvatarActor is set and call TryActivateAbility().
I recommend adding a bool to your custom UGameplayAbility class specifying if the GameplayAbility should be activated when granted. The Sample Project does this for its passive armor stacking ability.
Passive GameplayAbilities will typically have a Net Execution Policy of Server Only.
void UGDGameplayAbility::OnAvatarSet(const FGameplayAbilityActorInfo * ActorInfo, const FGameplayAbilitySpec & Spec)
{ Super::OnAvatarSet(ActorInfo, Spec); if (bActivateAbilityOnGranted) { ActorInfo->AbilitySystemComponent->TryActivateAbility(Spec.Handle, false); }
} Epic describes this function as the correct place to initiate passive abilities and to do BeginPlay type things.`},{header:"4.6.4.2 Activation Failed Tags",slug:"_4-6-4-2-activation-failed-tags",content:`Abilities have default logic to tell you why an ability activation failed. To enable this, you must set up the GameplayTags that correspond to the default failure cases.
Add these tags (or your own naming convention) to your project:
+GameplayTagList=(Tag="Activation.Fail.BlockedByTags",DevComment="")
+GameplayTagList=(Tag="Activation.Fail.CantAffordCost",DevComment="")
+GameplayTagList=(Tag="Activation.Fail.IsDead",DevComment="")
+GameplayTagList=(Tag="Activation.Fail.MissingTags",DevComment="")
+GameplayTagList=(Tag="Activation.Fail.Networking",DevComment="")
+GameplayTagList=(Tag="Activation.Fail.OnCooldown",DevComment="") Then add them to the GASDocumentation\\Config\\DefaultGame.ini:
[/Script/GameplayAbilities.AbilitySystemGlobals]
ActivateFailIsDeadName=Activation.Fail.IsDead
ActivateFailCooldownName=Activation.Fail.OnCooldown
ActivateFailCostName=Activation.Fail.CantAffordCost
ActivateFailTagsBlockedName=Activation.Fail.BlockedByTags
ActivateFailTagsMissingName=Activation.Fail.MissingTags
ActivateFailNetworkingName=Activation.Fail.Networking Now whenever an ability activation fails, this corresponding GameplayTag will be included in output log messages or visible on the showdebug AbilitySystem hud.
LogAbilitySystem: Display: InternalServerTryActivateAbility. Rejecting ClientActivation of Default__GA_FireGun_C. InternalTryActivateAbility failed: Activation.Fail.BlockedByTags
LogAbilitySystem: Display: ClientActivateAbilityFailed_Implementation. PredictionKey :109 Ability: Default__GA_FireGun_C Activation Failed Tags Displayed in showdebug AbilitySystem`},{header:"4.6.5 Canceling Abilities",slug:"_4-6-5-canceling-abilities",content:`To cancel a GameplayAbility from within, you call CancelAbility(). This will call EndAbility() and set its WasCancelled parameter to true.
To cancel a GameplayAbility externally, the ASC provides a few functions:
/** Cancels the specified ability CDO. */
void CancelAbility(UGameplayAbility* Ability); /** Cancels the ability indicated by passed in spec handle. If handle is not found among reactivated abilities nothing happens. */
void CancelAbilityHandle(const FGameplayAbilitySpecHandle& AbilityHandle); /** Cancel all abilities with the specified tags. Will not cancel the Ignore instance */
void CancelAbilities(const FGameplayTagContainer* WithTags=nullptr, const FGameplayTagContainer* WithoutTags=nullptr, UGameplayAbility* Ignore=nullptr); /** Cancels all abilities regardless of tags. Will not cancel the ignore instance */
void CancelAllAbilities(UGameplayAbility* Ignore=nullptr); /** Cancels all abilities and kills any remaining instanced abilities */
virtual void DestroyActiveState(); Note: I have found that CancelAllAbilities doesn't seem to work right if you have a Non-Instanced GameplayAbilities. It seems to hit the Non-Instanced GameplayAbility and give up. CancelAbilities can handle Non-Instanced GameplayAbilities better and that is what the Sample Project uses (Jump is a non-instanced GameplayAbility). Your mileage may vary.`},{header:"4.6.6 Getting Active Abilities",slug:"_4-6-6-getting-active-abilities",content:`Beginners often ask "How can I get the active ability?" perhaps to set variables on it or to cancel it. More than one GameplayAbility can be active at a time so there is no one "active ability". Instead, you must search through an ASC's list of ActivatableAbilities (granted GameplayAbilities that the ASC owns) and find the one matching the Asset or Granted GameplayTag that you are looking for.
UAbilitySystemComponent::GetActivatableAbilities() returns a TArray<FGameplayAbilitySpec> for you to iterate over.
The ASC also has another helper function that takes in a GameplayTagContainer as a parameter to assist in searching instead of manually iterating over the list of GameplayAbilitySpecs. The bOnlyAbilitiesThatSatisfyTagRequirements parameter will only return GameplayAbilitySpecs that satisfy their GameplayTag requirements and could be activated right now. For example, you could have two basic attack GameplayAbilities, one with a weapon and one with bare fists, and the correct one activates depending on if a weapon is equipped setting the GameplayTag requirement. See Epic's comment on the function for more information.
UAbilitySystemComponent::GetActivatableGameplayAbilitySpecsByAllMatchingTags(const FGameplayTagContainer& GameplayTagContainer, TArray < struct FGameplayAbilitySpec* >& MatchingGameplayAbilities, bool bOnlyAbilitiesThatSatisfyTagRequirements = true) Once you get the FGameplayAbilitySpec that you are looking for, you can call IsActive() on it.`},{header:"4.6.7 Instancing Policy",slug:"_4-6-7-instancing-policy",content:`A GameplayAbility's Instancing Policy determines if and how the GameplayAbility is instanced when activated. Instancing Policy
Description
Example of when to use Instanced Per Actor
Each ASC only has one instance of the GameplayAbility that is reused between activations.
This will probably be the Instancing Policy that you use the most. You can use it for any ability and provides persistence between activations. The designer is responsible for manually resetting any variables between activations that need it. Instanced Per Execution
Every time a GameplayAbility is activated, a new instance of the GameplayAbility is created.
The benefit of these GameplayAbilities is that the variables are reset everytime you activate. These provide worse performance than Instanced Per Actor since they will spawn new GameplayAbilities every time they activate. The Sample Project does not use any of these. Non-Instanced
The GameplayAbility operates on its ClassDefaultObject. No instances are created.
This has the best performance of the three but is the most restrictive in what can be done with it. Non-Instanced GameplayAbilities cannot store state, meaning no dynamic variables and no binding to AbilityTask delegates. The best place to use them is for frequently used simple abilities like minion basic attacks in a MOBA or RTS. The Sample Project's Jump GameplayAbility is Non-Instanced.`},{header:"4.6.8 Net Execution Policy",slug:"_4-6-8-net-execution-policy",content:`A GameplayAbility's Net Execution Policy determines who runs the GameplayAbility and in what order. Net Execution Policy
Description Local Only
The GameplayAbility is only run on the owning client. This could be useful for abilities that only make local cosmetic changes. Single player games should use Server Only. Local Predicted
Local Predicted GameplayAbilities activate first on the owning client and then on the server. The server's version will correct anything that the client predicted incorrectly. See Prediction. Server Only
The GameplayAbility is only run on the server. Passive GameplayAbilities will typically be Server Only. Single player games should use this. Server Initiated
Server Initiated GameplayAbilities activate first on the server and then on the owning client. I personally haven't used these much if any.`},{header:"4.6.9 Ability Tags",slug:"_4-6-9-ability-tags",content:`GameplayAbilities come with GameplayTagContainers with built-in logic. None of these GameplayTags are replicated. GameplayTag Container
Description Ability Tags
GameplayTags that the GameplayAbility owns. These are just GameplayTags to describe the GameplayAbility. Cancel Abilities with Tag
Other GameplayAbilities that have these GameplayTags in their Ability Tags will be canceled when this GameplayAbility is activated. Block Abilities with Tag
Other GameplayAbilities that have these GameplayTags in their Ability Tags are blocked from activating while this GameplayAbility is active. Activation Owned Tags
These GameplayTags are given to the GameplayAbility's owner while this GameplayAbility is active. Remember these are not replicated. Activation Required Tags
This GameplayAbility can only be activated if the owner has all of these GameplayTags. Activation Blocked Tags
This GameplayAbility cannot be activated if the owner has any of these GameplayTags. Source Required Tags
This GameplayAbility can only be activated if the Source has all of these GameplayTags. The Source GameplayTags are only set if the GameplayAbility is triggered by an event. Source Blocked Tags
This GameplayAbility cannot be activated if the Source has any of these GameplayTags. The Source GameplayTags are only set if the GameplayAbility is triggered by an event. Target Required Tags
This GameplayAbility can only be activated if the Target has all of these GameplayTags. The Target GameplayTags are only set if the GameplayAbility is triggered by an event. Target Blocked Tags
This GameplayAbility cannot be activated if the Target has any of these GameplayTags. The Target GameplayTags are only set if the GameplayAbility is triggered by an event.`},{header:"4.6.10 Gameplay Ability Spec",slug:"_4-6-10-gameplay-ability-spec",content:`A GameplayAbilitySpec exists on the ASC after a GameplayAbility is granted and defines the activatable GameplayAbility - GameplayAbility class, level, input bindings, and runtime state that must be kept separate from the GameplayAbility class.
When a GameplayAbility is granted on the server, the server replicates the GameplayAbilitySpec to the owning client so that she may activate it.
Activating a GameplayAbilitySpec will create an instance (or not for Non-Instanced GameplayAbilities) of the GameplayAbility depending on its Instancing Policy.`},{header:"4.6.11 Passing Data to Abilities",slug:"_4-6-11-passing-data-to-abilities",content:`The general paradigm for GameplayAbilities is Activate->Generate Data->Apply->End. Sometimes you need to act on existing data. GAS provides a few options for getting external data into your GameplayAbilities: Method
Description Activate GameplayAbility by Event
Activate a GameplayAbility with an event containing a payload of data. The event's payload is replicated from client to server for local predicted GameplayAbilities. Use the two Optional Object or the TargetData variables for arbitrary data that does not fit any of the existing variables. The downside to this is that it prevents you from activating the ability with an input bind. To activate a GameplayAbility by event, the GameplayAbility must have its Triggers set up in the GameplayAbility. Assign a GameplayTag and pick an option for GameplayEvent. To send the event, use the function UAbilitySystemBlueprintLibrary::SendGameplayEventToActor(AActor* Actor, FGameplayTag EventTag, FGameplayEventData Payload). Use WaitGameplayEvent AbilityTask
Use the WaitGameplayEvent AbilityTask to tell the GameplayAbility to listen for an event with payload data after it activates. The event payload and the process to send it is the same as activating GameplayAbilities by event. The downside to this is that events are not replicated by the AbilityTask and should only be used for Local Only and Server Only GameplayAbilities. You potentially could write your own AbilityTask that will replicate the event payload. Use TargetData
A custom TargetData struct is a good way to pass arbitrary data between the client and server. Store Data on the OwnerActor or AvatarActor
Use replicated variables stored on the OwnerActor, AvatarActor, or any other object that you can get a reference to. This method is the most flexible and will work with GameplayAbilities activated by input binds. However, it does not guarantee the data will be synchronized from replication at the time of use. You must ensure that ahead of time - meaning if you set a replicated variable and then immediately activate a GameplayAbility there is no guarantee the order that will happen on the receiver due to potential packet loss.`},{header:"4.6.12 Ability Cost and Cooldown",slug:"_4-6-12-ability-cost-and-cooldown",content:`GameplayAbilities come with functionality for optional costs and cooldowns. Costs are predefined amounts of Attributes that the ASC must have in order to activate the GameplayAbility implemented with an Instant GameplayEffect (Cost GE). Cooldowns are timers that prevent the reactivation of a GameplayAbility until it expires and is implemented with a Duration GameplayEffect (Cooldown GE).
Before a GameplayAbility calls UGameplayAbility::Activate(), it calls UGameplayAbility::CanActivateAbility(). This function checks if the owning ASC can afford the cost (UGameplayAbility::CheckCost()) and ensures that the GameplayAbility is not on cooldown (UGameplayAbility::CheckCooldown()).
After a GameplayAbility calls Activate(), it can optionally commit the cost and cooldown at any time using UGameplayAbility::CommitAbility() which calls UGameplayAbility::CommitCost() and UGameplayAbility::CommitCooldown(). The designer may choose to call CommitCost() or CommitCooldown() separately if they shouldn't be committed at the same time. Committing cost and cooldown calls CheckCost() and CheckCooldown() one more time and is the last chance for the GameplayAbility to fail related to them. The owning ASC's Attributes could potentially change after a GameplayAbility is activated, failing to meet the cost at time of commit. Committing the cost and cooldown can be locally predicted if the prediction key is valid at the time of commit.
See CostGE and CooldownGE for implementation details.`},{header:"4.6.13 Leveling Up Abilities",slug:"_4-6-13-leveling-up-abilities",content:`There are two common methods for leveling up an ability: Level Up Method
Description Ungrant and Regrant at the New Level
Ungrant (remove) the GameplayAbility from the ASC and regrant it back at the next level on the server. This terminates the GameplayAbility if it was active at the time. Increase the GameplayAbilitySpec's Level
On the server, find the GameplayAbilitySpec, increase its level, and mark it dirty so that replicates to the owning client. This method does not terminate the GameplayAbility if it was active at the time. The main difference between the two methods is if you want active GameplayAbilities to be canceled at the time of level up. You will most likely use both methods depending on your GameplayAbilities. I recommend adding a bool to your UGameplayAbility subclass specifying which method to use.`},{header:"4.6.14 Ability Sets",slug:"_4-6-14-ability-sets",content:`GameplayAbilitySets are convenience UDataAsset classes for holding input bindings and lists of startup GameplayAbilities for Characters with logic to grant the GameplayAbilities. Subclasses can also include extra logic or properties. Paragon had a GameplayAbilitySet per hero that included all of their given GameplayAbilities.
I find this class to be unnecessary at least given what I've seen of it so far. The Sample Project handles all of the functionality of GameplayAbilitySets inside of the GDCharacterBase and its subclasses.`},{header:"4.6.15 Ability Batching",slug:"_4-6-15-ability-batching",content:`Traditional Gameplay Ability lifecycle involves a minimum of two or three RPCs from the client to the server. CallServerTryActivateAbility()
ServerSetReplicatedTargetData() (Optional)
ServerEndAbility() If a GameplayAbility performs all of these actions in one atomic grouping in a frame, we can optimize this workflow to batch (combine) all two or three RPCs into one RPC. GAS refers to this RPC optimization as Ability Batching. The common example of when to use Ability Batching is for hitscan guns. Hitscan guns activate, do a line trace, send the TargetData to the server, and end the ability all in one atomic group in one frame. The GASShooter sample project demonstrates this technique for its hitscan guns.
Semi-Automatic guns are the best case scenario and batch the CallServerTryActivateAbility(), ServerSetReplicatedTargetData() (the bullet hit result), and ServerEndAbility() into one RPC instead of three RPCs.
Full-Automatic/Burst guns batch CallServerTryActivateAbility() and ServerSetReplicatedTargetData() for the first bullet into one RPC instead of two RPCs. Each subsequent bullet is its own ServerSetReplicatedTargetData() RPC. Finally, ServerEndAbility() is sent as a separate RPC when the gun stops firing. This is a worst case scenario where we only save one RPC on the first bullet instead of two. This scenario could have also been implemented with activating the ability via a Gameplay Event which would send the bullet's TargetData in with the EventPayload to the server from the client. The downside of the latter approach is that the TargetData would have to be generated externally to the ability whereas the batching approach generates the TargetData inside of the ability.
Ability Batching is disabled by default on the ASC. To enable Ability Batching, override ShouldDoServerAbilityRPCBatch() to return true:
virtual bool ShouldDoServerAbilityRPCBatch() const override { return true; } Now that Ability Batching is enabled, before activating abilities that you want batched, you must create a FScopedServerAbilityRPCBatcher struct beforehand. This special struct will try to batch any abilities following it within its scope. Once the FScopedServerAbilityRPCBatcher falls out of scope, any abilities activated will not try to batch. FScopedServerAbilityRPCBatcher works by having special code in each of the functions that can be batched that intercepts the call from sending the RPC and instead packs the message into a batch struct. When FScopedServerAbilityRPCBatcher falls out of scope, it automatically RPCs this batch struct to the server in UAbilitySystemComponent::EndServerAbilityRPCBatch(). The server receives the batch RPC in UAbilitySystemComponent::ServerAbilityRPCBatch_Internal(FServerAbilityRPCBatch& BatchInfo). The BatchInfo parameter will contain flags for if the ability should end and if input was pressed at the time of activation and the TargetData if that was included. This is a good function to put a breakpoint on to confirm that your batching is working properly. Alternatively, use the cvar AbilitySystem.ServerRPCBatching.Log 1 to enable special ability batching logging.
This mechanism can only be done in C++ and can only activate abilities by their FGameplayAbilitySpecHandle.
bool UGSAbilitySystemComponent::BatchRPCTryActivateAbility(FGameplayAbilitySpecHandle InAbilityHandle, bool EndAbilityImmediately)
{ bool AbilityActivated = false; if (InAbilityHandle.IsValid()) { FScopedServerAbilityRPCBatcher GSAbilityRPCBatcher(this, InAbilityHandle); AbilityActivated = TryActivateAbility(InAbilityHandle, true); if (EndAbilityImmediately) { FGameplayAbilitySpec* AbilitySpec = FindAbilitySpecFromHandle(InAbilityHandle); if (AbilitySpec) { UGSGameplayAbility* GSAbility = Cast<UGSGameplayAbility>(AbilitySpec->GetPrimaryInstance()); GSAbility->ExternalEndAbility(); } } return AbilityActivated; } return AbilityActivated;
} GASShooter reuses the same batched GameplayAbility for semi-automatic and full-automatic guns which never directly call EndAbility() (it is handled outside of the ability by a local-only ability that manages player input and the call to the batched ability based on the current firemode). Since all of the RPCs must happen within the scope of the FScopedServerAbilityRPCBatcher, I provide the EndAbilityImmediately parameter so that the controlling/managing local-only can specify whether this ability should batch the EndAbility() call (semi-automatic), or not batch the EndAbility() call (full-automatic) and the EndAbility() call will happen sometime later in its own RPC.
GASShooter exposes a Blueprint node to allow batching abilities which the aforementioned local-only ability uses to trigger the batched ability.
Activate Batched Ability`},{header:"4.6.16 Net Security Policy",slug:"_4-6-16-net-security-policy",content:`A GameplayAbility's NetSecurityPolicy determines where should an ability execute on the network. It provides protection from clients attempting to execute restricted abilities. NetSecurityPolicy
Description ClientOrServer
No security requirements. Client or server can trigger execution and termination of this ability freely. ServerOnlyExecution
A client requesting execution of this ability will be ignored by the server. Clients can still request that the server cancel or end this ability. ServerOnlyTermination
A client requesting cancellation or ending of this ability will be ignored by the server. Clients can still request execution of the ability. ServerOnly
Server controls both execution and termination of this ability. A client making any requests will be ignored.`},{header:"4.7 Ability Tasks",slug:"_4-7-ability-tasks",content:""},{header:"4.7.1 Ability Task Definition",slug:"_4-7-1-ability-task-definition",content:`GameplayAbilities only execute in one frame. This does not allow for much flexibility on its own. To do actions that happen over time or require responding to delegates fired at some point later in time we use latent actions called AbilityTasks.
GAS comes with many AbilityTasks out of the box: Tasks for moving Characters with RootMotionSource
A task for playing animation montages
Tasks for responding to Attribute changes
Tasks for responding to GameplayEffect changes
Tasks for responding to player input
and more The UAbilityTask constructor enforces a hardcoded game-wide maximum of 1000 concurrent AbilityTasks running at the same time. Keep this in mind when designing GameplayAbilities for games that can have hundreds of characters in the world at the same time like RTS games.`},{header:"4.7.2 Custom Ability Tasks",slug:"_4-7-2-custom-ability-tasks",content:`Often you will be creating your own custom AbilityTasks (in C++). The Sample Project comes with two custom AbilityTasks: PlayMontageAndWaitForEvent is a combination of the default PlayMontageAndWait and WaitGameplayEvent AbilityTasks. This allows animation montages to send gameplay events from AnimNotifies back to the GameplayAbility that started them. Use this to trigger actions at specific times during animation montages.
WaitReceiveDamage listens for the OwnerActor to receive damage. The passive armor stacks GameplayAbility removes a stack of armor when the hero receives an instance of damage. AbilityTasks are composed of: A static function that creates new instances of the AbilityTask
Delegates that are broadcasted on when the AbilityTask completes its purpose
An Activate() function to start its main job, bind to external delegates, etc.
An OnDestroy() function for cleanup, including external delegates that it bound to
Callback functions for any external delegates that it bound to
Member variables and any internal helper functions Note: AbilityTasks can only declare one type of output delegate. All of your output delegates must be of this type, regardless if they use the parameters or not. Pass default values for unused delegate parameters.
AbilityTasks only run on the Client or Server that is running the owning GameplayAbility; however, AbilityTasks can be set to run on simulated clients by setting bSimulatedTask = true; in the AbilityTask constructor, overriding virtual void InitSimulatedTask(UGameplayTasksComponent& InGameplayTasksComponent);, and setting any member variables to be replicated. This is only useful in rare situations like movement AbilityTasks where you don't want to replicate every movement change but instead simulate the entire movement AbilityTask. All of the RootMotionSource AbilityTasks do this. See AbilityTask_MoveToLocation.h/.cpp as an example.
AbilityTasks can Tick if you set bTickingTask = true; in the AbilityTask constructor and override virtual void TickTask(float DeltaTime);. This is useful when you need to lerp values smoothly across frames. See AbilityTask_MoveToLocation.h/.cpp as an example.`},{header:"4.7.3 Using Ability Tasks",slug:"_4-7-3-using-ability-tasks",content:`To create and activate an AbilityTask in C++ (From GDGA_FireGun.cpp):
UGDAT_PlayMontageAndWaitForEvent* Task = UGDAT_PlayMontageAndWaitForEvent::PlayMontageAndWaitForEvent(this, NAME_None, MontageToPlay, FGameplayTagContainer(), 1.0f, NAME_None, false, 1.0f);
Task->OnBlendOut.AddDynamic(this, &UGDGA_FireGun::OnCompleted);
Task->OnCompleted.AddDynamic(this, &UGDGA_FireGun::OnCompleted);
Task->OnInterrupted.AddDynamic(this, &UGDGA_FireGun::OnCancelled);
Task->OnCancelled.AddDynamic(this, &UGDGA_FireGun::OnCancelled);
Task->EventReceived.AddDynamic(this, &UGDGA_FireGun::EventReceived);
Task->ReadyForActivation(); In Blueprint, we just use the Blueprint node that we create for the AbilityTask. We don't have to call ReadyForActivation(). That is automatically called by Engine/Source/Editor/GameplayTasksEditor/Private/K2Node_LatentGameplayTaskCall.cpp. K2Node_LatentGameplayTaskCall also automatically calls BeginSpawningActor() and FinishSpawningActor() if they exist in your AbilityTask class (see AbilityTask_WaitTargetData). To reiterate, K2Node_LatentGameplayTaskCall only does automagic sorcery for Blueprint. In C++, we have to manually call ReadyForActivation(), BeginSpawningActor(), and FinishSpawningActor().
Blueprint WaitTargetData AbilityTask
To manually cancel an AbilityTask, just call EndTask() on the AbilityTask object in Blueprint (called Async Task Proxy) or in C++.`},{header:"4.7.4 Root Motion Source Ability Tasks",slug:"_4-7-4-root-motion-source-ability-tasks",content:`GAS comes with AbilityTasks for moving Characters over time for things like knockbacks, complex jumps, pulls, and dashes using Root Motion Sources hooked into the CharacterMovementComponent.
Note: Predicting RootMotionSource AbilityTasks works up to engine version 4.19 and 4.25+. Prediction is bugged for engine versions 4.20-4.24; however, the AbilityTasks still perform their function in multiplayer with minor net corrections and work perfectly in single player. It is possible to cherry pick the prediction fix from 4.25 into a custom 4.20-4.24 engine.`},{header:"4.8 Gameplay Cues",slug:"_4-8-gameplay-cues",content:""},{header:"4.8.1 Gameplay Cue Definition",slug:"_4-8-1-gameplay-cue-definition",content:`GameplayCues (GC) execute non-gameplay related things like sound effects, particle effects, camera shakes, etc. GameplayCues are typically replicated (unless explicitly Executed, Added, or Removed locally) and predicted.
We trigger GameplayCues by sending a corresponding GameplayTag with the mandatory parent name of GameplayCue. and an event type (Execute, Add, or Remove) to the GameplayCueManager via the ASC. GameplayCueNotify objects and other Actors that implement the IGameplayCueInterface can subscribe to these events based on the GameplayCue's GameplayTag (GameplayCueTag).
Note: Just to reiterate, GameplayCue GameplayTags need to start with the parent GameplayTag of GameplayCue. So for example, a valid GameplayCue GameplayTag might be GameplayCue.A.B.C.
There are two classes of GameplayCueNotifies, Static and Actor. They respond to different events and different types of GameplayEffects can trigger them. Override the corresponding event with your logic. GameplayCue Class
Event
GameplayEffect Type
Description GameplayCueNotify_Static
Execute
Instant or Periodic
Static GameplayCueNotifies operate on the ClassDefaultObject (meaning no instances) and are perfect for one-off effects like hit impacts. GameplayCueNotify_Actor
Add or Remove
Duration or Infinite
Actor GameplayCueNotifies spawn a new instance when Added. Because these are instanced, they can do actions over time until they are Removed. These are good for looping sounds and particle effects that will be removed when the backing Duration or Infinite GameplayEffect is removed or by manually calling remove. These also come with options to manage how many are allowed to be Added at the same time so that multiple applications of the same effect only start the sounds or particles once. GameplayCueNotifies technically can respond to any of the events but this is typically how we use them.
Note: When using GameplayCueNotify_Actor, check Auto Destroy on Remove otherwise subsequent calls to Add that GameplayCueTag won't work.
When using an ASC Replication Mode other than Full, Add and Remove GC events will fire twice on Server players (listen server) - once for applying the GE and again from the "Minimal" NetMultiCast to the clients. However, WhileActive events will still only fire once. All events will only fire once on clients.
The Sample Project includes a GameplayCueNotify_Actor for stun and sprint effects. It also has a GameplayCueNotify_Static for the FireGun's projectile impact. These GCs can be optimized further by triggering them locally instead of replicating them through a GE. I opted for showing the beginner way of using them in the Sample Project.`},{header:"4.8.2 Triggering Gameplay Cues",slug:"_4-8-2-triggering-gameplay-cues",content:`From inside of a GameplayEffect when it is successfully applied (not blocked by tags or immunity), fill in the GameplayTags of all the GameplayCues that should be triggered.
GameplayCue Triggered from a GameplayEffect
UGameplayAbility offers Blueprint nodes to Execute, Add, or Remove GameplayCues.
GameplayCue Triggered from a GameplayAbility
In C++, you can call functions directly on the ASC (or expose them to Blueprint in your ASC subclass):
/** GameplayCues can also come on their own. These take an optional effect context to pass through hit result, etc */
void ExecuteGameplayCue(const FGameplayTag GameplayCueTag, FGameplayEffectContextHandle EffectContext = FGameplayEffectContextHandle());
void ExecuteGameplayCue(const FGameplayTag GameplayCueTag, const FGameplayCueParameters& GameplayCueParameters); /** Add a persistent gameplay cue */
void AddGameplayCue(const FGameplayTag GameplayCueTag, FGameplayEffectContextHandle EffectContext = FGameplayEffectContextHandle());
void AddGameplayCue(const FGameplayTag GameplayCueTag, const FGameplayCueParameters& GameplayCueParameters); /** Remove a persistent gameplay cue */
void RemoveGameplayCue(const FGameplayTag GameplayCueTag); /** Removes any GameplayCue added on its own, i.e. not as part of a GameplayEffect. */
void RemoveAllGameplayCues();`},{header:"4.8.3 Local Gameplay Cues",slug:"_4-8-3-local-gameplay-cues",content:`The exposed functions for firing GameplayCues from GameplayAbilities and the ASC are replicated by default. Each GameplayCue event is a multicast RPC. This can cause a lot of RPCs. GAS also enforces a maximum of two of the same GameplayCue RPCs per net update. We avoid this by using local GameplayCues where we can. Local GameplayCues only Execute, Add, or Remove on the individual client.
Scenarios where we can use local GameplayCues: Projectile impacts
Melee collision impacts
GameplayCues fired from animation montages Local GameplayCue functions that you should add to your ASC subclass:
UFUNCTION(BlueprintCallable, Category = "GameplayCue", Meta = (AutoCreateRefTerm = "GameplayCueParameters", GameplayTagFilter = "GameplayCue"))
void ExecuteGameplayCueLocal(const FGameplayTag GameplayCueTag, const FGameplayCueParameters& GameplayCueParameters); UFUNCTION(BlueprintCallable, Category = "GameplayCue", Meta = (AutoCreateRefTerm = "GameplayCueParameters", GameplayTagFilter = "GameplayCue"))
void AddGameplayCueLocal(const FGameplayTag GameplayCueTag, const FGameplayCueParameters& GameplayCueParameters); UFUNCTION(BlueprintCallable, Category = "GameplayCue", Meta = (AutoCreateRefTerm = "GameplayCueParameters", GameplayTagFilter = "GameplayCue"))
void RemoveGameplayCueLocal(const FGameplayTag GameplayCueTag, const FGameplayCueParameters& GameplayCueParameters); void UPAAbilitySystemComponent::ExecuteGameplayCueLocal(const FGameplayTag GameplayCueTag, const FGameplayCueParameters & GameplayCueParameters)
{ UAbilitySystemGlobals::Get().GetGameplayCueManager()->HandleGameplayCue(GetOwner(), GameplayCueTag, EGameplayCueEvent::Type::Executed, GameplayCueParameters);
} void UPAAbilitySystemComponent::AddGameplayCueLocal(const FGameplayTag GameplayCueTag, const FGameplayCueParameters & GameplayCueParameters)
{ UAbilitySystemGlobals::Get().GetGameplayCueManager()->HandleGameplayCue(GetOwner(), GameplayCueTag, EGameplayCueEvent::Type::OnActive, GameplayCueParameters); UAbilitySystemGlobals::Get().GetGameplayCueManager()->HandleGameplayCue(GetOwner(), GameplayCueTag, EGameplayCueEvent::Type::WhileActive, GameplayCueParameters);
} void UPAAbilitySystemComponent::RemoveGameplayCueLocal(const FGameplayTag GameplayCueTag, const FGameplayCueParameters & GameplayCueParameters)
{ UAbilitySystemGlobals::Get().GetGameplayCueManager()->HandleGameplayCue(GetOwner(), GameplayCueTag, EGameplayCueEvent::Type::Removed, GameplayCueParameters);
} If a GameplayCue was Added locally, it should be Removed locally. If it was Added via replication, it should be Removed via replication.`},{header:"4.8.4 Gameplay Cue Parameters",slug:"_4-8-4-gameplay-cue-parameters",content:`GameplayCues receive a FGameplayCueParameters structure containing extra information for the GameplayCue as a parameter. If you manually trigger the GameplayCue from a function on the GameplayAbility or the ASC, then you must manually fill in the GameplayCueParameters structure that is passed to the GameplayCue. If the GameplayCue is triggered by a GameplayEffect, then the following variables are automatically filled in on the GameplayCueParameters structure: AggregatedSourceTags
AggregatedTargetTags
GameplayEffectLevel
AbilityLevel
EffectContext
Magnitude (if the GameplayEffect has an Attribute for magnitude selected in the dropdown above the GameplayCue tag container and a corresponding Modifier that affects that Attribute) The SourceObject variable in the GameplayCueParameters structure is potentially a good place to pass arbitrary data to the GameplayCue when triggering the GameplayCue manually.
Note: Some of the variables in the parameters structure like Instigator might already exist in the EffectContext. The EffectContext can also contain a FHitResult for location of where to spawn the GameplayCue in the world. Subclassing EffectContext is potentially a good way to pass more data to GameplayCues, especially those triggered by a GameplayEffect.
See the 3 functions in UAbilitySystemGlobals that populate the GameplayCueParameters structure for more information. They are virtual so you can override them to autopopulate more information.
/** Initialize GameplayCue Parameters */
virtual void InitGameplayCueParameters(FGameplayCueParameters& CueParameters, const FGameplayEffectSpecForRPC &Spec);
virtual void InitGameplayCueParameters_GESpec(FGameplayCueParameters& CueParameters, const FGameplayEffectSpec &Spec);
virtual void InitGameplayCueParameters(FGameplayCueParameters& CueParameters, const FGameplayEffectContextHandle& EffectContext);`},{header:"4.8.5 Gameplay Cue Manager",slug:"_4-8-5-gameplay-cue-manager",content:`By default, the GameplayCueManager will scan the entire game directory for GameplayCueNotifies and load them into memory on play. We can change the path where the GameplayCueManager scans by setting it in the DefaultGame.ini.
[/Script/GameplayAbilities.AbilitySystemGlobals]
GameplayCueNotifyPaths="/Game/GASDocumentation/Characters" We do want the GameplayCueManager to scan and find all of the GameplayCueNotifies; however, we don't want it to async load every single one on play. This will put every GameplayCueNotify and all of their referenced sounds and particles into memory regardless if they're even used in a level. In a large game like Paragon, this can be hundreds of megabytes of unneeded assets in memory and cause hitching and game freezes on startup.
An alternative to async loading every GameplayCue on startup is to only async load GameplayCues as they're triggered in-game. This mitigates the unnecessary memory usage and potential game hard freezes while async loading every GameplayCue in exchange for potentially delayed effects for the first time that a specific GameplayCue is triggered during play. This potential delay is nonexistent for SSDs. I have not tested on a HDD. If using this option in the UE Editor, there may be slight hitches or freezes during the first load of GameplayCues if the Editor needs to compile particle systems. This is not an issue in builds as the particle systems will already be compiled.
First we must subclass UGameplayCueManager and tell the AbilitySystemGlobals class to use our UGameplayCueManager subclass in DefaultGame.ini.
[/Script/GameplayAbilities.AbilitySystemGlobals]
GlobalGameplayCueManagerClass="/Script/ParagonAssets.PBGameplayCueManager" In our UGameplayCueManager subclass, override ShouldAsyncLoadRuntimeObjectLibraries().
virtual bool ShouldAsyncLoadRuntimeObjectLibraries() const override
{ return false;
}`},{header:"4.8.6 Prevent Gameplay Cues from Firing",slug:"_4-8-6-prevent-gameplay-cues-from-firing",content:`Sometimes we don't want GameplayCues to fire. For example if we block an attack, we may not want to play the hit impact attached to the damage GameplayEffect or play a custom one instead. We can do this inside of GameplayEffectExecutionCalculations by calling OutExecutionOutput.MarkGameplayCuesHandledManually() and then manually sending our GameplayCue event to the Target or Source's ASC.
If you never want any GameplayCues to fire on a specific ASC, you can set AbilitySystemComponent->bSuppressGameplayCues = true;.`},{header:"4.8.7 Gameplay Cue Batching",slug:"_4-8-7-gameplay-cue-batching",content:"Each GameplayCue triggered is an unreliable NetMulticast RPC. In situations where we fire multiple GCs at the same time, there are a few optimization methods to condense them down into one RPC or save bandwidth by sending less data."},{header:"4.8.7.1 Manual RPC",slug:"_4-8-7-1-manual-rpc",content:`Say you have a shotgun that shoots eight pellets. That's eight trace and impact GameplayCues. GASShooter takes the lazy approach of combining them into one RPC by stashing all of the trace information into the EffectContext as TargetData. While this reduces the RPCs from eight to one, it still sends a lot of data over the network in that one RPC (~500 bytes). A more optimized approach is to send an RPC with a custom struct where you efficiently encode the hit locations or maybe you give it a random seed number to recreate/approximate the impact locations on the receiving side. The clients would then unpack this custom struct and turn back into locally executed GameplayCues.
How this works: Declare a FScopedGameplayCueSendContext. This suppresses UGameplayCueManager::FlushPendingCues() until it falls out of scope, meaning all GameplayCues will be queued up until the FScopedGameplayCueSendContext falls out of scope.
Override UGameplayCueManager::FlushPendingCues() to merge GameplayCues that can be batched together based on some custom GameplayTag into your custom struct and RPC it to clients.
Clients receive the custom struct and unpack it into locally executed GameplayCues. This method can also be used when you need specific parameters for your GameplayCues that don't fit with what GameplayCueParameters offer and you don't want to add them to the EffectContext like damage numbers, crit indicator, broken shield indicator, was fatal hit indicator, etc.
https://forums.unrealengine.com/development-discussion/c-gameplay-programming/1711546-fscopedgameplaycuesendcontext-gameplaycuemanager`},{header:"4.8.7.2 Multiple GCs on one GE",slug:"_4-8-7-2-multiple-gcs-on-one-ge",content:"All of the GameplayCues on a GameplayEffect are sent in one RPC already. By default, UGameplayCueManager::InvokeGameplayCueAddedAndWhileActive_FromSpec() will send the whole GameplayEffectSpec (but converted to FGameplayEffectSpecForRPC) in the unreliable NetMulticast regardless of the ASC's Replication Mode. This could potentially be a lot of bandwidth depending on what is in the GameplayEffectSpec. We can potentially optimize this by setting the cvar AbilitySystem.AlwaysConvertGESpecToGCParams 1. This will convert GameplayEffectSpecs to FGameplayCueParameter structures and RPC those instead of the whole FGameplayEffectSpecForRPC. This potentially saves bandwidth but also has less information, depending on how the GESpec is converted to GameplayCueParameters and what your GCs need to know."},{header:"4.8.8 Gameplay Cue Events",slug:"_4-8-8-gameplay-cue-events",content:`GameplayCues respond to specific EGameplayCueEvents: EGameplayCueEvent
Description OnActive
Called when a GameplayCue is activated (added). WhileActive
Called when GameplayCue is active, even if it wasn't actually just applied (Join in progress, etc). This is not Tick! It's called once just like OnActive when a GameplayCueNotify_Actor is added or becomes relevant. If you need Tick(), just use the GameplayCueNotify_Actor's Tick(). It's an AActor after all. Removed
Called when a GameplayCue is removed. The Blueprint GameplayCue function that responds to this event is OnRemove. Executed
Called when a GameplayCue is executed: instant effects or periodic Tick(). The Blueprint GameplayCue function that responds to this event is OnExecute. Use OnActive for anything in your GameplayCue that happen at the start of the GameplayCue but is okay if late joiners miss. Use WhileActive for ongoing effects in the GameplayCue that you would want late joiners to see. For example, if you have a GameplayCue for a tower structure in a MOBA exploding, you would put the initial explosion particle system and explosion sound in OnActive and you would put any residual ongoing fire particles or sounds in the WhileActive. In this scenario, it wouldn't make sense for late joiners to replay the initial explosion from OnActive, but you would want them to see the persistent, looping fire effects on the ground after the explosion happened from WhileActive. OnRemove should clean up anything added in OnActive and WhileActive. WhileActive will be called every time an Actor enters the relevancy range of a GameplayCueNotify_Actor. OnRemove will be called every time an Actor leaves relevancy range of a GameplayCueNotify_Actor.`},{header:"4.8.9 Gameplay Cue Reliability",slug:"_4-8-9-gameplay-cue-reliability",content:`GameplayCues in general should be considered unreliable and thus unsuited for anything that directly affects gameplay.
Executed GameplayCues: These GameplayCues are applied via unreliable multicasts and are always unreliable.
GameplayCues applied from GameplayEffects: Autonomous proxy reliably receives OnActive, WhileActive, and OnRemove
FActiveGameplayEffectsContainer::NetDeltaSerialize() calls UAbilitySystemComponent::HandleDeferredGameplayCues() to call OnActive and WhileActive. FActiveGameplayEffectsContainer::RemoveActiveGameplayEffectGrantedTagsAndModifiers() makes the call to OnRemoved.
Simulated proxies reliably receive WhileActive and OnRemove
UAbilitySystemComponent::MinimalReplicationGameplayCues's replication calls WhileActive and OnRemove. The OnActive event is called by an unreliable multicast. GameplayCues applied without a GameplayEffect: Autonomous proxy reliably receives OnRemove
The OnActive and WhileActive events are called by an unreliable multicast.
Simulated proxies reliably receive WhileActive and OnRemove
UAbilitySystemComponent::MinimalReplicationGameplayCues's replication calls WhileActive and OnRemove. The OnActive event is called by an unreliable multicast. If you need something in a GameplayCue to be 'reliable', then apply it from a GameplayEffect and use WhileActive to add the FX and OnRemove to remove the FX.`},{header:"4.9 Ability System Globals",slug:"_4-9-ability-system-globals",content:`The AbilitySystemGlobals class holds global information about GAS. Most of the variables can be set from the DefaultGame.ini. Generally you won't have to interact with this class, but you should be aware of its existence. If you need to subclass things like the GameplayCueManager or the GameplayEffectContext, you have to do that through the AbilitySystemGlobals.
To subclass AbilitySystemGlobals, set the class name in the DefaultGame.ini:
[/Script/GameplayAbilities.AbilitySystemGlobals]
AbilitySystemGlobalsClassName="/Script/ParagonAssets.PAAbilitySystemGlobals"`},{header:"4.9.1 InitGlobalData()",slug:"_4-9-1-initglobaldata",content:`Starting in UE 4.24, it is now necessary to call UAbilitySystemGlobals::Get().InitGlobalData() to use TargetData, otherwise you will get errors related to ScriptStructCache and clients will be disconnected from the server. This function only needs to be called once in a project. Fortnite calls it from UAssetManager::StartInitialLoading() and Paragon called it from UEngine::Init(). I find that putting it in UAssetManager::StartInitialLoading() is a good place as shown in the Sample Project. I would consider this boilerplate code that you should copy into your project to avoid issues with TargetData.
If you run into a crash while using the AbilitySystemGlobals GlobalAttributeSetDefaultsTableNames, you may need to call UAbilitySystemGlobals::Get().InitGlobalData() later like Fortnite in the AssetManager or in the GameInstance.`},{header:"4.10 Prediction",slug:"_4-10-prediction",content:`GAS comes out of the box with support for client-side prediction; however, it does not predict everything. Client-side prediction in GAS means that the client does not have to wait for the server's permission to activate a GameplayAbility and apply GameplayEffects. It can "predict" the server giving it permission to do this and predict the targets that it would apply GameplayEffects to. The server then runs the GameplayAbility network latency-time after the client activates and tells the client if he was correct or not in his predictions. If the client was wrong in any of his predictions, he will "roll back" his changes from his "mispredictions" to match the server.
The definitive source for GAS-related prediction is GameplayPrediction.h in the plugin source code.
Epic's mindset is to only predict what you "can get away with". For example, Paragon and Fortnite do not predict damage. Most likely they use ExecutionCalculations for their damage which cannot be predicted anyway. This is not to say that you can't try to predict certain things like damage. By all means if you do it and it works well for you then that's great. ... we are also not all in on a "predict everything: seamlessly and automatically" solution. We still feel player prediction is best kept to a minimum (meaning: predict the minimum amount of stuff you can get away with). Dave Ratti from Epic's comment from the new Network Prediction Plugin
What is predicted: Ability activation
Triggered Events
GameplayEffect application: Attribute modification (EXCEPTIONS: Executions do not currently predict, only attribute modifiers)
GameplayTag modification Gameplay Cue events (both from within predictive gameplay effect and on their own)
Montages
Movement (built into UE's UCharacterMovement) What is not predicted: GameplayEffect removal
GameplayEffect periodic effects (dots ticking) From GameplayPrediction.h
While we can predict GameplayEffect application, we cannot predict GameplayEffect removal. One way that we can work around this limitation is to predict the inverse effect when we want to remove a GameplayEffect. Say we predict a movement speed slow of 40%. We can predictively remove it by applying a movement speed buff of 40%. Then remove both GameplayEffects at the same time. This is not appropriate for every scenario and support for predicting GameplayEffect removal is still needed. Dave Ratti from Epic has expressed desire to add it to a future iteration of GAS.
Because we cannot predict the removal of GameplayEffects, we cannot fully predict GameplayAbility cooldowns and there is no inverse GameplayEffect workaround for them. The server's replicated Cooldown GE will exist on the client and any attempts to bypass this (with Minimal replication mode for example) will be rejected by the server. This means clients with higher latencies take longer to tell the server to go on cooldown and to receive the removal of the server's Cooldown GE. This means players with higher latencies will have a lower rate of fire than players with lower latencies, giving them a disadvantage against lower latency players. Fortnite avoids this issue by using custom bookkeeping instead of Cooldown GEs.
Regarding predicting damage, I personally do not recommend it despite it being one of the first things that most people try when starting with GAS. I especially do not recommend trying to predict death. While you can predict damage, doing so is tricky. If you mispredict applying damage, the player will see the enemy's health jump back up. This can be especially awkward and frustrating if you try to predict death. Say you mispredict a Character's death and it starts ragdolling only to stop ragdolling and continue shooting at you when the server corrects it.
Note: Instant	GameplayEffects (like Cost GEs) that change Attributes can be predicted on yourself seamlessly, predicting Instant Attribute changes to other characters will show a brief anomaly or "blip" in their Attributes. Predicted Instant GameplayEffects are actually treated like Infinite GameplayEffects so that they can be rolled back if mispredicted. When the server's GameplayEffect is applied, there potentially exists two of the same GameplayEffect's causing the Modifier to be applied twice or not at all for a brief moment. It will eventually correct itself but sometimes the blip is noticeable to players.
Problems that GAS's prediction implementation is trying to solve: "Can I do this?" Basic protocol for prediction.
"Undo" How to undo side effects when a prediction fails.
"Redo" How to avoid replaying side effects that we predicted locally but that also get replicated from the server.
"Completeness" How to be sure we /really/ predicted all side effects.
"Dependencies" How to manage dependent prediction and chains of predicted events.
"Override" How to override state predictively that is otherwise replicated/owned by the server. From GameplayPrediction.h`},{header:"4.10.1 Prediction Key",slug:"_4-10-1-prediction-key",content:`GAS's prediction works on the concept of a Prediction Key which is an integer identifier that the client generates when he activates a GameplayAbility. Client generates a prediction key when it activates a GameplayAbility. This is the Activation Prediction Key. Client sends this prediction key to the server with CallServerTryActivateAbility(). Client adds this prediction key to all GameplayEffects that it applies while the prediction key is valid. Client's prediction key falls out of scope. Further predicted effects in the same GameplayAbility need a new Scoped Prediction Window. Server receives the prediction key from the client. Server adds this prediction key to all GameplayEffects that it applies. Server replicates the prediction key back to the client. Client receives replicated GameplayEffects from the server with the prediction key used to apply them. If any of the replicated GameplayEffects match the GameplayEffects that the client applied with the same prediction key, they were predicted correctly. There will temporarily be two copies of the GameplayEffect on the target until the client removes its predicted one. Client receives the prediction key back from the server. This is the Replicated Prediction Key. This prediction key is now marked stale. Client removes all GameplayEffects that it created with the now stale replicated prediction key. GameplayEffects replicated by the server will persist. Any GameplayEffects that the client added and didn't receive a matching replicated version from the server were mispredicted. Prediction keys are guaranteed to be valid during an atomic grouping of instructions "window" in GameplayAbilities starting with Activation from the activation prediction key. You can think of this as being only valid during one frame. Any callbacks from latent action AbilityTasks will no longer have a valid prediction key unless the AbilityTask has a built-in Synch Point which generates a new Scoped Prediction Window.`},{header:"4.10.2 Creating New Prediction Windows in Abilities",slug:"_4-10-2-creating-new-prediction-windows-in-abilities",content:`To predict more actions in callbacks from AbilityTasks, we need to create a new Scoped Prediction Window with a new Scoped Prediction Key. This is sometimes referred to as a Synch Point between the client and server. Some AbilityTasks like all of the input related ones come with built-in functionality to create a new scoped prediction window, meaning atomic code in the AbilityTasks' callbacks have a valid scoped prediction key to use. Other tasks like the WaitDelay task do not have built-in code to create a new scoped prediction window for its callback. If you need to predict actions after an AbilityTask that does not have built-in code to create a scoped prediction window like WaitDelay, we must manually do that using the WaitNetSync AbilityTask with the option OnlyServerWait. When the client hits a WaitNetSync with OnlyServerWait, it generates a new scoped prediction key based on the GameplayAbility's activation prediction key, RPCs it to the server, and adds it to any new GameplayEffects that it applies. When the server hits a WaitNetSync with OnlyServerWait, it waits until it receives the new scoped prediction key from the client before continuing. This scoped prediction key does the same dance as activation prediction keys - applied to GameplayEffects and replicated back to clients to be marked stale. The scoped prediction key is valid until it falls out of scope, meaning the scoped prediction window has closed. So again, only atomic operations, nothing latent, can use the new scoped prediction key.
You can create as many scoped prediction windows as you need.
If you would like to add the synch point functionality to your own custom AbilityTasks, look at how the input ones essentially inject the WaitNetSync AbilityTask code into them.
Note: When using WaitNetSync, this does block the server's GameplayAbility from continuing execution until it hears from the client. This could potentially be abused by malicious users who hack the game and intentionally delay sending their new scoped prediction key. While Epic uses the WaitNetSync sparingly, it recommends potentially building a new version of the AbilityTask with a delay that automatically continues without the client if this is a concern for you.
The Sample Project uses WaitNetSync in the Sprint GameplayAbility to create a new scoped prediction window every time we apply the stamina cost so that we can predict it. Ideally we want a valid prediction key when applying costs and cooldowns.
If you have a predicted GameplayEffect that is playing twice on the owning client, your prediction key is stale and you're experiencing the "redo" problem. You can usually solve this by putting a WaitNetSync AbilityTask with OnlyServerWait right before you apply the GameplayEffect to create a new scoped prediction key.`},{header:"4.10.3 Predictively Spawning Actors",slug:"_4-10-3-predictively-spawning-actors",content:`Spawning Actors predictively on clients is an advanced topic. GAS does not provide functionality to handle this out of the box (the SpawnActor AbilityTask only spawns the Actor on the server). The key concept is to spawn a replicated Actor on both the client and the server.
If the Actor is just cosmetic or doesn't serve any gameplay purpose, the simple solution is to override the Actor's IsNetRelevantFor() function to restrict the server from replicating to the owning client. The owning client would have his locally spawned version and the server and other clients would have the server's replicated version.
bool APAReplicatedActorExceptOwner::IsNetRelevantFor(const AActor * RealViewer, const AActor * ViewTarget, const FVector & SrcLocation) const
{ return !IsOwnedBy(ViewTarget);
} If the spawned Actor affects gameplay like a projectile that needs to predict damage, then you need advanced logic that is outside of the scope of this documentation. Look at how UnrealTournament predictively spawns projectiles on Epic Games' GitHub. They have a dummy projectile spawned only on the owning client that synchs up with the server's replicated projectile.`},{header:"4.10.4 Future of Prediction in GAS",slug:"_4-10-4-future-of-prediction-in-gas",content:`GameplayPrediction.h states in the future they could potentially add functionality for predicting GameplayEffect removal and periodic GameplayEffects.
Dave Ratti from Epic has expressed interest in fixing the latency reconciliation problem for predicting cooldowns, disadvantaging players with higher latencies versus players with lower latencies.
The new Network Prediction plugin by Epic is expected to be fully interoperable with the GAS like the CharacterMovementComponent was before it.`},{header:"4.10.5 Network Prediction Plugin",slug:"_4-10-5-network-prediction-plugin",content:"Epic recently started an initiative to replace the CharacterMovementComponent with a new Network Prediction plugin. This plugin is still in its very early stages but is available to very early access on the Unreal Engine GitHub. It's too soon to tell which future version of the Engine that it will make its experimental beta debut in."},{header:"4.11 Targeting",slug:"_4-11-targeting",content:""},{header:"4.11.1 Target Data",slug:"_4-11-1-target-data",content:`FGameplayAbilityTargetData is a generic structure for targeting data meant to be passed across the network. TargetData will typically hold AActor/UObject references, FHitResults, and other generic location/direction/origin information. However, you can subclass it to put essentially anything that you want inside of them as a simple means to pass data between the client and server in GameplayAbilities. The base struct FGameplayAbilityTargetData is not meant to be used directly but instead subclassed. GAS comes with a few subclassed FGameplayAbilityTargetData structs out of the box located in GameplayAbilityTargetTypes.h.
TargetData is typically produced by Target Actors or created manually and consumed by AbilityTasks and GameplayEffects via the EffectContext. As a result of being in the EffectContext, Executions, MMCs, GameplayCues, and the functions on the backend of the AttributeSet can access the TargetData.
We don't typically pass around the FGameplayAbilityTargetData directly, instead we use a FGameplayAbilityTargetDataHandle which has an internal TArray of pointers to FGameplayAbilityTargetData. This intermediate struct provides support for polymorphism of the TargetData.
An example of inheritting from FGameplayAbilityTargetData:
USTRUCT(BlueprintType)
struct MYGAME_API FGameplayAbilityTargetData_CustomData : public FGameplayAbilityTargetData
{ GENERATED_BODY()
public: FGameplayAbilityTargetData_CustomData() { } UPROPERTY() FName CoolName = NAME_None; UPROPERTY() FPredictionKey MyCoolPredictionKey; // This is required for all child structs of FGameplayAbilityTargetData virtual UScriptStruct* GetScriptStruct() const override { return FGameplayAbilityTargetData_CustomData::StaticStruct(); } // This is required for all child structs of FGameplayAbilityTargetData bool NetSerialize(FArchive& Ar, class UPackageMap* Map, bool& bOutSuccess) { // The engine already defined NetSerialize for FName & FPredictionKey, thanks Epic! CoolName.NetSerialize(Ar, Map, bOutSuccess); MyCoolPredictionKey.NetSerialize(Ar, Map, bOutSuccess); bOutSuccess = true; return true; }
} template<>
struct TStructOpsTypeTraits<FGameplayAbilityTargetData_CustomData> : public TStructOpsTypeTraitsBase2<FGameplayAbilityTargetData_CustomData>
{ enum { WithNetSerializer = true // This is REQUIRED for FGameplayAbilityTargetDataHandle net serialization to work };
}; For adding the target data to a handle:
UFUNCTION(BlueprintPure)
FGameplayAbilityTargetDataHandle MakeTargetDataFromCustomName(const FName CustomName)
{ // Create our target data type, // Handle's automatically cleanup and delete this data when the handle is destructed, // if you don't add this to a handle then be careful because this deals with memory management and memory leaks so its safe to just always add it to a handle at some point in the frame! FGameplayAbilityTargetData_CustomData* MyCustomData = new FGameplayAbilityTargetData_CustomData(); // Setup the struct's information to use the inputted name and any other changes we may want to do MyCustomData->CoolName = CustomName; // Make our handle wrapper for Blueprint usage FGameplayAbilityTargetDataHandle Handle; // Add the target data to our handle Handle.Add(MyCustomData); // Output our handle to Blueprint return Handle
} For getting values it requires doing type safety checking, because the only way to get values from the handle's target data is by using generic C/C++ casting for it which is NOT type safe which can cause object slicing and crashes. For type checking there are multiple ways of doing this(however you want honestly) two common ways are: Gameplay Tag(s): You can use a subclass hierarchy where you know that anytime a certain code architecture's functionality occurs, you can cast for the base parent type and get its gameplay tag(s) and then compare against those for casting for inherited classes.
Script Struct & Static Structs: You can instead do direct class comparison(which can involve a lot of IF statements or making some template functions), below is an example of doing this but basically you can get the script struct from any FGameplayAbilityTargetData(this is a nice advantage of it being a USTRUCT and requiring any inherited classes to specify the struct type in GetScriptStruct) and compare if its the type you're looking for. Below is an example of using these functions for type checking: UFUNCTION(BlueprintPure)
FName GetCoolNameFromTargetData(const FGameplayAbilityTargetDataHandle& Handle, const int Index)
{ // NOTE, there is two versions of this '::Get(int32 Index)' function; // 1) const version that returns 'const FGameplayAbilityTargetData*', good for reading target data values // 2) non-const version that returns 'FGameplayAbilityTargetData*', good for modifying target data values FGameplayAbilityTargetData* Data = Handle.Get(Index); // This will valid check the index for you // Valid check we have something to use, null data means nothing to cast for if(Data == nullptr) { return NAME_None; } // This is basically the type checking pass, static_cast does not have type safety, this is why we do this check. // If we don't do this then it will object slice the struct and thus we have no way of making sure its that type. if(Data->GetScriptStruct() == FGameplayAbilityTargetData_CustomData::StaticStruct()) { // Here is when you would do the cast because we know its the correct type already FGameplayAbilityTargetData_CustomData* CustomData = static_cast<FGameplayAbilityTargetData_CustomData*>(Data); return CustomData->CoolName; } return NAME_None;
}`},{header:"4.11.2 Target Actors",slug:"_4-11-2-target-actors",content:`GameplayAbilities spawn TargetActors with the WaitTargetData AbilityTask to visualize and capture targeting information from the world. TargetActors may optionally use GameplayAbilityWorldReticles to display current targets. Upon confirmation, the targeting information is returned as TargetData which can then be passed into GameplayEffects.
TargetActors are based on AActor so they can have any kind of visible component to represent where and how they are targeting such as static meshes or decals. Static meshes may be used to visualize placement of an object that your character will build. Decals may be used to show an area of effect on the ground. The Sample Project uses AGameplayAbilityTargetActor_GroundTrace with a decal on the ground to represent the damage area of effect for the Meteor ability. They also don't need to display anything either. For example it wouldn't make sense to display anything for a hitscan gun that instantly traces a line to its target as used in GASShooter.
They capture targeting information using basic traces or collision overlaps and convert the results as FHitResults or AActor arrays to TargetData depending on the TargetActor implementation. The WaitTargetData AbilityTask determines when the targets are confirmed through its TEnumAsByte<EGameplayTargetingConfirmation::Type> ConfirmationType parameter. When not using TEnumAsByte<EGameplayTargetingConfirmation::Type::Instant, the TargetActor typically performs the trace/overlap on Tick() and updates its location to the FHitResult depending on its implementation. While this performs a trace/overlap on Tick(), it's generally not terrible since it's not replicated and you typically don't have more than one (although you could have more) TargetActor running at a time. Just be aware that it uses Tick() and some complex TargetActors might do a lot on it like the rocket launcher's secondary ability in GASShooter. While tracing on Tick() is very responsive to the client, you may consider lowering the tick rate on the TargetActor if the performance hit is too much. In the case of TEnumAsByte<EGameplayTargetingConfirmation::Type::Instant, the TargetActor immediately spawns, produces TargetData, and destroys. Tick() is never called. EGameplayTargetingConfirmation::Type
When targets are confirmed Instant
The targeting happens instantly without special logic or user input deciding when to 'fire'. UserConfirmed
The targeting happens when the user confirms the targeting when the ability is bound to a Confirm input or by calling UAbilitySystemComponent::TargetConfirm(). The TargetActor will also respond to a bound Cancel input or call to UAbilitySystemComponent::TargetCancel() to cancel targeting. Custom
The GameplayTargeting Ability is responsible for deciding when the targeting data is ready by calling UGameplayAbility::ConfirmTaskByInstanceName(). The TargetActor will also respond to UGameplayAbility::CancelTaskByInstanceName() to cancel targeting. CustomMulti
The GameplayTargeting Ability is responsible for deciding when the targeting data is ready by calling UGameplayAbility::ConfirmTaskByInstanceName(). The TargetActor will also respond to UGameplayAbility::CancelTaskByInstanceName() to cancel targeting. Should not end the AbilityTask upon data production. Not every EGameplayTargetingConfirmation::Type is supported by every TargetActor. For example, AGameplayAbilityTargetActor_GroundTrace does not support Instant confirmation.
The WaitTargetData AbilityTask takes in a AGameplayAbilityTargetActor class as a parameter and will spawn an instance on each activation of the AbilityTask and will destroy the TargetActor when the AbilityTask ends. The WaitTargetDataUsingActor AbilityTask takes in an already spawned TargetActor, but still destroys it when the AbilityTask ends. Both of these AbilityTasks are inefficient in that they either spawn or require a newly spawned TargetActor for each use. They're great for prototyping, but in production you might explore optimizing it if you have cases where you are constantly producing TargetData like in the case of an automatic rifle. GASShooter has a custom subclass of AGameplayAbilityTargetActor and a new WaitTargetDataWithReusableActor AbilityTask written from scratch that allows you to reuse a TargetActor without destroying it.
TargetActors are not replicated by default; however, they can be made to replicate if that makes sense in your game to show other players where the local player is targeting. They do include default functionality to communicate with the server via RPCs on the WaitTargetData AbilityTask. If the TargetActor's ShouldProduceTargetDataOnServer property is set to false, then the client will RPC its TargetData to the server on confirmation via CallServerSetReplicatedTargetData() in UAbilityTask_WaitTargetData::OnTargetDataReadyCallback(). If ShouldProduceTargetDataOnServer is true, the client will send a generic confirm event, EAbilityGenericReplicatedEvent::GenericConfirm, RPC to the server in UAbilityTask_WaitTargetData::OnTargetDataReadyCallback() and the server will do the trace or overlap check upon receiving the RPC to produce data on the server. If the client cancels the targeting, it will send a generic cancel event, EAbilityGenericReplicatedEvent::GenericCancel, RPC to the server in UAbilityTask_WaitTargetData::OnTargetDataCancelledCallback. As you can see, there are a lot of delegates on both the TargetActor and the WaitTargetData AbilityTask. The TargetActor responds to inputs to produce and broadcast TargetData ready, confirm, or cancel delegates. WaitTargetData listens to the TargetActor's TargetData ready, confirm, and cancel delegates and relays that information back to the GameplayAbility and to the server. If you send TargetData to the server, you may want to do validation on the server to make sure the TargetData looks reasonable to prevent cheating. Producing the TargetData directly on the server avoids this issue entirely, but will potentially lead to mispredictions for the owning client.
Depending on the particular subclass of AGameplayAbilityTargetActor that you use, different ExposeOnSpawn parameters will be exposed on the WaitTargetData AbilityTask node. Some common parameters include: Common TargetActor Parameters
Definition Debug
If true, it will draw debug tracing/overlapping information whenever the TargetActor performs a trace in non-shipping builds. Remember, non-Instant TargetActors will perform a trace on Tick() so these debug draw calls will also happen on Tick(). Filter
[Optional] A special struct for filtering out (removing) Actors from the targets when the trace/overlap happens. Typical use cases are to filter out the player's Pawn, require targets be of a specific class. See Target Data Filters for more advanced use cases. Reticle Class
[Optional] Subclass of AGameplayAbilityWorldReticle that the TargetActor will spawn. Reticle Parameters
[Optional] Configure your Reticles. See Reticles. Start Location
A special struct for where tracing should start from. Typically this will be the player's viewpoint, a weapon muzzle, or the Pawn's location. With the default TargetActor classes, Actors are only valid targets when they are directly in the trace/overlap. If they leave the trace/overlap (they move or you look away), they are no longer valid. If you want the TargetActor to remember the last valid target(s), you will need to add this functionality to a custom TargetActor class. I refer to these as persistent targets as they will persist until the TargetActor receives confirmation or cancellation, the TargetActor finds a new valid target in its trace/overlap, or the target is no longer valid (destroyed). GASShooter uses persistent targets for its rocket launcher's secondary ability's homing rockets targeting.`},{header:"4.11.3 Target Data Filters",slug:"_4-11-3-target-data-filters",content:`Using both the Make GameplayTargetDataFilter and Make Filter Handle nodes, you can filter out the player's Pawn or select only a specific class. If you need more advanced filtering, you can subclass FGameplayTargetDataFilter and override the FilterPassesForActor function.
USTRUCT(BlueprintType)
struct GASDOCUMENTATION_API FGDNameTargetDataFilter : public FGameplayTargetDataFilter
{ GENERATED_BODY() /** Returns true if the actor passes the filter and will be targeted */ virtual bool FilterPassesForActor(const AActor* ActorToBeFiltered) const override;
}; However, this will not work directly into the Wait Target Data node as it requires a FGameplayTargetDataFilterHandle. A new custom Make Filter Handle must be made to accept the subclass:
FGameplayTargetDataFilterHandle UGDTargetDataFilterBlueprintLibrary::MakeGDNameFilterHandle(FGDNameTargetDataFilter Filter, AActor* FilterActor)
{ FGameplayTargetDataFilter* NewFilter = new FGDNameTargetDataFilter(Filter); NewFilter->InitializeFilterContext(FilterActor); FGameplayTargetDataFilterHandle FilterHandle; FilterHandle.Filter = TSharedPtr<FGameplayTargetDataFilter>(NewFilter); return FilterHandle;
}`},{header:"4.11.4 Gameplay Ability World Reticles",slug:"_4-11-4-gameplay-ability-world-reticles",content:`AGameplayAbilityWorldReticles (Reticles) visualize who you are targeting when targeting with non-Instant confirmed TargetActors. TargetActors are responsible for the spawn and destroy lifetimes for all Reticles. Reticles are AActors so they can use any kind of visual component for representation. A common implementation as seen in GASShooter is to use a WidgetComponent to display a UMG Widget in screen space (always facing the player's camera). Reticles do not know which AActor that they're on, but you could subclass in that functionality on a custom TargetActor. TargetActors will typically update the Reticle's location to the target's location on every Tick().
GASShooter uses Reticles to show locked-on targets for the rocket launcher's secondary ability's homing rockets. The red indicator on the enemy is the Reticle. The similar white image is the rocket launcher's crosshair. Reticles come with a handful of BlueprintImplementableEvents for designers (they're intended to be developed in Blueprints):
/** Called whenever bIsTargetValid changes value. */
UFUNCTION(BlueprintImplementableEvent, Category = Reticle)
void OnValidTargetChanged(bool bNewValue); /** Called whenever bIsTargetAnActor changes value. */
UFUNCTION(BlueprintImplementableEvent, Category = Reticle)
void OnTargetingAnActor(bool bNewValue); UFUNCTION(BlueprintImplementableEvent, Category = Reticle)
void OnParametersInitialized(); UFUNCTION(BlueprintImplementableEvent, Category = Reticle)
void SetReticleMaterialParamFloat(FName ParamName, float value); UFUNCTION(BlueprintImplementableEvent, Category = Reticle)
void SetReticleMaterialParamVector(FName ParamName, FVector value); Reticles can optionally use FWorldReticleParameters provided by the TargetActor for configuration. The default struct only provides one variable FVector AOEScale. While you can technically subclass this struct, the TargetActor will only accept the base struct. It seems a little short-sighted to not allow this to be subclassed with default TargetActors. However, if you make your own custom TargetActor, you can provide your own custom reticle parameters struct and manually pass it to your subclass of AGameplayAbilityWorldReticles when you spawn them.
Reticles are not replicated by default, but can be made replicated if it makes sense for your game to show other players who the local player is targeting.
Reticles will only display on the current valid target with the default TargetActors. For example, if you're using a AGameplayAbilityTargetActor_SingleLineTrace to trace for a target, the Reticle will only appear when the enemy is directly in the trace path. If you look away, the enemy is no longer a valid target and the Reticle will disappear. If you want the Reticle to stay on the last valid target, you will want to customize your TargetActor to remember the last valid target and keep the Reticle on them. I refer to these as persistent targets as they will persist until the TargetActor receives confirmation or cancellation, the TargetActor finds a new valid target in its trace/overlap, or the target is no longer valid (destroyed). GASShooter uses persistent targets for its rocket launcher's secondary ability's homing rockets targeting.`},{header:"4.11.5 Gameplay Effect Containers Targeting",slug:"_4-11-5-gameplay-effect-containers-targeting",content:"GameplayEffectContainers come with an optional, efficient means of producing TargetData. This targeting takes place instantly when the EffectContainer is applied on the client and the server. It's more efficient than TargetActors because it runs on the CDO of the targeting object (no spawning and destroying of Actors), but it lacks player input, happens instantly without needing confirmation, cannot be canceled, and cannot send data from the client to the server (produces data on both). It works well for instant traces and collision overlaps. Epic's Action RPG Sample Project includes two example types of targeting with its containers - target the ability owner and pull TargetData from an event. It also implements one in Blueprint to do instant sphere traces at some offset (set by child Blueprint classes) from the player. You can subclass URPGTargetType in C++ or Blueprint to make your own targeting types."},{header:"5. Commonly Implemented Abilities and Effects",slug:"_5-commonly-implemented-abilities-and-effects",content:""},{header:"5.1 Stun",slug:"_5-1-stun",content:`Typically with stuns, we want to cancel all of a Character's active GameplayAbilities, prevent new GameplayAbility activations, and prevent movement throughout the duration of the stun. The Sample Project's Meteor GameplayAbility applies a stun on hit targets.
To cancel the target's active GameplayAbilities, we call AbilitySystemComponent->CancelAbilities() when the stun GameplayTag is added.
To prevent new GameplayAbilities from activating while stunned, the GameplayAbilities are given the stun GameplayTag in their Activation Blocked Tags GameplayTagContainer.
To prevent movement while stunned, we override the CharacterMovementComponent's GetMaxSpeed() function to return 0 when the owner has the stun GameplayTag.`},{header:"5.2 Sprint",slug:"_5-2-sprint",content:`The Sample Project provides an example of how to sprint - run faster while Left Shift is held down.
The faster movement is handled predictively by the CharacterMovementComponent by sending a flag over the network to the server. See GDCharacterMovementComponent.h/cpp for details.
The GA handles responding to the Left Shift input, tells the CMC to begin and stop sprinting, and to predictively charge stamina while Left Shift is pressed. See GA_Sprint_BP for details.`},{header:"5.3 Aim Down Sights",slug:"_5-3-aim-down-sights",content:`The Sample Project handles this the exact same way as sprinting but decreasing the movement speed instead of increasing it.
See GDCharacterMovementComponent.h/cpp for details on predictively decreasing the movement speed.
See GA_AimDownSight_BP for details on handling the input. There is no stamina cost for aiming down sights.`},{header:"5.4 Lifesteal",slug:"_5-4-lifesteal",content:`I handle lifesteal inside of the damage ExecutionCalculation. The GameplayEffect will have a GameplayTag on it like Effect.CanLifesteal. The ExecutionCalculation checks if the GameplayEffectSpec has that Effect.CanLifesteal GameplayTag. If the GameplayTag exists, the ExecutionCalculation creates a dynamic Instant GameplayEffect with the amount of health to give as the modifier and applies it back to the Source's ASC.
if (SpecAssetTags.HasTag(FGameplayTag::RequestGameplayTag(FName("Effect.Damage.CanLifesteal"))))
{ float Lifesteal = Damage * LifestealPercent; UGameplayEffect* GELifesteal = NewObject<UGameplayEffect>(GetTransientPackage(), FName(TEXT("Lifesteal"))); GELifesteal->DurationPolicy = EGameplayEffectDurationType::Instant; int32 Idx = GELifesteal->Modifiers.Num(); GELifesteal->Modifiers.SetNum(Idx + 1); FGameplayModifierInfo& Info = GELifesteal->Modifiers[Idx]; Info.ModifierMagnitude = FScalableFloat(Lifesteal); Info.ModifierOp = EGameplayModOp::Additive; Info.Attribute = UPAAttributeSetBase::GetHealthAttribute(); SourceAbilitySystemComponent->ApplyGameplayEffectToSelf(GELifesteal, 1.0f, SourceAbilitySystemComponent->MakeEffectContext());
}`},{header:"5.5 Generating a Random Number on Client and Server",slug:"_5-5-generating-a-random-number-on-client-and-server",content:`Sometimes you need to generate a "random" number inside of a GameplayAbility for things like bullet recoil or spread. The client and the server will both want to generate the same random numbers. To do this, we must set the random seed to be the same at the time of GameplayAbility activation. You will want to set the random seed each time you activate the GameplayAbility in case the client mispredicts activation and its random number sequence becomes out of synch with the server's. Seed Setting Method
Description Use the activation prediction key
The GameplayAbility activation prediction key is an int16 guaranteed to be synchronized and available in both the client and server in the Activation(). You can set this as the random seed on both the client and the server. The downside to this method is that the prediction key always starts at zero each time the game starts and consistently increments the value to use between generating keys. This means each match will have the exact same random number sequence. This may or may not be random enough for your needs. Send a seed through an event payload when you activate the GameplayAbility
Activate your GameplayAbility by event and send the randomly generated seed from the client to the server via the replicated event payload. This allows for more randomness but the client could easily hack their game to only send the same seed value every time. Also activating GameplayAbilities by event will prevent them from activating from the input bind. If your random deviation is small, most players won't notice that the sequence is the same every game and using the activation prediction key as the random seed should work for you. If you're doing something more complex that needs to be hacker proof, perhaps using a Server Initiated GameplayAbility would work better where the server can create the prediction key or generate the random seed to send via an event payload.`},{header:"5.6 Critical Hits",slug:"_5-6-critical-hits",content:`I handle critical hits inside of the damage ExecutionCalculation. The GameplayEffect will have a GameplayTag on it like Effect.CanCrit. The ExecutionCalculation checks if the GameplayEffectSpec has that Effect.CanCrit GameplayTag. If the GameplayTag exists, the ExecutionCalculation generates a random number corresponding to the critical hit chance (Attribute captured from the Source) and adds the critical hit damage (also an Attribute captured from the Source) if it succeeded. Since I don't predict damage, I don't have to worry about synchronizing the random number generators on the client and server since the ExecutionCalculation will only run on the server. If you tried to do this predictively using an MMC to do your damage calculation, you would have to get a reference to the random seed from the GameplayEffectSpec->GameplayEffectContext->GameplayAbilityInstance.
See how GASShooter does headshots. It's the same concept except that it does not rely on a random number for chance and instead checks the FHitResult bone name.`},{header:"5.7 Non-Stacking Gameplay Effects but Only the Greatest Magnitude Actually Affects the Target",slug:"_5-7-non-stacking-gameplay-effects-but-only-the-greatest-magnitude-actually-affects-the-target",content:"Slow effects in Paragon did not stack. Each slow instance applied and kept track of their lifetimes as normal, but only the greatest magnitude slow effect actually affected the Character. GAS provides for this scenario out of the box with AggregatorEvaluateMetaData. See AggregatorEvaluateMetaData() for details and implementation."},{header:"5.8 Generate Target Data While Game is Paused",slug:"_5-8-generate-target-data-while-game-is-paused",content:"If you need to pause the game while waiting to generate TargetData from a WaitTargetData AbilityTask from your player, I suggest instead of pausing to use slomo 0."},{header:"5.9 One Button Interaction System",slug:"_5-9-one-button-interaction-system",content:"GASShooter implements a one button interaction system where the player can press or hold 'E' to interact with interactable objects like reviving a player, opening a weapon chest, and opening or closing a sliding door."},{header:"6. Debugging GAS",slug:"_6-debugging-gas",content:`Often when debugging GAS related issues, you want to know things like: "What are the values of my attributes?"
"What gameplay tags do I have?"
"What gameplay effects do I currently have?"
"What abilities do I have granted, which ones are running, and which ones are blocked from activating?". GAS comes with two techniques for answering these questions at runtime - showdebug abilitysystem and hooks in the GameplayDebugger.
Tip: Unreal Engine likes to optimize C++ code which makes it hard to debug some functions. You will encounter this rarely when tracing deep into your code. If setting your Visual Studio solution configuration to DebugGame Editor still prevents tracing code or inspecting variables, you can disable all optimizations by wrapping the optimized function with the UE_DISABLE_OPTIMIZATION and UE_ENABLE_OPTIMIZATION macros or the ship variations defined in CoreMiscDefines.h. This cannot be used on the plugin code unless you rebuild the plugin from source. This may or may not work on inline functions depending on what they do and where they are. Be sure to remove the macros when you're done debugging!
UE_DISABLE_OPTIMIZATION
void MyClass::MyFunction(int32 MyIntParameter)
{ // My code
}
UE_ENABLE_OPTIMIZATION`},{header:"6.1 showdebug abilitysystem",slug:"_6-1-showdebug-abilitysystem",content:`Type showdebug abilitysystem in the in-game console. This feature is split into three "pages". All three pages will show the GameplayTags that you currently have. Type AbilitySystem.Debug.NextCategory into the console to cycle between the pages.
The first page shows the CurrentValue of all of your Attributes: The second page shows all of the Duration and Infinite GameplayEffects on you, their number of stacks, what GameplayTags they give, and what Modifiers they give. The third page shows all of the GameplayAbilities that have been granted to you, whether they are currently running, whether they are blocked from activating, and the status of currently running AbilityTasks. To cycle between targets (denoted by a green rectangular prism around the Actor), use the PageUp key or NextDebugTarget console command to go to the next target and the PageDown key or PreviousDebugTarget console command to go to the previous target.
Note: In order for the ability system information to update based on the currently selected debug Actor, you need to set bUseDebugTargetFromHud=true in the AbilitySystemGlobals like so in the DefaultGame.ini:
[/Script/GameplayAbilities.AbilitySystemGlobals]
bUseDebugTargetFromHud=true Note: For showdebug abilitysystem to work an actual HUD class must be selected in the GameMode. Otherwise the command is not found and "Unknown Command" is returned.`},{header:"6.2 Gameplay Debugger",slug:"_6-2-gameplay-debugger",content:`GAS adds functionality to the Gameplay Debugger. Access the Gameplay Debugger with the Apostrophe (') key. Enable the Abilities category by pressing 3 on your numpad. The category may be different depending on what plugins you have. If your keyboard doesn't have a numpad like a laptop, then you can change the keybindings in the project settings.
Use the Gameplay Debugger when you want to see the GameplayTags, GameplayEffects, and GameplayAbilities on other Characters. Unfortunately it does not show the CurrentValue of the target's Attributes. It will target whatever Character is in the center of your screen. You can change targets by selecting them in the World Outliner in the Editor or by looking at a different Character and press Apostrophe (') again. The currently inspected Character has the largest red circle above it.
Gameplay Debugger`},{header:"6.3 GAS Logging",slug:"_6-3-gas-logging",content:`The GAS source code contains a lot of logging statements produced at varying verbosity levels. You will most likely see these as ABILITY_LOG() statements. The default verbosity level is Display. Anything higher will not be displayed in the console by default.
To change the verbosity level of a log category, type into your console:
log [category] [verbosity] For example, to turn on ABILITY_LOG() statements, you would type into your console:
log LogAbilitySystem VeryVerbose To reset it back to default, type:
log LogAbilitySystem Display To display all log categories, type:
log list Notable GAS related logging categories: Logging Category
Default Verbosity Level LogAbilitySystem
Display LogAbilitySystemComponent
Log LogGameplayCueDetails
Log LogGameplayCueTranslator
Display LogGameplayEffectDetails
Log LogGameplayEffects
Display LogGameplayTags
Log LogGameplayTasks
Log VLogAbilitySystem
Display See the Wiki on Logging for more information.`},{header:"7. Optimizations",slug:"_7-optimizations",content:""},{header:"7.1 Ability Batching",slug:"_7-1-ability-batching",content:"GameplayAbilities that activate, optionally send TargetData to the server, and end all in one frame can be batched to condense two-three RPCs into one RPC. These types of abilities are commonly used for hitscan guns."},{header:"7.2 Gameplay Cue Batching",slug:"_7-2-gameplay-cue-batching",content:"If you're sending many GameplayCues at the same time, consider batching them into one RPC. The goal is to reduce the number of RPCs (GameplayCues are unreliable NetMulticasts) and send as little data as possible."},{header:"7.3 AbilitySystemComponent Replication Mode",slug:"_7-3-abilitysystemcomponent-replication-mode",content:"By default, the ASC is in Full Replication Mode. This will replicate all GameplayEffects to every client (which is fine for a single player game). In a multiplayer game, set the player owned ASCs to Mixed Replication Mode and AI controlled characters to Minimal Replication Mode. This will replicate GEs applied on a player character to only replicate to the owner of that character and GEs applied on AI controlled characters will never replicate GEs to clients. GameplayTags will still replicate and GameplayCues will still be unreliable NetMulticast to all clients, regardless of the Replication Mode. This will cut down on network data from GEs being replicated when all clients don't need to see them."},{header:"7.4 Attribute Proxy Replication",slug:"_7-4-attribute-proxy-replication",content:"In large games with many players like Fortnite Battle Royale (FNBR), there will be a lot of ASCs living on always-relevant PlayerStates replicating a lot of Attributes. To optimize this bottleneck, Fortnite disables the ASC and its AttributeSets from replicating altogether on simulated player-controlled proxies in the PlayerState::ReplicateSubobjects(). Autonomous proxies and AI controlled Pawns still fully replicate according to their Replication Mode. Instead of replicating Attributes on the ASC on the always-relevant PlayerStates, FNBR uses a replicated proxy structure on the player's Pawn. When Attributes change on the server's ASC, they are changed on the proxy struct too. The client receives the replicated Attributes from the proxy struct and pushes the changes back into its local ASC. This allows Attribute replication to use the Pawn's relevancy and NetUpdateFrequency. This proxy struct also replicates a small white-listed set of GameplayTags in a bitmask. This optimization reduces the amount of data over the network and allows us to take advantage of pawn relevancy. AI controlled Pawns have their ASC on the Pawn which already uses its relevancy so this optimization is not needed for them. I’m not sure if it is still necessary with other server side optimizations that have been done since then (Replication Graph, etc) and it is not the most maintainable pattern. Dave Ratti from Epic's answer to community questions #3"},{header:"7.5 ASC Lazy Loading",slug:"_7-5-asc-lazy-loading",content:"Fortnite Battle Royale (FNBR) has a lot of damageable AActors (trees, buildings, etc) in the world, each with an ASC. This can add up in memory cost. FNBR optimizes this by lazily loading ASCs only when they're needed (when they first take damage by a player). This reduces overall memory usage since some AActors may never be damaged in a match."},{header:"8. Quality of Life Suggestions",slug:"_8-quality-of-life-suggestions",content:""},{header:"8.1 Gameplay Effect Containers",slug:"_8-1-gameplay-effect-containers",content:"GameplayEffectContainers combine GameplayEffectSpecs, TargetData, simple targeting, and related functionality into easy to use structures. These are great for transfering GameplayEffectSpecs to projectiles spawned from an ability that will then apply them on collision at a later time."},{header:"8.2 Blueprint AsyncTasks to Bind to ASC Delegates",slug:"_8-2-blueprint-asynctasks-to-bind-to-asc-delegates",content:`To increase designer-friendly iteration times, especially when designing UMG Widgets for UI, create Blueprint AsyncTasks (in C++) to bind to the common change delegates on the ASC directly from your UMG Blueprint graphs. The only caveat is that they must be manually destroyed (like when the widget is destroyed) otherwise they will live in memory forever. The Sample Project includes three Blueprint AsyncTasks.
Listen for Attribute changes:
Listen for Attributes Changes BP Node
Listen for cooldown changes:
Listen for Cooldown Change BP Node
Listen for GE stack changes:
Listen for GameplayEffect Stack Change BP Node`},{header:"9. Troubleshooting",slug:"_9-troubleshooting",content:""},{header:"9.1 LogAbilitySystem: Warning: Can't activate LocalOnly or LocalPredicted ability %s when not local!",slug:"_9-1-logabilitysystem-warning-can-t-activate-localonly-or-localpredicted-ability-s-when-not-local",content:"You need to initialize the ASC on the client."},{header:"9.2 ScriptStructCache errors",slug:"_9-2-scriptstructcache-errors",content:"You need to call UAbilitySystemGlobals::InitGlobalData()."},{header:"9.3 Animation Montages are not replicating to clients",slug:"_9-3-animation-montages-are-not-replicating-to-clients",content:"Make sure that you're using the PlayMontageAndWait Blueprint node instead of PlayMontage in your GameplayAbilities. This AbilityTask replicates the montage through the ASC automatically whereas the PlayMontage node does not."},{header:"9.4 Duplicating Blueprint Actors is setting AttributeSets to nullptr",slug:"_9-4-duplicating-blueprint-actors-is-setting-attributesets-to-nullptr",content:`There is a bug in Unreal Engine that will set AttributeSet pointers on your classes to nullptr for Blueprint Actor classes that are duplicated from existing Blueprint Actor classes. There are a few workarounds for this. I've had success not creating bespoke AttributeSet pointers on my classes (no pointer in the .h, not calling CreateDefaultSubobject in the constructor) and instead just directly adding AttributeSets to the ASC in PostInitializeComponents() (not shown in the Sample Project). The replicated AttributeSets will still live in the ASC's SpawnedAttributes array. It would look something like this:
void AGDPlayerState::PostInitializeComponents()
{ Super::PostInitializeComponents(); if (AbilitySystemComponent) { AbilitySystemComponent->AddSet<UGDAttributeSetBase>(); // ... any other AttributeSets that you may have }
} In this scenario, you would read and set the values in the AttributeSet using the functions on the ASC instead of calling functions on the AttributeSet made from the macros.
/** Returns current (final) value of an attribute */
float GetNumericAttribute(const FGameplayAttribute &Attribute) const; /** Sets the base value of an attribute. Existing active modifiers are NOT cleared and will act upon the new base value. */
void SetNumericAttributeBase(const FGameplayAttribute &Attribute, float NewBaseValue); So the GetHealth() would look something like:
float AGDPlayerState::GetHealth() const
{ if (AbilitySystemComponent) { return AbilitySystemComponent->GetNumericAttribute(UGDAttributeSetBase::GetHealthAttribute()); } return 0.0f;
} Setting (initializing) the health Attribute would look something like:
const float NewHealth = 100.0f;
if (AbilitySystemComponent)
{ AbilitySystemComponent->SetNumericAttributeBase(UGDAttributeSetBase::GetHealthAttribute(), NewHealth);
} As a reminder, the ASC only ever expects at most one AttributeSet object per AttributeSet class.`},{header:"9.5 unresolved external symbol UEPushModelPrivate::MarkPropertyDirty(int,int)",slug:"_9-5-unresolved-external-symbol-uepushmodelprivate-markpropertydirty-int-int",content:`If you get a compiler error like:
error LNK2019: unresolved external symbol "__declspec(dllimport) void __cdecl UEPushModelPrivate::MarkPropertyDirty(int,int)" (__imp_?MarkPropertyDirty@UEPushModelPrivate@@YAXHH@Z) referenced in function "public: void __cdecl FFastArraySerializer::IncrementArrayReplicationKey(void)" (?IncrementArrayReplicationKey@FFastArraySerializer@@QEAAXXZ) This is from trying to call MarkItemDirty() on a FFastArraySerializer. I've encountered this from updating an ActiveGameplayEffect such as when updating the cooldown duration.
ActiveGameplayEffects.MarkItemDirty(*AGE); What's happening is that WITH_PUSH_MODEL is getting defined in more than one place. PushModelMacros.h is defining it as 0 while it's defined as 1 in multiple places. PushModel.h is seeing it as 1 but PushModel.cpp is seeing it as 0.
The solution is to add NetCore to your project's PublicDependencyModuleNames in the Build.cs.`},{header:"9.6 Enum names are now represented by path name",slug:"_9-6-enum-names-are-now-represented-by-path-name",content:`If you get a compiler warning like:
warning C4996: 'FGameplayAbilityInputBinds::FGameplayAbilityInputBinds': Enum names are now represented by path names. Please use a version of FGameplayAbilityInputBinds constructor that accepts FTopLevelAssetPath. Please update your code to the new API before upgrading to the next release, otherwise your project will no longer compile. UE 5.1 deprecated using FString in the constructor for BindAbilityActivationToInputComponent(). Instead, we must pass in an FTopLevelAssetPath.
Old, deprecated way:
AbilitySystemComponent->BindAbilityActivationToInputComponent(InputComponent, FGameplayAbilityInputBinds(FString("ConfirmTarget"), FString("CancelTarget"), FString("EGDAbilityInputID"), static_cast<int32>(EGDAbilityInputID::Confirm), static_cast<int32>(EGDAbilityInputID::Cancel))); New way:
FTopLevelAssetPath AbilityEnumAssetPath = FTopLevelAssetPath(FName("/Script/GASDocumentation"), FName("EGDAbilityInputID"));
AbilitySystemComponent->BindAbilityActivationToInputComponent(InputComponent, FGameplayAbilityInputBinds(FString("ConfirmTarget"), FString("CancelTarget"), AbilityEnumAssetPath, static_cast<int32>(EGDAbilityInputID::Confirm), static_cast<int32>(EGDAbilityInputID::Cancel))); See Engine\\Source\\Runtime\\CoreUObject\\Public\\UObject\\TopLevelAssetPath.h for more info.`},{header:"10. Common GAS Acronyms",slug:"_10-common-gas-acronyms",content:`Name
Acronyms AbilitySystemComponent
ASC AbilityTask
AT Action RPG Sample Project by Epic
ARPG, ARPG Sample CharacterMovementComponent
CMC GameplayAbility
GA GameplayAbilitySystem
GAS GameplayCue
GC GameplayEffect
GE GameplayEffectExecutionCalculation
ExecCalc, Execution GameplayTag
Tag, GT ModifierMagnitudeCalculation
ModMagCalc, MMC`},{header:"11. Other Resources",slug:"_11-other-resources",content:`Official Documentation
Source Code! Especially GameplayPrediction.h Lyra Sample Project by Epic
Action RPG Sample Project by Epic
Unreal Slackers Discord has a text channel dedicated to GAS #gameplay-ability-system Check pinned messages GitHub repository of resources by Dan 'Pan'
YouTube Videos by SabreDartStudios`},{header:"11.1 Q&A With Epic Game's Dave Ratti",slug:"_11-1-q-a-with-epic-game-s-dave-ratti",content:""},{header:"11.1.1 Community Questions 1",slug:"_11-1-1-community-questions-1",content:`Dave Ratti responses to the Unreal Slackers Discord Server community questions about GAS: How can we create scoped prediction windows on demand outside or irrespective of GameplayAbilities? For example, how can a fire and forget projectile locally predict a damage GameplayEffect when it hits an enemy? The PredictionKey system is not really meant to do this. Fundamentally this systems works by a client initiating a predictive action, telling the server about it with a key, and then both client and server running the same thing and associating predictive side effects with the given prediction key. For example, “I am predictively activating an ability” or “I have produced target data and am going to predictively run the part of the ability graph after the WaitTargetData task”.
With this pattern, the PredictionKey “bounces” off the server and comes back to the client via UAbilitySystemComponent::ReplicatedPredictionKeyMap (replicated property). Once the key is replicated back from the server, the client is able to undo all of the locally predictive side effects (GameplayCues, GameplayEffects): the replicated versions will be there and if they aren’t then it was a misprediction. Knowing exactly when to undo the predictive side effects is crucial here: if you are too early you will see gaps, if you are too late you will have “double”. (Note this is referring to stateful prediction, like a looping GameplayCue of a duration based Gameplay Effect. “Burst” GameplayCues and instant Gameplay Effects are never “undone” or rolled back. They are just skipped on the client if there is a prediction key associated with them).
To further hit home the point: it’s crucial that predictive action is something the server does not do on their own, but only does so when the client tells them to. So having a generic “Create a key on demand and tell the server so I can run something” does not work unless that “something” is something the server will only do once told to by the client.
Backing up to the original question: something like a fire and forget projectile. Both Paragon and Fornite have projectile actor classes that use GameplayCues. However we do not use the Prediction Key system to do these. Instead we have a concept on Non-Replicated GameplayCues. GameplayCues that just fire off locally and are skipped by the server completely. Essentially all these are direct calls to UGameplayCueManager::HandleGameplayCue. They do not route through the UAbilitySystemComponent so no prediction key checks / early returns are made.
The downside with non replicated GameplayCues is that, well, they are not replicated. So its up to the projectile class/blueprint to make sure the code paths that call these functions are running on everyone. We have for cues startup (called in BeginPlay), explosion, hit wall/character, etc.
These type of events are already generated client side, so calling into a non replicated gameplay cue was no big deal. Complicated blueprints can be tricky, and are up to the author to make sure they understand what is running where. When using a WaitNetSync AbilityTask with OnlyServerWait to create a scoped prediction window in a locally predicted GameplayAbility, could players potentially cheat by delaying their packets to the Server to control GameplayAbility timing since the Server is waiting for their RPC withtheir prediction key? Was this ever an issue in Paragon or Fortnite, and if so, what did Epic do to remedy it? Yes, this is a valid concern. Any ability blueprint running on the server that is waiting for a client “signal” is potentially vulnerable to lag switch type exploits.
Paragon had a custom targeting task similar to UAbilityTask_WaitTargetData. In this task we had timeouts, or a “max delay” that we would wait on the client for instantaneous targeting modes. If the targeting mode was waiting for user confirmation (button press) then it would be ignored since the user is allowed to take his time. But for abilities that instantly confirmed targeting we would only wait a certain amount of time before either A) generating the target data server side or B) canceling the ability.
We never had such mechanisms for WaitNetSync, which we used pretty sparingly.
I don’t believe Fortnite makes use of anything like this though. The weapon abilities in Fortnite are special cased batched to a single fortnite-specific RPC: one RPC to activate the ability, provide target data, and end the ability. So weapon abilities are intrinsically not vulnerable to this in Battle Royale.
My take is that this is something that could probably be solved system wide but I don’t see us making the change ourselves anytime soon. Spot fixing WaitNetSync to include a max delay for the case you mention is probably a reasonable task, but again - unlikely we will do this on our end in the immediate future. Which EGameplayEffectReplicationMode did Paragon and Fortnite use and what are Epic’s recommendations for when to use each? Both games essentially use Mixed mode for their player controlled characters and Minimal for AI controlled (AI minions, jungle creeps, AI Husks, etc). This is what I would recommend most people using the system in a multiplayer game. The sooner into your project you set these, the better.
Fortnite goes a few steps further with its optimizations. It actually does not replicate the UAbilitySystemComponent at all for simulated proxies. The component and attribute subobjects are skipped inside ::ReplicateSubobjects() on the owning fortnite player state class. We do push the bare minimum replicated data from the ability system component to a structure on the pawn itself (basically, a subset of attribute values and a white list subset of tags that we replicate down in a bitmask). We call this a “proxy”. On the receiving side we take the proxy data, replicated on the pawn, and push it back into ability system component on the player state. So you do have an ASC for each player in FNBR, it just doesn’t directly replicate: instead it replicates data via a minimal proxy struct on the pawn and then routes back to the ASC on receiving side. This is advantage since its A) a more minimal set of data B) takes advantage of pawn relevancy.
I’m not sure if it is still necessary with other server side optimizations that have been done since then (Replication Graph, etc) and it is not the most maintainable pattern. Since we cannot predict the removal of GameplayEffects as per GameplayPrediction.h, are there any strategies for mitigating the effects of latency on removing GameplayEffects? For example, when removing a movement speed slow, we currently have to wait for the Server to replicate the GameplayEffect removal resulting in a snap of the player’s character position. This is a tough one and I don’t have a good answer. We generally skirted around these problems with tolerances and smoothing. I totally agree that ability system and precise synchronization with the character movement system is not in a good place and something we do want to fix.
I had a shelf of allowing predictive removal of GEs but could never work out all edge cases before having to move on. This doesn’t solve everything though since character movement still has an internal saved move buffer that does not know anything about the ability system and possible movement speed modifiers, etc. It is still possible to get into correction feedback loops even outside of not being able to predict the removal of GEs.
If you think you have a case that is truly desperate, you are able to predictively add a GE that would inhibit your movement speed GEs. I’ve never done this myself but have theorized about it before. It may be able to help with a certain class of problem. We know that the AbilitySystemComponent lives on the PlayerState in Paragon and Fortnite and on the Character in the Action RPG Sample. What are Epic’s internal rules, guidelines, or recommendations for where the AbilitySystemComponent should live, and what should its Owner be? In general I would say anything that does not need to respawn should have the Owner and Avatar actor be the same thing. Anything like AI enemies, buildings, world props, etc.
Anything that does respawn should have the Owner and Avatar be different so that the Ability System Component does not need to be saved off / recreated / restored after a respawn. PlayerState is the logical choice it is replicated to all clients (where as PlayerController is not). The downside is PlayerStates are always relevant so you can run into problems in 100 player games (See notes on what FN did in question #3). Is it viable to have several AbilitySystemComponents which have the same owner but different avatars (e.g. on pawn and weapon/items/projectiles with Owner set to PlayerState)? The first problem I see there would be implementing the IGameplayTagAssetInterface and IAbilitySystemInterface on the owning actor. The former may be possible: just aggregate the tags from all ASCs (but watch out - HasAllMatchingGameplayTags may be met only via cross ASC aggregation. It wouldn't be enough to just forward that calls to each ASC and OR the results together). But the later is even trickier: which ASC is the authoritative one? If someone wants to apply a GE - which one should receive it? Maybe you can work these out but this side of the problem will be the hardest: owners will multiple ASCs beneath them.
Separate ASCs on the pawn and the weapon can make sense on its own though. E.g, distinguishing between tags the describe the weapon vs those that describe the owning pawn. Maybe it does make sense that tags granted to the weapon also “apply” to the owner and nothing else (E.g, attributes and GEs are independent but the owner will aggregate the owned tags like I describe above). This could work out, I am sure. But having multiple ASCs with the same owner may get dicey. Is there a way to stop the Server from overwriting the cooldown duration of locally predicted abilities on the Owning Client? In scenarios of high latency, this would let the Owning Client "try" to activate the ability again when its local cooldown expires but it is still on cooldown on the Server. By the time the Owning Client's activation request reaches the Server over the network, the Server may be off cooldown or the Server might be able to queue the activation request for the remaining milliseconds that it has left. Otherwise as is, clients with higher latency have a longer delay before when they can reactivate an ability versus those with less latency. This is most apparent with very low cooldown abilities like a basic attack that can be less than one second of cooldown. If there isn't a way to stop the Server from overwriting the cooldown duration of locally predicted abilities, what is Epic's strategy for mitigating the effects of high latency on reactivating abilities? To word it another example-based way, how did Epic design Paragon's basic attacks and other abilities so that high latency players could attack or activate at the same speed as low latency players with local prediction? The short answer there is not a way to prevent this and Paragon definitely had the problem. Higher latency connections would have a lower ROF with basic attacks.
I attempted to fix this by adding “GE reconciliation” where latency was taken into account when calculating GE duration. Essentially allowing the server to eat some of the total GE time so that the effective time of the GE client side would be 100% consistent with any amount of latency (though fluctuations could still cause issues). However I never got this working in a state that could ship and the project moved fast and we just never fully addressed it.
Fortnite does its own bookkeeping for weapon firing rates: it does not use GEs for cooldowns on weapons. I would recommend this if this is a critical problem for your game. What is Epic’s roadmap for the GameplayAbilitySystem plugin? Which features does Epic plan to add in 2019 and beyond? We feel that overall the system is pretty stable at this point and we don’t have anyone working on major new features. Bug fixes and small improvements occasionally are made for Fortnite or from UDN/pull requests, but that is it right now.
Longer term, I think we will eventually do a “V2” or some big changes. We learned a lot from writing this system and feel we got a lot right and a lot wrong. I would love a chance to correct those mistakes and improve some of the fatal flaws that were pointed out above.
If a V2 was to ever come, providing an upgrade path would be of utmost importance. We would never make a V2 and leave Fortnite on V1 forever: there would be some path or procedures that would automatically migrate as much as possible, though there would still almost certainly be some manual remaking required.
The high priority fixes would be: Better interoperability with the character movement system. Unifying client prediction.
GE removal prediction (question #4)
GE latency reconciliation (question #7)
Generalized network optimizations such as batching RPCs and proxy structures. Mostly the stuff that we’ve done for Fortnite but find ways to break it down into more generalized form, at least so that games can write their own game specific optimizations more easily. The more general refactor type of changes I would consider making: I would like to look at fundamentally moving away from having GEs reference spreadsheet values directly, instead they would be able to emit parameters and those parameters could be filled by some higher level object that is bound to spreadsheet values. The problem with the current model is that GEs become unsharable due to their tight coupling with the curve table rows. I think a generalized system for parameterization could be written and be the underpinning of a V2 system.
Reduce number of “policies” on UGameplayAbility. I would remove ReplicationPolicy and InstancingPolicy. Replication is, imo, almost never actually needed and causes confusion. InstancingPolicy should be replaced instead by making FGameplayAbilitySpec a UObject that can be subclassed. This should have been the “non instantiated ability object” that has events and is blueprintable. The UGameplayAbility should be the “instanced per execution” object. It could be optional if you need to actually instantiate: instead “non instanced” abilities would be implemented via the new UGameplayAbilitySpec object.
The system should provide more “middle level” constructs such as “filtered GE application container” (data drive what GEs to apply to which actors with higher level gameplay logic), “Overlapping volume support” (apply the “Filtered GE application container” based on collision primitive overlap events), etc. These are building blocks that every project ends up implementing in their own way. Getting them right is non trivial so I think we should do a better job providing some basic implementations.
In general, reducing boilerplate needed to get your project up and running. Possibly a separate module “Ex library” or whatever that could provide things like passive abilities or basic hitscan weapons out of the box. This module would be optional but would get you up and running quickly.
I would like to move GameplayCues to a separate module that is not coupled with the ability system. I think there are a lot of improvements that could be made here. This is only my personal opinion and not a commitment from anyone. I think the most realistic course of action will be as new engine tech initiatives come through, the ability system will need to be updated and that will be a time to do this sort of thing. These initiatives could be related to scripting, networking, or physics/character movement. This is all very far looking ahead though so I cannot give commitments or estimates on timelines.`},{header:"11.1.2 Community Questions 2",slug:"_11-1-2-community-questions-2",content:`Community member iniside's Q&A with Dave Ratti: Is the support for decoupled fixed ticking planned? I'd like to
have Game Thread be fixed (like 30/60fps) and let the rendering thread
run wild. I ask if this is something we should expect in future or
not, to make some assumptions about how gameplay should work.
I ask mainly because there is now a fixed async tick for physics and
this poses a question how the rest of the system might work in the
future. I do not hide that having the ability to have fixed tick game
thread without also fixing tick rate of the rest of the engine would
be beyond awesome. There are no plans to decouple rendering frame rate and game thread tick frame rate. I think the ship has sailed on this ever happening due to the complexity of these systems and the requirement to preserve backwards compatibility with previous engine versions.
Instead, the direction we've gone is to have an asynchronous "Physics Thread" which runs at a fixed tick rate, independent of the game thread. Things that need to run at a fixed rate can run here and the game thread / rendering can operate how they always have.
It's worth clarifying that Network Prediction supports what it calls Independent Ticking and Fixed Ticking modes. My long term plan is to keep Independent Ticking roughly how it is today in Network Prediction where it runs on the game thread at variable frame rate and there is no "group/world" prediction, it's just the classic "clients predict their own pawn and owned actors" model. And Fixed Ticking would be what uses the async physics stuff and allows you to predict non client controlled/owned actors like physics objects and other clients/pawns/vehicles/etc. Is there any plan on how the integration of Network Prediction will
look with the Ability System? Like for example, fixed frame ability
activation (so the server gets frames in which abilities were
activated and tasks executed instead of prediction keys)? Yes, the plan is to rewrite/remove the Ability System's prediction keys and replace them with Network Prediction constructs. The MockAbility examples in NetworkPredictionExtras show how this might work but they are more "hard coded" than what GAS will require.
The main idea would be that we remove the explicit client->server Prediction Key exchange in the ASC's RPCs. There would no longer be prediction windows or scoped prediction keys. Instead everything would be anchored around NetworkPrediction frames. The important thing is that client and server agree on when things happen. Examples would be: When abilities were activated/ended/cancelled
When Gameplay Effects were applied/removed
Attribute values (what an attributes value was at frame X) I think this could be done generically at the ability system level. But actually making the user-defined logic inside a UGameplayAbility completely rollback-able would still take more work. We may end up having a subclass of UGameplayAbility that is fully rollbackable and has access to a more limited set of functionality or only Ability Tasks that are marked as rollback-friendly. Something like that. There are also many implications to animation events and root motion and how those are processed.
Wish I had a more clear answer but it's really important we get the foundation right before touching GAS again. Movement and physics have to be solid before the higher level systems can be changed. Is there a plan to move Network Prediction development toward the
main branch? Not gonna lie, I'd really like to check the latest code.
Regardless of it's state. We are working towards it. The system work is still all being done in NetworkPrediction (see NetworkPhysics.h) and the underlying async physics stuff should be all available (RewindData.h etc). But we also have use cases in Fortnite that we have been focused on that obviously can't be made public. We are working through bugs, performance optimizations, etc.
For more context: when working on the early versions of this system, we were very focused on the "front end" of things - how state and simulations were defined and written. We learned a lot there. But as the async physics stuff has come online, we've been much more focused on just getting something real to work in this system, at the expense of throwing out some of our early abstractions. The goal here is to circle back when the real thing is working and reunifying things. E.g, get back to the "front end" and make the final version of that on top of the core pieces of tech we are working on now. For some time on main branch there was a plugin for sending Gameplay
Messages (Looked like Event/Message Bus), but it was removed. Any
plans to restore it? With the Game Features/Modular Gameplay plugins,
having a generic Event Bus Dispatcher would be extremely useful. I think you are referring to the GameplayMessages plugin. This will probably come back at some point - the API isn't really finalized yet and the author didn't mean for it to be public yet. I agree it should be useful for modular gameplay design. But it's not really my area so I don't have much more information. I've been playing recently with async fixed physics and the results
are promising, though if there is going to be NP update in the future
I will probably just play around and wait, since to get it working I
still need to get entire engine into fixed tick and on the other hand
I try to keep physics at 33ms. Which does not make for a good
experience if everything is at 30 fps (:. I have noticed there was some work on Async
CharacterMovementComponent, but not sure if this will be using Network
Prediction, or it is a separate effort?
Since I noticed it, I also went ahead and tried to implement my custom
async movement at fixed tick rate, which worked okay, but on top of it
I also needed to add a separate update for interpolation. The setup
was to run simulation tick on separate worker threads at fixed 33ms
update, do calculations, save result, and interpolate it at the game
thread to match current frame rate. Not perfect, but it got the job
done.
My question is, if this is something that might be easier to set up in
the future, as there is just quite a bit of boilerplate code to write,
(the interpolation part) and it's not particularly efficient to
interpolate each moving object individually.
The async stuff is really interesting, because it would allow you to
really run game simulation at fixed update rate (which would make
fixed thread unneeded) and have more predictable results. Is this
something that is intended going forward, or more of a benefit to
select systems? As far as I remember actor transforms are not updated
async and blueprints are not entirely thread safe. In other words is
it something that is planned to be supported at more of a framework
level or something that each game has to solve on it's own? Async CharacterMovementComponent
This is basically an early prototype/experiment of porting CMC as it is to the physics thread. I don't view it as the future of CMC yet, but it could evolve into that. Right now there is no networking support so it's not something I would really follow. The people doing it are mostly concerned with measuring input latency that this system would add and how that could be mitigated.
I still need to get entire engine into fixed tick and on the other hand I try to keep physics at 33ms. Which does not make for a good experience if everything is at 30 fps (:.
The async stuff is really interesting, because it would allow you to really run game simulation at fixed update rate (which would make fixed thread unneeded)
Yes. The goal here is that with async physics enabled, you can run the engine at variable tick rate while the physics and "core" gameplay simulations can run at the fixed rate (such as character movement, vehicles, GAS, etc).
These are the cvars that need to be set to enable this now: (I think you've figured this out)
p.DefaultAsyncDt=0.03333
p.RewindCaptureNumFrames=64
Chaos does provide interpolation for the physics state (e.g, the transforms that get pushed back to the UPrimitiveComponent and are visible to the game code). There is a cvar now, p.AsyncInterpolationMultiplier, which controls that if you want to look at it. You should see smooth continuous motion of physics bodies without having to write any extra code.
If you want to interpolate non physics state, it is still up to you to do that right now. The example would be like a cool-down that you want to update (tick) on the async physics thread but see smooth continuous interpolation on the game thread so that every render frame the cool-down visualization is updated. We will get to this eventually but don't have examples yet.
there is just quite a bit of boilerplate code to write,
Yeah, so that has been a big general problem with the system up until now. We want to provide an interface that experienced programmers can use to maximize performance and safety (the ability to write gameplay code that "just works" predictively without tons of hazards and things you could-do-but-better-not). So something like CharacterMoverment might do a bunch of custom stuff to maximize its performance - e.g, writing templated code and doing batch updating, going wide, breaking the update loop into distinct phases etc. We want to provide a good "low level" interface into the async thread and rollback systems for this use case. And in this case too - it's still reasonable that the character movement system itself is extendable in its own way. For example providing a way to blueprint a custom movement mode and providing a blueprint API that is thread safe.
But we recognize this is not acceptable for simpler gameplay objects that don't really need their own "system". Something more inline with Unreal is what is needed. E.g, using the reflection system, having general blueprint support, etc. There are examples of blueprints being used on other threads (see BlueprintThreadSafe keyword and what the animation system has been working towards). So I think there will be some form of this one day. But again, we aren't there yet.
I realize you were just asking about interpolation but that is the general answer: right now we have you do everything manually like NetSerialize, ShouldReconcile, Interpolate, etc but eventually we'll have a way that is like "if you want to just use the reflection system, you don't have to manually write this stuff". We just don't want to force everyone to use the reflection system since that imposes other limitations that we think we don't want to take on the lowest levels of the system.
And then just to tie this back to what I said earlier - right now we are really focused on getting a few very specific examples working and performant and then we will turn attention back to the front end and making things friendly to use and iterate on, reducing boilerplate, etc for everybody else to use.`},{header:"12. GAS Changelog",slug:"_12-gas-changelog",content:"This is a list of notable changes (fixes, changes, and new features) to GAS compiled from the official Unreal Engine upgrade changelog and from undocumented changes that I've encountered. If you've found something that isn't listed here, please make an issue or pull request."},{header:"5.3",slug:"_5-3",content:`Crash Fix: Fixed a crash when trying to apply Gameplay Cues after a seamless travel.
Crash Fix: Fixed a crash caused by GlobalAbilityTaskCount when using Live Coding.
Crash Fix: Fixed UAbilityTask::OnDestroy to not crash if called recursively for cases like UAbilityTask_StartAbilityState.
Bug Fix: It is now safe to call Super::ActivateAbility in a child class. Previously, it would call CommitAbility.
Bug Fix: Added support for properly replicating different types of FGameplayEffectContext.
Bug Fix: FGameplayEffectContextHandle will now check if data is valid before retrieving "Actors".
Bug Fix: Retain rotation for Gameplay Ability System Target Data LocationInfo.
Bug Fix: Gameplay Ability System now stops searching for PC only if a valid PC is found.
Bug Fix: Use existing GameplayCueParameters if it exists instead of default parameters object in RemoveGameplayCue_Internal.
Bug Fix: GameplayAbilityWorldReticle now faces towards the source Actor instead of the TargetingActor.
Bug Fix: Cache trigger event data if it was passed in with GiveAbilityAndActivateOnce and the ability list was locked.
Bug Fix: Support has been added for the FInheritedGameplayTags to update its CombinedTags immediately rather than waiting until a Save.
Bug Fix: Moved ShouldAbilityRespondToEvent from client-only code path to both server and client.
Bug Fix: Fixed FAttributeSetInitterDiscreteLevels from not working in Cooked Builds due to Curve Simplification.
Bug Fix: Set CurrentEventData in GameplayAbility.
Bug Fix: Ensure MinimalReplicationTags are set up correctly before potentially executing callbacks.
Bug Fix: Fixed ShouldAbilityRespondToEvent from not getting called on the instanced GameplayAbility.
Bug Fix: Gameplay Cue Notify Actors executing on Child Actors no longer leak memory when gc.PendingKill is disabled.
Bug Fix: Fixed an issue in GameplayCueManager where GameplayCueNotify_Actors could be 'lost' due to hash collisions.
Bug Fix: WaitGameplayTagQuery will now respect its Query even if we have no Gameplay Tags on the Actor.
Bug Fix: PostAttributeChange and AttributeValueChangeDelegates will now have the correct OldValue.
Bug Fix: Fixed FGameplayTagQuery from not showing a proper Query Description if the struct was created by native code.
Bug Fix: Ensure that the UAbilitySystemGlobals::InitGlobalData is called if the Ability System is in use. Previously if the user did not call it, the Gameplay Ability System did not function correctly.
Bug Fix: Fixed issue when linking/unlinking anim layers from UGameplayAbility::EndAbility.
Bug Fix: Updated Ability System Component function to check the Spec's ability pointer before use.
New: Added a GameplayTagQuery field to FGameplayTagRequirements to enable more complex requirements to be specified.
New: Introduced FGameplayEffectQuery::SourceAggregateTagQuery to augment SourceTagQuery.
New: Extended the functonality to execute and cancel Gameplay Abilities & Gameplay Effects from a console command.
New: Added the ability to perform an "Audit" on Gameplay Ability Blueprints that will show information on how they're developed and intended to be used.
Change: OnAvatarSet is now called on the primary instance instead of the CDO for instanced per Actor Gameplay Abilities.
Change: Allow both Activate Ability and Activate Ability From Event in the same Gameplay Ability Graph.
Change: AnimTask_PlayMontageAndWait now has a toggle to allow Completed and Interrupted after a BlendOut event.
Change: ModMagnitudeCalc wrapper functions have been declared const.
Change: FGameplayTagQuery::Matches now returns false for empty queries.
Change: Updated FGameplayAttribute::PostSerialize to mark the contained attribute as a searchable name.
Change: Updated GetAbilitySystemComponent to default parameter to Self.
Change: Marked functions as virtual in AbilityTask_WaitTargetData.
Change: Removed unused function FGameplayAbilityTargetData::AddTargetDataToGameplayCueParameters.
Change: Removed vestigial GameplayAbility::SetMovementSyncPoint.
Change: Removed unused replication flag from Gameplay tasks & Ability system components.
Change: Moved some gameplay effect functionality into optional components. All existing content will automatically update to use components during PostCDOCompiled, if necessary. https://docs.unrealengine.com/5.3/en-US/unreal-engine-5.3-release-notes/`},{header:"5.2",slug:"_5-2",content:`Bug Fix: Fixed a crash in the UAbilitySystemBlueprintLibrary::MakeSpecHandle function.
Bug Fix: Fixed logic in the Gameplay Ability System where a non-Controlled Pawn would be considered remote, even if it was spawned locally on the server (e.g. Vehicles).
Bug Fix: Correctly set activation info on predicted instanced abilities that were rejected by the server.
Bug Fix: Fixed a bug that would cause GameplayCues to get stuck on remote instances.
Bug Fix: Fixed a memory stomp when chaining calls to WaitGameplayEvent.
Bug Fix: Calling the AbilitySystemComponent GetOwnedGameplayTags() function in Blueprint no longer retains the previous call's return values when the same node is executed multiple times.
Bug Fix: Fixed an issue with GameplayEffectContext replicating a reference to a dynamic object that would never be replicated. This prevented GameplayEffect from calling Owner->HandleDeferredGameplayCues(this) as bHasMoreUnmappedReferences would always be true. New: The Gameplay Targeting System is a way to create data-driven targeting requests.
New: Added custom serialization support for GameplayTag Queries.
New: Added support for replicating derived FGameplayEffectContext types.
New: Gameplay Attributes in assets are now registered as searchable names on save, allowing for references to attributes to be seen in the reference viewer.
New: Added some basic unit tests for the AbilitySystemComponent.
New: Gameplay Ability System Attributes now respect Core Redirects. This means you can now rename Attribute Sets and their Attributes in code and have them load properly in assets saved with the old names by adding redirect entries to DefaultEngine.ini.
Change: Allow changing the evaluation channel of a Gameplay Effect Modifier from code.
Change: Removed previously unused variable FGameplayModifierInfo::Magnitude from the Gameplay Abilities Plugin.
Change: Removed the synchronization logic between the ability system component and Smart Object instance tags. https://docs.unrealengine.com/5.2/en-US/unreal-engine-5.2-release-notes/`},{header:"5.1",slug:"_5-1",content:`Bug Fix: Fixed issue where replicated loose gameplay tags were not replicating to the owner.
Bug Fix: Fixed AbilityTask bug where abilities could be blocked from timely garbage-collection.
Bug Fix: Fixed an issue when a gameplay ability listening to activate based on a tag would fail to be activated. This would happen if there were more than one Gameplay Ability listening to this tag, and the first one in the list was invalid or didn't have authority to activate.
Bug Fix: Fixed GameplayEffects that use Data Registries correctly from warning on load and improved the warning text.
Bug Fix: Removed code from UGameplayAbility that was incorrectly only registering the last instanced ability with the Blueprint debugger for breakpoints.
Bug Fix: Fixed Gameplay Ability System Ability getting stuck if EndAbility was called during the lock inside ApplyGameplayEffectSpecToTarget.
New: Added support for Gameplay Effects to add blocked ability tags.
New: Added WaitGameplayTagQuery nodes. One is based off of the UAbilityTask and the other is of UAbilityAsync. This node specifies a TagQuery, and will trigger its output pin when the query becomes true or false, based on configuration.
New: Modified AbilityTask debugging in Console Variables to enable debug recording and printing to log by default in non-shipping builds (with ability to hotfix on/off as needed).
New: You can now set AbilitySystem.AbilityTask.Debug.RecordingEnabled to 0 to disable, 1 to enable in non-shipping builds, and 2 to enable all builds (including shipping).
New: You can use AbilitySystem.AbilityTask.Debug.AbilityTaskDebugPrintTopNResults to only print the top N results in log (to avoid log spam).
New: STAT_AbilityTaskDebugRecording can be used to test perf impact from these on-by-default debugging changes.
New: Added a debug command to filter GameplayCue events.
New: Added new debug commandsAbilitySystem.DebugAbilityTags, AbilitySystem.DebugBlockedTags, andAbilitySystem.DebugAttribute to the Gameplay Ability System.
New: Added a Blueprint function to get a debug string representation of a Gameplay Attribute.
New: Added a new Gameplay Task resource overlap policy to cancel existing tasks.
Change: Now Ability Tasks should make sure to call Super::OnDestroy only after they do anything needed to the Ability pointer, as it will be nulled out after calling it.
Change: Converted FGameplayAbilitySpec/Def::SourceObject to be a weak reference.
Change: Made a Ability System Component reference in the Ability Task a weak pointer so Garbage Collection can delete it.
Change: Removed redundant enum EWaitGameplayTagQueryAsyncTriggerCondition.
Change: GameplayTasksComponent and AbilitySystemComponent now support the registered subobject API.
Change: Added better logging to indicate why Gameplay Abilities failed to be activated.
Change: Removed AbilitySystem.Debug.NextTarget and PrevTarget commands in favor of global HUD NextDebugTarget and PrevDebugTarget commands. https://docs.unrealengine.com/5.1/en-US/unreal-engine-5.1-release-notes/`},{header:"5.0",slug:"_5-0",content:"https://docs.unrealengine.com/5.0/en-US/unreal-engine-5.0-release-notes/"},{header:"4.27",slug:"_4-27",content:`Crash Fix: Fixed a root motion source issue where a networked client could crash when an Actor finishes executing an ability that uses a constant force root motion task with a strength-over-time modifier.
Bug Fix: Fixed a regression in Editor loading time when using GameplayCues.
Bug Fix: GameplayEffectsContainer's SetActiveGameplayEffectLevel method will no longer dirty FastArray if setting the same EffectLevel.
Bug Fix: Fixed an edge case in GameplayEffect mixed replication mode where Actors not explicitly owned by the net connection but who utilize that connection from GetNetConnection will not received mixed replication updates.
Bug Fix: Fixed an endless recursion occuring in GameplayAbility's class method EndAbility which was called by calling EndAbility again from K2_OnEndAbility.
Bug Fix: GameplayTags Blueprint pins will no longer be silently cleared if they are loaded before tags are registered. They now work the same as GameplayTag variables, and the behavior for both can be changed with the ClearInvalidTags option in the Project Settings.
Bug Fix: Improved thread safety of GameplayTag operations.
New: Exposed SourceObject to GameplayAbility's K2_CanActivateAbility method.
New: Native GameplayTags. Introducing a new FNativeGameplayTag, these make it possible to do one off native tags that are correctly registered and unregistered when the module is loaded and unloaded.
New: Updated GiveAbilityAndActivateOnce to pass in FGameplayEventData parameter.
New: Improved ScalableFloats in the GameplayAbilities plugin to support dynamic lookup of curve tables from the new Data Registry System. Added a ScalableFloat header for easier reuse of the generic struct outside the abilities plugin.
New: Added code support for using the GameplayTag UI in other Editor customizations via GameplayTagsEditorModule.
New: Modified UGameplayAbility's PreActivate method to optionally take in trigger event data.
New: Added more support to filter GameplayTags in the Editor using a project-specific filter. OnFilterGameplayTag supplies the referencing property and the tag source, so you can filter tags based on what asset is requesting the tag.
New: Added option to preserve the original captured SourceTags when GameplayEffectSpec's class method SetContext is called after initialization.
New: Improved UI for registering GameplayTags from specific plugins. The new tag UI now lets you select a plugin location on disk for newly added GameplayTag sources.
New: A new track has been added to Sequencer to allow for triggering notify states on Actors built using the GameplayAbiltiySystem. Like notifies, the GameplayCueTrack can utilize range-based events or trigger-based events.
Change: Changed the GameplayCueInterface to pass GameplayCueParameters struct by reference.
Optimization: Made several performance improvements to loading and regenerating the GameplayTag table were implemented so that this option would be optimized. https://docs.unrealengine.com/en-US/WhatsNew/Builds/ReleaseNotes/4_27/`},{header:"4.26",slug:"_4-26",content:`GAS plugin is no longer flagged as beta.
Crash Fix: Fixed a crash when adding a gameplay tag without a valid tag source selection.
Crash Fix: Added the path string arg to a message to fix a crash in UGameplayCueManager::VerifyNotifyAssetIsInValidPath.
Crash Fix: Fixed an access violation crash in AbilitySystemComponent_Abilities when using a ptr without checking it.
Bug Fix: Fixed a bug where stacking GEs that did not reset the duration on additional instances of the effect being applied.
Bug Fix: Fixed an issue that caused CancelAllAbilities to only cancel non-instanced abilities.
New: Added optional tag parameters to gameplay ability commit functions.
New: Added StartTimeSeconds to PlayMontageAndWait ability task and improved comments.
New: Added tag container "DynamicAbilityTags" to FGameplayAbilitySpec. These are optional ability tags that are replicated with the spec. They are also captured as source tags by applied gameplay effects.
New: GameplayAbility IsLocallyControlled and HasAuthority functions are now callable from Blueprint.
New: Visual logger will now only collect and store info about instant GEs if we're currently recording visual logging data.
New: Added support for redirectors on gameplay attribute pins in blueprint nodes.
New: Added new functionality for when root motion movement related ability tasks end they will return the movement component's movement mode to the movement mode it was in before the task started. https://docs.unrealengine.com/en-US/WhatsNew/Builds/ReleaseNotes/4_26/`},{header:"4.25.1",slug:"_4-25-1",content:`Fixed! UE-92787 Crash saving blueprint with a Get Float Attribute node and the attribute pin is set inline
Fixed! UE-92810 Crash spawning actor with instance editable gameplay tag property that was changed inline`},{header:"4.25",slug:"_4-25",content:`Fixed prediction of RootMotionSource AbilityTasks
GAMEPLAYATTRIBUTE_REPNOTIFY() now additionally takes in the old Attribute value. We must supply that as the optional parameter to our OnRep functions. Previously, it was reading the attribute value to try to get the old value. However, if called from a replication function, the old value had already been discarded before reaching SetBaseAttributeValueFromReplication so we'd get the new value instead.
Added NetSecurityPolicy to UGameplayAbility.
Crash Fix: Fixed a crash when adding a gameplay tag without a valid tag source selection.
Crash Fix: Removed a few ways for attackers to crash a server through the ability system.
Crash Fix: We now make sure we have a GameplayEffect definition before checking tag requirements.
Bug Fix: Fixed an issue with gameplay tag categories not applying to function parameters in Blueprints if they were part of a function terminator node.
Bug Fix: Fixed an issue with gameplay effects' tags not being replicated with multiple viewports.
Bug Fix: Fixed a bug where a gameplay ability spec could be invalidated by the InternalTryActivateAbility function while looping through triggered abilities.
Bug Fix: Changed how we handle updating gameplay tags inside of tag count containers. When deferring the update of parent tags while removing gameplay tags, we will now call the change-related delegates after the parent tags have updated. This ensures that the tag table is in a consistent state when the delegates broadcast.
Bug Fix: We now make a copy of the spawned target actor array before iterating over it inside when confirming targets because some callbacks may modify the array.
Bug Fix: Fixed a bug where stacking GameplayEffects that did not reset the duration on additional instances of the effect being applied and with set by caller durations would only have the duration correctly set for the first instance on the stack. All other GE specs in the stack would have a duration of 1 second. Added automation tests to detect this case.
Bug Fix: Fixed a bug that could occur if handling gameplay event delegates modified the list of gameplay event delegates.
Bug Fix: Fixed a bug causing GiveAbilityAndActivateOnce to behave inconsistently.
Bug Fix: Reordered some operations inside FGameplayEffectSpec::Initialize to deal with a potential ordering dependency.
New: UGameplayAbility now has an OnRemoveAbility function. It follows the same pattern as OnGiveAbility and is only called on the primary instance of the ability or the class default object.
New: When displaying blocked ability tags, the debug text now includes the total number of blocked tags.
New: Renamed UAbilitySystemComponent::InternalServerTryActiveAbility to UAbilitySystemComponent::InternalServerTryActivateAbility.Code that was calling InternalServerTryActiveAbility should now call InternalServerTryActivateAbility.
New: Continue to use the filter text for displaying gameplay tags when a tag is added or deleted. The previous behavior cleared the filter.
New: Don't reset the tag source when we add a new tag in the editor.
New: Added the ability to query an ability system component for all active gameplay effects that have a specified set of tags. The new function is called GetActiveEffectsWithAllTags and can be accessed through code or blueprints.
New: When root motion movement related ability tasks end they now return the movement component's movement mode to the movement mode it was in before the task started.
New: Made SpawnedAttributes transient so it won't save data that can become stale and incorrect. Added null checks to prevent any currently saved stale data from propagating. This prevents problems related to bad data getting stored in SpawnedAttributes.
API Change: AddDefaultSubobjectSet has been deprecated. AddAttributeSetSubobject should be used instead.
New: Gameplay Abilities can now specify the Anim Instance on which to play a montage. https://docs.unrealengine.com/en-US/WhatsNew/Builds/ReleaseNotes/4_25/`},{header:"4.24",slug:"_4-24",content:`Fixed blueprint node Attribute variables resetting to None on compile.
Need to call UAbilitySystemGlobals::InitGlobalData() to use TargetData otherwise you will get ScriptStructCache errors and clients will be disconnected from the server. My advice is to always call this in every project now whereas before 4.24 it was optional.
Fixed crash when copying a GameplayTag setter to a blueprint that didn't have the variable previously defined.
UGameplayAbility::MontageStop() function now properly uses the OverrideBlendOutTime parameter.
Fixed GameplayTag query variables on components not being modified when edited.
Added the ability for GameplayEffectExecutionCalculations to support scoped modifiers against "temporary variables" that aren't required to be backed by an attribute capture. Implementation basically enables GameplayTag-identified aggregators to be created as a means for an execution to expose a temporary value to be manipulated with scoped modifiers; you can now build formulas that want manipulatable values that don't need to be captured from a source or target.
To use, an execution has to add a tag to the new member variable ValidTransientAggregatorIdentifiers; those tags will show up in the calculation modifier array of scoped mods at the bottom, marked as temporary variables—with updated details customizations accordingly to support feature Added restricted tag quality-of-life improvements. Removed the default option for restricted GameplayTag source. We no longer reset the source when adding restricted tags to make it easier to add several in a row.
APawn::PossessedBy() now sets the owner of the Pawn to the new Controller. Useful because Mixed Replication Mode expects the owner of the Pawn to be the Controller if the ASC lives on the Pawn.
Fixed bug with POD (Plain Old Data) in FAttributeSetInitterDiscreteLevels. https://docs.unrealengine.com/en-US/WhatsNew/Builds/ReleaseNotes/4_24/`}]},{path:"/GameEngine/Unreal/manual/GameplayAbilitySystem.html",title:"Gameplay Ability System",pathLocale:"/",contents:[{header:"Gameplay Ability System",slug:"gameplay-ability-system",content:`Alt text Ability System Component：控制技能生命周期。
Attribute Set：数据配置
Gameplay Ability：技能逻辑
Ability Task：技能执行在一帧，可以设置不同的回调也就是任务，来响应技能执行。
Gameplay Effect：技能产生的影响，修改了那些数据。
Gameplay Cue：技能相关的音效，粒子效果，相机抖动等。
Gameplay Tag：描述物体的状态或数据，可以用来控制技能的释放等。`},{header:"Ability System Component",slug:"ability-system-component",content:`Alt text
Ability System Component和Attribute Set可以放在Pawn上也可以放在Player State。他们的区别是Pawn会在游戏中会被销毁，那么技能系统也就销毁了。`},{header:"Init Ability Actor Info",slug:"init-ability-actor-info",content:`当ASC在不同的宿主上时，初始化的地方各有不同，主要原因是要确保Controller已经被初始化。
Alt text
ASC可以有两种类型的宿主，在初始化ASC时，使用该函数：
void UAbilitySystemComponent::InitAbilityActorInfo(AActor* InOwnerActor, AActor* InAvatarActor) InOwnerActor 逻辑上的宿主
InAvatarActor 游戏世界里物理宿主 在多人游戏中一般可以这样设置：
Alt text`},{header:"EGameplayEffectReplicationMode",slug:"egameplayeffectreplicationmode",content:`Replication
Use Case
Description Full
Single Player
Gameplay Effects are replicated to all clients Mixed
Multiplayer, Player-Controlled
Game Effects are replicated to the owning client only. Gameplay Cues and Gameplay Tags replicated to all clients. Minimal
Multiplayer, AI-Controlled
Gameplay Effects are NOT replicated. Gameplay Cues and Gameplay Tags replicated to all clients. 当设置为Mixed时，ASC的拥有者必须是Controller。PlayerState会自动转换为Controller。如果是其他的类型，就需要调用SetOwner()把ASC设置到Controller上。
使用蓝图库来获取该组件：
#include "AbilitySystemBlueprintLibrary.h"
UAbilitySystemBlueprintLibrary::GetAbilitySystemComponent(AActor* Target);`},{header:"Attribute Set",slug:"attribute-set",content:`使用下面的宏来设置属性函数：
#include "AbilitySystemComponent.h" #define ATTRIBUTE_ACCESSORS(ClassName, PropertyName) \\ GAMEPLAYATTRIBUTE_PROPERTY_GETTER(ClassName, PropertyName) \\ GAMEPLAYATTRIBUTE_VALUE_GETTER(PropertyName) \\ GAMEPLAYATTRIBUTE_VALUE_SETTER(PropertyName) \\ GAMEPLAYATTRIBUTE_VALUE_INITTER(PropertyName) 头文件实列： UPROPERTY(BlueprintReadOnly, ReplicatedUsing = OnRep_Health, Category = "Vital Attributes") FGameplayAttributeData Health; ATTRIBUTE_ACCESSORS(ThisClass, Health); UFUNCTION() void OnRep_Health(const FGameplayAttributeData& OldHealth); 类实列：
void UAuraAttributeSet::GetLifetimeReplicatedProps(TArray<class FLifetimeProperty>& OutLifetimeProps) const
{ Super::GetLifetimeReplicatedProps(OutLifetimeProps); DOREPLIFETIME_CONDITION_NOTIFY(ThisClass, Health, COND_None, REPNOTIFY_Always);
} void UAuraAttributeSet::OnRep_Health(const FGameplayAttributeData& OldHealth)
{ GAMEPLAYATTRIBUTE_REPNOTIFY(ThisClass, Health, OldHealth);
}`},{header:"BaseValue vs CurrentValue",slug:"basevalue-vs-currentvalue",content:`一个Attribute是由两个数值组成的： BaseValue：在一段时间内的永久的值(GameplayEffectExecute执行期间)
CurrentValue：BaseValue+GameplayEffect的临时修改值 在GameplayEffect Execute对Atrribute进行修改时，BaseValue在这个期间是不做修改的。CurrentValue是实时在修改的。在Debug中显示的数值一直都是CurrentValue。
不过GameplayEffect设置的Scalabe Float 如下图：
GameplayEffect Scalabe Float
BaseValue 最先被修改，之后再是CurrentValue。其中回调的顺序为：
PreAttributeBaseChange->PreAttributeChange->PostAttributeChange->PostAttributeBaseChange->PostGameplayEffectExecute`},{header:"使用DataTable初始化",slug:"使用datatable初始化",content:"创建 FAttributeMetaData的DataTable，配置如下： 行的名字为C++中AttributeSet类型名字+属性名字，然后把这个数据表配置到PlayerSate->Attribute Test->Default Starting Data上即可。 这种方式并不是良策，常见的初始化属性值：直接对ACS添加一个初始化的GameplayEffect。"},{header:"常用函数",slug:"常用函数",content:`PreAttributeBaseChange(const FGameplayAttribute& Attribute, float& NewValue) const：BaseValue在修改前，调用。
PreAttributeChange(const FGameplayAttribute& Attribute, float& NewValue) ：CurrentValue在修改前，调用。
PostAttributeChange(const FGameplayAttribute& Attribute, float OldValue, float NewValue)：CurrentValue在修改后，调用。
PostAttributeBaseChange(const FGameplayAttribute& Attribute, float OldValue, float NewValue) const：BaseValue在修改后，调用。
PostGameplayEffectExecute(const struct FGameplayEffectModCallbackData &Data):在一个GameplayEffect执行修改数据之前，调用。 **注意：在PreAttributeChange函数中对NewValue进行范围设置，只会影响到当前数据的变化，并不会影响到基础数据，所以需要在PostGameplayEffectExecute函数中再对基础数据做出范围设置，Epic 推荐在每一次Attribute被修改后都做一次范围设置，也就是监听UAbilitySystemComponent::GetGameplayAttributeValueChangeDelegate(FGameplayAttribute Attribute)委托 **`},{header:"Gameplay Effect",slug:"gameplay-effect",content:`Alt text
执行规则： Instant 一次
Has Duration 一段时间
Infinite 无限次`},{header:"Periodic Gameplay Effects",slug:"periodic-gameplay-effects",content:`Alt text
在一段时间内定期修改基础数值`},{header:"Stacking",slug:"stacking",content:""},{header:"Aggregate by Soucre",slug:"aggregate-by-soucre",content:"Alt text"},{header:"Aggregate by Soucre",slug:"aggregate-by-soucre-1",content:"Alt text"},{header:"Modifiers Magnitdue",slug:"modifiers-magnitdue",content:`更改的操作有4种： Operation
Description Add
在指定的Attribute上加上配置的数值，使用负数来实现减法。 Multiply
Multiplies the result to the Modifier's specified Attribute. Divide
Divides the result against the Modifier's specified Attribute. Override
Overrides the Modifier's specified Attribute with the result. 有4种修改器： Modifier Type
Description Scalable Float
FScalableFloats are a structure that can point to a Data Table that has the variables as rows and levels as columns. The Scalable Floats will automatically read the value of the specified table row at the ability's current level (or different level if overriden on the GameplayEffectSpec). This value can further be manipulated by a coefficient. If no Data Table/Row is specified, it treats the value as a 1 so the coefficient can be used to hard code in a single value at all levels. Attribute Based
Attribute Based Modifiers take the CurrentValue or BaseValue of a backing Attribute on the Source (who created the GameplayEffectSpec) or Target (who received the GameplayEffectSpec) and further modifies it with a coefficient and pre and post coefficient additions. Snapshotting means the backing Attribute is captured when the GameplayEffectSpec is created whereas no snapshotting means the Attribute is captured when the GameplayEffectSpec is applied. Custom Calculation Class
Custom Calculation Class provides the most flexibility for complex Modifiers. This Modifier takes a ModifierMagnitudeCalculation class and can further manipulate the resulting float value with a coefficient and pre and post coefficient additions. Set By Caller
SetByCaller Modifiers are values that are set outside of the GameplayEffect at runtime by the ability or whoever made the GameplayEffectSpec on the GameplayEffectSpec. For example, you would use a SetByCaller if you want to set the damage to be based on how long the player held down a button to charge the ability. SetByCallers are essentially TMap<FGameplayTag, float> that live on the GameplayEffectSpec. The Modifier is just telling the Aggregator to look for a SetByCaller value associated with the supplied GameplayTag. The SetByCallers used by Modifiers can only use the GameplayTag version of the concept. The FName version is disabled here. If the Modifier is set to SetByCaller but a SetByCaller with the correct GameplayTag does not exist on the GameplayEffectSpec, the game will throw a runtime error and return a value of 0. This might cause issues in the case of a Divide operation. See SetByCallers for more information on how to use SetByCallers.`},{header:"Modifiers Order of Operation",slug:"modifiers-order-of-operation",content:"执行顺序是从上往下。"},{header:"Attribute Base Modifier Coefficeient",slug:"attribute-base-modifier-coefficeient",content:"与预先处理基础数据。"},{header:"Custom Calculation",slug:"custom-calculation",content:"Custom Calculation"},{header:"Execution Calculation",slug:"execution-calculation",content:""},{header:"Set By Caller",slug:"set-by-caller",content:"使用UAbilitySystemBlueprintLibrary::AssignTagSetByCallerMagnitude(SpecHandle, GameplayTags.Damage, 50.f);函数来设置Tag对于的数值。"},{header:"Tags",slug:"tags",content:`GameplayEffect中的Tag配置：
Alt text Category
Description Gameplay Effect Asset Tags
Tags that the GameplayEffect has. They do not do any function on their own and serve only the purpose of describing the GameplayEffect. Granted Tags
Tags that live on the GameplayEffect but are also given to the ASC that the GameplayEffect is applied to. They are removed from the ASC when the GameplayEffect is removed. This only works for Duration and Infinite GameplayEffects. Ongoing Tag Requirements
Once applied, these tags determine whether the GameplayEffect is on or off. A GameplayEffect can be off and still be applied. If a GameplayEffect is off due to failing the Ongoing Tag Requirements, but the requirements are then met, the GameplayEffect will turn on again and reapply its modifiers. This only works for Duration and Infinite GameplayEffects. Application Tag Requirements
Tags on the Target that determine if a GameplayEffect can be applied to the Target. If these requirements are not met, the GameplayEffect is not applied. Remove Gameplay Effects with Tags
GameplayEffects on the Target that have any of these tags in their Asset Tags or Granted Tags will be removed from the Target when this GameplayEffect is successfully applied. 以上设置在5.3之前还是有的，在5.3中是把上面的属性设置到组件里如图：
Alt text Gameplay Effect
Component Description UChanceToApplyGameplayEffectComponent
应用Gameplay效果的率。 UBlockAbilityTagsGameplayEffectComponent
根据所有者Gameplay效果目标Actor的Gameplay标签，进行Gameplay技能激活阻止处理。 UAssetTagsGameplayEffectComponent
Gameplay效果资产拥有的标签。这些标签 不会 转移到Actor。 UAdditionalEffectsGameplayEffectComponent
添加尝试在特定条件下激活（或任何条件下都不激活）的其他Gameplay效果。 UTargetTagsGameplayEffectComponent
将标签授予Gameplay效果的目标（有时指所有者），在效果结束时会自动取消掉该标签。只在Duration模式下，生效且在开启Stack限制时，只会添加一此在对象上。 UTargetTagRequirementsGameplayEffectComponent
指定如果此GE须应用或继续执行，目标（Gameplay效果的拥有者）必须具备的标签要求。 URemoveOtherGameplayEffectComponent
基于某些条件移除其他Gameplay效果。 UCustomCanApplyGameplayEffectComponent
处理CustomApplicationRequirement函数的配置，以查看是否应该应用此Gameplay效果。 UImmunityGameplayEffectComponent
免疫会阻止其他GameplayEffectSpecs的应用。`},{header:"GameplayEffectContext",slug:"gameplayeffectcontext",content:`可以自定义FGameplayEffectContext，用来存储技能中使用到的一些数据。不过一定需要重写以下两个东西：
/** Returns the actual struct used for serialization,subclasses must override this! */
virtual UScriptStruct* GetScriptStruct() const override
{ return FAuraGameplayEffectContext::StaticStruct();
} template <>
struct TStructOpsTypeTraits<FAuraGameplayEffectContext> : public TStructOpsTypeTraitsBase2<FAuraGameplayEffectContext>
{ enum { WithNetSerializer = true, WithCopy = true // Necessary so that TSharedPtr<FHitResult> Data is copied around };
}; 如果还需要网络同步的话，需要重写： /** Custom serialization, subclasses must override this */ virtual bool NetSerialize(FArchive& Ar, class UPackageMap* Map, bool& bOutSuccess) override;`},{header:"Gameplay Ability",slug:"gameplay-ability",content:`可以简单总结为以下几点： 一定定义了技能或能力的类
必须被生成 在服务器上生成
Spec复制给对应的客户端 使用Activated方法来使用
激活需要消耗，也有冷却
异步执行 同一时间激活多个 技能任务 异步表现不同操作`},{header:"Tags",slug:"tags-1",content:`Gameplay Tag
Description Ability Tags
该技能拥有的标签 Cancel Abilities with Tag
激活该技能时，取消带有这些标签的所有技能 Block Abilities with Tag
激活该技能时，锁定带有这些标签的所有技能 Activation Owned Tags
激活该技能时，把这些标签赋予激活对象。在AbilitySystemGlobals中开启ReplicateActivationOwnedTags，这些标签会被复制。 Activation Required Tags
该技能只能在拥有这些标签的Actor/Component上激活 Activation Blocked Tags
该技能被锁定，如果激活对象Actor/Component上有这些标签 Source Required Tags
激活源Actor/Component上有所有这些标签才能激活这个技能 Source Blocked Tags
激活源Actor/Component上有所有这些标签，该技能被锁定 Target Required Tags
激活目标Actor/Component上有所有这些标签才能激活这个技能 Target Blocked Tags
激活目标Actor/Component上有所有这些标签，该技能被锁定`},{header:"Instancing Policy",slug:"instancing-policy",content:`Instancing Policy
Description
Details Instanced Per Actor
一个单例在能力被创建时，每一次激活复用
可以存储持久数据。每次激活，变量必须手动重置。 Instanced Per Execution
每激活一次，创建一个实例
不能存储两次激活之间的数据。 Non-Instanced
只有默认类对象，没有实例，静态类
不能存储状态，不能绑定回调任务。`},{header:"Net Execution Policy",slug:"net-execution-policy",content:`Net Execution Policy
Description Local Only
只在客户端上运行，不在服务器运行。 Local Predicted
先在客户端上激活，然后在服务器上。本地使用预测。服务器可以回滚非法改变 Server Only
只在服务器上运行 Server Initiated
现在服务器上运行，然后在对于客户端上执行`},{header:"Things Not to Use",slug:"things-not-to-use",content:""},{header:"Enhanced Input",slug:"enhanced-input",content:`Input Action are bound to inputs via the Input Mapping Context.
We can decide how to activate abilities in response to inputs. Lyra provides one example
We'll use a similar approach (though less complicated) Data Driven Change Input-to-Ability mappings at runtime`},{header:"Cost",slug:"cost",content:"在GA面板上设置特定的GE即可。 在GE中设置需要扣除的属性即可。需要在技能激活时调用CommitAbilityCost执行扣除逻辑。"},{header:"Cooldown",slug:"cooldown",content:`在GA面板上设置特定的GE即可。 该GE需要特殊设置两个参数： Duration Policy：改为时间持续，这里的时间即为CD时间。
设置专属冷却Tag，这个标签是用来判断冷却是否结束。`},{header:"Ability Task",slug:"ability-task",content:""},{header:"Target Data",slug:"target-data",content:"如果需要使用这个数据，需要调用初始化: // This is required to use Target Data UAbilitySystemGlobals::Get().InitGlobalData(); 使用ServerSetReplicatedTargetData()把数据复制到服务器"},{header:"Wait Gameplay Event",slug:"wait-gameplay-event",content:"如果技能不是每次激活生成新的对象，最好把OnlyTriggerOnce选择上，防止多次触发。"},{header:"Gameplay Cue",slug:"gameplay-cue",content:""},{header:"Gameplay Tag",slug:"gameplay-tag",content:`Alt text
可以多出使用Tag： Inputs
Abilities
Attributes
Damage Types
Buffs/Debuffs
Messages
Data
Anything you want！ 管理所有Tags： 存在Config/DefaultGameplayTags.ini文件中
-Edit->Project Setting->GameplayTags
使用DataTable创建GameplayTagTableRow数据表，需要配置到项目设置中的Gameplay Tag Table List 如果直接在编辑器下定义，需要在C++中使用，可以使用这个API：
FGameplayTag::RequestGameplayTag("Ability.Attack", false) 在c++中声明自定义Tag，使用UGameplayTagsManager::Get().AddNativeGameplayTag()： // 头文件
#include "GameplayTagContainer.h" struct FAuraGameplayTags
{
public: static const FAuraGameplayTags& Get() { return GameplayTags; } static void InitNativeGameplayTags(); public: FGameplayTag Attributes_Primary_Strength;
private: static FAuraGameplayTags GameplayTags;
}; //源文件
#include "GameplayTagsManager.h" FAuraGameplayTags FAuraGameplayTags::GameplayTags; void FAuraGameplayTags::InitNativeGameplayTags()
{ GameplayTags.Attributes_Primary_Strength = UGameplayTagsManager::Get().AddNativeGameplayTag(FName("Attributes.Primary.Strength"), FString("Test Des."));
} 在c++中最简单的方式定义：
// 放在头文件其他模块可用
UE_DEFINE_GAMEPLAY_TAG(TagName,"Tag");
// 放在源文件中独立存在
UE_DEFINE_GAMEPLAY_TAG_STATIC(TagName,"Tag");`},{header:"Prediction",slug:"prediction",content:"如果客户端使用一个技能，向服务器请求，然后服务器确认给客户端。这里的时间差就会很久。 预测就是，客户端先执行需要使用的技能，同时向服务器发送。服务器在验证后，如果正常就不需要做什么，如果不正常需要取消客户端的技能操作。"},{header:"GAS Automatically Predicts",slug:"gas-automatically-predicts",content:`Gameplay Ability Activation
Triggered Events
Gameplay Effect Application Attribute Modifiers (not Execution Calculations)
GameplayTag Modification Gameplay Cue Events From within a predicted Gameplay Ability
Their own Events Montages
Movement (UCharacterMovement)`},{header:"GAS Does NOT Predict",slug:"gas-does-not-predict",content:`Gameplay Effect Removal
Gameplay Effect Periodic Effects`},{header:"Prediction Key",slug:"prediction-key",content:""},{header:"Ability Activation",slug:"ability-activation",content:""},{header:"Gameplay Effects Prediction",slug:"gameplay-effects-prediction",content:`Side effects
Only applied on Clients if: There is a valid prediction key The following are predicted: Attribute Modifications
Gameplay Tag Modifcations
Gameplay Cues When the FActiveGameplayEffect is created Stores the Prediction key (Active Gameplay Effect) On the server, it gets the same key
FActiveGameplayEffect is replicated Client checks the key
If they match, then "OnApplied" logic doesn't need to be done`},{header:"More Info",slug:"more-info",content:"GameplayPrediction.h"},{header:"Replication Mode",slug:"replication-mode",content:`Replication Mode
Use Case
Description Full
Single Player
Gameplay Effects are replicated to all clients Mixed
Multiplayer,Player-Controlled
Gameplay Effects are replicated to the owning client only. Gameplay Cues and Gameplay Tags replicated to all clients. Minimal
Multiplayer,AI-Controlled
GamePlay Effects are not replicated. Gameplay Cues and Gameplay Tags replicated to all clients.`},{header:"Saving Progress",slug:"saving-progress",content:"alt text"},{header:"Debug",slug:"debug",content:`调试命令：ShowDebug AbilitySystem
可以使用插件GASAttachEditor。可以看到角色的技能和Tag等信息。`},{header:"Reference",slug:"reference",content:`https://docs.unrealengine.com/5.0/en-US/gameplay-ability-system-for-unreal-engine/
https://github.com/tranek/GASDocumentation#intro`}]},{path:"/GameEngine/Unreal/manual/HotFix.html",title:"热更",pathLocale:"/",contents:[{header:"热更",slug:"热更",content:""},{header:"资源",slug:"资源",content:`使用插件HotPatcher，具体操作查看文档地址：https://imzlp.com/posts/17590/。
遇到一个问题：Io Store不能被打开: 所以在Project Settings -> Packaging -> Use Io Stroe 要取消，导出的pkg包就可以更新成功。
至于为什么没被打开，是因为CookPatchAssets打开时，Io Store是不被可用的。`},{header:"代码",slug:"代码",content:`比较成熟的解决方案： puerts 鸣潮一些实践建议
https://www.bilibili.com/video/BV1ms4y1T7Q UnLua`}]},{path:"/GameEngine/Unreal/manual/Interface.html",title:"Interface",pathLocale:"/",contents:[{header:"Interface",slug:"interface",content:`下面是一个简单的接口示例：
#pragma once
#include "CoreMinimal.h"
#include "DoSomeThings.generated.h" UINTERFACE(MinimalAPI)
class UDoSomeThings : public UInterface
{ GENERATED_BODY() // This will always be empty!
}; class YOURPROJECT_API IDoSomeThings
{ GENERATED_BODY()
public: // Get the number of things UFUNCTION(BlueprintCallable, BlueprintNativeEvent, Category="Things") int GetNumberOfThings();
}; 继承接口的类：
#pragma once #include "CoreMinimal.h"
#include "DoSomeThings.h"
#include "SomeThingsActor.generated.h" UCLASS(Blueprintable)
class YOURPROJECT_API ASomeThingsActor : public AActor, public IDoSomeThings
{ GENERATED_BODY()
public: virtual int GetNumberOfThings_Implementation() override;
}; #include "SomeThingsActor.h" int ASomeThingsActor::GetNumberOfThings_Implementation()
{ return 1;
} UE中C++的接口有一些特别使用方法，下面记录一下：`},{header:"BlueprintNativeEvent",slug:"blueprintnativeevent",content:`在接口里使用BlueprintNativeEvent来标记方法为虚方法，而不是直接使用virtual。这样做的好处是可以在蓝图实现也可以在C++里使用，与此同时可以在C++中不实现该接口方法也是可以的。
最重要的是在调用接口方法时不需要手动强转一次，虚幻提供了专用的调用方式：
int Num = IDoSomeThings::Execute_GetNumberOfThings(SomethingInstance);`},{header:"Implements",slug:"implements",content:`判断一个对象是否继承与一个接口，使用U开头的类来判读，而不是I开头的。
if (Actor && Actor->Implements<UDoSomeThings>())
{ // Use the interface
}`},{header:"Storing Interfaces As Variables",slug:"storing-interfaces-as-variables",content:`把接口作为类的变量，官方提供了TScriptInterface<>来存储，不过这种方式很容易出错，所以这里并不推荐。直接使用UObject存储更加合适。
UPROPERTY(BlueprintReadWrite)
UObject* SomethingInstance; 在调用接口函数时也更加方便，因为Execute方法传入的时UObject：
// I'm assuming here that we checked the object supported the interface before saving
// it to the variable; if not we should check for that as well as nulls
if (SomethingInstance)
{ int Num = IDoSomeThings::Execute_GetNumberOfThings(SomethingInstance);
}`},{header:"Reference",slug:"reference",content:`UE4 C++ Interfaces - Hints n Tips
https://dev.epicgames.com/community/learning/tutorials/bLXe/interfaces-bp-c
https://dev.epicgames.com/documentation/en-us/unreal-engine/interfaces-in-unreal-engine`}]},{path:"/GameEngine/Unreal/manual/Level.html",title:"Level",pathLocale:"/",contents:[{header:"Level",slug:"level",content:""},{header:"多人游戏连接",slug:"多人游戏连接",content:`在打开场景的时候，可以设置当前场景是listen状态，然后另一台电脑可以直接使用命令行Open Ip进入，这有点东西。 同样可以使用代码加载关卡以及开启服务器： UWorld* world = GetWorld(); if (world) { // /Game/ = Content floder // ?listen, set the level is a listen server world->ServerTravel("/Game/ThirdPerson/Maps/Lobby?listen"); } 加入服务器可以使用：
UGameplayStatics::OpenLevel(this, IPAddress); 或者使用： APlayerController* playerController = GetGameInstance()->GetFirstLocalPlayerController(); if (playerController) { playerController->ClientTravel(IPAddress, ETravelType::TRAVEL_Absolute); }`},{header:"无缝加载：Seamless travel",slug:"无缝加载-seamless-travel",content:"不能使用无缝加载： 无缝加载："}]},{path:"/GameEngine/Unreal/manual/Load.html",title:"Load",pathLocale:"/",contents:[{header:"Load",slug:"load",content:`加载使用LoadObject与ConstructorHelper区别：
ConstructorHelper：静态加载，只能在构造函数中调用
LoadObject：动态加载，但是不能加载蓝图类`}]},{path:"/GameEngine/Unreal/manual/Log.html",title:"Log",pathLocale:"/",contents:[{header:"Log",slug:"log",content:`使用UE_LOG时，前面的频道可以使用
CORE_API DECLARE_LOG_CATEGORY_EXTERN(YourChannel, Log, All); 声明自定义频道与类型
官方自带的声明，可以在\\Engine\\Source\\Runtime\\Core\\Public\\CoreGlobals.h中查看
CORE_API DECLARE_LOG_CATEGORY_EXTERN(LogHAL, Log, All);
CORE_API DECLARE_LOG_CATEGORY_EXTERN(LogSerialization, Log, All);
CORE_API DECLARE_LOG_CATEGORY_EXTERN(LogUnrealMath, Log, All);
CORE_API DECLARE_LOG_CATEGORY_EXTERN(LogUnrealMatrix, Log, All);
CORE_API DECLARE_LOG_CATEGORY_EXTERN(LogContentComparisonCommandlet, Log, All);
CORE_API DECLARE_LOG_CATEGORY_EXTERN(LogNetPackageMap, Warning, All);
CORE_API DECLARE_LOG_CATEGORY_EXTERN(LogNetSerialization, Warning, All);
CORE_API DECLARE_LOG_CATEGORY_EXTERN(LogMemory, Log, All);
CORE_API DECLARE_LOG_CATEGORY_EXTERN(LogProfilingDebugging, Log, All);
CORE_API DECLARE_LOG_CATEGORY_EXTERN(LogCore, Log, All);
CORE_API DECLARE_LOG_CATEGORY_EXTERN(LogOutputDevice, Log, All); CORE_API DECLARE_LOG_CATEGORY_EXTERN(LogSHA, Warning, All);
CORE_API DECLARE_LOG_CATEGORY_EXTERN(LogStats, Log, All);
CORE_API DECLARE_LOG_CATEGORY_EXTERN(LogStreaming, Display, All);
CORE_API DECLARE_LOG_CATEGORY_EXTERN(LogInit, Log, All);
CORE_API DECLARE_LOG_CATEGORY_EXTERN(LogExit, Log, All);
CORE_API DECLARE_LOG_CATEGORY_EXTERN(LogExec, Warning, All);
CORE_API DECLARE_LOG_CATEGORY_EXTERN(LogScript, Warning, All);
CORE_API DECLARE_LOG_CATEGORY_EXTERN(LogLocalization, Error, All);
CORE_API DECLARE_LOG_CATEGORY_EXTERN(LogLongPackageNames, Log, All);
CORE_API DECLARE_LOG_CATEGORY_EXTERN(LogProcess, Log, All);
CORE_API DECLARE_LOG_CATEGORY_EXTERN(LogLoad, Log, All); 使用:
int intVar = 5;
float floatVar = 3.7f;
FString fstringVar = "an fstring variable";
UE_LOG(LogTemp, Warning, TEXT("Text, %d %f %s"), intVar, floatVar, *fstringVar );`}]},{path:"/GameEngine/Unreal/manual/LyraALS.html",title:"Lyra ALS",pathLocale:"/",contents:[{header:"Lyra ALS",slug:"lyra-als",content:"这篇文章是课程 Unreal engine 5:Advance locomotion system ALS (Intermediate) 的笔记。这个课程就是重新实现了一遍Lyra工程中的角色动画，工程仓库：https://github.com/BanMing/LyraALS。课程是全蓝图，我在实现时，把蓝图转换为C++了。"},{header:"Idle Animation",slug:"idle-animation",content:""},{header:"Idle Switch",slug:"idle-switch",content:"有四种实现方式："},{header:"状态机",slug:"状态机",content:""},{header:"Transition Rule Sharing",slug:"transition-rule-sharing",content:"共享跳转条件，在转换条件中可以设置："},{header:"通过整数混合",slug:"通过整数混合",content:""},{header:"通过枚举混合",slug:"通过枚举混合",content:""},{header:"序列播放器",slug:"序列播放器",content:`使用Update方法绑定 这里使用的了惯性插值。这是一个对性能友好的插值。具体讲解：
https://dev.epicgames.com/documentation/en-us/unreal-engine/animation-blueprint-blendnodes-in-unreal-engine#inertialization`},{header:"Linked Animations",slug:"linked-animations",content:""},{header:"Animation Layer",slug:"animation-layer",content:"Animation Layer就是在动画图中的函数，用来封装动画图的中的逻辑。"},{header:"Animation Layer Interface",slug:"animation-layer-interface",content:"跟动画蓝图的接口差不多，只是它适用于动画蓝图，创建位置： 设置位置跟蓝图接口位置一样。 设置后，直接在动画蓝图的Animation Layers中找到在接口里声明的方法实现即可。"},{header:"LinkAnimClassLayers",slug:"linkanimclasslayers",content:`可以使用 LinkAnimClassLayers 方法实现重载动画蓝图接口。简单来说：
动画蓝图层级接口类 I 中有 IdleLayer动画蓝图A继承接口I，实现IdleLayer动画蓝图B继承接口I，实现IdleLayer在角色的Mesh上设置动画蓝图A• 在运行时，可以把动画蓝图A中的IdleLayer替换为动画蓝图B的实现。
文档：https://dev.epicgames.com/documentation/en-us/unreal-engine/animation-in-lyrasample-game-in-unreal-engine#linkedlayeranimationblueprint​`},{header:"Property Access",slug:"property-access",content:`文档：https://dev.epicgames.com/documentation/en-us/unreal-engine/property-access-inunreal-engine
可以在非游戏线程中访问游戏线程的数据，这里有个比较特殊的点是在定义绑定方法的返回值时，返回值的名字一定是 ReturnValue 关于在 c++ 中使用这个属性：https://forums.unrealengine.com/t/animation-property-access-system-in-c/541917/17。
直接重载这个方法，在该方法中编写数据即可。
virtual void NativeThreadSafeUpdateAnimation(float DeltaSeconds) override;`},{header:"Locomotion Cycle Animation",slug:"locomotion-cycle-animation",content:""},{header:"Root Motion",slug:"root-motion",content:"值得注意的是，角色的移动是由程序来控制，但是为了解决滑步和45°移动这些问题，使用了插件Motion Warping，这个插件是去处理在动画使用Root Motion时，程序介入改变Root Motion移动的位置或旋转。所以在动画设置中既需要打开Root Motion，也需要打开Force Root Lock。"},{header:"CalculateDirection",slug:"calculatedirection",content:`UKismetAnimationLibrary::CalculateDirection 这个方法十分有用，用来计算速度和角色之间的夹角。
/** * Returns degree of the angle between Velocity and Rotation forward vector * The range of return will be from [-180, 180]. Useful for feeding directional blendspaces. * @param Velocity The velocity to use as direction relative to BaseRotation * @param BaseRotation The base rotation, e.g. of a pawn */
UFUNCTION(BlueprintPure, Category="Animation|Utilities")
static ANIMGRAPHRUNTIME_API float CalculateDirection(const FVector& Velocity, const FRotator& BaseRotation);`},{header:"Dead Zone",slug:"dead-zone",content:`把移动动画分为4个方向，为了解决角色已经在某个方向了，在此方向稍微偏移一点角度，角色就会立马改变方向的问题，设计一个缓冲区域。也就是扩大当前方向的角度。
// // // // // // // // // // // // // // //
// ForwardMin Forward BackwardMax
// ↖ 0° ↗
// - - - - - - -
// | ↖ | ↑ | ↗ |
// - - - - - - -
// -90° Left | ← | o | → | Right 90°
// - - - - - - -
// | ↙ | ↓ | ↘ |
// - - - - - - -
// ↙ -180°/180° ↘
// BackwardMin Backward BackwardMax
// // // // // // // // // // // // // // // // Check dead zone
switch (CurrentDirection)
{ case ELocomotionDirection::Forward: if (CurVelocityLocomotionAngle > ForwardMin - DeadZone && CurVelocityLocomotionAngle < ForwardMax + DeadZone) { return ELocomotionDirection::Forward; } break; case ELocomotionDirection::Backward: if (CurVelocityLocomotionAngle > BackwardMax - DeadZone || CurVelocityLocomotionAngle < BackwardMin + DeadZone) { return ELocomotionDirection::Backward; } break; case ELocomotionDirection::Left: if (CurVelocityLocomotionAngle > BackwardMin - DeadZone && CurVelocityLocomotionAngle < ForwardMin + DeadZone) { return ELocomotionDirection::Left; } break; case ELocomotionDirection::Right: if (CurVelocityLocomotionAngle > ForwardMax - DeadZone && CurVelocityLocomotionAngle < BackwardMax + DeadZone) { return ELocomotionDirection::Right; } break;
}`},{header:"Stride Warping",slug:"stride-warping",content:"这是一个解决滑步的节点，需要启动 Animation Warping 插件。 具体的配置如下： 这里会用到骨骼上的ik节点，如果是自定义的骨骼，这里需要加上ik的节点，可以参考SK_Mannequin中的设置。"},{header:"Orientation Warping",slug:"orientation-warping",content:"使用该节点可以制作角色斜方向的移动。 同样也是使用的ik来实时计算的，具体配置如下："},{header:"Lean Animations",slug:"lean-animations",content:`使用叠加动画做偏向。动画叠加设置： 把左右方向的偏移做成BlendSpace： 横坐标：偏移角度[-90,90]纵坐标：步伐[0,1]，移动到跑步。
需要设置一下 Smoothing Time ，多个动画切换更加的自然。
在动画蓝图中设置如下： 偏向角度通过角色Actor这一帧的Yaw轴旋转与上一帧的Yaw轴旋转的相减得到。
LastFrameActorYaw = ActorYaw;
ActorYaw = WorldRotation.Yaw;
DeltaActorYaw = ActorYaw - LastFrameActorYaw;
LeanAngle = FMath::ClampAngle(DeltaActorYaw / (LeanFactor * DeltaSeconds), -90.f, 90.f);
if (LocomotionDirection == ELocomotionDirection::Backward)
{ LeanAngle *= -1.f;
}`},{header:"Stop Animation",slug:"stop-animation",content:""},{header:"Stop Layer",slug:"stop-layer",content:`与Cycle Layer相似，不过这里使用的使用的是 SequenceEvaluator 来播放停步动画，不同的是 SequenceEvaluator 可以设置播放时间的偏移。这样就可以在停步时，根据停止点去动态适应不同的
播放时间。 这里绑定了两个方法：
SetupStopAnims：根据角色移动方向选择不同的停步动画OnStopUdate：动态设置播放时间点，推进 SequenceEvaluator 播放时间`},{header:"Stop Location",slug:"stop-location",content:`使用了 AnimationLocomotionLibrary 插件中的方法 PredictGroundMovementStopLocation 来计算出未来可能的停止点。
/** * Predict where the character will stop based on its current movement properties and parameters from the movement component. * This uses prediction logic that is heavily tied to the UCharacterMovementComponent. * Each parameter corresponds to a value from the UCharacterMovementComponent with the same name. * Because this is a thread safe function, it's recommended to populate these fields via the Property Access system. * @return The predicted stop position in local space to the character. The size of this vector will be the distance to the stop location. */
UFUNCTION(BlueprintPure, Category = "Animation Character Movement", meta = (BlueprintThreadSafe))
static FVector PredictGroundMovementStopLocation(const FVector& Velocity,bool bUseSeparateBrakingFriction, float BrakingFriction, float GroundFriction,float BrakingFrictionFactor, float BrakingDecelerationWalking); 简单来说就是根据当前的速度和一些停止的速度参数得到未来的停止点，这些参数都可以在 UCharacterMovementComponent 中获取到。`},{header:"Distance Curve",slug:"distance-curve",content:`可以根据停止点获得当前角色位置离停止点的距离 Distance 。因为停止动画本身是带有位移信息，就可以根据 Distance 来设置动画播放的时间点。
动画位移数据可以使用曲线的方式获得。使用插件 Animation Modifier Library 可以自动画出位移曲线。 点击 Window->Animation Data Modifier 打开面板，选择添加 DistanceCurveModifier ，最后点击 Apply All Modifiers 即可。 这里可以选中所有停止动画，来生成距离曲线。`},{header:"Distance Match",slug:"distance-match",content:`使用了 AnimationLocomotionLibrary 插件中的方法 DistanceMatchToTarget 来设置 SequenceEvaluator 的播放时间。
/** * Set the time of the sequence evaluator to the point in the animation where the distance curve matches the DistanceToTarget input. * A common use case is to achieve stops without foot sliding by, each frame, selecting the point in the animation that matches the distance the character has remaining until it stops. * Note that because this technique sets the time of the animation by distance remaining, it doesn't respect phase of any previous animation (e.g. from a jog cycle). * @param SequenceEvaluator - The sequence evaluator node to operate on. * @param DistanceToTarget - The distance remaining to a target (e.g. a stop or pivot point). * @param DistanceCurveName - Name of the curve we want to match */
UFUNCTION(BlueprintCallable, Category = "Distance Matching", meta=(BlueprintThreadSafe))
static FSequenceEvaluatorReference DistanceMatchToTarget(const FSequenceEvaluatorReference& SequenceEvaluator, float DistanceToTarget, FName DistanceCurveName); 原理就是根据当前角色位置到停步点的距离 DistanceToTarget ，获取到 DistanceCurveName 曲线中相似距离的点，该点就是播放停止动画的时间点。
文档：https://dev.epicgames.com/documentation/en-us/unreal-engine/animation-in-lyrasample-game-in-unreal-engine#distancematchingandstridewarping​`},{header:"Orientation Warping",slug:"orientation-warping-1",content:"与Cycle相同， $45^{\\circ}$ 的停止动画也是用 Orientation Warping 节点来实现。不同的点是需要把 SequenceEvaluator 节点上的 Teleport to Explicit Time 关上。 文档：https://dev.epicgames.com/documentation/en-us/unreal-engine/animation-in-lyrasample-game-in-unreal-engine#orientationwarping​"},{header:"Start Animation",slug:"start-animation",content:`实现的逻辑与Stop Animation是一样的，不同的点是开始不需要计算停止位置，但是还是需要使用Distance Matching来控制起步动画播放的时间点。使用了 UAnimDistanceMatchingLibrary 中的方法 AdvanceTimeByDistanceMatching 来设置 SequenceEvaluator 的播放时间。
/** * Advance the sequence evaluator forward by distance traveled rather than time. A distance curve is required on the animation that * describes the distance traveled by the root bone in the animation. See UDistanceCurveModifier. * @param UpdateContext - The update context provided in the anim node function. * @param SequenceEvaluator - The sequence evaluator node to operate on. * @param DistanceTraveled - The distance traveled by the character since the last animation update. * @param DistanceCurveName - Name of the curve we want to match * @param PlayRateClamp - A clamp on the effective play rate of the animation after distance matching. Set to (0,0) for no clamping. */
UFUNCTION(BlueprintCallable, Category = "Distance Matching", meta=(BlueprintThreadSafe))
static FSequenceEvaluatorReference AdvanceTimeByDistanceMatching(const FAnimUpdateContext& UpdateContext, const FSequenceEvaluatorReference& SequenceEvaluator, float DistanceTraveled, FName DistanceCurveName, FVector2D PlayRateClamp = FVector2D(0.75f, 1.25f)); 动画状态机也进行了变更：`},{header:"Pivot Animation",slug:"pivot-animation",content:"急停动画，实现与Start Animation相似。Base状态机添加动画状态："},{header:"State Alias",slug:"state-alias",content:"为了减少各个状态之间的直接连接带来的混乱，使用匿名的状态来设置哪些状态可以跳转到特定的状态。"},{header:"Pivot State Machine",slug:"pivot-state-machine",content:"在Pivot Layer中设置两个相同的状态，因为在急停播放时，可能会触发另一个方向的急停。 这里课程中有一点问题，在计算两个状态切换时，这里的急停加速度（PivotAcceleration）应该与当前加速度（CurAcceleration）作比较。 与此同时急停加速度应该放在，急停动画开始时进行记录。这样两个急停状态互相切换就没有问题。 同时也不需要在急停动画的Update方法中实时检测当前动画是否播放正确。"},{header:"Turn In Place",slug:"turn-in-place",content:`这个功能是镜头先旋转，角色会滞后旋转到镜头正方向。镜头旋转超过一定的角度时，才会触发角色旋转。这个功能仅在角色处于Idle状态时应用。 这个功能实际的旋转的值是由程序来控制的，将分为两部分来实现：
逻辑：角色的旋转，在ABP_Base中实现。
表现：角色旋转动画的播放，在ABP_Layers中实现。`},{header:"Turn Logic",slug:"turn-logic",content:""},{header:"Root Yaw Offset",slug:"root-yaw-offset",content:`相机的旋转时跟着PlayerController的 同时角色的Yaw轴的旋转也是跟着PlayerController的 所以相机的Yaw旋转和角色Yaw轴旋转是一样，这里就需要添加旋转偏移。偏移直接使用计算角色偏向角度时用到的DeltaActorYaw作为基础即可。
RootYawOffset = UKismetMathLibrary::NormalizeAxis(RootYawOffset + DeltaActorYaw * -1.f); 因为是要还原角色的旋转所以这里需要乘上-1，同时这个偏移角度应该是(-180,180)的范围。`},{header:"Rotate Root Bone",slug:"rotate-root-bone",content:`把偏移旋转应用到角色上，使用Rotate Root Bone这个动画蓝图的节点。
动画蓝图中的节点： 因为该功能只在Idle状态下生效，所以需要设置一个状态RootYawOffsetMode 来区别移动和待机。 Accumulate 待机状态
BlendOut 移动状态，RootYawOffset的值应该为0，这里对其做了插值处理。 if (RootYawOffsetMode == ERootYawOffsetMode::Accumulate)
{ RootYawOffset = UKismetMathLibrary::NormalizeAxis(RootYawOffset + DeltaActorYaw * -1.f);
}
else if (RootYawOffsetMode == ERootYawOffsetMode::BlendOut)
{ FFloatSpringState RootYawOffsetSpringState; RootYawOffset = UKismetMathLibrary::FloatSpringInterp(RootYawOffset, 0.f, RootYawOffsetSpringState, 80.f, 1.f, DeltaSeconds);
}
RootYawOffsetMode = ERootYawOffsetMode::BlendOut; 这段逻辑会在每帧去检测，同时在每帧结束时把旋转偏移模式设置为移动状态。需要在ABP_Base中的Idle状态里添加Update的监听函数，用来设置旋转偏移模式为Accumulate。`},{header:"Root Rotation Curve",slug:"root-rotation-curve",content:"角色每一帧实际旋转多少值可以根据旋转动画获取。这里使用动画变形器MotionExtractorModifier来提取角色根节点在动画中的Yaw轴变化曲线。 得到曲线： 这里需要对曲线的范围做一定的修改，使旋转结束时角度为0，这样便于在设置RootYawOffset时不需要做过多的检测。"},{header:"Is Turning Curve",slug:"is-turning-curve",content:"程序在旋转角色时，需要在动画播放旋转的期间，也就是说在root_rotation_Z曲线中不为0的时间点都是在旋转。为了更加直观的看出角色是否在播放旋转动画，这里添加了新的动画曲线，来表示角色是否在旋转中。 这里自定义了一个动画变形器 IsTurningModifier，逻辑也很简单，从动画最后一帧开始查询与最后一帧根骨骼Yaw轴旋转不同的时间点A，那么A之前就是在旋转，A之后就是为旋转停止。"},{header:"Process Turn Yaw Curve",slug:"process-turn-yaw-curve",content:`有了这两个曲线，可以实时更新RootYawOffset来使角色贴近相机方向。
void ULyraALSAnimInstanceBase::ProcessTurnYawCurve()
{ LastFrameTurnYawCurveValue = TurnYawCurveValue; const float TurningValue = GetCurveValue("IsTurning"); if (TurningValue < 1.0f) { LastFrameTurnYawCurveValue = TurnYawCurveValue = 0; } else { TurnYawCurveValue = GetCurveValue("root_rotation_Z") * TurningValue; if (LastFrameTurnYawCurveValue != 0.f) { RootYawOffset = UKismetMathLibrary::NormalizeAxis(RootYawOffset - (TurnYawCurveValue - LastFrameTurnYawCurveValue)); } }
} 同样这段代码会在Idle状态监听的Update方法中调用。每帧减少偏移的数值是动画中两帧旋转数值的差值。`},{header:"Turn Animation",slug:"turn-animation",content:""},{header:"Idle State Machine",slug:"idle-state-machine",content:`在ABP_Layers中把IdleLayer设置为Idle状态机，如下图： 值得注意的是：需要把状态机的Max Transition Per Frame设置为1。
这里为什么会有3个状态，因为角色在转向时，是一个持续性动画，所以在转向的过程中可能会变向。也就是说本身角色需要向左转90度，在转到60度时，这时候又收到指令需要向右旋转90度，那就需要重新选取转向动画。如果只有一个转向的状态就无法满足这个需求。`},{header:"Turn In Place Entry",slug:"turn-in-place-entry",content:`这个状态用于播放转向动画中转向的部分，也就是旋转曲线数值不为0的那一部分。 进入的条件：为RootYawOffset的绝对值大于50。这个值可以手动调整。
退出条件：当IsTurning为0时。也就是说旋转停止了。 绑定了三个方法： SetupTurnInPlaceEntryState：根据RootYawOffset设置转向方向
SetupTurnInPlaceEntryAnims：根据RootYawOffset和转向方向旋转选择动画
UpdateTurnInPlaceEntryAnims：推进旋转动画的播放 在该状态中需要记录选择的动画和播放的时间。`},{header:"Turn In Place Recovery",slug:"turn-in-place-recovery",content:`这个状态主要就是播放旋转动画中的一小段待机动作，其中进入该状态不需要设置过渡时间，因为是于Turn In Place Entry状态播放的同一个动画，就是接着上一个状态继续播放即可。 退出条件： 为RootYawOffset的绝对值大于50。这个值可以手动调整。
旋转动画播放完成 在旋转180度时，会出现插值混合的问题。可以使用惯性化混合解决这个问题。`},{header:"Crouch Animation",slug:"crouch-animation",content:"蹲伏包括前面的所有功能，只是在不同的状态中把原有的动画替换为蹲伏即可。同时在Gate中添加一个新为Crounching。这样可以根据角色当前的Gate来选择不同的动画。"},{header:"Switch Crouch",slug:"switch-crouch",content:`按键触发切换蹲伏：
void ALyraALSPlayerController::OnCrouchInput(const FInputActionValue& InputActionValue)
{ switch (LyraALSCharacterBase->GetCurrentGate()) { case EGate::Walking: case EGate::Jogging: LyraALSCharacterBase->SwitchGate(EGate::Crounching); break; case EGate::Crounching: LyraALSCharacterBase->SwitchGate(EGate::Jogging); break; }
} 直接使用角色自带的蹲伏功能即可。`},{header:"Select Animation",slug:"select-animation",content:"只需要在原有系统中加入对 EGate::Crouching 的处理即可。如下："},{header:"Stance Transition",slug:"stance-transition",content:`把Idle状态转换为状态机，用来做站立和蹲伏之间的切换。 在Stance Transition中只播放进入蹲伏和退出蹲伏动画。蹲伏的待机还是在Idle状态中。
文档：https://dev.epicgames.com/documentation/en-us/unreal-engine/animation-in-lyrasample-game-in-unreal-engine#turninplace​`},{header:"Jump Animation",slug:"jump-animation",content:"跳跃是一个相对来说比较独立的模块，它的动画由多个状态组成，逻辑直接使用角色知道的Jump方法即可。同时从高处落下也是使用该模块。"},{header:"Logic​",slug:"logic​",content:"在按键按下时直接触发 Character->Jump ,在按键完成时触发 Character->Stop 。"},{header:"Jump Info",slug:"jump-info",content:`动画蓝图会使用到三个跳跃的状态数据，每帧都会刷新： bIsInAir = CharacterMovementComp->IsFalling();
bIsJumping = CharacterVelocity.Z>0 && bIsInAir;
bIsFalling = CharacterVelocity.Z<0 && bIsInAir;`},{header:"Time To Jump Apex",slug:"time-to-jump-apex",content:`角色跳跃到最高点所需要的时间，计算方式：角色Z轴的速度除以Z轴的重力即可。只在角色时跳跃时计算
if (bIsJumping)
{ TimeToJumpApex = -CharacterVelocity.Z / CharacterMovementComp->GetGravityZ();
}
else
{ TimeToJumpApex = 0.f;
} 该值作为跳跃循环状态切换到跳跃最高点状态的条件。`},{header:"Ground Distance",slug:"ground-distance",content:`角色离地面的距离，使用射线碰撞获得该值。
void ALyraALSCharacterBase::UpdateGroundDistance()
{ if (GetWorld() == nullptr) { return; } if (GetCharacterMovement()->IsFalling()) { FHitResult OutHit; FVector Start = GetActorLocation() - FVector(0.f, 0.f, GetCapsuleComponent()->GetScaledCapsuleHalfHeight()); FVector End = GetActorLocation() - FVector(0.f, 0.f, 1000.f); if (GetWorld()->LineTraceSingleByChannel(OutHit, Start, End, ECollisionChannel::ECC_Visibility) && AnimationInterface) { AnimationInterface->ReceiveGroundDistance(OutHit.Distance); } }
}`},{header:"State Machine",slug:"state-machine",content:`这些状态在基础动画蓝图中的移动状态机里，同时这些状态分为三类： 粉色：匿名状态
绿色：选择器
灰色：状态 接下来会按照状态流程依次介绍每个状态，每个状态一一对应着一个动画层。 匿名状态文档：https://dev.epicgames.com/documentation/en-us/unreal-engine/animation-inlyra-sample-game-in-unreal-engine#statealiases`},{header:"Jump Sources",slug:"jump-sources",content:`从其他状态进入跳跃模块的入口点，其他状态有： Idle
Cycle​
Stop​
Start​
Pivot​`},{header:"Jump Selector",slug:"jump-selector",content:"通过数据进入对应状态： bIsJumping ：JumpStart bIsFalling ：JumpApex"},{header:"JumpStart​",slug:"jumpstart​",content:"在JumpStartLayer中使用Sequence Player直接绑定对应的动画，播放结束进入JumpStartLoop"},{header:"JumpStartLoop",slug:"jumpstartloop",content:"在JumpStartLoopLayer中使用Sequence Player直接绑定对应的动画，当跳到最高的时间TimeToJumpApex小于特定值时，进入JumpApex。"},{header:"JumpApex",slug:"jumpapex",content:"在JumpApexLayer中使用Sequence Player直接绑定对应的动画，播放结束进入JumpFallLoop。"},{header:"JumpFallLoop",slug:"jumpfallloop",content:"在JumpFallLoopLayer中使用Sequence Player直接绑定对应的动画，当GroundDistance小于一个特定的值时，进入JumpFallLand。"},{header:"JumpFallLand",slug:"jumpfallland",content:`在JumpFallLayer中使用Sequence Evaluator播放绑定对应的动画。该播放器绑定了两个方法： SetupJumpFallLandAnims：在播放开始时，设置播放动画时间点为0。
UpdateJumpFallLandAnims：根据GroundDistance数值，每帧动态调整动画播放的时间点。这使用到了DistanceMatching，匹配的距离是在动画中设置的Z轴下来曲线。在角色的状态不在空中时进入到EndInAir选择状态。`},{header:"EndInAir",slug:"endinair",content:`结束空中状态后，根据角色当前的水平方向的速度决定去以下两个状态： Cycle：速度大于0
Idle：速度接近0`},{header:"JumpInteruptSource",slug:"jumpinteruptsource",content:`当然在角色执行跳的过程中，也会突然结束角色在空中这个状态。比如说角色跳台阶，可能角色还在播起跳循环时，角色已经落到更高的台阶上了，就不需要下落的动画了，直接进入EndInAir状态即可。以下几个跳跃的状态可以被打断： JumpStart
JumpApex
JumpStartLoop
JumpFallLLoop`},{header:"Jump Fall Land Recovery",slug:"jump-fall-land-recovery",content:"角色在落地后，一般会有一个落地反馈动画。这个动画并没有放在整个跳跃的状态机里，因为角色在下落后可能会立马进入移动状态，如果加一个反馈动画，这样会让移动等一会响应，这就很呆。所以把这个动画做成叠加动画呈现到角色上，在基础动画蓝图中如下："},{header:"Time Falling",slug:"time-falling",content:`角色下落到地面所花费的时间。作为落地反馈动画叠加的插值。计算方式只需要在角色处于下落时，加上变换时间即可。
if (bIsFalling)
{ TimeFalling += DeltaSeconds;
}
else
{ if (bIsJumping) { TimeFalling = 0.f; }
} 这个值是需要每一帧计算的。`},{header:"JumpLandRecoverySM",slug:"jumplandrecoverysm",content:`在JumpFallLandRecoveryLayer中使用状态机来旋转播放下落反馈动画。 因为叠加动画是放在Locomotion状态机后面，换句话说这个叠加动画是常态存在的，所以需要设置在特定的情况下播放反馈动画。
其中Default和InAir状态中并没有什么动画，跳转条件如下： Default->InAir：bInAir为真
InAir->JumpFallLandRecovery：bInAir为假
JumpFallLandRecovery->Default: bInAir为真，优先级1
叠加动画播放完，优先级2 JumpFallLandRecovery状态的逻辑如下： 反馈动画和默认叠加动画进行混合，混合的程度由下落时间决定。其中Additive Identity Pose就是一个空的叠加姿势，主姿势叠加该姿势就是主姿势。
参考：https://forums.unrealengine.com/t/what-is-ls-ref-pose-and-additive-identity-posefor/478394/5`},{header:"Sync Group",slug:"sync-group",content:`主要解决两个不同周期动画混合时，出现因为人物姿势巨大的不同产生跳跃感的问题。这种情况多出现在角色从步行到跑步过渡时，角色脚不同位置产生的跳跃感。 同步组关闭
同步组打开 之前在项目中遇到一个问题，角色在频繁转向时的脚步声会播重复，使用同步组可以解决这个问题。因为播放脚步声是使用动画通知，由于动画比较短，转向时会切动画，这时就会触发动画通知。如果频繁切动画，动画通知就会多次触发，声音就会重叠。同步组会抑制跟随者的动画通知，这样就可以减少不必要的通知。
文档：https://dev.epicgames.com/documentation/zh-cn/unreal-engine/animation-sync-groups-in-unreal-engine?application_version $=5.4$`},{header:"Group",slug:"group",content:`以下几种动画状态设置为同一个组，几个状态的角色如下： Cycle: Always Follower
Pivot : Always Leader
Start: Can be Leader​
Stop: Can be Leader 使用基于标识同步，所以急停、启动、停步都设置为Leader的角色。`},{header:"SyncMarkerAnimModifier",slug:"syncmarkeranimmodifier",content:"使用该动画变形器，自动为动画添加脚步同步标识。在使用该变形器时需要关闭动画的force Rootlock选项，同时通话启动Root Motion。"},{header:"Aim Offset",slug:"aim-offset",content:"瞄准偏移，存储了一系列可混合的姿势，用于帮助角色瞄准武器。可以理解为一种特殊的混合空间，其中每个动画改为特定的姿势。这瞄准的姿势都是叠加到角色的当前姿势上。"},{header:"Logic​",slug:"logic​-1",content:`瞄准偏移主要分为两个轴： Yaw：直接使用Turn In Place里使用的RootYawOffset，这个值需要取一下反。
Pitch：直接使用 Pawn->GetBaseAimRotation().Pitch ，他底层也是直接使用的Controller的旋转。`},{header:"Animation Setting",slug:"animation-setting",content:""},{header:"Sequence",slug:"sequence",content:"每一个Sequence中都需要设置叠加动画，设置基础姿势都会对应武器正象的姿势： 在AO中可以设置Grid Divisions来方便吸附动画配置。"},{header:"ABP Base",slug:"abp-base",content:"因为是叠加动画，所以AimOffsetLayer不需要放在Locomotion状态机里，直接放在最外层， Locomotion之后即可。"},{header:"AimOffsetLayer",slug:"aimoffsetlayer",content:"只需要把参数和动画传入AimOffset Player即可： 参考： https://dev.epicgames.com/documentation/zh-cn/unreal-engine/creating-an-aim-offset-inunreal-engine​"},{header:"Foot Placement",slug:"foot-placement",content:"解决了图中脚没有放在地面上的问题，这是一个UE5全新的节点，集合SlopeWar平，FootLock和IK预算等功能。在ABPBase中使用如下： 具体的设置： 详细的介绍可以看这篇文章：https://zhuanlan.zhihu.com/p/687084876"},{header:"Blend Options",slug:"blend-options",content:""},{header:"Blend Profile",slug:"blend-profile",content:`混合描述（Blend Profiles） 可以添加至骨骼，用于定义每个骨骼的混合速度，从而让一些骨骼比其它的骨骼更快混合。
UE默认有一个FastFeet的选项，可以用于从Idle状态过渡到Start状态。它的效果是开始混合下半身。 在骨骼中可以看到FastFeet的配置如下： 文档：https://dev.epicgames.com/documentation/en-us/unreal-engine/blend-masks-andblend-profiles-in-unreal-engine#blendprofiles​`},{header:"Blend Layers",slug:"blend-layers",content:"切换不同的动画层时，会出现闪烁的问题，可以配置层级混合时间，来解决这个问题。因为在ABP_Base中使用了惯性化插值，所以这里配置混合时间是可以起作用的。每个动画层上都可以配置混合时间和混合描述："},{header:"Weapon",slug:"weapon",content:"开枪动画使用蒙太奇播放，使用叠加的方式混合进入当前人物姿势。"},{header:"Hand IK",slug:"hand-ik",content:`具体动画蓝图如下： 使用Hand IK Retargeting节点修正持枪手的骨骼位置，防止手臂的拉伸。设置以右手为基准，移动左手对齐右手。移动到的点为 ik_hand_gun 。 左手只是跟随了右手的移动，同属需要保持枪到左手的位置。这里新建虚拟骨骼VB_weapon_r_hand_l ，从右手武器点到左手。 每一帧把该骨骼位置和旋转信息复制 ik_hand_l 骨骼上。最后使用Two Bone Ik节点应用ik_hand 骨骼信息到 hand 骨骼链上。
添加一个开关， 来设置是否启用手部IK，通过在动画上设置曲线值来实现。比如在换弹时，不需要应用手部IK，这样可以在换弹动画中设置曲线如下： Hand IK Retargeting 文档：https://dev.epicgames.com/documentation/en-us/unrealengine/animation-blueprint-hand-ik-retargeting-in-unreal-engine​`},{header:"Upper Body",slug:"upper-body",content:"实现边走边换弹的功能，需要使用到上下半身分别混合。具体蓝图如下： 换弹动画使用蒙太奇来播放，并把蒙太奇的插槽标记为上半身。使用 Layered blend per bone节点实现上下半身分别混合，该节点配置如下： 这里使用了混合遮罩来进行控制上半身混合， ALS Upper Body 遮罩配置如下："},{header:"Max Transitions Per Frame",slug:"max-transitions-per-frame",content:`该数字定义了单个帧或更新中可以发生的转换或 决策 数量。如果你的状态机有许多状态和转换，其中多个转换可以在给定时间均成立，可能需要将该数字设置为 1 。这样一来，一次只能做出一个决策，防止多个决策和转换彼此竞争。
在该项目中所有的状态机都把这个数值设置为1了，以确保过渡的状态没有被跳过。`}]},{path:"/GameEngine/Unreal/manual/MVVM.html",title:"MVVM",pathLocale:"/",contents:[{header:"MVVM",slug:"mvvm",content:""},{header:"Tips",slug:"tips",content:`绑定ViewModel到Widget，使用属性路径时，填写的函数必须为const。
在5.3中绑定ViewModel设置为手动时，在设置时，需要至少使用ViewModel绑定一个属性到Widget上。`},{header:"Reference",slug:"reference",content:"https://dev.epicgames.com/documentation/zh-cn/unreal-engine/umg-viewmodel"}]},{path:"/GameEngine/Unreal/manual/NetWorkIDs.html",title:"NetWorkIDs",pathLocale:"/",contents:[{header:"NetWorkIDs",slug:"networkids",content:"FUniqueNetID vs FNetworkGUID vs PlayerId"},{header:"GetUniqueID()",slug:"getuniqueid",content:"这个是UObject的唯一ID，只有object是激活的。但是它并不是一样数值存在于服务器和客户端。"},{header:"FNetworkGUID",slug:"fnetworkguid",content:`这个是服务器和客户端统一的一个UObject的唯一ID。它是存在 UNetDriver 里的FNetGUICache中的。我们可以这样获取：
FNetworkGUID networkID = GetWorld()->GetNetDriver()->GuidCache->GetNetGUID(GetOwner());;`},{header:"APlayerState.PlayerId",slug:"aplayerstate-playerid",content:""},{header:"APlayerState.UniqueID",slug:"aplayerstate-uniqueid",content:"Reference From https://udn.unrealengine.com/questions/232509/about-testing-multiplayer.html"}]},{path:"/GameEngine/Unreal/manual/SomeTips.html",title:"Some Tips",pathLocale:"/",contents:[{header:"Some Tips",slug:"some-tips",content:"如果在build时出现cannot open file ... dll 需要把引擎的文件夹的read only去掉"},{header:"",slug:"",content:`Hitting D8049 errors when building editor
https://forums.unrealengine.com/t/hitting-d8049-errors-when-building-editor-from-ue4-sln/449409/4`},{header:"",slug:"-1",content:'关于UCLASS和UPROPERTY中的设置可以在UnrealEngine\\Engine\\Source\\Runtime\\CoreUObject\\Public\\UObject\\ObjectMacros.h文件中查看。或者直接引用#include "UObject/ObjectMacros.h"，直接使用UC::或者UP::会有提示。'},{header:"",slug:"-2",content:'在使用Lambda表达式时，如果会使用到类中的内容时，需要把对象传入，例子： Cast<UAuraAbilitySystemComponent>(AbilitySystemComponent) ->EffectAssetTags.AddLambda( [this](const FGameplayTagContainer& AssetTags) { for (const FGameplayTag Tag : AssetTags) { const FString Msg = FString::Printf(TEXT("GE Tag %s"), *Tag.ToString()); GEngine->AddOnScreenDebugMessage(-1, 8, FColor::Blue, Msg); GetDataTableRowByTag<FUIWidgetRow>(MessageWidgetDataTable, Tag); } });'},{header:"",slug:"-3",content:"在一个类中声明Actor，一定要声明为指针。因为Actor的构造一定要使用NewObject。这个类在构造时，也会构造去这个Actor变量，这里会出现断言。"},{header:"",slug:"-4",content:`函数中传入结构体引用时，如下所示：
UFUNCTION(BlueprintCallable)
void SetIsBlockedHit( FGameplayEffectContextHandle& EffectContextHandle, bool bIsBlockedHit); 在蓝图中调用，该引用会在输出节点，如下图： 如果想实现以下效果： 需要在引用前加入UPARAM(ref)，函数改为如下：
UFUNCTION(BlueprintCallable)
static void SetIsBlockedHit(UPARAM(ref) FGameplayEffectContextHandle& EffectContextHandle, bool bIsBlockedHit);`},{header:"",slug:"-5",content:`这段代码，为什么要从数组中取出来的数值，存成本地变量？
alt text
因为这里随机数是使用BlueprintPure，他会在每一次取值时候，都被调用一次，也就是重新随机一次。所以在最右边的红色框中，又取了一次值，所以这里会产生两次随机。`},{header:"",slug:"-6",content:`设置自定义Tick方法，使用FTickFunction，并可以设置bRunOnAnyThread 让其运行在其他线程。注册该方方法类似：
bool UActorComponent::SetupActorComponentTickFunction(struct FTickFunction* TickFunction)
{ if(TickFunction->bCanEverTick && !IsTemplate()) { AActor* MyOwner = GetOwner(); if (!MyOwner || !MyOwner->IsTemplate()) { ULevel* ComponentLevel = (MyOwner ? MyOwner->GetLevel() : ToRawPtr(GetWorld()->PersistentLevel)); TickFunction->SetTickFunctionEnable(TickFunction->bStartWithTickEnabled || TickFunction->IsTickFunctionEnabled()); TickFunction->RegisterTickFunction(ComponentLevel); return true; } } return false;
}`},{header:"",slug:"-7",content:`有时直接复制一个蓝图类会出现不可控的一些问题，所以建议如果需要复制一个蓝图可以直接创建这个蓝图的子类。
https://www.bilibili.com/video/BV1RV4y1t77u/?spm_id_from=pageDriver&vd_source=631c1232c45e3ad448a6cc1d8713c7c2`},{header:"",slug:"-8",content:`FRotator Rotation = (ActorA->GetActorLocation() - ActorB->GetActorLocation()).Rotation();
Rotation.Pitch = 45.f;
const FVector ToTarget = Rotation.Vector(); 以上代码的意义是，从B到A的向量在Pitch方向旋转45度得到ToTarget方向向量，且该值是进行了标准化操作。这个也太方便了吧。
这里Rotation方法其实就是ToOrientationRotator。`},{header:"",slug:"-9",content:`FVector Direction = ActorA->GetActorRotation().Vector();
FVector ForwardVector = GetActorForwardVector(); 以上的Direction与ForwardVector这两个值是相同的。`},{header:"",slug:"-10",content:"可以使用Property Matrix进行多文件同时操作"},{header:"",slug:"-11",content:`在蓝图中减少或避免使用Cast到一个蓝图类。因为在强转到一个蓝图类时，会把强转的那个类的对象所有的资源都会再加载一边，再cook的时候也会多cook一次。
这里强转一个角色类： 可以看到这个角色类会被引用到：`},{header:"",slug:"-12",content:"谨防蓝图与宏中的硬引用"},{header:"",slug:"-13",content:"可以使用Redirectors功能快速热更某项蓝图。"},{header:"",slug:"-14",content:`在修改了USkeletalMeshComponent中的mesh后，如果是有动画蓝图在该组件上。需要重新初始化一下动画蓝图，不然有可能会把已经垃圾处理的mesh姿势加入计算并传入渲染管线，这会造成crash。调用以下方法即可：
BaseMesh->InitAnim(true);`}]},{path:"/GameEngine/Unreal/manual/UnrealEnginePipeline.html",title:"Unreal Engine Pipeline",pathLocale:"/",contents:[{header:"Unreal Engine Pipeline",slug:"unreal-engine-pipeline",content:""},{header:"UE4",slug:"ue4",content:""},{header:"UE5",slug:"ue5",content:""},{header:"Animation",slug:"animation",content:""},{header:"Blueprint",slug:"blueprint",content:""},{header:"Character",slug:"character",content:""},{header:"Materials",slug:"materials",content:""},{header:"Programming",slug:"programming",content:""},{header:"Rendering",slug:"rendering",content:""},{header:"World Building",slug:"world-building",content:""},{header:"Refence",slug:"refence",content:`https://dev.epicgames.com/community/learning/courses/7L/engine-structure-beginplay/98E/overview-engine-structure-beginplay
https://dev.epicgames.com/community/profile/zV4/Online_Learning
https://github.com/drstreit/unreal_schematics`}]},{path:"/GameEngine/Unreal/manual/UnrealPak.html",title:"Unreal Park",pathLocale:"/",contents:[{header:"Unreal Park",slug:"unreal-park",content:`https://ue5wiki.com/wiki/35741/
UnrealPak.exe在Engine\\Binaries\\Win64这其中。
源码在PakFileUtilities这里面，这里所有的输出路径根节点都是UnrealPak.exe的路径。`},{header:"Audit",slug:"audit",content:`查看这个包中有那些资源并导出csv。
UnrealPak <PakFolder> -AuditFiles [-OnlyDeleted] [-CSV=<filename>] [-order=<OrderingFile>] [-SortByOrdering] Example:
UnrealPak.exe E:\\Paks -AuditFiles -CSV=audit.csv`},{header:"Extract",slug:"extract",content:`解压pak文件到某个路径，并且需要生成responsefile后来重新打包。
UnrealPak <PakFilename> -Extract <ExtractDir> [-Filter=<filename>] Example:
UnrealPak.exe -Extract E:\\Paks\\pakchunk0-Stadia.pak E:\\Paks\\chunk0 -responsefile= E:\\Paks\\chunk0.response`},{header:"Create",slug:"create",content:`重新打包资源
UnrealPak <PakFilename> -Create=<ResponseFile> [Options] Example:
UnrealPak.exe E:\\Paks\\repack\\pakchunk0-Stadia.pak -Create=E:\\Paks\\chunk0.response @echo off set Paks_Exe=..\\Engine\\Binaries\\Win64\\UnrealPak-Win64-Test.exe
set Paks_Path=%~dp0WindowsNoEditor\\DH\\Content\\Paks
set CSV_Path=%~dp0audit.csv
set Pak_Name=pakchunk0-WindowsNoEditor.pak
set Chunk_Name=chunk0 %Paks_Exe% %Paks_Path% -AuditFiles -CSV=%CSV_Path% %Paks_Exe% -Extract %Paks_Path%\\%Pak_Name% %Paks_Path%\\%Chunk_Name% -responseFile=%Paks_Path%\\%Chunk_Name%.response %Paks_Exe% %Paks_Path%\\%Pak_Name% -Create=%Paks_Path%\\%Chunk_Name%.response pause`}]},{path:"/GameEngine/Unreal/online/Multiplayer%20Shooter.html",title:"Multiplayer Shooter",pathLocale:"/",contents:[{header:"Multiplayer Shooter",slug:"multiplayer-shooter",content:`https://www.udemy.com/course/unreal-engine-5-cpp-multiplayer-shooter
Peer-to-Peer, Client-Server
UE5 Uses an Authorirtative Client-Server Model`},{header:"多人游戏连接",slug:"多人游戏连接",content:`在打开场景的时候，可以设置当前场景是listen状态，然后另一台电脑可以直接使用命令行Open Ip进入，这有点东西。 同样可以使用代码加载关卡以及开启服务器： UWorld* world = GetWorld(); if (world) { // /Game/ = Content floder // ?listen, set the level is a listen server world->ServerTravel("/Game/ThirdPerson/Maps/Lobby?listen"); } 加入服务器可以使用：
UGameplayStatics::OpenLevel(this, IPAddress); 或者使用： APlayerController* playerController = GetGameInstance()->GetFirstLocalPlayerController(); if (playerController) { playerController->ClientTravel(IPAddress, ETravelType::TRAVEL_Absolute); }`},{header:"Online Subsystem",slug:"online-subsystem",content:`在Engine.ini中设置使用哪个平台的服务器： 使用一下代码来获取网络系统：
IOnlineSubsystem* onlineSubsystem = IOnlineSubsystem::Get()`},{header:"Session Interface",slug:"session-interface",content:"其中最主要的接口是Session，他的主要工作如下: Session的生命周期以及对应的几个关键方法："},{header:"Online Subsystem Steam",slug:"online-subsystem-steam",content:`https://docs.unrealengine.com/4.27/en-US/ProgrammingAndScripting/Online/Steam/
在插件中添加OnlineSubsystemSteam插件，并且需要在.Build.cs文件中的PublicDependencyModuleNames添加：
"OnlineSubsystemSteam", "OnlineSubsystem"`},{header:"Game Instance",slug:"game-instance",content:`Spawned at game creation
Not detroyed until the game is shut down
Persists between levels`},{header:"Game Instance Subsystem",slug:"game-instance-subsystem",content:`Created after the Game Instance is created
Destroyed and garbage collected when the Game Instance is shut down`},{header:"Game State",slug:"game-state",content:""},{header:"Travel in multiplayer",slug:"travel-in-multiplayer",content:""},{header:"ENetRole",slug:"enetrole",content:`ROLE_Authority ：服务器
ROLE_SimulatedProxy ： 本地其他客户端
ROLE_AutonomousProxy : 本地客户端
ROLE_None 服务器上显示的角色类型如下图，其中最靠近屏幕的Pawn是本地控制角色： 客户端上显示的角色类型如下图，其中最靠近屏幕的Pawn是本地控制角色：`},{header:"Replicated",slug:"replicated",content:`UPROPERTY(Replicated) 复制变量，只能从服务器复制到客户端上。不能再客户端上修改了值，同步到其他客户端。
这个方法调用的地方：GetLifetimeReplicatedProps： UClass::ValidateRuntimeReplicationData()
UClass::SetUpRuntimeReplicationData()
UNetDriver::HandleNetDumpServerRPCCommand( const TCHAR* Cmd, FOutputDevice& Ar )`}]},{path:"/GameEngine/Unreal/online/References.html",title:"References",pathLocale:"/",contents:[{header:"References",slug:"references",content:""},{header:"Redpoint",slug:"redpoint",content:`license key
eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiJ9.eyJpc3MiOiJodHRwczovL2xpY2Vuc2luZy5yZWRwb2ludC5nYW1lcy8iLCJpYXQiOjE2NzAzOTMxMzcuMCwic3ViIjoiNTg5MjM0MTMxNTQwMzc3NiIsImF1ZCI6ImVwaWMtb25saW5lLXN1YnN5c3RlbS1mcmVlIn0.JLBFoIcsUcyTDEfkEVvtcstMjm2hcYbhweZj6VMPAK1fRqx3V23WHdLI85_onRQrKRrRUNEFURt9SjM2jH2md_IE_WHng4CqahvpEZrTedg7aYUW24rdUohVpjixV71GxVK8_Fb2wktMPVyhczKiAreLD9OEdm99S32fxANMPeFlzgoAMSCeNAHymRKzHxtExGVYB20UgXKVQtyLVbhQbmgZILMtNQMXb-FbP6h3BoNQEgRbCZZTKCCgUysWc033gkABV3rB5bYlnXECOjgxmT4M7Kx9ZMhqpTOeD_rmi7Lc2_qs31yMr-FErcGe8xqtRhzQGlIgzKpD6b-yx1kQLw`},{header:"Network Profile",slug:"network-profile",content:"工具"},{header:"Connection Timeout",slug:"connection-timeout",content:"Engine\\Engine\\Plugins\\Online\\OnlineSubsystemUtils\\Source\\OnlineSubsystemUtils\\Private\\IpNetDriver.cpp 命令：net.IpNetDriverReceiveThreadPollTimeMS"},{header:"使用LAN测试",slug:"使用lan测试",content:`需要设置以下参数：
-log -NoRedpointEOS -NetDriverOverrides=/Script/OnlineSubsystemUtils.IpNetDriver -UserDir=
这里需要研究一下这个NetDriverOverrides.`},{header:"Blogs",slug:"blogs",content:"[使用虚幻引擎4年，我想再谈谈他的网络架构【经验总结】]（https://zhuanlan.zhihu.com/p/105040792）"}]},{path:"/GameEngine/Unreal/optimize/References.html",title:"References",pathLocale:"/",contents:[{header:"References",slug:"references",content:""},{header:"Video",slug:"video",content:`Profiling and Optimization in UE4
Optimizing UE4 for Fortnite: Battle Royale - Part 1
Optimizing UE4 for Fortnite: Battle Royale - Part 2`},{header:"Intel Unreal Engine 4 Optimization Tutorial",slug:"intel-unreal-engine-4-optimization-tutorial",content:"https://www.intel.com/content/www/us/en/developer/articles/training/unreal-engine-4-optimization-tutorial-part-1.html"},{header:"Blog",slug:"blog",content:`https://unrealartoptimization.github.io/book/
https://www.tomlooman.com/unrealengine-optimization-talk/`}]},{path:"/Gameplay/AI/DecisionMaking/BehaviorTrees.html",title:"Behavior Trees",pathLocale:"/",contents:[{header:"Behavior Trees",slug:"behavior-trees",content:""}]},{path:"/Gameplay/AI/DecisionMaking/DecisionTrees.html",title:"Decision Trees",pathLocale:"/",contents:[{header:"Decision Trees",slug:"decision-trees",content:""}]},{path:"/Gameplay/AI/DecisionMaking/StateMachines.html",title:"State Machines",pathLocale:"/",contents:[{header:"State Machines",slug:"state-machines",content:"AI角色在游戏中一般都是一直做一样的事情，直到收到某个信息才会改变角色现在做的事情。这我们就可以使用状态机来制作。"},{header:"A Basic State Machine",slug:"a-basic-state-machine",content:"在一个状态中每个角色都有一个状态变量。一个行为对应着一个状态，并且有一系列的条件。当满足状态切换条件时，这个叫做触发（trigger）,当切换到一个新的状态时，这叫激活（fired） 上图展示了一个简单的状态机：巡逻，战斗，逃跑。每个状态都有自己的一些条件。"},{header:"Finite State Machines",slug:"finite-state-machines",content:"有限状态机就是一般状态机。"},{header:"The Problem",slug:"the-problem",content:"我们想要一个支持具有任何类型转换条件的任意状态机的一般系统。状态机将符合上述结构，并且同一时刻只占据一种状态。"},{header:"The Algorithm",slug:"the-algorithm",content:`为了实现这个，我们可以使用一个通用的状态接口，并且状态中用条件。一个状态机有着一些可能进入的状态和记录着当前的状态。
在每一帧我们就更新状态机，状态机去更新当前状态，从而检测是否切换状态。`},{header:"Pseudo-code",slug:"pseudo-code",content:`这里我们一帧去检测当前状态是已经被切换了，并且调佣特定的切换的方法。
class StateMachine: # We’re in one state at a time. initialState: State currentState: State = initialState targetState: State # transfrom to next state function transitionTo(state) targetState = state # Checks and applies transitions, returning current state actions. function update() currentState.update() if targetState ! = null then executeStateTransition() # execute transition funtion executeStateTransition() currentState.exit() currentState = targetState currentState.OnTransitionTo = transitionTo currentState.entry()`},{header:"Data Structures and Interfaces",slug:"data-structures-and-interfaces",content:`状态的接口：
class IState: Action<IState> OnTransitionTo function entry() # do state actions function update() function exit()`},{header:"Weaknesses",slug:"weaknesses",content:"TODO： 腾讯课程"}]},{path:"/Gameplay/AI/DecisionMaking/",title:"Decision Making",pathLocale:"/",contents:[{header:"Decision Making",slug:"decision-making",content:`询问一个游戏玩家关于游戏AI，他大致会认为说做决策：角色决定去做什么的能力。
实际上，决策制定通常只是构建出色游戏所需工作的一小部分AI。大多数游戏使用简单的决策系统：状态机和行为树。
最近十年也出现了很多精密的方案：模糊逻辑和神经网络。但是在游戏开发中用的并不是很多。 决策制定是中间组件在AI模型中。
可以通过两个方向的信息来： 外部信息：在角色周围的游戏环境，角色的位置
内部信息：角色的生命值，觉得的目标。 通过决策制定来得到执行的行为。`}]},{path:"/Gameplay/AI/Movement/Movement.html",title:"Movement",pathLocale:"/",contents:[{header:"Movement",slug:"movement",content:""},{header:"Basic Movement",slug:"basic-movement",content:"移动算法的结构图"},{header:"2D",slug:"_2d",content:"角色在2维空间移动，大多数3维游戏也可以看做二维的移动。"},{header:"Statics",slug:"statics",content:`在处理角色的位置、转向这些数据使用的公式与算法叫做静态，因为这些数据不含有任何角色移动的数据。数据结构可以定义为：
class Static: position: Vector orientation: float`},{header:"Kinematic",slug:"kinematic",content:`如果一个角色正在向一个方向移动，突然改变他的速度与方向，这看起来有点突兀。为了让这个运动更加的丝滑，不让角色加速太快。我们就需要一些算法去考虑角色当前的速度，使用合理的加速度去改变速度。
我们就要记录这个角色的速度与转向的速度(角速度)，我们可以定义数据结构为：
class Kinematic: position: Vector orientation: float velocity: Vector rotation: float`},{header:"Kinematic Movement",slug:"kinematic-movement",content:""},{header:"Seek",slug:"seek",content:`给定一个角色的静态数据以及目标的静态数据。来计算角色到目标的方向以及一个直线速度。大概实现如下：
class KinematicSeek: character: Static target: Static maxSpeed: float function getSteering() -> KinematicSteeringOutput: result = new KinematicSteeringOutput() # Get the direction to the target. result.velocity = target.position - character.position # The velocity is along this direction, at full speed. result.velocity.normalize() result.velocity *= maxSpeed # Face in the direction we want to move. character.orientation = newOrientation( character.orientation, result.velocity) result.rotation = 0 return result 这个算法可以用于追击的一些情况。但是我们如果要让角色到一个点，然后停下来。我们可以添加一个以目标点为圆心的半径。当我们的角色到这个半径内时，就停止移动。当我们的设置半径不合理时，太小了，会使角色一直到不了目标点，还会看到角色的抖动。这里有几种解决方式： 固定时间到达目标点，需要设置一个最大速度阀值
扩大半径 class KinematicSeek: character: Static target: Static maxSpeed: float function getSteering() -> KinematicSteeringOutput: result = new KinematicSteeringOutput() # Get the direction to the target. result.velocity = target.position - character.position # Check if we’re within radius. if result.velocity.length() < radius: # Request no steering. return null # We need to move to our target, we’d like to # get there in timeToTarget seconds. result.velocity /= timeToTarget # If this is too fast, clip it to the max speed. if result.velocity.length() > maxSpeed: result.velocity.normalize() result.velocity *= maxSpeed # Face in the direction we want to move. character.orientation = newOrientation( character.orientation, result.velocity) result.rotation = 0 return result`},{header:"Wandering",slug:"wandering",content:""},{header:"Arrive",slug:"arrive",content:`可以设置以目标点设置两个圈，一个大半径圈，当进入这个圈后，角色开始减速。小圈是判断角色是否已经到达。
class Arrive: haracter: Kinematic arget: Kinematic axAcceleration: float axSpeed: float # The radius for arriving at the target. argetRadius: float # The radius for beginning to slow down. slowRadius: float # The time over which to achieve target speed. timeToTarget: float = 0.1 function getSteering() -> SteeringOutput: result = new SteeringOutput() # Get the direction to the target. direction = target.position - character.position distance = direction.length() # Check if we are there, return no steering. if distance < targetRadius: return null # If we are outside the slowRadius, then move at max speed. if distance > slowRadius: targetSpeed = maxSpeed # Otherwise calculate a scaled speed. else: targetSpeed = maxSpeed * distance / slowRadius # The target velocity combines speed and direction targetVelocity = direction targetVelocity.normalize() targetVelocity *= targetSpeed # Acceleration tries to get to the target velocity. result.linear = targetVelocity - character.velocity result.linear /= timeToTarget # Check if the acceleration is too fast. if result.linear.length() > maxAcceleration: result.linear.normalize() result.linear *= maxAcceleration result.angular = 0 return result 在很多实现中并没有使用到大圈这种方式，因为在减速是会有震荡的可能性`},{header:"ALIGN",slug:"align",content:`对齐使角色的转向与目标的转向相匹配。
class Align: character: Kinematic target: Kinematic maxAngularAcceleration: float maxRotation: float # The radius for arriving at the target. targetRadius: float # The radius for beginning to slow down. slowRadius: float # The time over which to achieve target speed. timeToTarget: float = 0.1 function getSteering() -> SteeringOutput: result = new SteeringOutput() # Get the naive direction to the target. rotation = target.orientation - character.orientation # Map the result to the (-pi, pi) interval. rotation = mapToRange(rotation) rotationSize = abs(rotation) # Check if we are there, return no steering. if rotationSize < targetRadius: return null # If we are outside the slowRadius, then use maximum tation. if rotationSize > slowRadius: targetRotation = maxRotation # Otherwise calculate a scaled rotation. else: targetRotation = maxRotation * rotationSize / slowRadius # The final target rotation combines speed (already inthe # variable) and direction. targetRotation *= rotation / rotationSize # Acceleration tries to get to the target rotation. result.angular = targetRotation - character.rotation result.angular /= timeToTarget # Check if the acceleration is too great. angularAcceleration = abs(result.angular) if angularAcceleration > maxAngularAcceleration: result.angular /= angularAcceleration result.angular *= maxAngularAcceleration result.linear = 0 return result`},{header:"VELOCITY MATCHING",slug:"velocity-matching",content:`把角色的速度与目标的数据设置为一样
class VelocityMatch: character: Kinematic target: Kinematic maxAcceleration: float # The time over which to achieve target speed. timeToTarget = 0.1 function getSteering() -> SteeringOutput: result = new SteeringOutput() # Acceleration tries to get to the target velocity. result.linear = target.velocity - character.velocity result.linear /= timeToTarget # Check if the acceleration is too fast. if result.linear.length() > maxAcceleration: result.linear.normalize() result.linear *= maxAcceleration result.angular = 0 return result`},{header:"FACE",slug:"face",content:`这个行为使角色看向目标,他委托对齐行为但是先计算目标的方向。
class Face extends Align: # Overrides the Align.target member. target: Kinematic # ... Other data is derived from the superclass ... # Implemented as it was in Pursue. function getSteering() -> SteeringOutput: # 1. Calculate the target to delegate to align Work out the direction to target. direction = target.position - character.position # Check for a zero direction, and make no change if so. if direction.length() == 0: return target # 2. Delegate to align. Align.target = explicitTarget Align.target.orientation = atan2(-direction.x, direction.z) return Align.getSteering()`},{header:"LOOKING WHERE YOU`RE GOING",slug:"looking-where-you-re-going",content:"class LookWhereYoureGoing extends Align: # No need for an overridden target member, we have # no explicit target to set. # ... Other data is derived from the superclass ... function getSteering() -> SteeringOutput: # 1. Calculate the target to delegate to align # Check for a zero direction, and make no change if so. velocity: Vector = character.velocity if velocity.length() == 0: return null # Otherwise set the target based on the velocity. target.orientation = atan2(-velocity.x, velocity.z) # 2. Delegate to align. return Align.getSteering()"},{header:"WANDER",slug:"wander",content:""}]},{path:"/Gameplay/AI/Movement/SteeringBehaviors.html",title:"Steering Behaviors",pathLocale:"/",contents:[{header:"Steering Behaviors",slug:"steering-behaviors",content:"转向行为可认为是基础行为和基础行为组合的行为两部分。"},{header:"Steering Basics",slug:"steering-basics",content:""},{header:"Variable Matching",slug:"variable-matching",content:"试图将角色的运动学中的一个或多个元素与一个单一的目标运动学相匹配"},{header:"Seek And Flee",slug:"seek-and-flee",content:"Seek尝试匹配角色的位置和目标的位置"}]},{path:"/Gameplay/AI/PathFinding/Astar.html",title:"A*",pathLocale:"/",contents:[{header:"A*",slug:"a",content:"寻路在游戏里的等同于A*算法。跟Dijkstra不一样，A*是用于点对点的路径查询而不是解决图中的最短路径问题。"},{header:"The Problem",slug:"the-problem",content:"给一个图（一个有向非负权重图）和两个点（开始点和目标点），找到俩个点直接连通的一条最短花费的路径。"},{header:"The Algorithm",slug:"the-algorithm",content:"这个算法的工作原理跟Dijkstra差不多。也是使用迭代器来遍历计算。不同的是A*关注的是最有可能导致总体路径最短的节点，而不是到当前最短花销值的节点。这就会产生如果这节点并不是最有可能产生最短路径的节点，那么A*的效率并不如Dijkstra。"},{header:"Processing the Current Node",slug:"processing-the-current-node",content:`我们在当前节点中还是会存有：每个节点的连接，每个连接的花销，以及连接的尾结点。
额外的我们还需要记录一个值：从起始节点到此节点再到目标的路径的总花销的估计值。这个估计值是两个值得总和：到目前为止当前节点的总花销加上我们丛当前节点到目标的距离的估计。 上图显示了一些节点 在图中的计算值。其中heuristic就是预计当前点到终点需要的花销。这个值不属于当前算法，是由其他程序生成的，暂时不管。`},{header:"The Node List",slug:"the-node-list",content:`同样的这里还是有两个列表： open ：记录已经被发现的点，但是还未被处理的点。在处理点时把该点连接尾的点加入其中。
closed ：记录已经被处理过的点，处理完该点就把该点加入该列表。 不像Dijkstra，在每次遍历开始就选最少花销的节点，而是选择预计花销最短的点。`},{header:"Calculating Cost-So-Far for Open and Closed Nodes",slug:"calculating-cost-so-far-for-open-and-closed-nodes",content:`我们计算当前节点总花销跟Dijkstra是一样的，比较当前节点加上连接的花销与之前尾结点的总花销做比较就可以。
不同的是，A*可以发现更好的路径在closed列表中。因为每次遍历并不是找的最小花销的。所以在发现更好的路径在closed里时，可以把这个节点的总花销更新了，然后把它再次放入open列表中。 我们可以看到上图是已经遍历过几次了。当前节点C,发现起始点到E的总共花销小于之前算出的。我们就可以把E的总花销数值更新了，然后把它加入到open列表中再次计算。这样就可以到达终点G。`},{header:"Terminating the Algorithm",slug:"terminating-the-algorithm",content:`在很多实现中，跟Dijkstra一样，当目标节点在open列表里是最小的节点时，就结束算法。
但是在A*中，我们每次取出的节点并不是最少花销的节点。所以我们并不能保证取出来的节点生成的路径是最短的路径。
但是如果我们为了找到最短路径时，反复去查找，那么这样所带来的的性能消耗，跟Dijkstra是差不多的。所以我们需要做的是对预测方法的调整。并且在第一次访问目标节点时终止。`},{header:"Retrieving the Path",slug:"retrieving-the-path",content:"得到路径后再反序该路径即可。"},{header:"Pseudo-Code",slug:"pseudo-code",content:`# This structure is used to keep track of the
# information we need for each node.
class NodeRecord: node: Node connection: Connection costSoFar: float estimatedTotalCost: float function pathfindAStar (graph: Graph, start: Node, end: Node, heuristic: Heuristic ) -> Connection[]: # Initialize the record for the start node. startRecord = new NodeRecord() startRecord.node = start startRecord.connection = null startRecord.costSoFar = 0 startRecord.estimatedTotalCost = heuristic.estimate(start) # Initialize the open and closed lists. open = new PathfindingList() open += startRecord closed = new PathfindingList() # Iterate through processing each node. while length(open) > 0: # Find the smallest element in the open list (using the # estimatedTotalCost). current = open.smallestElement() # If it is the goal node, then terminate. if current.node == goal: break # Otherwise get its outgoing connections. connections = graph.getConnections(current) # Loop through each connection in turn. for connection in connections: # Get the cost estimate for the end node. endNode = connection.getToNode() endNodeCost = current.costSoFar + connection.getCost() # If the node is closed we may have to skip, or remove it # from the closed list. if closed.contains(endNode): # Here we find the record in the closed list # corresponding to the endNode. endNodeRecord = closed.find(endNode) # If we didn’t find a shorter route, skip. if endNodeRecord.costSoFar <= endNodeCost: continue # Otherwise remove it from the closed list. closed -= endNodeRecord # We can use the node’s old cost values to calculate # its heuristic without calling the possibly expensive # heuristic function. endNodeHeuristic = endNodeRecord.estimatedTotalCost - endNodeRecord.costSoFar # Skip if the node is open and we’ve not found a better # route. else if open.contains(endNode): # Here we find the record in the open list # corresponding to the endNode. endNodeRecord = open.find(endNode) # If our route is no better, then skip. if endNodeRecord.costSoFar <= endNodeCost: continue # Again, we can calculate its heuristic. endNodeHeuristic = endNodeRecord.cost - endNodeRecord.costSoFar # Otherwise we know we’ve got an unvisited node, so make a # record for it. else: endNodeRecord = new NodeRecord() endNodeRecord.node = endNode # We’ll need to calculate the heuristic value using # the function, since we don’t have an existing record # to use. endNodeHeuristic = heuristic.estimate(endNode) # We’re here if we need to update the node. Update the # cost, estimate and connection. endNodeRecord.cost = endNodeCost endNodeRecord.connection = connection endNodeRecord.estimatedTotalCost = endNodeCost + endNodeHeuristic # And add it to the open list. if not open.contains(endNode): open += endNodeRecord # We’ve finished looking at the connections for the current # node, so add it to the closed list and remove it from the # open list. open -= current closed += current # We’re here if we’ve either found the goal, or if we’ve no more # nodes to search, find which. if current.node != goal: # We’ve run out of nodes without finding the goal, so there’s # no solution. return null else: # Compile the list of connections in the path. path = [] # Work back along the path, accumulating connections. while current.node != start: path += current.connection current = current.connection.getFromNode() # Reverse the path, and return it. return reverse(path)`},{header:"Changes from Dijkstra",slug:"changes-from-dijkstra",content:`这个算法基本和Dijkstra一样。它多了一个检测在closed里的节点是否需要更新并从新计算该节点。同时也额外的计算了预估花销。
我们可以把每个节点的预估花销缓存起来，这样就不需要每次都重新计算一次。`},{header:"Data Structure and Interface",slug:"data-structure-and-interface",content:"其他数据基本都和Dijkstra一样，但是这里多了一个预估到终点的方法。"},{header:"Pathfinding List",slug:"pathfinding-list",content:`用来存储open和close列表，这两个列表对该算法非常重要，这直接关系到算法效率的好坏。这个列表主要有4个操作： 添加节点到列表
从列表中移除移除节点
找到最小的花销的节点
找到列表中中特殊的节点 其中3，4是最具有优化空间的。有很多种方式去优化，我们这里使用优先级队列（priority queue）来做优化。`},{header:"Priority Queue",slug:"priority-queue",content:`最简单的实现是open列表一直都是排序好了的。也就是说列表中的第一个就是我们需要取的数值。
我们只需要在添加节点时，保证把这个节点放入正确的位置即可。也就是说在添加的时候就按照排序的规则来添加。
这里我们可以使用链表来做基础的存储数据结构，但是我们在添加时还是需要遍历已有数据来获取正确的索引。
如果我们这里使用数组来作为基础数据，我们可以使用二分搜索（binary search）来找到插入点。这比使用链表快很多。如果数据量更大的话，这里的提升会更高些。`},{header:"Priority Heaps",slug:"priority-heaps",content:`优先堆是一个以数组为基础的树形数据结构。每一个节点都有两个子节点并且子节点的值都比它大。 可以看上图，树是一个平衡树，因此没有一个分支比其他任何层次都深超过一个层次。此外，它还从左到右填充了每一层。
同时这个数也可以很好的映射到内存上。比如：当前节点是i,那么他的子节点的位置就是2i和2i+1。同时也可以使用堆排序，让树保持节点的有序性。取出和添加时间复杂度都是O(logn)，n是列表中元素的个数。`},{header:"Bucketed Priority Queues",slug:"bucketed-priority-queues",content:`分桶优先队列是更复杂的数据结构，它可以对部分数据排序。这个数据结构提供了跨不同操作的混合性能，它对删除增加都可以做到很快。 要添加到这类优先级队列中，请在桶中进行搜索，以找到节点所在的桶。然后将其添加到桶列表的开头中。
简单说就是把数据分块，先找需要插入数据属于那个桶，再在桶中排序。这样就减少了循环。`},{header:"Implementations",slug:"implementations",content:`简单地说： 大图，百万级别的节点数，使用分桶优先队列更好
小图，几千，几万节点的，使用优先堆更好`},{header:"Heuristic Function",slug:"heuristic-function",content:`我们可以简单设置预估花销接口如下 ：
class Heuristic: # An estimated cost to reach the goal from the given node. function estimate(node: Node) -> float`},{header:"A Heuristic for Any Goal",slug:"a-heuristic-for-any-goal",content:`由于为世界上每个可能的目标生成不同的启发式函数不方便，因此启发式通常由目标节点参数化。通过这种方式，可以编写一个通用的启发式实现来估计图中任意两个节点之间的距离。改接口差不多是这样：
class Heuristic: # Stores the goal node that this heuristic is estimating for. goalNode: Node # Estimated cost to reach the stored goal from the given node. function estimate(fromNode: Node) -> float: return estimate(fromNode, goalNode) # Estimated cost to move between any two nodes. function estimate(fromNode: Node, toNode: Node) -> float 然后可以用来在代码中调用路径查找器，例如：
pathfindAStar(graph, start, end, new Heuristic(end))`},{header:"Heuristic Speed",slug:"heuristic-speed",content:"这个计算是在很底层调用的，所以我们需要时刻注意这个算法的效率。"},{header:"Algorithm Performance",slug:"algorithm-performance",content:`决定A*算法性能好坏主要因数是这几个的数据结构：寻路列表，图和启发式计算。
A*执行的迭代次数由总估计路径成本小于目标的节点数给出。我们叫这个数为l，这个数比Dijkstra中的n要小。通用m代表每个节点平均的 连接数。他的时间复杂度就为O(lm)，空间复杂度也为O(lm)。
除了Dijkstra对寻路列表和图的性能关注外，我们还添加了启发式函数。在上面的伪代码中，启发式值为每个节点计算一次，然后再重用。尽管如此，这在循环中发生得非常低，以O(l)时间的顺序排列。如果启发式值没有被重用，它将被称为O(lm)次数。`},{header:"Node Array A*",slug:"node-array-a",content:"在该算法中有一个关键步骤，在列表中搜索与特定节点对应的节点记录"},{header:"Keeping a Node Array",slug:"keeping-a-node-array",content:`我们可以使用增加内存的方式来提高运行效率，我需要申请一个拥有所有图中节点的数组。
如果节点使用整数进行顺序编号，那么我们根本不需要在这两个列表中搜索一个节点。我们可以简单的使用索引号来查找其在数组中的记录。`},{header:"Checking if a Node Is in Open or Closed",slug:"checking-if-a-node-is-in-open-or-closed",content:`当我们检测一个节点是否在open或close,那么就需要遍历列表。我们可以直接在节点信息中加一个类型来存储该节点是什么类型的。
# The structure used to track the information we need for each node.
class NodeRecord: node: Node connection: Connection costSoFar: float estimatedTotalCost: float category: {CLOSED, OPEN, UNVISITED} 如果我们使用类型来区分节点，那么我们是可以不需要close这个列表的。`},{header:"The Open List Implementation",slug:"the-open-list-implementation",content:`我们不能直接去掉open列表，因为还是需要求得最小的值。但是我们可以把记录改造成链表式，让每个记录点都记录着它后面的一个记录点。这样我们就需要修改节点的数据结构，如下：
# The structure used to track the information we need for each node.
class NodeRecord: node: Node connection: Connection costSoFar: float estimatedTotalCost: float category: {CLOSED, OPEN, UNVISITED} nextRecordInList: NodeRecord 但是这种实现会造成内存的浪费，大多数节点都不会在列表里。不需要的代码变得更加复杂，主要的优先级队列看起来很难看。
最好还是独立出一个节点索引的优先队列来解决open列表的优化。`},{header:"A Variation for Large Graphs",slug:"a-variation-for-large-graphs",content:`创建图中所有节点的实例是一种非常浪费的内存的。
这里有两种方式：
对有指针的语言中，我们可以先创建一个空壳数组，在需要使用那些节点时，当需要节点时，就创建节点。当我们检测一个节点的状态，我们可以直接判断数组中对应的索引的是否有实例。就可以判断节点是否已经被发现。
对于拥有垃圾回收的语言，我们最好是在关卡加载是就把所有节点实例化出来，不然在每次寻路时都会创建一些垃圾，这反而造成了卡顿。`},{header:"Choosing a Heuristic",slug:"choosing-a-heuristic",content:"更好的启发式方法，可以使A*跑的更快。所以选好了启发式方法可以事半功倍。"},{header:"Underestimating Heuristics",slug:"underestimating-heuristics",content:`当我们的预估值低的时候，该算法会跑的久些，但是精确度是高的。如果是最低值也就是低于所有情况，那我们可以获得真正的最短距离。这跟最短路径算法就是一样的。
所以我们在要求精度高的情况下，就需要选择低预估值。在实际的游戏开发中，我们可以选择一些高预估值的方法，因为游戏中并不需要太大精度值，关键是角色可以到达目标点。`},{header:"Overstimating Heuristics",slug:"overstimating-heuristics",content:`如果预估值过高，生成的路径就会更长。
但是并不意味着得到的路径就是一条不好的路径。如果预估值最多多x，最终的路径的长度也不会多过x。
高估值可以使的A*运行的更快。`},{header:"Euclidean Distance",slug:"euclidean-distance",content:"两点的距离来做预估值。 如果寻路的情况是在室内，两点之间就会出现墙壁或是障碍物，这样角色会花一些时间去绕过障碍物找到目标。 使用这种方式，要么是最快找到最好的路径，要么就会是严重低预估值。如上图在室内就会走很多次，但是在室外我们可以很快地找到最优路径。"},{header:"Cluster Heuristic",slug:"cluster-heuristic",content:`把节点分组，然后分别计算组与组之间的预估值。这个计算我们可以在关卡设计时就做好一个查询表，同样分组的也是设计时做。 如上图，我们需要从J点到K点。可以发现J点在A组，K点在C组。通过查表可以知道A到C的预值是29。我们就知道在组之间怎么走了，就可以找到每个组的出入点。然后在组点使用距离做预估值来寻路。
这种做法往往在室内寻路会有奇效。`},{header:"Fill Patterns in A*",slug:"fill-patterns-in-a",content:`上图，我们看到在障碍物多时，两种预估值的对比。
换一个说法就是，我们在执行A*时，预估值（启发式方法）对其影响很大，如果预估方法可以提供大量的地图信息，A*就会执行的更加的块。
其实我们使用距离来做预估值已经是很好的了。`},{header:"Quality of Heuristics",slug:"quality-of-heuristics",content:`很多程序使用A*时只使用了距离来做启发式，这并不是很好的，对寻路的优化来说修改启发式是很好的途径。
如果你想要优化你的寻路程序，最好的办法就是把寻路的代码过程可视化，这很重要。不要盲目的去修改。`},{header:"Improving On A*",slug:"improving-on-a",content:""}]},{path:"/Gameplay/AI/PathFinding/DIJKSTRA.html",title:"DIJKSTRA",pathLocale:"/",contents:[{header:"DIJKSTRA",slug:"dijkstra",content:`这个算法最开始设计出来并不是用来解决游戏中的寻路问题，而是来解决数学图形原理叫做最短路径。
这个方法一般在游戏寻路开发中使用的比较少，因为他是需要找到从开始点到结束点的所有路径，然后筛选出最短路径，这样做非常的浪费。
但是这是一个简单版本的A*算法，可以让我们更加容易的去理解A*。`},{header:"The Problem",slug:"the-problem",content:"我们需要找到一个最短路径，从开始点到目标点。"},{header:"The Algorithm",slug:"the-algorithm",content:"粗略的概括这个算法就是，从起始节点根据它的连接线开始扩张。当它扩张的后面的节点时，我们需要记录下来，它是怎么来到这个节点的，我们可以反向画一个箭头，从当前节点指向上一个节点。这样我们就可以得到一个从前节点到当起始点的路径。最终我们到达目标节点，此时的路径就是我们所求得最短路径。"},{header:"Processing the Current Node",slug:"processing-the-current-node",content:`这个算法使用迭代器来驱动，每一个迭代器记录着一个节点信息和连接这个节点的所有连接信息。
节点信息中有：上一个节点到节点的连接信息，从起始点到节点所有的花销
连接信息中有：头节点，尾节点和花销。 在上图中，对于第一个迭代器，开始节点就是当前节点。也就是说对于所有A点的连接的尾节点的总共花销就是对应每个连接的花销。 在上图中，当前节点是B时，B的每个连接的尾节点的总共花销等于当前连接的花销加上B节点的总共花销。
即：E的总共花销 = B到E的花销 + B节点的总共花销`},{header:"The Node Lists",slug:"the-node-lists",content:`我们使用两个列表来记录已经被发现的节点： open ：已经发现了的节点，并未遍历到的节点（未处理的节点），我们在处理当前节点时，当前节点所有连接的尾节点都应该属于open列表里。
closed ：已经遍历过的节点（处理过的节点）。 在一张图中，所有的节点只有三种状态： 被发现的节点，还未遍历
已经遍历过的节点
未被发现的节点`},{header:"Calculating Cost-So-Far for Open and Closed Nodes",slug:"calculating-cost-so-far-for-open-and-closed-nodes",content:"当我们计算尾节点的总共花销时，尾节点如果已经是被发现的节点，那么这个尾节点他是具有总共花销值的。我们就需要比较以当前节点做连接的总共花销小还是之前的总共花销小，如果之前的花销小，那么我们就跳过当前尾节点，反之我们就需要更新尾节点的数据。 上图中，在最开始，我们就设置A->D的花销为3.3。当我遍历到C点时，计算C的尾节点D的总共花销等于连接VI的花销加上C的总共花销，也就是1.3+1.6=2.9。这个数值显然小于之前的3.3，所以我们需要更新D节点的迭代数据。"},{header:"Terminating the Algorithm",slug:"terminating-the-algorithm",content:`当open列表里没有值时，这个算法就结束了，这时已经计算过从起始点到图中所有节点的路径，且所有节点都在closed列表里。
对于寻路，我们只关心到达目标节点，所以我们可以更早的结束遍历。
当前节点是目标节点时，我们就可以停止迭代。
但是很多时候，我们会在发现目标节点时，就停止迭代，即使我们获得的路径不是最短。因为在实际应用中最短的距离与发现目标节点时的那个路径差距并不大，所花去的时间差不多。`},{header:"Retrieving the Path",slug:"retrieving-the-path",content:"如上图，我们找到目标点G后，我们回溯G点的连接，再让他倒序即可获得路径。"},{header:"Pseudo-Code",slug:"pseudo-code",content:`# This structure is used to keep track of the information we need
# for each node.
class NodeRecord: node: Node connection: Connection costSoFar: float function pathfindDijkstra(graph: Graph, start: Node, end: Node) -> Connection[]: # Initialize the record for the start node. startRecord = new NodeRecord() startRecord.node = start startRecord.connection = null startRecord.costSoFar = 0 # Initialize the open and closed lists. open = new PathfindingList() open += startRecord closed = new PathfindingList() # Iterate through processing each node. while length(open) > 0: # Find the smallest element in the open list. current: NodeRecord = open.smallestElement() # If it is the goal node, then terminate. if current.node == goal: break # Otherwise get its outgoing connections. connections = graph.getConnections(current) # Loop through each connection in turn. for connection in connections: # Get the cost estimate for the end node. endNode = connection.getToNode() endNodeCost = current.costSoFar + connection.getCost() # Skip if the node is closed. if closed.contains(endNode): continue # .. or if it is open and we’ve found a worse route. else if open.contains(endNode): # Here we find the record in the open list # corresponding to the endNode. endNodeRecord = open.find(endNode) if endNodeRecord.cost <= endNodeCost: continue # Otherwise we know we’ve got an unvisited node, so make a # record for it. else: endNodeRecord = new NodeRecord() endNodeRecord.node = endNode # We’re here if we need to update the node. Update the # cost and connection. endNodeRecord.cost = endNodeCost endNodeRecord.connection = connection # And add it to the open list. if not open.contains(endNode): open += endNodeRecord # We’ve finished looking at the connections for the current # node, so add it to the closed list and remove it from the # open list. open -= current closed += current # We’re here if we’ve either found the goal, or if we’ve no more # nodes to search, find which. if current.node != goal: # We’ve run out of nodes without finding the goal, so there’s # no solution. return null else: # Compile the list of connections in the path. path = [] # Work back along the path, accumulating connections. while current.node != start: path += current.connection current = current.connection.getFromNode() # Reverse the path, and return it. return reverse(path)`},{header:"Data Structures and Interfaces",slug:"data-structures-and-interfaces",content:""},{header:"Simple List",slug:"simple-list",content:"用来存储最后找到的路径，可以使用链表(std::list)或者变长数组(std::vector)"},{header:"Pathfinding List",slug:"pathfinding-list",content:`用来存储open和close列表，这两个列表对该算法非常重要，这直接关系到算法效率的好坏。这个列表主要有4个操作： 添加节点到列表
从列表中移除移除节点
找到最小的花销的节点
找到列表中中特殊的节点 我们需要合理的找到一个数据结构来使用，我们会在A*的章节来详细讲解一下这些数据结构。`},{header:"Graph",slug:"graph",content:`我们在前面的实现也可以看到图的一些接口。
其中getConnections是最重要的一个方法，同时也是对性能影响至关重要。最常见的实现是：有一个存储的查询表并且使用节点的索引来查询。一个索引对应的是一个连接的数组。
连接的数据结构大概是这样的：
class Connection: cost: float fromNode: Node toNode: Node function getCost() -> float: return cost function getFromNode() -> Node: return fromNode function getToNode() -> Node: return toNode`},{header:"Peformance of Dijkstra",slug:"peformance-of-dijkstra",content:`该算法在内存和速度最大的依赖是操作寻路列表的数据结构，也就是open和close列表。
图中所有节点的个数为n，平均每个节点的连接数为m。那么这个算法的时间复杂度为O(nm)。
在算法结束时，有n个节点在close列表中，不会有超高nm个节点在open列表中。实际上在open列表里肯定会少于n个。所以最差情况下空间复杂O(nm)。
加上操作数据结构的时间，最差肯定会超过O(nm)。当然空间复杂度也会超过。`},{header:"Weaknesses",slug:"weaknesses",content:`该算法最大的劣势是不假选择的搜索整个图来找到最短的路径。
我们可以通过典型运行在不同阶段显示当前打开和关闭列表上的节点来可视化算法的工作方式。 在每种情况下，搜索的边界都由开放列表上的节点组成。因为靠近开始点已经被处理过了。
可以看到最后一个图，找到了最短路径，也就是那根线。同时也发现了有很多离那根线很远的点，我们也处理了。这也增加了很多计算时间。
我们需要有选择性的去处理节点。`}]},{path:"/Gameplay/AI/PathFinding/PathingFindingGraph.html",title:"The PathingFinding Graph",pathLocale:"/",contents:[{header:"The PathingFinding Graph",slug:"the-pathingfinding-graph",content:"寻路都可以使用数据结构图中的一种类型来表示：有方向非负权重图。"},{header:"GRAPHS",slug:"graphs",content:`图是有两种元素类型： 节点：常常被画成点或者圆圈
连接线：连接点的线
图是由一堆点和一堆先组成的。在寻路里每一个节点代表这一个区域或者位置信息啥的，连接线代表角色可以行走的路径。 我的寻路就是确定角色当前在那个节点，要去往那个节点，找到怎么从角色节点到目标节点的所有连接线。把所有连接线加起来就是我们的寻路路径。`},{header:"WEGHTED GRAPHS",slug:"weghted-graphs",content:`前面我们知道了怎么找到寻路路径，但是路径可能会是有多种方式。那我们如何选出最优的路径呢？
其中有一种方式就是在每一条连接线上都增加一个数值。这个数值常常叫做权重，有的游戏设计里叫做花销。 权重一般代表时间或者距离，当然很多开发者也会把权重的数值设置成一个复合参数，也就是把时间、距离和其他因素混合成一个数值。
使用权重我们就可以在多个路径中选取权重和最小的路径。 如果我们是需要从A点到C点，可以直接看出来有两条路径： A -> B -> C : 权重和为9
A -> D -> B -> C ：权重和为16 所以我们选择第一个。`},{header:"DIRECTED WEIGHTED GRAPHS",slug:"directed-weighted-graphs",content:"两个节点A,B如果是有连接线联通，在一般的图里既是A可以走到B，B可以走到A。假设有一种情况，角色从二楼直接跳到一楼，但是不能从一楼直接跳到二楼。这个时候的连接线就需要增加一个方向的属性，这样的图可以叫做方向权重图。"},{header:"Data Structure",slug:"data-structure",content:`我们可以简单的把图抽象为：
class Graph: # An array of connections outgoing from the given node. function getConnections(fromNode: Node) -> Connection[] class Connection: # The node that this connection came from. fromNode: Node # The node that this connection leads to. toNode: Node # The non-negative cost of this connection. function getCost() -> float`}]},{path:"/Gameplay/AI/PathFinding/",title:"Pathfinding",pathLocale:"/",contents:[{header:"Pathfinding",slug:"pathfinding",content:"寻路是让角色知道自己在哪里并且决定自己去哪里，怎么去目标点。"}]},{path:"/Gameplay/AI/PathFinding/VisibilityGraphPathPlanning.html",title:"可见性路径规划",pathLocale:"/",contents:[{header:"可见性路径规划",slug:"可见性路径规划",content:"我不知道翻译是不是对的,英文是：Visibility Graph Path Planning，简称：VGAPH。"},{header:"是什么",slug:"是什么",content:"我们从实际问题出发，如下图，当我们在游戏中需要使一个角色自动从start点移动到goal点并且绕开障碍物，蓝色为障碍物。 我们第一个想到的使用的方法就是寻路，那么我们说的VGAPH就是一种寻路的策略。"},{header:"为什么",slug:"为什么",content:"我们常见的寻路方案中，需要在角色移动或者是在规划路线时检测物理碰撞，从而找到顺畅通过的路线。检测碰撞也是一个比较耗时的工作，如果使用不当的话。 VGAPH这个寻路的方案是直接跳过碰撞检测。"},{header:"怎么用",slug:"怎么用",content:""},{header:"实现",slug:"实现",content:""},{header:"参考",slug:"参考",content:`https://lis.csail.mit.edu/pubs/tlp/collision-free-planning-cacm.pdf
http://ntur.lib.ntu.edu.tw/bitstream/246246/200704191001565/1/01389835.pdf
https://github.com/christopher-boustros/Unity-Visibility-Graph-Path-Planning-Simulation
http://www.ijoar.org/journals/IJOARM/papers/Visibility-Graph-Shortest-Path-in-Polygonal-Arena-Motion-Planning.pdf
http://lavalle.pl/planning/`}]},{path:"/Gameplay/AI/PathFinding/WorldRepresentation.html",title:"World Representations",pathLocale:"/",contents:[{header:"World Representations",slug:"world-representations",content:`我们现在知道寻路使用图来解决，但是我们的游戏场景并不是由多个节点和节点的连接组成的。那么我们就需要有游戏场景抽象话。
抽象场景的方式叫做划分方案（division schemes）,每个划分方案都有三个重要的性质：量化/定位（quantization/localization）、分区（generation）和有效性（validity）`},{header:"Quantization and Localization",slug:"quantization-and-localization",content:`在游戏中，角色想要去商店，就需要把角色当前的位置转化到图中节点，同样商店的位置也要转化到图中节点。这个转化过程叫做量化（quantization）。
在找到了去商店的路径后，我们需要把路径中的节点转化为游戏场景中的位置，这个过程叫做定位（localization）`},{header:"Generation",slug:"generation",content:`有很多分区的方法，每个游戏中用到的可能都不太一样。一般分为手动分区和自动分区。
手动分区最常用的是 狄利克雷分布（Dirichlet domain）
自动分区最常用的的 瓦片地图（tile graphs），可视化点（points of visibility）和 导航网格（navigation meshes）`},{header:"Validity",slug:"validity",content:"我们寻路得到一个路径了，从节点A到节点B,那么意味着角色无论如何都可以从A点移动到B点，但是如果无法量化A点或者B点的话或者角色不具备通过这个路径中的某个能力（如游泳）。那么这个寻路就是无效的。"},{header:"Tile Graphs",slug:"tile-graphs",content:"这种方式一般在2D游戏里使用，多出现在独立游戏里。但是也有很多3D游戏会使用网格在映射游戏。比如很多RTS游戏，在里面建造房子，以格子来设置房子大小以及位置。"},{header:"Division Scheme",slug:"division-scheme",content:"用网格代表游戏世界。每一个小块一般都是正方形的，换句话说就是棋盘格。每个小块周围有8个小块围绕，与每个小块连接的也就是8个。"},{header:"Quantization and Localization",slug:"quantization-and-localization-1",content:`我们可以很简单的量化角色在那个节点，我们以网格左下角为原点，向上为Z轴，向右为X轴建立坐标系。我们就可以用下面的表达式获得角色节点位置：
tileX: int = floor(x / tileSize)
tileZ: int = floor(z / tileSize) 同样定位也可以很容易的做到，反向求一下x和z值就可以。`},{header:"Generation",slug:"generation-1",content:"基本的网络生成一般都是自动的。因为它每一个片基本都是差不多。它可以在游戏运行时生成。"},{header:"Validity",slug:"validity-1",content:"如果有的格子是半格可以走，半格被遮挡住。这种情况就需要在由节点定位到游戏场景位置时，考虑角色是否在那个位置。"},{header:"Usefulness",slug:"usefulness",content:"在一个RTS游戏关卡里可能有成千上百的小块，这会使得寻路算法，花销很多。 从上图可以看到寻路得到的路径和理想上的路径有一定的区别，而且看起来不是那么的丝滑。"},{header:"Dirichlet Domains",slug:"dirichlet-domains",content:""},{header:"Division Scheme",slug:"division-scheme-1",content:"寻路节点在空间中有一个称为特征点的关联点，并且通过将该点的狄利克雷分布的所有位置映射到该节点来进行量化。确定游戏中的一个位置的节点，我们找到了 最接近的特征点。 你可以把狄利克雷分布看作是来之源点的锥体。如果你从顶部查看它们。你就可以看到每个圆锥体的区域都是属于该源点的区域。这是一个很有用的排除故障的可视化方法。 我们可以为点增加一个权重，来调整圆锥的斜率，这样就可以调整么诶个圆锥覆盖的区域。当然也需要注意这关卡编辑时，设置关键点时，他的权重值不能过高。不然就会出现上图的情况。"},{header:"Quantization and Localization",slug:"quantization-and-localization-2",content:"位置通过找到最接近的特征点来量化，节点的定位是由形成分布域的特征点的位置（即 上诉例子中锥的尖端）给出的 。"},{header:"Validity",slug:"validity-2",content:`无法保证从一个域中的一个点移动到 连接域中的某个点不会通过第三个域。这第三个域可能无法逾越，而且可能已经被寻路器忽略了。在这种情况下，遵循该路径将会导致一个问题。有可能角色就撞墙了。
为了防止这种情况，我们 可以设置某种备份机制（如避免墙上的转向行为），来解决这个问题。`},{header:"Usefulness",slug:"usefulness-1",content:"应用非常广泛。它的优点是非常容易编程，并且易于更改。可以在几倍编辑工具中快速更改寻路图的结构，而无需更改任何级别的几何结构。"},{header:"Points of Visibility",slug:"points-of-visibility",content:"在2D环境中最短的路径一般都是会经过转角处。那我们可以把几个转角连接起来就是最短路径了。如果我们移动的角色有半径，那么就从转角点向外偏移直到可以使角色转向过那个转角点。"},{header:"Division Scheme",slug:"division-scheme-2",content:"我们在连接两个点时，怎么判断两个点 之间是可以通过的呢？我们从其中一个点发射射线，如果这个射线并没有碰撞到其他物体，直接到达了对应点，那么我们就认为这两个点时可以相互走的。"},{header:"Quantization and Localization and Validity",slug:"quantization-and-localization-and-validity",content:"为了量化，通常用课件点来表示狄利克雷域的中心 。此外，如果使用狄利克雷域进行量化，则量化到两个节点的点可能无法相互到达。正如我们在上的狄利克雷域中所看到的，这意味着该图是无效的。"},{header:"Usefulness",slug:"usefulness-2",content:"这是一个很好的方案，但是这其中有很多无用的连接，我们需要手动去处理。使用导航网格更好一些。"},{header:"Navigation Meshes",slug:"navigation-meshes",content:"这个是最常用的一个方式。"},{header:"Division Scheme",slug:"division-scheme-3",content:"可以对游戏场景中的地面做了多边形划分区域。对于每个多边形可以认为就是一个节点。如下图所示："},{header:"Quantization and Localization",slug:"quantization-and-localization-3",content:`我们做量化时，是不是就需要找到角色现在处于那个多边形内？最容易想到的方式就是遍历所有多边形，如果多边形少还可以，多了的话是不是就会等一会。这里有一种简单的方式，我们会记录下来角色上一帧所在的多边形，我们先检查这个多边形 ，然后以扩张（上一帧多边形周围）的方式来检查。这样可以更快的找到。 量化中有一个问题，如果游戏场景有多层的情况。我们划分多边形时，不考虑垂直方向的情况。这就会出现错误。比如：上图，量化看出人物在底层，但是实际上这个人物是在上层的。我们同样可以使用角色上一帧的多边形来确定角色是在上还是下。在一些特殊的情况下使用这样的方式还是会出现一定的问题，通常需要一些特殊的案例代码来知道一个角色何时在跳跃，或者推迟寻径，或者使用轨迹预测来确定它将降落在哪里。
定位一般是定到多边形的重心位置。当然多边形一定要是凸的。`},{header:"Validity",slug:"validity-3",content:"理论上我们可以中一个区域的任何一个点直接到达相邻区域。 我们看上图，就出现了从一个区域到另一个去区域产生了碰撞的情况。这就是在生成多边形或是设计多边形时的错误。"},{header:"Usefulness",slug:"usefulness-3",content:`这是个很好的方案，在一些特殊情况下也可以使用，比如爬墙，跳跃等。
有一个问题，如果分的区域很小，角色不能容纳进去。就会有一些问题。我们可以在设计时对其限制。`},{header:"Edges as Nodes",slug:"edges-as-nodes",content:`地面多边形还可以通过将节点分配到多边形的边上，并使用跨多边形的面连接，从而将地板多边形转换为寻路。 这种方式在渲染中很常用叫做基于块渲染（portal-based rendering）。就是把一个整的几何体，分成多个小块，当我需要那个块时就渲染那块。
在导航网格中，每个楼层多边形的边缘都像一个块，因此有自己的节点。我们不需要做射线检测。根据定义，凸底多边形的每一条边都可以从其他的每一条边看到。 如上图，我们也可以把节点在多边形线上的位置改成动态的，改到角色移动的方向。这是一种连续的寻路算法。`},{header:"Non-Translation Problems",slug:"non-translation-problems",content:""},{header:"Cost Functions",slug:"cost-functions",content:""},{header:"Path Smoothing",slug:"path-smoothing",content:""}]},{path:"/Gameplay/AI/Tactical/TacticalAnalyse.html",title:"Tactical Analyse",pathLocale:"/",contents:[{header:"Tactical Analyse",slug:"tactical-analyse",content:""},{header:"Influence Map",slug:"influence-map",content:`给每个角色一个影响力，然后角色处于地图中的某个位置。他就会对他周围的地区产生一些影响。
比如说我们要派一个队AI小兵去抢滩登陆，我们就需要知道敌方的布防，根据这个 布防去规划一条路径。布防敌军是在巡逻，所以点位还不是固定的。我们就不能简单的使用寻路算法，我们就需要做一些预测。
这里就可以用到这个工具，我们先把整个地图映射到2d平面化成格子块。再把每个角色放入到他位置 对应的格子块里。每一个敌方单位都有攻击力，这个就可以作为一个影响范围，覆盖角色周围的 格子。
然后再规划路径时，我们就 把拥有数值的格子当做障碍物即可 。`},{header:"Refence",slug:"refence",content:`https://www.gamedev.net/articles/programming/artificial-intelligence/the-core-mechanics-of-influence-mapping-r2799/
https://gameschoolgems.blogspot.com/2009/12/influence-maps-i.html
http://vigir.missouri.edu/~gdesouza/Research/Conference_CDs/IEEE_SSCI_2007/CI%20and%20Games%20-%20CIG%202007/data/papers/CIG/S001P012.pdf
http://www.aisharing.com/archives/80`},{header:"Terrain Analysis",slug:"terrain-analysis",content:""}]},{path:"/Gameplay/AI/Tactical/WaypointTactics.html",title:"Waypoint Tactics",pathLocale:"/",contents:[{header:"Waypoint Tactics",slug:"waypoint-tactics",content:""},{header:"Tactical Locations",slug:"tactical-locations",content:""},{header:"A Set of Locations",slug:"a-set-of-locations",content:""},{header:"Primitive and Compound Tactics",slug:"primitive-and-compound-tactics",content:""}]},{path:"/Gameplay/AI/Tactical/",title:"Tactical",pathLocale:"/",contents:[{header:"Tactical",slug:"tactical",content:`行为决策对于角色来说有两个重要的限制： 用于单个角色
不对基于现有的一些信息去预测整个游戏的走向 策略方法从简略的信息中推断出战术形势的方法，使用展示形势作出决定，并且多个角色之间进行调节。
并不是所有的游戏都会有这个模块`}]},{path:"/Gameplay/AI/%E6%B8%B8%E6%88%8FAI%E8%AF%BE%E7%A8%8B/TraineeAI.html",title:"游戏人工智能",pathLocale:"/",contents:[{header:"游戏人工智能",slug:"游戏人工智能",content:""},{header:"游戏人工智能引论",slug:"游戏人工智能引论",content:`大家好，我叫吴鹏。
一个工作多年且依旧发量浓密的程序员。
我在公司的项目是做一款纯真的RTS的游戏，我负责其中AI的一些工作做。
我们这个课程的标题是游戏性人工智能基础，
ppt
所以会着重讲一些在对于实现游戏玩法
所使用到的一些人工智能相关的基础知识。
ppt
首先我们来了解下人工智能和游戏
ppt`},{header:"为什么玩游戏",slug:"为什么玩游戏",content:`你们觉得人们为什么玩游戏？大家自己也要玩游戏的话，可以讲讲自己从游戏中的能得到什么？为什么玩游戏？
游戏范围其实很广，像我们成都最受欢迎的麻将，一些运动足球，篮球都是游戏。你们有玩的吗？
你们觉得在参与这些游戏的时候，你获得了什么？
我们来讨论为什么玩游戏，其实就像了解一下什么是游戏？
我觉得游戏，有人用它消磨时间，有人用他来社交，有人用他来挑战自我来获得一些成就感。
那么游戏可以满足我们很多需求，它是什么？`},{header:"游戏是什么",slug:"游戏是什么",content:`ppt
我们一般认为他有三方面的属性：
科学 ：有数学、有计算机科学、有图像视觉、有物理模拟仿真学。
同时呢它也具有艺术的成分在里面，我们说游戏是所谓的第九大艺术。
他有图画、他有剧情、他有音乐。游戏作为一个作品也是设计者传递给玩家的一种想法，一种理念
那么第三呢？商业。
并不是所有游戏都有商业的成分在里面，但是游戏这个行业，一定有商业这个成分在里面。
一个游戏一般是有这三个部分组成的。`},{header:"什么是人工智能",slug:"什么是人工智能",content:`ppt
那我们再看看什么是人工智能的？
这两年人工智能这个词很火热哈
什么深度学习 什么机器学习
不知道同学们 有没有听过
比如说AlphaGo 战胜了人类的顶尖棋手，
AlphaStar在星际中战胜人类的顶尖选手。
人工智能是关于让计算机能够执行人类和动物能够完成的思维任务。
其实人工智能的定义是很广泛 比如我们做算法时 穷举法 也是人工智能
有人 不是说世界上最强的人工 智能 就是if else么
现在人工智能都这么 火热了
它能为游戏带来了什么呢？`},{header:"人工智能为游戏带来了什么",slug:"人工智能为游戏带来了什么",content:`ppt
我认为给游戏带来的主要就是两个方面：
赋能，把以前不能做的事，现在能做了。
比如说我们使用 人工智能可以让更真实的游戏、可以有更平衡的游戏。
另外一方面呢，它可以提高我们的开发效率。作为商业这个是比较重要的。
我们需要更块的开发速度，更低的开发成本。
那你可能要说了现在人工智能都这么厉害了
又可以 给我们的游戏带来那么多的好处
是不是这些技术早已经在游戏中运用起来了
其实在现在绝大部分做游戏特别是Gameplay方面，并没有使用现在最火的深度学习、机器学习。
那么是为什么？`},{header:"人工智能应用在游戏中的难点",slug:"人工智能应用在游戏中的难点",content:`ppt
主要难点就是成本和效果。
我们需要花时间去训练AI且还要维护它
并且需要大量的数据支撑,或者是纠错
在训练完后他会不会是人工智障
这个AI有多么像人 他的可控性大不
其实这里就是科研和工业的最大区别，我们刚刚看到那几个例子都是科研项目对吧。
科研是以获得最好的结果为基准。
而工业是需要以最小的成本来获取最大的成果。
举一个这几年比较火的一个概念在游戏行业,
光线追踪,这个技术其实很多年前就有了
但是我们这几年才开始听说 游戏里面有这个
主要还是会有一些实际应用上的 一些技术没有完善 包括硬件上的不支持
我们以例子来讲解人工智能在游戏中的难点。
ppt
成本问题，比如说麻将
第一个是麻将的玩法众多，我们知道当我们训练好了一个AI。
它在这个场景可以很好的工作，但是换一个场景可能就会有些问题。
还有就是我们需要训练一个AI，需要使用大量的数据做支撑。
这个数据的质量的好坏直接影响到AI的强弱。
pptControllable
下一个问题，我们说一下拟人。
其实在游戏中我们并不需要AI很智能，我们需要的是像人。
这其实是一个悖论，我们举个例子。
比如你在打王者荣耀，你的队友本来很发挥好好的，后来浪了
老是失误，犯了错误，导致最后这局游戏输了，你可能很会理解他
这就是人性，人随时都会改变主意，人都会犯错嘛。
但是我告诉你那个队友其实是AI控制的。
你就会说这AI有bug。
这就是人们的期望不同，得到的效果不同
ppt
那么我们第三个我们再看一下 可控程度
我们再以王者荣耀为例子 ，你的队友和对手都有可能是AI控制的
我们希望每个人都有自己的风格 整个队伍都有整个队伍的风格
就是猥琐发育或者就是喜欢一个人gank五个人
你怎么控制它 如果你做了一个不可控的AI
你这些都不太好实现
那么我们的人工智能主要在游戏里有哪些 应用呢？`},{header:"人工智能的应用",slug:"人工智能的应用",content:`ppt
人工智能在游戏领域主要有三个应用场景：游戏性、游戏内容制作、玩家服务
第一个能就是玩游戏，这个大家应该都很好理解，不管是作为你的对手还是队友。
比如说我们打游戏遇到的每一个敌人其实都由人工智能控制的。
在一款游戏刚发布的时候，可能玩有的人不是很多。
为了让玩家能体验到游戏，我们可能会往游戏中添加机器人玩家。
第二个呢，就是游戏内容生成。这个方面其实比上一个方面还要应用的多一些在行业里。
现在一个比较大型的游戏，它可能就会有很多关卡，地图，剧情什么。
如果过这些都是人为手动去制作，这会很耗时耗力。
如果有人工智能来制作或是辅助制作，就会很好
比如说，现在有些厂商他的场景，城市都是自动生成的。
像很常见的Rogue Like类型游戏他里面的关卡，道具属性都是自动生成
不用让策划去设置那么多的关卡
第三个就是玩家服务，这是衡量玩家的体验。
比如说玩家会有一些反馈，我们就可以把这些反馈统计起来。
或者说是一些智能客户助手啥的。
讲了那么多人工智能相关的东西。
接下来我们来看看今天的一个主题人工智能在游戏玩法中主要用到了那些方法。`},{header:"游戏性AI 模型",slug:"游戏性ai-模型",content:`ppt
我们今天主要介绍一下传统Gameplay中制作AI的一些方法。
这个图也是AI在我们整个游戏中的架构或者说是模块，
这其中主要有三个块：移动、行为决策、策略
我们可以看到到AI层在整个游戏的架构中其实是比较上层。
我们AI层是从我们游戏环境 中获取到一些 消息，
然后 再调用 动画层 和 物理层这些基础服务来实现功能`},{header:"移动 & 导航",slug:"移动-导航",content:`ppt
那么我们进入今天的 第一个主题。
上面的AI模型图中上写移动，可以分为两部分
角色移动与导航
这个板块主要是讲这几个东西`},{header:"移动",slug:"移动",content:`ppt
这里的移动并不是说怎么控制 角色 移动
或者说怎么实现角色移动
而是在角色移动时的处理，这些处理可以 使得AI更加 的合理性
或者是说看起来没有那么的僵硬
这里一般分为：
转向行为，集体移动，预计算物理
转向行为就是保证角色以正确的速度和正确的方向移动
集体移动就是当需要控制多个角色移动时
需要考虑他们的队形 移动方式
有可能有的角色移动速度快 有的慢
我们是否需要处理一下这个问题
预计算物理，最简单的例子是玩家发射导弹打AI
AI需要躲避这个导弹 就需要计算一下他的轨迹
然后合理的移动开
当然还有其他的特殊处理的移动比如说跳跃，汽车移动
咱们今天就不一一介绍他们
我们简单的说说角色移动的两个小问题
ppt
比如说我们需要把这个车 从A点 移动到B点 。
那我们 如何判定车到达 了B点？
停顿
如果说我们就判断角色的位置与 B点位置是否相等是不是就可以了呢？
那我有多个角色都同时需要到达B点，会出现什么 情况呢？
ppt
蠕动 对吧
我们大概率会看到几个角色都是疯狂靠近B点，但是就是不能触发到达的方法。
其实解决方案也很简单，我们把检测到达B点的条件改为
ppt
到达B附近即可，以 B点为圆心 设置一个半径为到达范围。
你们觉得这样处理是否已经是一个完美的方法了？
停顿
并不然 ，这里 如果说还需要严谨一些， 我们一般会把 角色的体型算入其中
这是为防止大体型的角色的中心位置点依旧无法到达那个范围。
于此同时 我可以再加一个比检测到达的半径更大的半径 ，
当进入第一个半径时，我们的 角色 可以适当减少速度。
这样到达我们的目标范围时，就可以平滑的停下来。
当然对 AI 移动时的 小处理还有很多，一般都是不同情况有着不同的处理。
ppt
比如AI需要追逐时，AI角色的转向问题，我们是先转向再移动还是边转向变移动。
转到那个方向，AI到追逐对象的方向还是追逐对象的方向？
今天我们就不一一的来讲解这些情况
大家可以下来思考一下
接下来我们来聊聊寻路。`},{header:"导航",slug:"导航",content:`ppt
寻路其实都可以使用图这个数据结构来抽象出来。
图中的每个节点可以代表着一个位置或者一个区域
图中的连线上面的数值代表着从一点到另一点的花费的多少
当然这个线中如果有箭头 就说明只能从这个点到另一个 点
那么我们怎么个寻路呢
其实就是求怎么从一个点走到另一个点且这个路径是最短的
该这么求呢？
我们第一个的想法就是一个点一个点的挨着走
算出所有从A点到B点路径，然后赛选出花销最短的一条路
这样是不是看起来很暴力
有点像小时候玩的那个迷宫图
这里我们可以使用最短路径算法来求解。
ppt
我们来简单的介绍一下这个算法
在这之前我们介绍一下
这个算法会用到的一些东西
首先是连接信息 ：也就是图中我们 看到的每一个根线
它包含了头结点和 尾结点
当然还有走这个连接的花销
每个节点的都记录 着与这个节点的所有连接
比如说A就记录了连接1,2,3
这里第二个是记录着这个节点到寻路起点的所有花销
它的计算方式也很简单就是上一个节点的 这个值加上上一个节点到该节点的花销值
也就是说 B 点的这个值1.8等于A点的这个值0.5加上连接一的1.3
是不是有点像斐波拉契数列 前面两个加起来等于后面一个
第三个则是走的那个连接到这个节点，也就是到这个的节点的上一个连接是什么
下面这个是两个 列表
这个open list存放的是 已经被发现的节点
这个closed list存放的是 已经被处理过的节点
这里说的处理是 更新当前节点所有连接的尾结点的信息
也就是总花销以及连接信息
这个说起来有点绕
我们看图来 解释哈
我们当前节点是A点
那我们就需要更新B,C,D这三个点的信息
比如说B点，先更新从B点到开始节点的花销就是连接1的花销值1.3
加上从A点到开始节点的花销0.5，得到最后的值1.8
并且记录连接1到B点。 C，D点是同样的操作
再完成了这个处理后 咱们就把新发现的B，C,D这三个点加入到open列表里
再把A加入到closed列表里面
下面就是我们记录的当前节点，也就是每次处理的节点。
这个节点是从已经发现的节点中找到起点最短花销的点作为当前节点 。
寻路起点会作为第一个当前节点
介绍了这些内容，大家可能 对这个算法有那么一些了解
但是还是不是特别的清晰对吧
ppt
我们来具体讲讲这个流程
这是一个以迭代器为基础的算法
开始我们把起点加入到Open list 里
然后检测Open list 是否为空
我们先看正常流程下来
如果不是空就找Open list最小总花销的节点作为当前节点
然后判断当前节点是不是终点
如果不是，我就更新当前节点连接上的所有尾结点的信息
再把新发现的尾结点加入到open list里面
然后把当前节点从移除open list 中移除
加入到closed列表里
然后 再回到前面 检测open list
这里有两个方式终止迭代器也就是循环
当我们发现open list 里面没有值时
就终止 这是为什么呢？
因为 我们已经处理完了图中所有的节点
都没有发现一个路径可以到达终点
第二个就是我们 找到的当前节点
如果是目标节点 那就说明我们找到了
最短路径 为什么呢？
这是因为我们每次在open list 筛选节点时
都是选择 的最短总花销的节点
所以这样选择出来的必然是最短路径
这个流程大致就是这样的,可能大家听的还是有点云里雾里. 没关系
这里我们来例子讲解一下：
Figure 4.11:我们要求 A->G 最短 路径
这个过程就是 最短路径算法。
大家对这算法应该是了解了吧
你们觉得说这个算法最大的缺点是什么呢？
ppt
我们看这个算法 最大 的劣势是不加选择的搜索整个图来找到最短的路径
这个 图显示了不同 阶段的 open 和closed列表中的节点的情况 。
每种情况 下，搜索的边界都 由开放列表上的节点组成。因为靠近开始点已经被处理过了。
可以看到最后一个图，找到最短路径，也就是那根 线。
同时也可以看到有很多 离那根线 很远的点，我们也处理了
这就增加了很多计算时间 。
为了减少处理那些不必要的点，我们可以对这个方法做了一定的改进
就形成了我们的A*算法，`},{header:"A*",slug:"a",content:`ppt
可以说现有游戏中的寻路算法基本都还是使用的这个算法
最短路径算法最早设计之初也不是为了游戏
而A*设计出来就是为解决游戏中的寻路问题
A*算法翻译过来叫启发式寻路 我更喜欢叫他预估值寻路
A*跟最短路径算法的工作原理差不多
所用到的信息都是差不多.
我们可以看到在节点信息中多了两个字段
多了一个预估值，直译就是启发值
这个值是当前 节点预计到终点所用的花销
这个值 咱们先放一边 就当它是已知数
咱们先看A*算法的流程
咱们后面会讲这个值是怎么个计算
最后一个 值就是从起点到当前点的花销加上
预估从当前点到终点的花销
也就是我们的第二个值加上第四个值
同样是需要两个列表，分别存发现的节点和已经处理的节点
ppt
我们来看看流程图
跟最短路径算法整个流程是差不多的
与最短路径算法最大的不同就是
我们在open列表中获取当前节点时
并不是取从起始点到节点的最小花销的点，而是取最小预计经过节点到终点的花销点。
A*在迭代时，可能会发现在closed列表中的节点更小花销。
也就是说,我们发现有一条新的路径可以走到closed中一个节点,并且走这条路他的花销更小
因为每次遍历并不是找的最小花销
所以在发现更好的路径在closed列表里时
可以把这个节点的总共预估花销更新了
再把他放到open列表中
我们A*的结束在大多数情况下跟最短路径一样
计算到当前节点为终点时就结束
但是这个是有一定的问题的
因为我们取的是预计总共花销最小
而不是取得总共花销最小
但是我们还是使用的这样一个结束的原因
如果我们为了找到最短路径，反复的查找
那么这样所带来的性能消耗，就会跟最短路径差不多。
但是在游戏中就会出现,角色等一会才移动.
我们是希望游戏中的角色即使的响应玩家,让玩家有一个好的体验.
同样我们以一个实际例子来讲解
ppt
我们来看一个示例
Figure 4.14
这里需要
流程
我们对A*算法的流程已经了解了吧
之前咱们说这个启发值是预制，那我们怎么去计算这个 值呢
可以说这个预估值计算是A*算法性能的关键
当我们的预估值越精确，A*算法就会越快。
所以说这个预估方法就很关键
那我们来看看怎么计算这个预估值
ppt
一般有两种方式：距离和分组
距离
这个很好理解就是两点之间的距离
使用这样方式最好是在室外，或者是阻挡物比较少的时候
我们看这个图就知道，在室内是算法明显多处理了很多点
这是为什么呢？
因为两个节点他的 直线距离很近，但是角色不能直接而到达。
需要绕路 这个跟我们去重庆使用导航是一个道理哈
那么我们怎么解决这个问题呢？
我们可以把室内分组来形成一个大的节点，
我们可以先计算怎么从起点组到终点组
再计算组内怎移动
比如说一个房间内分为一组
我们看这个图，有三个房间
我们想从j点走到k点
先看J和K分别在A和C组
就先计算怎么从A组 到C组
算出 A-B-C
然后在每一个组里分别计算
由那个节点进入和出组内
当然还有一些其他的预估方式，是根据我们游戏的特殊处理的。
比如说，我需要过河，当我具备游泳能力时，我可以直接游过去，不具备时 就需要绕路
当然还有很多其他 的寻路的算法
绝大多数新的寻路 的算法都是 基于我们A星算法改进
比如说我们可以把两个列表去掉
使用状态记录在节点 信息中
也可以说当你在open list里发现了终点
你就找到了一条路,此时也可以结束寻路
当然如果说你想要去优化你的寻路算法
最好的方式就是把寻路的过程 可视化出来
这样可以很清晰明了的分析
今天 咱们算法就讲到这里
我们现在已经了解如何解决图中求路径的问题
那么怎么把图转化成我们的游戏场景
又怎么把游戏场景转化成图呢？
ppt
一般会有这四种
瓦片图
狄利克雷分布 我一般叫他圆锥域
可视化点
导航网格 navmesh
ppt
我们先来看看 瓦片式地图
这个也是最简单的 它在2D游戏中使用很广泛 同样也会在3D游戏中使用到
想很多战棋类的游戏,或者是slg策略类的游戏会用到这种.
一般是用网络代表着游戏世界 也就是棋盘格
每个小格代表着一个地点
当然也会有蜂窝型的
我们一般把
游戏场景抽象为图的这一过程叫做量化
我们一般把图转化为游戏场景叫做定位
量化和定位都比较简单，
我们根据当前的位置除以格子大小就可以知道我们在哪一格了
反之定位也是如此计算
PTT
在定位时我们需要注意
角色是否能够在当前位置
因为有可能当前位置已经被挡住了部分
缺点
格子数多时 几千个几万个时 这会使寻路算法 花销很多
同样的它所产生的路径不会那么的丝滑
有人就提出了 一个针对这个方案的专门的寻路算法 叫做 jsp
有兴趣的大家可以去看看
ppt
这种方式叫做狄利克雷分布
我们在游戏地图的空中放一个圆盘
然后在这个圆盘正上方放一个向地面照射方向光
地面上阴影的区域就是 属于该圆盘,这个圆盘就是我们图中的节点
我们一般在关卡设计的时候就对地图配置该点也就量化好了
在定位 时，只需要判断角色与那个节点近就可以了
这个方式有个需要注意的点就是我们无法保证两个域之间
能否直接到达，是否会通过第三个域。第三个域角色是否可以走过去
这些我们 都需要提前做好配置设置
这个 方式在游戏里使用的很多 一般像是mmo会使用这种
他非常容易去实现编程 但是对于地图编辑就会比较麻烦 去设置点位
是不是发现这种方式减少了之前说到的网格法的格子数量
ppt
我们在2D环境中最短的路径一般都会经过转角
那么我们可以把转角连接起来就形成了一张图
那么我们怎么去定义两个转角点是可以通过的呢？
我们可以使用射线检测 来检查两个点之间是否有障碍物
于此同时在量化时需要对转角节点的位置向外偏移
偏移到角色可以移动的为位置 而不是转角
这是一种简单好实现的方案
ppt
缺点就是如果自动连接的话 会有很多无用的连接
我们需要手动忽略一些连接线
这个方式不局限说使用在室内
我们也可以对地图做配置
比如说 建筑四周 ，山体转角设置点位
这也是我所在项目中 寻路使用一个方式
下面一种
可能对游戏开发有一定了解的同学
说到寻路可能就会说 导航网格
ppt
这确实是现在最常用的一个寻路转化方案
它跟刚刚讲的可视化节点有点像
不过他是把我们的地图切割成多边形的方式
然后把节点放在每个多边形的重心上
我们怎么定位角色在那个 节点呢？
首先想到的 就是遍历 所有多边形
这显然不是一个好的办法
我们一般的做法是记录下角色上一帧在那个多边形
这一帧获得节点时,从那个多边形开始搜索
再搜索那个那个多边形周围的
ppt
同时我们也需要注意
在划分多边形时 多变形的大小问题以及周边的障碍物
我们看这个图
角色可能处于这个三角形的这个位置
如果他想这样直接走过去可能就走不过去
当然 如果说 这个三角形面积小于角色的横截面面积时
可能角色就永远都无法到达
同样的我们在生成网格时
需要考虑好垂直方向的一个节点问题
不知道大家有用像ue或者unity这样的引擎没
他们里面就自带导航网格这个功能,
他在生成网格前就需要设置一些参数：
角色 半径，斜坡角度，障碍物这些
当然现在引擎里的一些navmesh的实现方式
跟我们现在讲的都差不多
不过还是会有一些优化点的
比如说我们把节点放在多边形的边上
这样可以不去判断同一个多边形两节点的连通性
因为凸底多边形的每一条边都可以从其他的每一条边看到。
还有的优化是把节点放在多边形边上且可以在边上移动
始终让角色与一些 节点是在一条线上
保证了寻路的连续性
下面咱们来聊聊行为决策`},{header:"行为决策",slug:"行为决策",content:`ppt
我们在游戏中一般会用这三种因为
前两种一般用的会多一些
第三种会少一些，它是一种结果导向的行为制定
会有一定的不可控 性
ptt
在讲之前我们先播放一个视频把
这里一个 打架的 一个视频
这个是一个 典型的AI
有很多方法去制作这个怪的AI 行为
一个状态机 一个行为树 都可以
待会我们来聊聊分别怎么实现的
大家可以看看 休息休息
也想想如果让你来做 你会怎么来做这个AI
这个游戏是巫师三 是比较早几年的游戏
也是一款非常优秀的游戏
是我很喜欢一个游戏 我是这两年才开始玩这种主机游戏
之前我是做手游的 基本还是刷的一些手机游戏
我记得当时家里pc带不动这个游戏
就买了个ps 然后 每天早上6点就起来打游戏
打到8点过就去上班
在玩了这个游戏后 我就想要做这种游戏
所以就来了咱们公司 所以 说啊
兴趣很是重要
咱么可以看到 这个怪在远距离 和在近距离时
它的行为模式是不一样的
所以是基于一些规则来AI的制作
他也是比较传统的
他在远处时就会跳到我们面前疯砍一波
在近处时，格挡我们的攻击并且撒药给我们
在受伤后会立即远离我们`},{header:"有限状态机",slug:"有限状态机",content:`ppt
我们需要使用状态机来简单的解释这个 怪的AI
那我们先看有限状态机的概念是什么
有限状态机顾名思义 就是 有限多个状态
之间可以转移的一个数学模型
那状态代表着对象的某种形态
也可以是一些属性，一些行为
每个角色同时且有一个状态
转移就是表明状态之间的变更
转移是通过一些条件来满足的
他有两个特性 ，离散性 和 有限性
离散性就是说
每个状态与每个状态之间是独立的
有限性是 他状态不会无线对
我们使用状态机来解释这个AI
ppt
就显而易见 就可以把怪物分为四个状态
近处攻击，远处冲刺，待机，虚弱状态
首先怪物在待机状态，玩家进入近距离攻击范围，就使用近处攻击
玩家进入远程攻击范围了，就使用 冲刺攻击
再被打中后 后进去虚弱状态 撤退
这么一个简单的模型就可以定义出怪物的AI行为
ppt
那么我们想状态机有什么缺点么？
状态机切实很好用 不仅可以使用在AI编程中
我们普通的实现也可以使用状态机
比如说我们的游戏框架，每个流程就是一个状态，
游戏开始，获取版本号，请求更新，对比资源，更新资源，加载资源
但是他的缺点也很明显
就是我们的状态过多的时候
并且连接很多 是不是 就会看起来非常的混乱
难以维护
怎解决这个问题呢
ppt
我们有一个分层的概念
假设我们现在有这几个状态
冲刺，搜索，攻击 ，待机，睡觉
在不分层的情况下 他们两两都会有联系
那么分层的情况下
我们可以分层 战斗，休息两层
每层内部实现转移
每一层中设置一个默认状态
这样 一个分类 就可以 把混乱的关系 稍微 减轻一些
我们上面讲A*的启发式方法时，是不是 也有一个归类的方法
其实在编程中你会发现最开始 的实现都是简单粗暴的
人们所说的优化 其中有一部分都是 把大问题 归类拆分
也是不是又听起来有点像类的封装
像Unity动画机系统也是使用的 状态机 实现的 他也有分层 的 一个概念对吧
所以说这个状态机这种方式 不一定 在AI编程中会用到
在游戏的编程里可以说是随处可见
很常用的设计模式
这时有限状态机来实现怪物的行为
ppt
我们来看看行为树是怎么做？
顾名思义它是一颗树的结构
他是有 条件节点，行为节点 和复合节点组成的
复合节点是整个行为树的执行逻辑吧
条件节点，行为节点有时候统一叫做行为节点
也就是具体执行的内容是什么
每个节点都有一个返回值：success，failed，running
表示他们现在的 一个状态是什么
其中复合节点中就包含了：
选择节点和顺序节点
选择节点的执行逻辑是从左到右依次执行它的子节点直到执行到子节点返回值为 成功
那么选择节点就就返回 成功 如果所有子节点为返回失败,那么他就返回失败
顺序节点跟选择节点恰恰相反
从左到右依次执行他的子节点直到执行到子节点返回 失败
那么顺序节点就返回 失败
有点像并与或的计算方式
我们 就以刚才视频为例子
首先我们从根节点开始
进入第一个选择器
然后进到顺序节点
如果发现周围有玩家
那就进入下一个选择节点
进入下面的顺序节点
依次执行下面几个顺序节点
直到有一个顺序节点执行成功
返回 成功
咱么就退出这个选择节点
最后推导根节点
这样我们的一颗树在这一帧就遍历完成
ppt
行为树的优势
就在在于他的逻辑很清晰
我们看到树的图 就可以知道整个逻辑
行为的数据和逻辑是分离的
我们的叶子节点 可以放在任意一个复合节点下
也就是说他的复用性也很高
可视化方便修改
他的劣势也很明显
我们在运行AI逻辑时
在每一帧我们都需要去遍历整个树
如果说树的深度过大 这里遍历开销就会很大
针对这样一个劣势我们怎么 去改变呢
ppt
如果说是成功的情况我们是不是可以固定知道下一个节点是什么
同样如果是失败的情况下我们是不是也是可以固定知道下一个节点是什么
那么我们整理出来这里两个数组
我们是不是就可以直接遍历数组即可
就不需要去遍历复合节点
当然我们也可以接合状态机来使用
当一个角色在一个状态时就可以设置一个小的树
这样我们就可以不去遍历整个大树
当然它的优化方式还有很多
咱们今天就不一一介绍了
那么我们介绍的额行为树 就先 这样了
ppt
其实GOAP 也可以是实现怪物的AI行为
不过一般都不这么用
我们先看看GOAP的概念是什么
就是我们有一个目标，并且有一堆行为
从中选出符合当前 环境并且可以达成目标的行为
再根据一些规则，如优先级啥的
最后选择执行的行为以达到目标
当然这个行为可能是一个也可能是一些列
这一般会运行到一些结果导向的AI行为中
虚拟人生也是使用这个方法来做的AI
我们是不是感觉有点似曾相识,有一个目标,有一堆行为.
这不就是A*算法吗?我们需要从一堆行中找到一个列为列表来达成这个目标.
就需要使这个列表最短最有效,这个算法叫IDA*,有兴趣的同学可以下来看看
他的流程跟A*差不多的.
ppt
他的优点就是 十分灵活
比如说我们有很多行为都可以去实现这个目标
每次可能选择出来的都是不一样的行为
这就让玩家眼前一亮
缺点也很明显 他并不可控
比如说 角色在野外战斗后需要回血
你可以吃药也可以打坐
如果说是吃药还好 但是打坐的话 并不确定说周围环境是否十分安全
那我们所有行为决策就讲完了
其实一款游戏里并不是说只有一种行为决策的方案
很多游戏都会涉及到多个的组合
当然行为角色还有一些方案 比如说模糊行为决策，规则系统。
这些都是基于我们讲的这几个所分化出来的`},{header:"策略",slug:"策略",content:`下面我们讲讲游戏里AI的战略系统
这个在很多游戏里是没有的
咱们就简单介绍一下这些
ppt
第一个是战术点
比如说在射击游戏里有埋伏点，掩体点等等
我们都可以利用这些点来制作战术策略
在moba游戏里的草丛可以隐藏角色
这些都算是战术点位
一般是在关卡编辑时就配置好
ppt
第二个 就是战略分析
是指咱们通过一些工具获取到当前游戏环境的信息
然后根据这些信息去调用行为决策，寻路等
一般使用到工具有
Influence Map
它的功能跟名字差不多 就是影响力
我们对游戏地图格子化
然后对一些信息与地点映射
比如说对于AI单位危险程度，在地图中有个很厉害的角色它的战力就可以与地点映射起来
我们在感知周围环境时 就不需要去挨着计算每个角色的战力然后计算距离 来判断 当前 我是否安全
可以直接从这个图中获得信息
一个简单的例子,比如抢滩登陆,其中敌人的手中的武器就可以影响到玩家走那条路.那我们在制作闯关的AI时,就可以通过敌人的武器强度来映射到地图上,然后我们在设置寻路时,是不是就可以对这些节点增加巨量的花费或者预估值来绕过这些节点.
下一个是地图分析
这个就是字面意思
这个跟战术点有一点像
就是角色在移动时，检测周围的地形 获得信息
比如我们射击游戏，就需要占领高地或者是房子城堡
这样是易守难攻对吧
ppt
最后一个是合作行为
首先是多层AI，因为我们每个角色都有自己的AI控制，他有一个行为树或状态机去控制它,当有一堆角色时，我们如何去分配。
像RTS游戏里一样的，我们在通过分析得到一个行为后，对每一个角色使用一样的行为
这大概率会有一定为奇怪的表现,比如我们通常会让重型兵冲锋,输出兵放后面.那我们需要怎么去协调他们移动.
最后就是战术层面的，比如我们英雄联盟 如何打好一场团战，这个是需要咱们好好的设计的 。
那么我们这个策略 方面的东西就讲完了，这里我们讲的比较沈略
都是基本介绍了一下会有哪些问题，大概是怎么处理的
因为我们时间有限 并且 这方面 不是 所有游戏都会涉及
所以讲的比较少 如果大家感兴趣的话
我会 给大家一些 资料 大家可以阅读一下
那么今天我们的这个AI课程就完了
当然还有很多 很多关于 AI的 内容可以去挖掘
今天 所讲的 基本都是一些基础设施
现在很多的 应用都 会 基于它做扩展
我们这个课程的目的 就是让 大家对AI有一个 大概的了解
谢谢大家`}]},{path:"/Graphic/basic/geometry/data_structures.html",title:"Data Structures for Graphics",pathLocale:"/",contents:[{header:"Data Structures for Graphics",slug:"data-structures-for-graphics",content:`mesh structures
用来存储静态网格数据和要来转换 spatial data structures 边界分层，空间分层，均匀空间细分 scene graph 管理对象和转换 tiled multidimensional arraysd 控制性能，`},{header:"Triangle Meshes",slug:"triangle-meshes",content:`三角形网格处理他们的效率是图形程序最大的工作。
一个网格可以比一个无关联的三角形序列更加效率，因为网格是共用顶点的三角形组成的。
三角形的数据一般包含： 顶点
边界
贴图映射
着色
动画 网格拓扑：三角形链接在一起，不通过顶点的位置信息。
三角形检测条件： 每个边被一个或二个三角形使用
每个顶点了连接到一组边连接的三角形 单个三角形存储需要向前，也就是三个顶点存储的顺序是逆时针 我们在存储三角形顶点位置时，有两种方式： 按三角形存储
按顶点索引存储 如下图： 我们可以看到按三角形存储会造成额外的重复存储。
按三角形存储我们可以简单写成以下形式：
Triangle { Vertex v[3]
} Vertex { vector3 position // or other vertex data
} 按顶点索引存储我们可一件简单写成：
IndexedMesh { int tInd[nt][3] vector3 verts[nv]
} 其中： tInd：每个三角形顶点的索引
nt：三角形的索引
nv：顶点的索引 顶点索引存储是最常见的存储三角形网格，因为他很好地平衡了简单、方便、小巧。 我们想存储三角形的相邻三角形，顶点数据中包含该顶点的三角形。我们可以简单设置mesh的数据结构：
Mesh { // ... per-vertex data ... int tInd[nt][3]; // vertex indices int tNbr[nt][3]; // indices of neighbor triangles int vTri[nv]; // index of any adjacent triangle
} 我们可以接合下图来说明： 这其中和上面IndexedMesh的参数是一样，其他的为： tNbr：三角形周围的三角形
vTri：顶点相邻的一个三角形(顺时针的下一个) Winged-Edge`},{header:"场景",slug:"场景",content:`我们在做物体顶点的转换时，需要注意矩阵相乘的顺序
function traverse(node) push(Mlocal) draw object using composite matrix from stack traverse(left child) traverse(right child) pop()`},{header:"碰撞检测",slug:"碰撞检测",content:"左图：空间的均匀划分。右图：包围盒划分"},{header:"包围盒",slug:"包围盒",content:`我们从2d视角来看，也就是需要做的就是找到最左边、最右边、最下边、最上边的值。
$$
x = x_{min},
x = x_{max},
y = y_{min},
y = y_{max}.
$$
$$(x, y) ∈ [x_{min}, x_{max}] × [y_{min}, y_{max}].$$`},{header:"分层包围盒",slug:"分层包围盒",content:`我们在检测碰撞时，可以设置包围盒。提前测试包围盒是否被射线穿过，然后再判断包围盒中的每个物体是否被穿透。这个看起来是减少了区域检测，但是我们在包围盒内部还是需要蛮力搜索。所以我们还可以把包围盒内部再次切割出不同的包围盒。 我们简单的伪代码可以写成这样：
if (ray hits root box) then if (ray hits left subtree box) then check three triangles for intersection if (ray intersects right subtree box) then check other three triangles for intersection if (an intersections returned from each subtree) then return the closest of the two hits else if (a intersection is returned from exactly one subtree)then return that intersection else return false
else return false 我们可以看到上面这种切分包围盒到更小的包围盒，然后始查询，这个查询其实是没有一定的顺序规则，先查询那个后查询那个。这里我们可以使用二叉树来管理，如下图： 把一个包围盒中的点分为灰色和黑色。我们可以简单的写出每个节点的数据结构：
class bvh-node subclass of surface virtual bool hit(ray e + td, real t0, real t1, hit-record rec) virtual box bounding-box() surface-pointer left surface-pointer right box bbox 实现一个碰撞的方法：
function bool bvh-node::hit(ray a + tb, real t0, real t1,hit-record rec) if (bbox.hitbox(a + tb, t0, t1)) then hit-record lrec, rrec left-hit = (left != NULL) and (left -> hit(a + tb, t0, t1, lrec)) right-hit = (right != NULL) and (right -> hit(a+tb, t0, t1, rrec)) if (left-hit and right-hit) then if (lrec.t < rrec.t) then rec = lrec else rec = rrec return true else if (left-hit) then rec = lrec return true else if (right-hit) then rec = rrec return true else return false else return false 这里就是递归检测分别检测左边右边时候有碰撞到。
我们可以使用一个轴来划分包围盒，这个轴可以是$x = 0, y = 1, z = 2$这样的，同时我们可以划分两部分包含的物体的个数相等，这样的话我们可以减少二叉树中有很多单子叶的情况。
function bvh-node::create(object-array A, int AXIS) N = A.length if (N = 1) then left = A[0] right = NULL bbox = bounding-box(A[0]) else if (N = 2) then left = A[0] right = A[1] bbox = combine(bounding-box(A[0]), bounding-box(A[1])) else find the midpoint m of the bounding box of A along AXIS partition A into lists with lengths k and (N − k) surrounding m left = new bvh-node(A[0..k], (AXIS +1) mod 3) right = new bvh-node(A[k + 1..N − 1], (AXIS +1) mod 3) bbox = combine(left → bbox, right → bbox)`},{header:"统一空间细分",slug:"统一空间细分",content:"我们可以换一种思路，就是直接切分空间，我们把空间切分成很多个同一大小的区域。从二维的角度我们可以划分成下图："},{header:"BSP",slug:"bsp",content:"我们可以使用二分法的思路来对空间细分，这种做法叫做binary space partitioning。"}]},{path:"/Graphic/basic/math/coordinate_system.html",title:"坐标系 Coordinate System",pathLocale:"/",contents:[{header:"坐标系 Coordinate System",slug:"坐标系-coordinate-system",content:""}]},{path:"/Graphic/basic/math/matrices.html",title:"矩阵 Matrix",pathLocale:"/",contents:[{header:"矩阵 Matrix",slug:"矩阵-matrix",content:""},{header:"是什么",slug:"是什么",content:"是以行和列形式组织的矩形数字块。向量是标量的数组，矩阵则是向量的数组。表示形式："},{header:"四则运算",slug:"四则运算",content:""},{header:"矩阵和标量的乘法",slug:"矩阵和标量的乘法",content:""},{header:"矩阵和矩阵的乘法",slug:"矩阵和矩阵的乘法",content:`规则：一个r X n的矩阵A和一个n X c的矩阵B才能相乘。
两矩阵相乘如下： 其中Pij计算如下： 换一种思维即：使用前面矩阵的i行与后面矩阵j列做点乘即可获得结果的值
实例：`},{header:"满足性质",slug:"满足性质",content:`A B != B A
A + B = B + A
(A + B) + C = A + (B + C)
r(A + B) = rA + rB
(r + s)A = rA + sA
A B C = A(B C)
(A + B)C = AC + BC`},{header:"特殊矩阵",slug:"特殊矩阵",content:""},{header:"方块矩阵",slug:"方块矩阵",content:"是指那些行和列数目相等的矩阵。"},{header:"单位矩阵",slug:"单位矩阵",content:"对角线都为1，其余为0. 性质：M I = I M = M"},{header:"转置矩阵",slug:"转置矩阵",content:"矩阵A转置就是把行列交换，也就是沿着矩阵的对角线翻折，实例如下："},{header:"满足性质",slug:"满足性质-1",content:"基本原理 矩阵的转置再转置就是本身 矩阵串接的转置，等于反向串接各个矩阵的转置"},{header:"逆矩阵",slug:"逆矩阵",content:`只有方矩才有逆矩阵。简单来说，如果一个矩阵的行列式不为0，那么它就是可逆的。
并不是所有矩阵都有逆矩阵`},{header:"满足性质",slug:"满足性质-2",content:"逆矩阵的逆矩阵是原矩阵本身 单位矩阵的逆矩阵是它本身 转置矩阵的逆矩阵是逆矩阵的转置 矩阵串接相乘后的逆矩阵等于反向串接各个矩阵的逆矩阵"},{header:"正交矩阵",slug:"正交矩阵",content:"如果： 满足这个公式（交换也可）则说明该矩阵为正交矩阵。I为单位矩阵。"},{header:"满足性质",slug:"满足性质-3",content:`逆矩阵与转置矩阵相等 矩阵的模为1或-1
从几何的角度来看就是矩阵的每一列形成的向量都相互垂直或者是每一行形成向量都相互垂直。`},{header:"变换",slug:"变换",content:`指的是我们把一些数据，如点、方向矢量甚至是颜色等，通过某种方式进行转换的过程。
变换的顺序是不能随意打乱，因为矩阵不存在交换律。`},{header:"缩放",slug:"缩放",content:`矩阵斜着对角线为缩放数据。推导原理，使用两个矩阵相乘即可验证。
2d缩放矩阵： 3d缩放矩阵：`},{header:"旋转",slug:"旋转",content:""},{header:"2d旋转",slug:"_2d旋转",content:`矩阵： 推导原理：
假设向量a要旋转φ角度到向量b，且a向量本身距x轴有角度α: xb = r cos(α + φ) = r cos α cos φ − r sin α sin φ yb = r sin(α + φ) = r sin α cos φ + r cos α sin φ. 因为 xa = r cos α and ya = r sin α 所以
xb = xa cos φ − ya sin φ,
yb = ya cos φ + xa sin φ.`},{header:"3d旋转",slug:"_3d旋转",content:"绕x轴旋转： 绕y轴旋转： 绕z轴旋转："},{header:"平移",slug:"平移",content:""},{header:"齐次坐标",slug:"齐次坐标",content:`为了统一使用矩阵相乘的方式表示变换。坐标w分量为1，对于矢量w分量为0。
具有特性 (x,y,z,1)
(kx,ky,kz,k)
(zx,zy,z*z,z) 以上三个都代表点(x,y,z)在3d场景中,当然这里乘上的系数不能为0。如k和z都不能为0。`},{header:"2d平移",slug:"_2d平移",content:""},{header:"3d平移",slug:"_3d平移",content:""}]},{path:"/Graphic/basic/math/trigonometry.html",title:"三角形 Trigonometry",pathLocale:"/",contents:[{header:"三角形 Trigonometry",slug:"三角形-trigonometry",content:""},{header:"角度与弧度",slug:"角度与弧度",content:""},{header:"角度",slug:"角度",content:`把一个圆周平均分成360份，其中每一份都是1º的角。这种以“度”作为单位度量角度单位制叫做角度制。
下图使我们常见的180º角度尺：`},{header:"弧度",slug:"弧度",content:`长度为半径长的弧，所对的圆心角是1弧度（Radian），用符号rad表示。
半径为r的圆的圆心角α所对的弧度长为l，那么角α的弧度数的绝对值是|α| = l/r。`},{header:"换算",slug:"换算",content:`360º = 2π rad
180º = π rad 1º =（π / 180）rad ≈ 0.01745 rad
1 rad =（180 /π）º ≈ 57.30º α 度的角 = α ·（π / 180）rad 常用的角度与弧度对照图`},{header:"三角函数",slug:"三角函数",content:""},{header:"在直角三角形ABC中，∠C = 90º",slug:"在直角三角形abc中-∠c-90o",content:`正弦（Sine）：sinA = ∠A的对边与斜边的比
余弦（Cosine） ：cosA = ∠A的邻边与斜边的比
正切（Tangent）：tanA = ∠A的对边与邻边的比
sin²A + cos²A = 1`},{header:"在单位圆（Unit Circle）中，任意角 α 的三角函数（Trigonometric Function）",slug:"在单位圆-unit-circle-中-任意角-α-的三角函数-trigonometric-function",content:`在相似三角形 Rt△ABC 与 Rt△AB′C′ 中，对于∠A，对边与斜边的比是一致的，邻边与斜边的比也是一致的。所以我们力求简单与方便计算，设定斜边为1，单位圆刚好能满足这个条件。 圆的圆心与直角坐标系的原点重合，圆的半径 r = 1，圆周上任意一点的坐标为（x, y）
自变量为角 α
函数是圆周上的坐标，或坐标和坐标的比值：sin α = y，cos α = x，tan α = y / x （x≠0）`},{header:"三角函数在各个象限的取值",slug:"三角函数在各个象限的取值",content:`第一象限
第二象限
第三象限
第四象限
x轴
y轴 sin α
>0
>0
<0
<0
0
±1 cos α
>0
<0
<0
>0
±1
0 tan α
>0
<0
>0
<0
0
/`},{header:"正弦曲线",slug:"正弦曲线",content:`y = sin x， x∈R， y∈[–1，1]，周期为2π，函数图像以 x = (π/2) + kπ 为对称轴
y = arcsin x， x∈[–1，1]， y∈[–π/2，π/2]
sin x = 0 ←→ arcsin x = 0
sin x = 1/2 ←→ arcsin x = π/6
sin x = √2/2 ←→ arcsin x = π/4
sin x = 1 ←→ arcsin x = π/2`},{header:"余弦曲线",slug:"余弦曲线",content:`y = cos x， x∈R， y∈[–1，1]，周期为2π，函数图像以 x = kπ 为对称轴
y = arccos x， x∈[–1，1]， y∈[0，π]
cos x = 0 ←→ arccos x = π/2
cos x = 1/2 ←→ arccos x = π/3
cos x = √2/2 ←→ arccos x = π/4
cos x = 1 ←→ arccos x = 0`},{header:"三角函数线",slug:"三角函数线",content:"图中的三条彩色线段 MP、OM、AT，分别叫正弦线、余弦线、正切线，统称为三角函数线"},{header:"曲线视频",slug:"曲线视频",content:""},{header:"一些公式",slug:"一些公式",content:""},{header:"平方",slug:"平方",content:""},{header:"任意角α与-α的三角函数值之间的关系",slug:"任意角α与-α的三角函数值之间的关系",content:""},{header:"两角和与差",slug:"两角和与差",content:""},{header:"常见问题",slug:"常见问题",content:""},{header:"一个点是否在三角形中？",slug:"一个点是否在三角形中",content:`我们可以简单的观察下面两种情况: P点在△ABC外：
P点在△ABC内： 可以看得出如果P点在三角形内的话，P点都在三角形边向量的左侧。我们是如何来判断一点在一个向量的某一边呢？我们知道两个向量的叉乘的结果可以判断这个两个向量是否同向，我们这里计算出每条边与边的起始点与P点连接的线段的叉乘，来判断点P是否与每条边同向，可以列出式子： Corss(AB,AP)
Corss(BC,BP)
Corss(CA,CP) 如果说这三个结果都为正，那么说明P点都在三角形的三边的一侧。简单的实现：
static bool insideTriangle(int x, int y, const Vector3f* _v)
{ // Implement this function to check if the point (x, y) // is inside the triangle represented by _v[0], _v[1], _v[2] Vector3f point(x + 0.5f, y + 0.5f, 1); for (int i = 0; i < 3; i++) { Vector3f triangle2point = point - _v[i]; int index = (i + 1) % 3; Vector3f triangleP2P = _v[index] - _v[i]; // case x , y cross equal z if (triangleP2P.cross(triangle2point).z() < 0) { return false; } } return true;
} 使用重心求法`},{header:"三角形重心",slug:"三角形重心",content:`设P点的坐标(α, β, γ)，为三角形的重心坐标。 我们这里简单的推导一下,： 根据向量的线性相关：AP = βAB + γAC
拆分上面式子：A - P = β(A - B) + γ(A - C)
整理得到：P = (1-β-γ)A + βB + γC = αA + βB + γC
α = 1 - γ - β
0 < α < 1, 0 < β < 1, 0 < γ < 1 从上面可以看出这里的重心点P可以有很多值，只需要满足以上列举出来的规则。
我们使用距离比例算法来简单的推导实现，我们知道当α = 0 时，点p在BC线上，当α = 1 时，点p就是点A。我们可以简单认为 α 的值就是A点到BC线距离的比例，不过是反比例。因为一个点带入一个直线方程求到的解就是该点到方程的近似距离，然后就可以列出计算方式：(这里的0、1、2表示的是三角形的三个顶点的索引,也就是A、B、C点) α = f12(x, y)/f12(x0, y0) ：点 P 到 BC 线的距离与点 A 到 BC 线的距离的比例
β = f20(x, y)/f20(x1, y1) ：点 P 到 CA 线的距离与点 B 到 CA 线的距离的比例
γ = f01(x, y)/f01(x2, y2) ：点 P 到 AB 线的距离与点 C 到 AB 线的距离的比例 我们可以根据直线公式获得： f01(x, y)=(y0 − y1)x + (x1 − x0)y + x0y1 − x1y0,
f12(x, y)=(y1 − y2)x + (x2 − x1)y + x1y2 − x2y1,
f20(x, y)=(y2 − y0)x + (x0 − x2)y + x2y0 − x0y2. 最终就可以求解出这个坐标，简单实现：
static std::tuple<float, float, float> computeBarycentric2D(float x, float y, const Vector4f *v)
{ float c1 = (x * (v[1].y() - v[2].y()) + (v[2].x() - v[1].x()) * y + v[1].x() * v[2].y() - v[2].x() * v[1].y()) / (v[0].x() * (v[1].y() - v[2].y()) + (v[2].x() - v[1].x()) * v[0].y() + v[1].x() * v[2].y() - v[2].x() * v[1].y()); float c2 = (x * (v[2].y() - v[0].y()) + (v[0].x() - v[2].x()) * y + v[2].x() * v[0].y() - v[0].x() * v[2].y()) / (v[1].x() * (v[2].y() - v[0].y()) + (v[0].x() - v[2].x()) * v[1].y() + v[2].x() * v[0].y() - v[0].x() * v[2].y()); float c3 = (x * (v[0].y() - v[1].y()) + (v[1].x() - v[0].x()) * y + v[0].x() * v[1].y() - v[1].x() * v[0].y()) / (v[2].x() * (v[0].y() - v[1].y()) + (v[1].x() - v[0].x()) * v[2].y() + v[0].x() * v[1].y() - v[1].x() * v[0].y()); return {c1, c2, c3};
} 重心讲解1
重心讲解2`}]},{path:"/Graphic/basic/math/vector.html",title:"向量 Vector",pathLocale:"/",contents:[{header:"向量 Vector",slug:"向量-vector",content:""},{header:"是什么",slug:"是什么",content:"向量是一个描述长度和方向的量，也可以叫做矢量。"},{header:"记法",slug:"记法",content:"一般使用a粗体表示。一般写作："},{header:"几何表示",slug:"几何表示",content:""},{header:"点与向量",slug:"点与向量",content:"任何一个点都可以写成y = aA + bB + cC"},{header:"四则运算",slug:"四则运算",content:""},{header:"加法",slug:"加法",content:`几何意义：
平行四边形法则 满足规则：
a + b = b + a (交换律)
a + b + c = b + (a + c) (结合律)`},{header:"减法",slug:"减法",content:"几何意义：平行四边形法则"},{header:"乘&除标量",slug:"乘-除标量",content:`几何意义：
对向量的缩放 乘以-1结果： 几何意义：
表示为长度相等并方向相反的向量。`},{header:"模",slug:"模",content:`向量的模也就是向量的长度。三维向量计算公式： 几何意义：
可以把一个向量转化为三角形，然后利用勾股定理转化为长度。`},{header:"点乘",slug:"点乘",content:""},{header:"数学",slug:"数学",content:"a与b点乘公式： 计算公式： 从公式可以看出向量点乘结果为一个标量。 点乘满足规则： p · p = ||p||²"},{header:"几何意义",slug:"几何意义",content:`给定两个向量v和n，将能v分解成两个分量：V∥和V⊥。它们分别平行于和垂直于n，并满足v = V∥ + V⊥。一般称平行分量V∥为v在n上的投影。 这里我们可以**V∥**表示为： 根据三角函数我们可以求出||V∥|| = cosθ||v||，这样我们就可以求到 我们可以根据点乘结果的符号可以判断两个向量的方向： 结果大于0，同向
结果等于0，垂直
结果小于0，反向`},{header:"叉乘",slug:"叉乘",content:`叉乘一般只存在三维坐标系，计算的结果是一个矢量。
计算公式： 两个向量叉乘的长度公式：
||a x b|| = ||a||||b||sinφ
可以看出来是平行四边形的面积。 满足规则： a x (b + c) = a x b + a x c
a x (kb) = k(a x b)
a x b = -(b x a)`},{header:"几何意义",slug:"几何意义-1",content:"结果的向量为同时垂直这两个向量的向量。 我们可以使用结果的正负（垂直方向的）判断两个向量是否为同向（大于0同向）。 两个向量的叉乘的结果，是依赖于两向量的夹角。"},{header:"单位向量",slug:"单位向量",content:"长度为1的向量，用来单纯存储方向，计算公式："},{header:"简单实现",slug:"简单实现",content:"简单Vector3"}]},{path:"/Graphic/basic/raster/",title:"渲染管线",pathLocale:"/",contents:[{header:"渲染管线",slug:"渲染管线",content:`开始我们先了解一下，以后我们需要学习那些东西，这样我们会对整个流程有一个大致的了解。让我们到每一个步骤都会明白我们是在处理什么，是在什么阶段，什么前提？
渲染管线就是渲染流程，就是我们需要把需要展示到屏幕中的模型数据从内存中拿出来，再经过CPU把这些数据传递给GPU，然后GPU做的一系列工作后，最后展示到屏幕上的过程。
对于在GPU中的工作流在不同的书里或者教材里都会有一些不同的描述，但是大致流程都是一样的。下面分别列举出了几个总结：`},{header:"Unity Shader入门精要",slug:"unity-shader入门精要",content:`我们主要会介绍： 几何阶段：对应是在顶点着色器中做转换，裁剪，屏幕映射
光栅阶段：三角形设置，着色`},{header:"Fundamentals of Computer Graphics",slug:"fundamentals-of-computer-graphics",content:"。"},{header:"Games 101",slug:"games-101",content:`总体流程： 接下来就分开说一下每个步骤：
转换： 三角形设置： 深度测试： 着色： 贴图：`}]},{path:"/Graphic/basic/raster/base.html",title:"三角形设置",pathLocale:"/",contents:[{header:"三角形设置",slug:"三角形设置",content:"我们进行了投影和转换之后就会获得一个标准立方体[-1，1]的3次方。 然后把这个立方体投射到屏幕上。最后我们需要把这个影像与我们的屏幕做成一个映射关系，把图像在屏幕上显示出来。"},{header:"屏幕定义",slug:"屏幕定义",content:`我们需要要把图像显示在屏幕上，那什么是屏幕呢？地球人都知道是显示器。那我们的电脑是怎么去定义我们的显示器呢？
屏幕就是一个二维数组的像素组成，数组长度是分辨率。我们定义屏幕的几何表示如下图。 左下角为原点(0，0)，每个像素的长宽为1。因为每个像素的中心并不是该像素的坐标，从图中可以看出像素中心为(x+0.5，y+0.5)。例如蓝色像素的坐标为(2.5，1.5)。
这里的像素就是一个格子。这个格子中显示什么颜色，然后所有格子组合起来就可以形成一个图像。如下图： 我们把一个横排像素个数与一个竖排像素个数相乘就是我们常常听说的分辨率。
用程序表达一个像素除了上面的位置信息以外还有颜色信息。我们知道三原色（红、黄、蓝）可以合成几乎所有的颜色，所以在计算机中使用三个浮点数来存储，叫做RGB。我们经常会看到白色可以表示为： (1，1，1)
(255，255，255) 这里的255表示每一个浮点数的容量为8-bit，可想而知如果每个浮点数的容量都变大到16-bit或者32-bit那么他可以存放的数据精度就更加的高，更直观的感受就是他画面中的细节更多，颜色更细腻。我们经常把存储大容量的数据的图片叫HDR(dhigh dynamic range)。有的时候会多一个alpha通道，所以叫做 RGBA。`},{header:"三角形的离散化",slug:"三角形的离散化",content:`我们明白屏幕是什么了，然后就是向屏幕中的像素填充颜色，那么我们怎么去判断说这个像素是什么颜色，是否有颜色呢？这里我们使用了把需要渲染出来的图像三角形化，就是把图像分割为无数个三角形。比如把这个头的模型划分成很多个三角形： 为什么要是用三角形呢？ 是最基础的多边形，可以组合其他多边形
形成的面在一个平面上
内外清晰分明
三个点的插值可以覆盖整个三角形 然后把这图像平铺到屏幕上，如下图，红色网格就是屏幕像素： 我们的目的是为每一个像素填上颜色，这个颜色我们可以根据三角形面上的颜色是什么，从而对应到像素上是什么颜色。这里就产生了两个问题： 我们怎么判断一个像素是否在三角形中？
解决：这里我们就使用像素坐标点与三角形做判断，具体可看之前三角形模块中的一个点是否在三角形中？ 三角形的颜色是怎么确定？
解决：我们使用三角形的顶点来存储颜色信息，再求得三角形的重心，以此对三个顶点的颜色做插值，最后得到整个三角形的颜色。同样在之前三角形模块中描述了三角的重心计算方式 Tips
当我们的像素坐标点刚好在一个三角形的边界上，那么这个像素是否被认定为被三角形覆盖，这个问题在不同的地方有不同的解决方案。我们也可以自定义规则，没有一个准确的规则。 这里我们就可以的为每一个三角形内的像素填色的伪代码
function rasterize_triangle(t) for Xmin to Xmax do for Ymin to Ymax do if is_in_trangle(t，x，y) then r，g，b = compute_barycentric(x，y，t) draw_color(r，g，b) 这里我们检测每一个三角形都需要遍历整个屏幕像素，是不是就没有很大的必要这样，有可能很多像素并没有被当前三角形覆盖，
我们可以对三角形做一个包围盒，求出最小x，最小y，最大x，最大y，然后就从最小x开始遍历而不是屏幕最小x坐标开始遍历。最终伪代码差不多就是这样：
function rasterize_triangle(t) Xmin = min(t) Ymin = min(t) Xmax = max(t) Ymax = max(t) for Xmin to Xmax do for Ymin to Ymax do if is_in_trangle(t，x，y) then r，g，b = compute_barycentric(x，y，t) draw_color(r，g，b)`},{header:"采样",slug:"采样",content:`我们这个时候已经可以把图片渲染到屏幕上了，把一个一个的像素的颜色填上去就可以了，我们逐个像素渲染出来就是这样： 这里跟我们想象中的模样不一样，我们想要的效果是： 这种情况就是叫做锯齿（aliasing）。我们需要解决这个问题，就先要说到采样。判断像素点是否在三角形内，然后采取在三角形内的像素块，这个过程就是采样。
在百度百科解释采样是指用每隔一定时间的信号样值序列来代替原来在时间上连续的信号，也就是在时间上将模拟信号离散化。简单的说就是把一个状态记录下来，然后把这个记录集中展示出来。
但是采样出现下面这几个问题（Sampling Artifact） ： Jaggies 锯齿 - 采样的间距 Moire 摩尔纹 - 采样不足 Wagon wheel effect 轮子反转 - 采样的时间 造成这些问题的原因是信号变化的太快但是采样很慢，采样就跟不上信号的变化。
举个例子，我们使用一个sin的波形图来看看，上面的采样点多一些，可以清晰的描绘出来sin的波形。 我们看下面，采样点少一些，把点用线连起来就不是我们想要的波形。我们直观看到的点少点多，经上面定义说，我们是每隔一段时间记录，换言之就是上面的采样频率要高一些，也就是隔的时间短一些。
换个方向理解，我们如果分别采样下图中的蓝色线和虚线，这样我们得到的采样点都是一样，那么是无法区别这两种波形。这就是造成走样的原因。`},{header:"走样",slug:"走样",content:`那需要怎么去解决这个问题呢？这里先把图片做一个模糊，然后对其做采样： 这样我们的边缘部分是不是就没有那么突变颜色了，就可以减少锯齿感。 这样子看是不是就会比上面的锯齿感不是那么的明显了呢。
那又怎么去做一个图片的模糊呢？这里使用到了 卷积（Convolution） ，
他的原理就是把两个函数合成一个，从图像的方向理解就是把两个波形合成一个波形，通俗的说法就是当你要计算一个点A的数据的时候，给你一个框，用这个框去框住点A周围的点，最后把这些点做一个合成计算得到新的点A′。我们把这个框叫做 滤波，滤波就可以认为是把一部分东西去掉。
这个合成的规则我们使用一个例子来说明： a 为一个原函数，一个基础波形。b 为一个滤波（Filter）函数。下面的图为 a 与 b 的卷积结果，计算过程： 我们假设求 a[i] 卷积后的结果 a★b[i]
根据上图花括号框住的对应关系，可以写出式子：（a[i-2] * 1 + a[i-1] * 4 + a[i] * 6 + a[i+1] * 4 + a[i+2] * 1） * 1/16
也就是把两两对应的数值相乘然后平均，因为 b 中只有中间一部分为非零，所以不需要写出来。 这个滤波器的合成计算规则就像是给需要计算的数据做一个加权平均，我们可以把这个总结成公式： Tips
公式中没有求平均，因为我们的过滤器所有的权重（值）加上的和为1。
公式中的 r 就是为我们滤波器的范围，上图中的 r 为2，这里 b[0] 对应的就是 a[i] 一个简单的伪代码：
function convolve(sequence a， filter b， int i) s = 0 r = b.radius for j = i − r to i + r do s = s + a[j]b[i − j] return s 上面的例子只是对应了一维的变换，也就是波形中y坐标的改变。我们需要对图片做卷积，那就是二维的，这里我们就会用到卷积核的一个东西，就是滤波器为一个矩形，如下图： 我们求一个点 a[i,j] 与数组 b 的卷积，b 就是一个卷积核，把这个矩形的中心 b[0,0] 放在 a[i,j] 上，然后把卷积核覆盖在 a 中对应的点分别乘上对应数组 b 中的值，把所有乘积就相加即可获得该点的卷积。 公式如： 简单的伪代码如下：
function convolve2d(sequence2d a， filter2d b， int i， int j) s = 0 r = b.radius for i′ = i − r to i + r do for j′ = j − r to j + r do s = s + a[i′][j′]b[i − i′][j − j′] return s 换个方向理解就是图片的模糊就是把一个像素与它周围的一些像素值按照一定的比例融合。
一些常见滤波器： box filter
是一个分段常函数，他的积分等于1。他的默认滤波半径为 r = ½ 。分为两种离散和连续： 离散的公式： 连续的公式： tent filter
也是一个常数分段函数。他的默认滤波半径为 r = 1 。图示： 公式： gaussian filter
是一种常用的滤波器，它可以使采样更加的丝滑。 高斯滤波是没有默认滤波半径，他是通过σ这个参数来控制效果。公式： cubic filter b-spline cubic filter
catmull-room cubic filter
mitchell-netravali cubic filter 这个滤波器分为4段， 公式为：`},{header:"采样原理",slug:"采样原理",content:`我们知道使用模糊可以解决这个走样的问题，但是为什么就解决了呢？我们可以从频率的方向来理解。采样是每隔一段时间记录一段信号，最后把这些信号连续起来。之前我们说到造成锯齿的原因是信号量变化太快了，使用的间隔时间跟不上这个变化，这个间隔时间就是频率。我们可以把一张图片转化为频率图。就要使用到 傅里叶变换。
傅里叶变换就是任何公式都可以写成正弦和余弦函数的组合。从图像上理解就是多个正弦波和余弦波叠加成最后公式的图像。如下图： 转换公式： 逆转换公式： 也就是说傅里叶变换是可逆的，可以一个波形分解成多个波形，也可以用多个波形组成原来的那个波形。这里我们可以使用傅里叶变换把图片的信号数据转换到频率数据。 我们可以把右边的图分为： 低频区：中心亮白色的地方
高频区：中心外围有很多白色黑色交替的地方 这里的高频低频是使用颜色变化的多少来判断的。我们尝试来去掉频率图中的一些部分，然后使用逆傅里叶变换，获得图像的图： 去掉低频的部分： 左边的图我们只能看出一些轮廓，那是否就说明 高频部分就是表示的图像的边缘部分。 去掉高频的部分： 左边的图像变得模糊了，根据上面的我们知道高频部分表示的图像的边缘部分，我们去掉了高频部分，所以就没有边缘了，看起来就有模糊的感觉。 去掉部分高频与低频的部分： 从上面可以看出想要达到使图片模糊的效果就是去掉图片中的高频部分，上面说到滤波的功能就是过滤掉部分原波形的数据。这个是不是就对应上关系了，正如下图： 上面的图片是在空间领域使用卷积，得到一个模糊的结果。
下面的图片是先使用傅里叶变换获得频率图，然后使用一个低频滤波，得到过滤后的频率图，最后再使用逆傅里叶转换回去，得到模糊的结果。 现在我们已经明白一个图片转换成频率图后，其中高频代表了什么，低频代表了什么。如果要去掉一部分频率，可以直接使用图片的数据乘上一个滤波。那我们接下来看采样在频率领域是怎么表示的。 左边：给你一个函数a乘上函数c（冲激函数），就可以得到函数e。也可以理解为使用函数c来采样出函数a。
右边：b为函数a的频率图，d为函数c的频率图，f为e的频率图。 从这里我们就可以得到一个结论：采样是重复频率上的内容。我们可以看到f图中重复了很多个b。如果重复的这个间距很近以至于到两个b函数右重合，就会想下图一样： 这样会产生出 走样 ，回想上面说到走样锯齿的产生就是信号的变化过快，我们看上面那个函数图中的c和f，他们每两个脉冲（箭头）的间隔，就可以理解为我们采样的频率。我们采样的频率是一定的，信号变化突然加速，这样就会产生上图中下面的那个情况。
我们要解决这个交叉的问题： 提高采样的频率，让信号的变化一直低于采样频率
把交叉部分使用滤波直接给砍掉就可以了，过滤掉那一部分的频率即可，如下图：`},{header:"抗锯齿",slug:"抗锯齿",content:`锯齿的产生是由于采样率不足，那么我们可以通过以下方式来时进行抗锯齿： 提高采样率
这是一种终极解决方法，如果 640x480 分辨率的屏幕换成 1920x1080 分辨率的屏幕，像素变小了，相当于提高了采样率，但这并不现实，我们需要的是在同一块屏幕实现抗锯齿的方法。 反走样
从上面的例子可以知道，我们可以先对图像进行一次模糊操作，在进行采样就可以实现抗锯齿。
在频率上，这种操作相当于先用低通滤波把高频信息过滤掉，再进行采样。这里用的低通滤波就是利用 卷积 求出当前像素和周围像素的平均值。
对于同一个像素，我们知道它原来有多少地方被覆盖了，这时候如果可以先算出覆盖比例，那么我们就可以根据这个比例对像素进行填充了。 如上图所示： 我们可以用肉眼看出四个像素分别被覆盖了12.5%、50%、87.5%、100%，但屏幕在填充像素是不能只填充一部分的，只能填充一整个像素。因此这时候可以对像素进行一次平均，最后得到像素的颜色。`},{header:"超采样（MSAA）",slug:"超采样-msaa",content:`事实上，刚刚提到的计算像素覆面积的做法是很难实现的。但我们可以通过超采样的方式来模拟。
所谓的超采样就是在一个像素里面放多个采样点来检测三角形是否有被覆盖。 上图表示一个像素里面包含了16个采样点，每个采样点采样后再把结果平均起来，最后就能得到三角形对改像素覆盖程度的 近似值。
如果想要更准确的近似值得的话，可以用更多的采样点，但这样计算量就会更大。
接下来看看实际例子： 上图中一个像素里面只有一个采样点。就有部分像素存在模棱两可的情况。
超采样的第一步是要为每个像素增加采样点，这里让每个像素有4个采样： 接下来是对每个像素中的所有采样点的结果进行平均： 最后就能得到平均后的结果： 对于 MSAA ，我们需要早知道如下几点： MSAA 是对抗锯齿操作的第一步，也就是模糊操作（求平均）
MSAA 增加采样点，并不是为了提高采样率（分辨率没有提高），而是为了得到一个更合理的三角形覆盖率。
MSAA 的代价是计算量大增，如果一个像素里面有4个采样点，那么计算量就打了4倍，如果一个像素里面有16个采样点，那么计算量就大了16倍。（事实上，工业界会复用、优化这些采样点，因此计算量并没有增加理论上那么多）`},{header:"画家算法",slug:"画家算法",content:`当我们要在屏幕上绘制物体的时候，会涉及到物体与物体的遮挡问题。最常见的做法是像画家绘画那样，先绘制远处的物体，再绘制近处的物体。
画家算法要求我们先在深度上进行一次排序（需要 nlogn 的时间），然后再进行绘制。但有些情况是无法通过画家算法来解决的，如下图： 上图中，无论怎么排序，都无法得到上图的结果。`},{header:"深度缓冲（Z-Buffer）",slug:"深度缓冲-z-buffer",content:`深度缓冲用来记录每个像素的最小深度。
他的工作原理是：每次渲染的时候除了生成最终的图像之外，还生成一张深度图，该深度图记录了每个像素当前的最小深度。 具体实现步骤如下： 初始化像素的深度为∞
在光栅化工程中，不断更新其深度： for (each triangle T) for (each sample(x,y,z) in T) if (z < zbuffer[x,y]) { framebuffer[x,y] = rgb; zbuffer[x,y] = z; } 对于 n 个三角形，要得到某个像素的最小深度值，我们只需要便利所有三角形即可，因此其复杂度为 O(n)。
深度缓冲还有以下的好处： 绘制三角形的顺序不影响最终结果
所有 GPU 都支持深度测试 需要注意的是 ： 深度缓冲不能处理透明物体`}]},{path:"/Graphic/basic/raster/base_draw.html",title:"基础绘画",pathLocale:"/",contents:[{header:"基础绘画",slug:"基础绘画",content:""},{header:"线",slug:"线",content:`我们从义务教育基础武器库中就可以学到直线的表达公式：
f(x, y) ≡ (y0 − y1)x + (x1 − x0)y + x0y1 − x1y0 = 0. 其中我们把直线的倾斜度数值化叫做斜率，公式如下：
m = (y1 − y0) / (x1 − x0) 斜率的基本原则就是： m > 0 : 直线为递增，也就是y值随着x增大而增大
m < 0 : 直线为递减，也就是y值随着x增大而减小
m = 0 ：直线为平行于x轴的一条线 我们需要把直线绘画到屏幕上，这里我们拿 m > 0 的情况来举例，我们把屏幕的左下角、下边、左边可看做一个坐标轴，之前了解到屏幕就是一个像素的二维数组，索引就是坐标。这样我们就可以把直线上的点映射到屏幕坐标上。我们把需要画线段的开始点设置为（x0,y0），从（X0,y0）开始画，遇到一些条件的时候就把当前 y 坐标加一，继续向右画。简单可以理解为一排一排的画出来。
简单的伪代码如下：
y = y0
for x = x0 to x1 do draw(x, y) if f(x + 1, y + 0.5) < 0 then y = y + 1 这里使y坐标加一条件就是用到了直线与点的关系的规则： 如果点在直线上，f(x,y) = 0
如果点在直线上方，f(x,y) > 0
如果点在直线下方，f(x,y) < 0 这个我们预计算同一排下一个像素的上边与我们的直线的位置关系： 预计算点在直线上方，所以线在 x+1 还未超过当前y值 预计算点在直线上方，所以线在 x+1 超过当前y值,需要画上面的像素`},{header:"三角形",slug:"三角形",content:"这里"}]},{path:"/Graphic/basic/raster/shading.html",title:"着色",pathLocale:"/",contents:[{header:"着色",slug:"着色",content:`我们在前面已经把图像三角形化了，明白了三角形的绘制规则，这样我们可以把一个物体画出来了，如下图： 我们看到这个图是感受不出来是一个3d的模型，就是看起来很不真实，我们可以认出这个是个牛的模型，但是不知道这个是什么牛。
我们现实世界中看一个物体认为他是三维物体，是因为光照的关系，让物体表面有了明暗的差别，让我们知道是什么牛是因为物体表面的质感，也就是材质。
如果我们要在电脑上实现明暗的差别，简单的说就是为我们的渲染世界加一个灯，然后我们根据灯的一些属性（位置，方向，强度，颜色等）接合我们模型的颜色和位置，就可以产生明暗差别的效果（高光，漫反射，环境光）。如下图： 计算明暗差别这个过程一般叫做着色，换句话说，着色是根据材质属性（如漫反射属性等）、光源信息（如光源方向、辐照度等），使用一个等式去计算沿某个观察方向的出射度的过程。我们也把这个等式称为光照模型。`},{header:"标准光照模型",slug:"标准光照模型",content:`标准光照模型也就是Binn-Phong着色模型，主要由四部分组成： 漫反射（Diffuse）：当光线从光源照射到模型表面时，该表面会向每个方向散射多少辐射量
高光（Specular）：描述当光线从光源照射到模型表面时，该表面会在完全镜面反射方向散射多少辐射量
环境光（Ambient）：描述其他所有的间接光照
自发光（Emissive）：当给定一个方向时，一个表面本身回想该方向发射多少辐射量。需要注意的是，如果没有使用全局光照技术，这些自发光的表面并不会真的照亮周围的物体，而是它本身看起来更亮了而已。这个一般物体是没有的。 对于每个着色点，我们可以简化成如下图所示： 其中有： $n$ ：表面法线方向
$l$ ：入射光方向
$v$ ：观察方向 注意：所有向量都是单位向量，所以确保向量进行过 normalize 操作。
另外，着色过程中是不会产生阴影的，阴影是通过其他技术手段来生成的。`},{header:"漫反射",slug:"漫反射",content:`漫反射光照是用于对那些被物体表面随机散射到各个方向的辐射度进行建模。 在漫反射中，视角的位置不重要，因为反射是完全随机的，因此可以认为在任何反射方向上的分布都是一样的。所以物体表面的颜色都是一样在任何方向上。
但是我们看到上面的牛的图片中并不是每个地方的颜色都一样，这里就会说到兰伯特定律（Lambert's law）：反射光线的强度与表面法线和光源方向之间夹角的余弦值成正比。因此入射光线的角度就很重要了。
可以这样理解这个过程，平时看一个物体的颜色，会受到物体本身表面的颜色和照射到该物体上的光的影响。比如：一个白色盒子在绿色灯光上，这个盒子我们看到就会是绿色，当然这个盒子上的绿色会根据我们灯光的强度和方向来改变成浅绿色或者深绿色。`},{header:"光的方向",slug:"光的方向",content:`我们知道一个红色的物体为什么是红色？是因为这个物体吸收了我们可以从光打到表面上，表面吸收了多少能量来理解这个： 这里我们可以看上图： 左：光线与平面法线平行，平面接受了所有光线的能量（6根光线）
中：光线与平面法线夹角为 60度，平面只接受了一半光线的能量（3根光线）
右：平面能接受的能量与该平面的法线和入射光的角度有关。其关系是：平面接受的能量的百分比 = cos(n,l) = n·l`},{header:"光的强度",slug:"光的强度",content:"我们明白了光照射到平面的方向的关系了，光的强度我们可以用烤火来理解，我们离火堆很近温度就高一些，离火堆远一点，温度就小一点，那我们就可以以火堆为圆心，火堆到我们的距离为半径，模拟成下图："},{header:"兰伯特光照模型",slug:"兰伯特光照模型",content:`接合上面两个因素我们就可以得到一个公式： 这其中： $L_d$：着色点的漫反射分量
$K_d$：漫反射系数，可调节。一般使用该着色点的RGB颜色。
$(I/r^2)$：光照强度
$max(0,n \\cdot l)$:如果光照方向与表面发现反方向，是不会接收到光照的，反方向点乘为负数，所以限制为0。 Kd数值对漫反射数值的影响：`},{header:"高光反射",slug:"高光反射",content:"我们平时看一些金属或者光滑的表面，我们会发现一些亮白色的块，那个就是高光。我们也可以容易的发现，当我们的眼睛移动时，物体表面的亮白色块也会移动。所以观察方向会影响到高光，相对漫反射中的条件就会多一个视角方向。这个亮块就是我们光源的反射造成的，它的颜色通常是光源的颜色。"},{header:"Phong",slug:"phong",content:`我们要模拟高光现象，用到了Phong光照模型，我们先看高光反射示意图： 图中所示： $l$：光源
$n$：法线
$r$：光源放射
$v$：观察 我们可以认为σ角越小时，就会看到高光。这个好比我们直接眼睛看光源，我们正对看光源，就会被闪瞎。我们就可以得到简单的公式：c = l(v·r)。
这个公式有两个问题： 点乘的结果会是负数
这样造成的亮块会比真实的亮块宽一些 为了解决这个问题我们可以把公式写成 ：c = lmax(0,v·r)^p。 上图可以看出为什么我们使用指数可以把亮块变窄，也就是数值就变窄。 r 向量我们可以使用上图解释列出公式：r = −l + 2(l · n)n
然后写出最终公式：
$$L_s = k_s \\cdot (\\frac I {r^2}) \\cdot max(0, v \\cdot r)^p$$
$$\\qquad\\qquad\\qquad\\quad= k_s \\cdot (\\frac I {r^2}) \\cdot max(0, v \\cdot (-l + 2( l \\cdot n)n))^p$$`},{header:"Blinn",slug:"blinn",content:`上述就是Phong光照模型，Blinn提出了一个简单的修改方法来得到类似的效果。它的基本思想是，避免计算反射方向 r。为此，Blinn模型引入了一个新的矢量 h，他是通过 l 和 v 的取平均后再归一化得到，也就是光源方向与视角方向的中间。根据我们漫反射公式，我们就可以写出最终公式： 公式中： $L_s$：高光反射
$K_s$：高光反射系数
$p$：用来调节高光的可是范围 Ks与p系数变化对高光的影响： 在硬件实现时，如果摄像机和光源距离模型足够远的话，Blinn模型会快于Phong模型，这是因为，此时可以认为 v 和 l 都是定值，因此 h 将是一个常量。但是，当 v 或者 l 不是定值时，Phong模型可能反而更快一些。需要注意的是，这两种光照模型都是经验模型，也就是说，我们不应该认为Blinn模型是对“正确的”Phong模型的近似。实际上，在一些情况下，Blinn模型更符合实验结果。`},{header:"环境光",slug:"环境光",content:`虽然标准光照模型的重点在于描述直接光照，但在现实的世界中，物体也可以被间接光照所照亮。间接光照指的是，光线通常会在多个物体之间反射，最后进入摄像机，也就是说，在管线进入摄像机之前，经过了不止一次的物体反射。例如，在红地毯上放置一个浅灰色的沙发，那么沙发底部也会有红色，这些红色是由红地毯反射了一部分光线，再反弹到沙发上的。
在标准光照模型中，我们使用了一种被称为环境光的部分来近似模拟间接光照。环境光的计算非常简单，它通常是个全局变量，即场景中的所有物体都使用这个环境光。下面给出计算环境光的部分： 这其中： $L_a$：着色点的环境光分量
$K_a$：材质的环境系数
$I_a$：场景的环境光强度 值得注意这个公式也是近似的算法。`},{header:"Blinn Phong 展示",slug:"blinn-phong-展示",content:`当我们计算出漫反射、高光、环境光之后，把它们加起来，就能得到 Blinn Phong 着色模型的结果了： Blinn Phong的着色公式为：$L = L_a + L_d + L_s$
$$L = k_a I_a + k_d(\\frac {I} {r^2}) max(0, n \\cdot l) + k_s(\\frac {I} {r^2}) max(0, n \\cdot h)^p$$`},{header:"逐像素还是逐顶点",slug:"逐像素还是逐顶点",content:"上面，我们给出了基本光照模型使用的数学公式，那么我们在哪里计算这些光照模型呢？通常来讲，我们有两个选择：在片元着色器中计算，也被称为逐像素光照；在顶点着色器中计算，也被称为逐顶点光照。"},{header:"平面着色",slug:"平面着色",content:"平面着色是指整个三角面中共用一个方向的法线，因此表现为整个三角面的颜色都是一样的。如下图："},{header:"Phong着色",slug:"phong着色",content:`在逐像素光照中，我们会以每个像素为基础，得到它的法线（可以是对顶点法线插值得到的，也可以是从法线纹理中采样得到的），然后进行光照模型的计算。这种在面片之间对顶点法线进行插值的技术被称为Phong着色，也被称为Phong插值或法线插值着色技术。这不同于我们之前讲到的Phong光照模型。
Phong着色如下图：`},{header:"高洛德着色",slug:"高洛德着色",content:"与之相对的是逐顶点光照，也被称为高洛德着色。在逐顶点光照中，我们在每个顶点上计算光照，然后会在渲染图元内部进行线性插值，最后输出成像素颜色。**由于顶点数目往往小于像素数目，因此逐顶点光照的计算量往往要小于逐像素光照。**高洛德着色如下图： 但是，由于逐顶点光照依赖于线性插值来得到像素光照，因此，当光照模型中有非线性的计算（例如计算高光反射）时，逐顶点光照会在渲染图元内部对顶点颜色进行插值，这回导致渲染图元内部的颜色总是暗于顶点处的最高颜色，这在某些情况下会产生明显的棱角。"},{header:"对比",slug:"对比",content:"如图所示，着色频率对结果的影响，取决于模型的复杂度。模型的复杂度越低，着色结果区别越大，但随着模型复杂度的提高，平面着色也可以达到冯氏着色的效果。因此我们不能迷信冯氏着色一定比平面着色好。"},{header:"简单实现",slug:"简单实现",content:`Vector3f phong_fragment_shader(const fragment_shader_payload &payload)
{ Vector3f ka = Vector3f(0.005, 0.005, 0.005); Vector3f kd = payload.color; Vector3f ks = Vector3f(0.7937, 0.7937, 0.7937); auto l1 = light{{20, 20, 20}, {500, 500, 500}}; auto l2 = light{{-20, 20, 0}, {500, 500, 500}}; std::vector<light> lights = {l1, l2}; Vector3f amb_light_intensity{10, 10, 10}; Vector3f eye_pos{0, 0, 10}; float p = 150; Vector3f color = payload.color; Vector3f point = payload.view_pos; Vector3f normal = payload.normal; Vector3f result_color = {0, 0, 0}; for (auto &light : lights) { // For each light source in the code, calculate what the *ambient*, *diffuse*, and *specular* // components are. Then, accumulate that result on the *result_color* object. Vector3f l = (light.position - point).normalized(); Vector3f I_r2 = (light.intensity / (light.position - point).squaredNorm()).normalized(); Vector3f v = (eye_pos - point).normalized(); Vector3f h = (v + l).normalized(); Vector3f n = normal.normalized(); Vector3f ambient = ka.cwiseProduct(amb_light_intensity); Vector3f diffuse = kd.cwiseProduct(I_r2) * std::max(0.f, n.dot(l)); Vector3f specular = ks.cwiseProduct(I_r2) * pow(std::max(0.f, n.dot(h)), p); result_color += ambient + specular + diffuse; } return result_color * 255.f;
}`}]},{path:"/Graphic/basic/raster/texture.html",title:"贴图",pathLocale:"/",contents:[{header:"贴图",slug:"贴图",content:`我们已经可以把模型使用光照模型着色了，展示成3d的模样，如下图： 但是我们平时看到一个牛的模型，我们会根据模型表面的颜色、质感会知道这个牛属于什么牛，如下图： 我们知道这个是一个奶牛。我们想要对一个模型做更多颜色表现，我们就需要对每个顶点做颜色的配置，我们最开始的图片设置的颜色就是所有顶点的颜色就是棕色。
我们就可以使用一个图片来存储每个顶点的颜色，然后我们在做着色时从那张图片中读取当前着色点的配置颜色。那张图片也就是我们常说的贴图，也就是模型颜色的配置表。当然现在的贴图也不一定是存储颜色信息，也可以存储如法线、反射、亮度等信息。
我们是一般是在做漫反射时，$K_d$漫反射系数包含了纹理中某个区域的颜色，我们也可以直接使用顶点的颜色作为$K_d$。`},{header:"贴图映射",slug:"贴图映射",content:`那么我们是怎么把着色点和贴图联系起来的呢？这里就需要使用到uv坐标，然后映射关联起来。
那uv坐标是怎么得到的呢？这个是在美术人员建模的时候，在建模软件中利用纹理展开技术把纹理映射坐标（uv坐标）存储在每个顶点上。
通常，uv坐标使用一个二维变量（u，v）来表示，其中u是横坐标，v是纵坐标。u与v的值范围都是[0,1]。下图为uv坐标到图片的转化： 映射uv坐标都是存放在我们的fbx、obj文件中，这个是obj文件中的信息： 其中： v ：顶点坐标
vn：法线坐标
vt：贴图坐标（uv坐标） 简单的贴图映射伪代码如下：
Color texture_lookup(Texture t, float u, float v) { int i = round(u * t.width() - 0.5) int j = round(v * t.height() - 0.5) return t.get_pixel(i,j)
} Color shade_surface_point(Surface s, Point p, Texture t) { Vector normal = s.get_normal(p) (u,v) = s.get_texcoord(p) Color diffuse_color = texture_lookup(u,v) // compute shading using diffuse_color and normal // return shading result
} 那我们怎么是确定一个三角形的颜色呢？上面说到我们对每个顶点都做了颜色的配置，但是我们是把模型切分成了很多个三角形，我们在填颜色时是对三角形填颜色。
这里我们使用了三角形的重心坐标来对三个顶点的颜色做插值，得到这个三角形的颜色。关于重心坐标的信息在之前三角形模块中描述了三角形的重心计算方式
我们得到重心坐标 (alpha,beta,gamma) 后，就可以计算出重心的uv值，然后再做漫反射即可。简单的代码如下：
Vector2f interpolate(float alpha, float beta, float gamma, const Vector2f &vert1, const Vector2f &vert2, const Vector2f &vert3, float weight)
{ auto u = (alpha * vert1[0] + beta * vert2[0] + gamma * vert3[0]); auto v = (alpha * vert1[1] + beta * vert2[1] + gamma * vert3[1]); u /= weight; v /= weight; return Vector2f(u, v);
} 当然我们的贴图也可以重复利用，也就是说模型中的多个顶点可以对应贴图中一个顶点。`},{header:"走样",slug:"走样",content:`现在我们可以把贴图和模型接合起来，并且使用漫反射渲染出来了。
这里有两个基本的概念： 像素：屏幕组成的基本单位
纹素：纹理（贴图）组成的基本单位 我们在这里把这两个简单的认为都是一小方块，我们对图片采样时，完美的情况下，就是一个像素就对应着一个纹素，像是铺地砖一样一个一个排出来。
但是在实际使用会出现一些问题： 高分辨率屏幕，展示小尺寸贴图：贴图放大
低分辨率屏幕，展示大尺寸贴图：贴图缩小`},{header:"贴图尺寸小",slug:"贴图尺寸小",content:`在这个时候贴图就需要放大，意味着一个纹素会映射到多个像素，那么就会出现像素图片，出现一块一块的那种情况，如下图左边： 我们想要效果是中间的图片的效果，我们可以使用一个叫做双线性插值的方式来获得。右边使用的是双立方插值获得。 我们使用第一种采样（Nearest/Point）的示意图： 其中： 红色为屏幕像素点
黑色为纹素点 我们四个像素点进行采样时，会得到小数的纹素坐标，然后四舍五入都会得到中间纹素的颜色。所以会出现方块状。 我们使用双线性插值采样(Bilinear)的示意图： 我们以一个像素点(红色点)来说明，我们找到离这个像素点最近的4个纹素点$u_{00}$、$u_{01}$、$u_{10}$、$u_{11}$。
我们分别对这4个纹素点做横向和纵向的插值，过程如下： 这其中： 我们假定$u_{01}$到$u_{11}$占比$s$，也就是横向的插值为$s$
我们假定$u_{00}$到$u_{01}$占比$t$，也就是纵向的插值为$t$
我们先使用横向插值求到：$u_0$、$u_1$
最后插值$u_0$、$u_1$就可以得到结果 双线性插值通常在合理的消耗下可以得到不错的效果。当然也有计算更多次的双立方插值等，我们可以看出效果其实是差不多。
简单的双线性插值实现：
Color tex_sample_bilinear(Texture t, float u, float v) { u_p = u * t.width - 0.5 v_p = v * t.height - 0.5 iu0 = floor(u_p); iu1 = iu0 + 1 iv0 = floor(v_p); iv1 = iv0 + 1 a_u = (iu1 - u_p); b_u = 1 - a_u a_v = (iv1 - v_p); b_v = 1 - a_v return a_u * a_v * t[iu0][iv0] + a_u * b_v * t[iu0][iv1] + b_u * a_v * t[iu1][iv0] + b_u * b_v * t[iu1][iv1]
}`},{header:"贴图尺寸大",slug:"贴图尺寸大",content:`在这个时候贴图就需要缩小，意味着多个纹素会映射一个像素。那就意味着一个像素中会有多个颜色杂糅在一起，如下图： 我们可以看到右边图的后面就是出现了这样的效果，也就是摩尔纹，同时可以发现前面部分发生了走样。为什么会出现这样的情况呢？
在上图左边图片，我们可以发现在越后面颜色会越密集，越前面颜色的变化要平稳一些。 那么我们就可以认为像素与纹素的关系是： 越前面，像素对应的纹素就越少，会出现一纹素对应多像素，如上图左边
越后面，像素对应的纹素就越多，会出现多纹素对应一像素，如上图右边 我们之前讲过解决走样，可以使用超采样。也就是增加多个采样点来感知变化。效果如下： 上图是把每个像素点增加512采样点做出的效果。但是这样做是非常消耗性能的。之前说过出现采样的原因是，图片的频率过快而采样的速度更不上。`},{header:"Mipmap",slug:"mipmap",content:`我们可以换一个思维来解决这个问题，我们不进行对图片的采样，只是获得一个平均的范围就可以了。因为当一个像素覆盖了多个纹素时，为了反走样我们平均多个纹素到平滑。
但是当我们需要计算平均个个数非常大的时候，这样会非常的消耗，所以预先计算出平均值。预先计算叫做Mipmap技术，Mipmap是指根据一张纹理去生成一系列更小的纹理技术。如下图： 这其中： 原始图片叫做base level或者level 0,$128*128$ level 1 :降低采样2倍,$64*64$ level 2 :降低采样4倍,$32*32$
····· 最后级得到 ：$1*1$ 最终分层出来的效果，是一个三角锥的样子： 上面生成了那么多图，但是存储仅仅是多了 $1/3$的储存量。
我们现在知道使用mipmap可以去查询一个纹素的平均，但是我们也不知道去哪一张mipmap中去查询。这里可以使用一个简单的方式：当前一个像素，映射到纹素集合的边长$L$是多少，我们就看$L$长度的贴图需要多少次降低采样得到的mipmap贴图成为$1*1$。这里又是因为mipmap的降低采样是以2为系数，所以我们可以得到公式：
$$Log_2L≈D$$
其中： $L$表示纹素的宽度
$D$表示层数 我们可以简单看看怎么计算$L$: 首先选择四个像素点（左图红点）
映射到纹理坐标上（右图红点）
求出右图红点边长
求出4个$L$，取最长的即可 这样我们在着色时，查询颜色时，就可以使用mipmap查询到颜色了。如下图： 这里颜色的不同就是mipmap的层级的不同，可以看到每个颜色值切换的非常深硬。这是因为我们mipmap的层数只有整数层。我们知道比如说2.8层的颜色，我们可以使用插值来计算，插值第2层到第3层即可。得到的结果： 综上所述，我们使用mipmap的过程： 求到当前像素对应总纹素边长$L$
获取到对应层级$D$的mipmap
这里对$D$求分值，$d_0$、$d_1$是$D$的上层与下层
然后分别对$d_0$、$d_1$求双线性插值得到$c_0$、$c_1$
对$c_0$、$c_1$做最后的插值即可 简单的实现三线性插值如下：
Color mipmap_sample_trilinear(Texture mip[], float u, float v,matrix J) { L = max_column_norm(J) D = log2(L) d0 = floor(D); d1 = d0 + 1 a = d1 - d; b = 1 - a c0 = tex_sample_bilinear(mip[d0], u, v) c1 = tex_sample_bilinear(mip[d1], u, v) return a * c0 + b * c1
} 这样的做法叫做三线性插值(Trilinear)。
但是使用mipmap也是会有一定的问题，如下图： 可以看到远处会很糊的颜色，这里我们就会看到最后一个策略（各项异性过滤）的效果会好于前两种。
因为mipmap只是预计算了正方形的颜色平均，但是我们在蒙皮时，可能是一个像素块映射到纹理上去，会是长条形的，如图： 可以看到后面的像素点映射到纹理上会是长条形的。所以说如果我们的mipmap也有长条形的样板的话，就会好一些，所以我们的各项异性过滤生成的贴图如下： 这其中： 斜对角线的缩小图是正方形mipmap
下边和右边的就是生成的长条形mipmap`},{header:"常用贴图",slug:"常用贴图",content:"我们已经知道在计算漫反射时我们可以把贴图颜色加入进去，这样就可以让我们的模型更加的直观。前面也说了贴图也就是一个配置表，那么我们就可以在这个配置表中配置我们需要的数据。我们把贴图分为很多类型，贴图中存放的数据代表的意义，这些都是我们会经常用的到贴图类型。"},{header:"法线贴图和深度贴图 Normal Maps and Bump Maps",slug:"法线贴图和深度贴图-normal-maps-and-bump-maps",content:`我们在计算漫反射、高光反射时，都会用到法线，我们每次去求每个着色点的法线是不是会很消耗。因为我们想可以把法线存放在贴图里。
我们最直接的想法就是就是直接使用模型空间的法线贴图，然后我们在平时修改了模型的表面过后，需要去重新生成法线贴图。这里我们使用了切线空间的法线贴图。
为什么使用切线空间： 自由度高。模型空间下的法线纹理记录的是绝对法线信息，仅可用于创建它时的那个模型，而应用到其他模型上效果就完全错误。切线空间下的法线纹理记录的是相对法线信息。
可进行UV动画
可以重用法线纹理
可压缩。由于切线空间下的法线问题中法线的Z方向总是正方向，因此我们可以仅储存XY方向，而推导得到Z方向。 加上法线贴图和深度贴图的对比： a漫反射
b高光计算使用了粗糙贴图
c表面的法线使用了深度贴图图 凹凸贴图是一种为模型添加细节的贴图。凹凸贴图是一张灰度图，它保存了着色点与原始表面的高度差，以此来影响光照信息。`},{header:"位移贴图 Displacement Maps",slug:"位移贴图-displacement-maps",content:"与深度图一样存储的高度信息，但是位移贴图会改变表面。最常见的用法：作为地形深度图。"},{header:"阴影贴图 Shadow Maps",slug:"阴影贴图-shadow-maps",content:`阴影贴图是一种使用阴影机制的技术纹理贴图从点光源获取阴影。
在确定遮挡关系的时候，z-buffer的深度值是相当于摄像头，也就是眼睛所见来确定物体是否被遮挡，这个很容易理解。眼睛看不见的地方，当然被挡住了。那么我们换个角度想想，阴影是如何产生的？
阴影其实就是光线看不见的地方。因此，如果我们把摄像机放到光源，那么光能看见的地方，亮度就会高；而光看不见的地方，就是阴影。所以，通过把摄像机放到光源处获得的每个像素点的深度值z-buffer保存起来得到一张类似于map的缓冲，就是Shadow Map。
当我们有了这一张Shadow Map以后，我们回到摄像机空间中，把每个点在光照空间的坐标求出来，获得每个点的深度值z，在fragment shader中通过光照模型渲染出来。`},{header:"环境贴图 Environment Maps",slug:"环境贴图-environment-maps",content:"用来表示环境光，不需要使用光源来自计算。"},{header:"固体噪声 Solid Noise",slug:"固体噪声-solid-noise",content:"获得噪声贴图通过随机每个点，这个就像电视机上的静态雪花。"},{header:"流动贴图 Turbulence",slug:"流动贴图-turbulence",content:"许多自然纹理在同一纹理中包含多种特征尺寸。重复添加噪声方法在顶部。"}]},{path:"/Graphic/basic/raster/viewing.html",title:"转换",pathLocale:"/",contents:[{header:"转换",slug:"转换",content:`转换是一个三维场景中的物体变化到屏幕二维空间上的一个过程，这个过程大致如下： 我们常说的MVP矩阵转换。 Modeling : 模型变换
View : 视图/相机变换，也就是图中的Camera transformation
Projection : 投影变换 这里在加上一个视口变换，就完成了所有转化。`},{header:"视图/相机变换",slug:"视图-相机变换",content:"这里我们先说视图变换，这样会好理解一些。"},{header:"定义相机",slug:"定义相机",content:`首先我们要知道怎么去定义一个相机，我们要想知道它在场景中的信息，可以通过以下几个向量来知道: 相机的位置坐标 e
相机的照射方向 g
相机的向上方向 t 相机定义图： 我们经常为了方便，在拍照的时候，先把相机固定了，构好图，然后再调整姿势。在渲染图片的时候我们也为方便也先固定好相机，所以约定相机： 我们需要把相机移动到世界坐标原点，
看向的方向为负z轴方向
向上方向与y轴正方向一样。 那我们要把相机设置成上面的状态。这个过程我们也可以认为是把相机从自己的坐标系转移到世界坐标系中，因为相机在世界坐标系原点。`},{header:"转换过程",slug:"转换过程",content:`我们就可以先把相机移动到原点，然后再把相机旋转到指定的方向。这样会方便计算旋转。
我们可以得到公式： Tips
因为使用矩阵(Mview)最后乘以相机坐标,所以这里是需要反过来相乘。`},{header:"平移",slug:"平移",content:"只需把相机坐标e移动到原点即可得到平移矩阵（视角变换）："},{header:"旋转",slug:"旋转",content:`我们要旋转任意的角度，可以分别沿想x、y、z轴旋转即可。获得旋转： t x g 旋转到x轴正方向
t 旋转到y轴正方向
g 旋转到z轴负方向 Tips
我们这里定义一下 t x g 这个方向为 r 方便用 这样子我们并不是很好的去求解旋转矩阵，我们可以反向旋转。先求到结果点旋转到原始点的旋转矩阵，即世界坐标轴旋转到相机在世界坐标的方向，然后对矩阵求逆即可。 旋转 x 轴正方向 r (1,0,0) 到 (rx,ry,rz)
旋转 y 轴正方向 t (0,1,0) 到 (tx,ty,tz)
旋转 z 轴正方向 -g (0,0,1) 到 (-gx,-gy,-gz) 从原点旋转得到相机场景中的矩阵： 我们可以很清晰的看出上面的旋转矩阵为正交矩阵，又因为正交矩阵的逆矩阵等于转置矩阵。
所以我们的旋转矩阵为：`},{header:"模型变换",slug:"模型变换",content:`我们把相机移动到世界坐标原点位置并且方向都改变了，物体被相机渲染出来的位置都不正确了吧。这里我们就要用到初中物理
相对运动。我们在移动相机的同时也移动物体，这样就可以保持相对运动，这样一来就可以使相机渲染出来的结果不变。这个过程我们常常叫模型变换（modeling transformation）。所以我们也把场景中的所有物体模型的位置坐标乘上上面我们求到 Tview 矩阵。`},{header:"投影变换",slug:"投影变换",content:`我们把相机和物体都摆放好了，我们就需要开始把场景中的物体映射到一个图片上了。这个过程叫做相机投影，这里我们把投影分为两种： 透视投影（Projective Projection）：把相机看做一个点形成一个锥体。
正交投影（Orthographic Projection）：把相机放的无限远后，投影出近处物体与远处的物体的大小差不多相同。`},{header:"正交投影",slug:"正交投影",content:`我们可以想象把物体坐标的z值去掉，然后平行投影到 [-1,1]² 的一个矩形中。投影到屏幕坐标范围 [0,1](NDC Normalized Device Coordinates) Tips
这里的 [-1,1]² 矩形是约定俗成。 有点像俯视图（平面图）的感觉。我们先把物体移动到世界坐标原点，然后对其进行缩放。我们具体怎么去实现这个过程呢？如下图： 我们先把物体移动到坐标原点，然后把物体缩放到一个 [-1,1]³ 的一个立方体中。这个立方体叫做“规范立方体”（canonical cube）。这其中参数： l 盒子最左边 （x轴）left
r 盒子最右边 （x轴）right
t 盒子最上边 （y轴）top
b 盒子最下边 （y轴）bottom
n 盒子最前边 （z轴）near
f 盒子最远边 （z轴）far 这样我们就可以写出变换矩阵了： Tips
这里n与f都是在z轴上的，相机的朝向是z轴负方向所以这里n的值是比f大。
因为我们的立方体是 [-1,1] 长宽高都为2，所以我们的缩放是2除以原来物体的长度。 最终矩阵：`},{header:"透视投影",slug:"透视投影",content:`正常我们人眼看到的构图结构———远小近大，就是透视投影。
透视投影我们需要三维的场景映射到观察窗口，然后把映射到窗口的做一次正交投影。
前面了解到，透视投影是把相机作为一个点，这样我们可以来获得一个横截面： Tips
观察窗口可以简单的理解为屏幕 各个参数： e为相机位置
g为相机照射方向
n为相机到屏幕距离
y场景中一点的高度基于g
ys我们需要求得屏幕映射点的高度基于g 这里最重要的根据就是相似三角形，可以得到公式: 同时我们也可以得到： 我们可以先写出一个简单的关系： Tips
这里用到一个齐次坐标的特性： (x,y,z,1)
(kx,ky,kz,k)
(zx,zy,z*z,z) 以上三个都代表点(x,y,z),当然这里乘上的系数不能为0。如k和z都不能为0。 这里我们的Zs一直不知道是什么，所以在乘上Z后还是不知道。这里我们已经获得一个矩阵的部分，我们只需要求出第三行即可。这个里我们用特殊值得方法来求: Tips n 相机的照射到的近平面的z值，相机到屏幕
f 相机的照射到的远平面的z值 当我们设的点就是屏幕上的点，这里我们的Zs和Z都为n，公式：Zs = Z = n。这里就可以写出以下等式： 这里的小步骤： 先把 [x,y,z,1]Τ 中间的 Z 替换成 n 得到 [x,y,n,1]Τ
然后把每一位都乘以 n 得到 [nx,ny,n²,n]Τ
这个形式很像上面矩阵计算的第三个 [nx,ny,*,z]Τ，把这其中的 z 也换成 n，得到 [nx,ny,*,n]Τ，所以说这里的*就为n²。 这里因为等于 n² 所以跟 x 与 y 都没有关系的，所以我们就可以写出上面最后一个相乘矩阵第三行的计算等式： 然后我们可以写出一个等式： 当我们设的点为远平面，在越来越远的地方它的 Zs 和 Z 都为 f ，公式：Zs = Z = f 。同理也可以得到下面的等式： 这两个等式解出来A与B如下： 最终写出透视投影到正交投影的矩阵： 这里最后再乘上正交投影即可:`},{header:"视锥",slug:"视锥",content:`我们相机是透视照射的话，就可以调整一个参数叫fov也就是视锥。我们可以用 (l, r, b, t) 来定义任意一个窗口， n 作为相机到窗口的距离。 这其中的关系有： l = -r
b = -t
宽高比 aspect = r / t
这里的Θ也就是我们的fovY可以得到`},{header:"视口变换",slug:"视口变换",content:`把之前算好的标准立方体的x和y拉伸到屏幕分辨率大小叫做视口变换。 Z值不变
width:屏幕宽度 height:屏幕高度
xy平面 [-1,1]² 转换到 [0,width] x [0,height] 这样就可以得到转换矩阵：`},{header:"最终结果",slug:"最终结果",content:`最后用这个变换矩阵乘上物体坐标，也就是物体的顶点坐标即可获得顶点在屏幕空间的坐标。
我们可以得到简单伪代码：
function view_transform(projection,view,model) // mvp transformation mvp = projection * view * model for vertex in allVertexes do vertex = mvp * vertex //Homogeneous division for vertex in allVertexes do vertex /= vertex.w //Viewport transformation for vertex in allVertexes do vertex.x = 0.5 * width * (vertex.x + 1.0) vertex.y = 0.5 * height * (vertex.y + 1.0) // vertex.z = -vertex.z * f1 +f2 这里的视口变换是直接写的结果试子，我们也可以直接传入矩阵`}]},{path:"/Graphic/basic/raytracing/",title:"光线追踪",pathLocale:"/",contents:[{header:"光线追踪",slug:"光线追踪",content:"以相机为原点，发出射线与每个像素中心点相交，射出射线，检测射线与是否与场景中的物体相交，来判断物体是否可见"}]},{path:"/Graphic/basic/raytracing/viewing.html",title:"ray tracing view transform",pathLocale:"/",contents:[{header:"ray tracing view transform",slug:"ray-tracing-view-transform",content:`they will project any point on
a given pixel’s viewing ray back to that pixel’s position in image space
float ndcPixelx = (0.5f + i) / (scene.width * 1.f);
float ndcPixely = (0.5f + j) / (scene.height * 1.f); // screen [-1,1],keep y > 0 // screen orgin is the center // ndc、raster orgin is the left-top
float screenPixelx = 2 * ndcPixelx - 1;
float screenPixely = 1 - 2 * ndcPixely; // world space
// camera-to-world matrix
float tanFov = (float)tan(scene.fov / 2 * M_PI / 180);
float cameraPixelx = screenPixelx * imageAspectRatio * tanFov;
float cameraPixely = screenPixely * tanFov;`}]},{path:"/Graphic/basic/shading/lighting_model.html",title:"lighting model",pathLocale:"/",contents:[{header:"lighting model",slug:"lighting-model",content:""}]},{path:"/Graphic/basic/shading/texture_mapping.html",title:"texture mapping",pathLocale:"/",contents:[{header:"texture mapping",slug:"texture-mapping",content:""}]},{path:"/Graphic/basic/textureformat/References.html",title:"References",pathLocale:"/",contents:[{header:"References",slug:"references",content:`https://zhuanlan.zhihu.com/p/133229655
https://www.cnblogs.com/yuluoxingkong/p/10681253.html
https://docs.fileformat.com/image/jpeg/
code:
https://github.com/ghallak/jpeg-python
https://github.com/thejinchao/jpeg_encoder`}]},{path:"/Basic/algorithm/leetcode/array/HeightChecker.html",title:"Height Checker",pathLocale:"/",contents:[{header:"Height Checker",slug:"height-checker",content:`Students are asked to stand in non-decreasing order of heights for an annual photo.
Return the minimum number of students that must move in order for all students to be standing in non-decreasing order of height.
Notice that when a group of students is selected they can reorder in any possible way between themselves and the non seleted students remain on their seats. Tips Build the correct order of heights by sorting another array, then compare the two arrays. Solution`},{header:"1. my badly solution",slug:"_1-my-badly-solution",content:`like bubble sort get the smallest height index A
swap A with current index
mark the heights to map
after sorting,get how many heights have swaped?`},{header:"2. best solution",slug:"_2-best-solution",content:`Build the correct order of heights by sorting another array
then compare the two arrays. int heightChecker(vector<int> &heights)
{ int res = 0; vector<int> sortHeights(heights.begin(), heights.end()); sort(sortHeights.begin(), sortHeights.end()); for (size_t i = 0; i < heights.size(); i++) { if (heights[i] != sortHeights[i]) { res++; } } return res;
}`}]},{path:"/Basic/algorithm/leetcode/array/",title:"Array",pathLocale:"/",contents:[{header:"Array",slug:"array",content:""}]},{path:"/Basic/algorithm/leetcode/array/SortedSquares.html",title:"Square of a Sorted Array",pathLocale:"/",contents:[{header:"Square of a Sorted Array",slug:"square-of-a-sorted-array",content:`Given an array of integers A sorted in non-decreasing order,retrun an array of the squares of each number,also in sorted non-decreasing order.
Example
Input:[-4,-1,0,3,10]
Output:[0,1,9,16,100] Tips two point Solution there are two solutions.`},{header:"1.Sort",slug:"_1-sort",content:"just get every element square then sort list."},{header:"2.Two Point",slug:"_2-two-point",content:`from the last element to the first.
use two point left and right
judge the left and right values which is bigger
the bigger one sets to the current last element
move point from last one to second last std::vector<int> sortedSquares(std::vector<int> &A)
{ int l = 0; size_t r = A.size(); size_t p = A.size() - 1; std::vector<int> res(A.size()); while (r > l) { int a = A[l] * A[l]; int b = A[r - 1] * A[r - 1]; if (a > b) { res[p] = a; l++; } else { res[p] = b; r--; } p--; } return res;
}`}]},{path:"/GameEngine/Unity/manual/animation/References.html",title:"References",pathLocale:"/",contents:[{header:"References",slug:"references",content:`http://www.sikiedu.com/course/82
https://docs.unity3d.com/Manual/AnimationSection.html
https://learn.unity.com/tutorial/controlling-animation#5c7f8528edbc2a002053b4e4
https://learn.unity.com/tutorial/character-animation
https://learn.unity.com/tutorial/working-with-animations-and-animation-curves#600c8ae0edbc2a001f35f5bc
https://learn.unity.com/tutorial/working-with-animation-clips
https://learn.unity.com/course/introduction-to-3d-animation-systems
https://learn.unity.com/tutorial/baking-animation-for-fbx-export#5d01ba3fedbc2a0021ac984d`}]},{path:"/GameEngine/Unity/manual/editor/References.html",title:"References",pathLocale:"/",contents:[{header:"References",slug:"references",content:"https://www.codenong.com/cs106689329/"}]},{path:"/GameEngine/Unity/manual/normal/Multi-Platform.html",title:"Multi-Platform 跨平台",pathLocale:"/",contents:[{header:"Multi-Platform 跨平台",slug:"multi-platform-跨平台",content:""},{header:"Mono",slug:"mono",content:`把c#转成IL（intermediatelanguage）中间语言，再在各平台上建上专属Mono VM（虚拟机），在VM上面运行IL即可以实现跨平台。
C#为静态语言，IL为动态语言。
难点：
实现各个平台的VM比较复杂，VM官方并没有实现太多。
5.png`},{header:"IL2CPP",slug:"il2cpp",content:`把C#直接转为各个平台原生C++执行，例如安卓使用ndk编译。这其中为了保证c#的一些原生特性，为此也加个一个VM，但是功能比较少，比如实现c#的GC功能等。 使用动态特性
可以使用link.xml文件来做黑名单：
<linker> <assembly fullname="System.Web.Services"> <type fullname="System.Web.Services.Protocols.SoapTypeStubInfo" preserve="all"/> </assembly> <assembly fullname="System"> <type fullname="System.Net.Configuration.WebRequestModuleHandler" preserve="all"/> <type fullname="System.Net.HttpRequestCreator" preserve="all"/> <type fullname="System.Net.FileWebRequestCreator" preserve="all"/> </assembly> <assembly fullname="mscorlib"> <type fullname="System.AppDomain" preserve="fields"/> <type fullname="System.InvalidOperationException" preserve="fields"> <method signature="System.Void .ctor()"/> </type> <type fullname="System.Object" preserve="nothing"> <method name="Finalize"/> </type> </assembly>
</linker> 参考：
https://docs.unity3d.com/Manual/IL2CPP-BytecodeStripping.html
https://zhuanlan.zhihu.com/p/19972689
扩展：.net 的跨平台
https://www.cnblogs.com/artech/p/how-to-cross-platform-03.html`}]},{path:"/GameEngine/Unity/manual/normal/assetbundle.html",title:"AssetBundle",pathLocale:"/",contents:[{header:"AssetBundle",slug:"assetbundle",content:`打包设置中加上BuildAssetBundleOptions.DisableWriteTypeTree
可以试包体内容减少，加载速度减少，同时也减少了内存。 TypeTree是来存储unity版本信息的一个东西，在加上这个的前提是保证一直使用的统一版本unity打包。 打包完了ab，就不能修改c#层的挂在游戏物体上的脚本中的变量的访问权限
一个预制件在异步加载时不要使用同步加载`}]},{path:"/GameEngine/Unity/manual/normal/coroutine.html",title:"Coroutine",pathLocale:"/",contents:[{header:"Coroutine",slug:"coroutine",content:`原理：
一个协成方法会在编译的时候，转化成一个类，在使用的时候生成一个对象，使用 DelayedCallManager 来调用。这个有点像timermanager那种感觉。
因为一个对象所有在协成中的局部变量都会成为对象中的变量，所以说如果协成不使用 yeild return ，也就不会释放该对象。在使用该协成时我们就是在使用的时候new一个即可，不需要保存下来。
尽量减少使用....或者说把多个协成合并起来，
在使用一个monobehavior中使用了StartCoroutine开启一个协成，我们把该脚本disable了是无法关闭协成的，
• 但是我们把该脚本的GameObject设置SetActive（false）时协成会被关掉，
• 当然调用 Destroy该脚本也可以关掉，
• 也可以直接调用StopCoroutine
参考：
https://docs.unity3d.com/Manual/BestPracticeUnderstandingPerformanceInUnity3.html`}]},{path:"/GameEngine/Unity/manual/normal/dll_lib_dev.html",title:"使用C#动态库开发unity游戏",pathLocale:"/",contents:[{header:"使用C#动态库开发unity游戏",slug:"使用c-动态库开发unity游戏",content:`我们不把C#放在unity工程中，单独建立一个c#的解决方案，在这其中分别实现多个项目，每个项目导出一个动态库，也就是dll。
实现： 设置unity官方库引用
调试，自动生成mdb
自动复制dll到unity工程中
加密mono TODO: 编译IL2CPP
加密IL2CPP`},{header:"C#项目props与targets文件",slug:"c-项目props与targets文件",content:""},{header:"props文件",slug:"props文件",content:`需要使用到.props文件，我们有找到这个的UI编辑器，官方文档1,文档2
这个文件就像是全局变量设置，也可以对每个项目单独设置。`},{header:"targets文件",slug:"targets文件",content:`文档，这是一个XML格式的文件让你控制怎么去构建特殊平台的软件，是由MSBuild提供的。这个文件包含了4个部分： properties:一个key/value类型配置项，跟.props文件一样
items:构建系统的输入，通常是文件
tasks:如何创建可由MSBuild用于执行原子构建操作的可执行代码单元
targets:解释如何按特定顺序将任务组合在一起，并使构建过程的各个部分能够在命令行上调用 https://learn.microsoft.com/en-us/visualstudio/msbuild/msbuild-targets?view=vs-2022
我们需要把写好的targets文件，在csproj中导入，这样同样会导入props文件。
<!-- If solution has custom targets file then include it. Used for deployment, defines, etc. -->
<Import Condition="Exists('$(SolutionDir)$(SolutionName).targets')" Project="$(SolutionDir)$(SolutionName).targets" /> 同样也需要在csproj中加入我们自定的Target行为：
<Target Name="BeforeBuild" DependsOnTargets="ProjectValidation" />
<!-- Deploy all required DLL's to Unity Assets folder after build.-->
<Target Name="AfterBuild" DependsOnTargets="UnityDeploy" />`},{header:"添加相对路径unity官方库",slug:"添加相对路径unity官方库",content:`我们可以先在.props中设置我们当前使用的unity版本：
<UnityVersion Condition=" '$(UnityVersion)' == '' ">2020.3.7f1</UnityVersion> 然后找到Unity的安装路径，设置为UnityInstallPath，我们可以从这几个位置去查询Unity程序的位置： 判断UnityInstallPath这个值是否已经被设置，如使用userprops文件
特定版本的安装位置的注册表<UnityInstallPath Condition=" '$(UnityInstallPath)' == '' ">$([MSBuild] ::GetRegistryValueFromView('HKEY_CURRENT_USER\\Software\\Unity Technologies\\Installer\\Unity $(UnityVersion)', 'Location x64', '', RegistryView. Registry64))</UnityInstallPath> 默认Unity Hub的安装路径(C:\\Program Files\\Unity\\Hub\\Editor\\{version})
默认Unity的安装路径(C:\\Program Files\\Unity\\{version})
默认Unity安装的注册表<UnityInstallPath Condition=" '$(UnityInstallPath)' == '' ">$([MSBuild] ::GetRegistryValueFromView('HKEY_CURRENT_USER\\Software\\Unity Technologies\\Installer\\Unity', 'Location x64', '', RegistryView.Registry64))</ UnityInstallPath> 然后就可以设置unity官方库的路径：
<!-- Path to Unity's managed assemblies. -->
<UnityReferencePath>$(UnityInstallPath)\\Editor\\Data\\Managed\\UnityEngine</UnityReferencePath>
<UnityEditorReferencePath>$(UnityInstallPath)\\Editor\\Data\\Managed</UnityEditorReferencePath>
<UnityExtensionsReferencePath>$(UnityInstallPath)\\Editor\\Data\\UnityExtensions</UnityExtensionsReferencePath>`},{header:"生成mdb",slug:"生成mdb",content:`因为unity识别mdb文件来调试，所以我们可以直接使用pdb2mdb工具转换pdb到mdb文件,可以在mono的GitHub找到源代码，在编译即可得到。当然也可以直接在unity的安装目录找到pdb2mdb.exe：
C:\\Program Files\\Unity\\2020.3.7f1\\Editor\\Data\\MonoBleedingEdge\\lib\\mono\\4.5\\pdb2mdb.exe 我们可以直接使用pdb2mdb命令生成mdb：
pdb2mdb.exe unity_dll_lib.dll 不过mono4.5版本的pdb2mdb.exe移动出来单独执行会报错：
Mono pdb to mdb debug symbol store converter
Usage: pdb2mdb assembly 我们可以根据源码的csproj工程文件看到：
<ItemGroup> <ProjectReference Include="../../class/corlib/corlib-net_4_x.csproj"> <Project>{2CA6026B-2DC8-4C4C-A12C-1E8234049DB7}</Project> <Name>corlib-net_4_x</Name> </ProjectReference> <ProjectReference Include="../../class/Mono.Cecil/Mono.Cecil-net_4_x.csproj"> <Project>{2C0D558F-0B38-4691-967E-A910A1B995C1}</Project> <Name>Mono.Cecil-net_4_x</Name> </ProjectReference> <ProjectReference Include="../../class/Mono.CompilerServices.SymbolWriter/Mono.CompilerServices.SymbolWriter-net_4_x.csproj"> <Project>{88177C4B-894F-485D-B95A-44199C06BE9F}</Project> <Name>Mono.CompilerServices.SymbolWriter-net_4_x</Name> </ProjectReference> <ProjectReference Include="../../class/System.Core/System.Core-net_4_x.csproj"> <Project>{359142A1-D80F-401E-AA64-7167C9317649}</Project> <Name>System.Core-net_4_x</Name> </ProjectReference>
</ItemGroup> 他是有几个引用项的，最后验证只需要依赖一下这两个dll： Mono.Cecil.dll（C:\\Program Files\\Unity\\2020.3.7f1\\Editor\\Data\\MonoBleedingEdge\\lib\\mono\\gac\\Mono.Cecil\\0.10.0.0__0738eb9f132ed756\\Mono.Cecil.dll）
Mono.CompilerServices.SymbolWriter.dll(C:\\Program Files\\Unity\\2020.3.7f1\\Editor\\Data\\MonoBleedingEdge\\lib\\mono\\4.5\\Mono.CompilerServices.SymbolWriter.dll) 所以把这三个文件放到同一个目录下就可以了。不过我们发现最新的提交已经把csproj文件删除了:( 。
自动生成mdb文件，只需要在targets文件中加入一个Target的执行命令即可：
<Target Name="DeployBuildMdbs" DependsOnTargets="ProjectValidation"> <!-- Build the .mdb files from the .dll and .pdbs. This is broken out into a separate target because msbuild will actually check the Inputs and Outputs timestamps and skip the step if everything is up-to-date. Using a single <Exec> call so it will run a little faster. --> <PropertyGroup> <ProjectDll>$(ProjectDir)$(OutputPath)$(ProjectName).dll</ProjectDll> <ProjectMdb>$(ProjectDll).mdb</ProjectMdb> </PropertyGroup> <Exec Command="$(MonoMdbGenerator) $(ProjectDll) &amp; echo Generating $(ProjectMdb)"/>
</Target>`},{header:"export dll",slug:"export-dll",content:`使用vs到处
https://blog.csdn.net/qq_15267341/article/details/51747000?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-5.control&dist_request_id=&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-5.control`},{header:"dnspy",slug:"dnspy",content:`https://github.com/dnSpy/dnSpy
使用dnspy修改了源码，先编译了，需要再保存一下`},{header:"调试dll",slug:"调试dll",content:`使用vs调试需要安装vs 插件。这里值得注意的是需要设置unity调式的话需要把dll的Target framework设置成unity版本的，或者4.6也可以
文档：
https://docs.microsoft.com/zh-cn/previous-versions/visualstudio/visual-studio-2015/cross-platform/using-visual-studio-tools-for-unity?view=vs-2015&viewFallbackFrom=vs-2019`},{header:"加密",slug:"加密",content:`我们可以在打包后，对dll做加密：
private static void EncryptAssemblyCSharp() { string acsPath = Application.dataPath + "/../Build/unity_dll_Data/Managed/Sample.dll"; int offset = Path.GetFileName(acsPath).Length; byte[] dllBytes = File.ReadAllBytes(acsPath); byte[] newBytes = new byte[dllBytes.Length + offset]; for (int i = 0; i < offset; i++) { Buffer.SetByte(newBytes, i, (byte)UnityEngine.Random.Range(byte.MinValue, byte.MaxValue)); } Buffer.BlockCopy(dllBytes, 0, newBytes, offset, dllBytes.Length); File.WriteAllBytes(acsPath, newBytes); Debug.Log("Encrypt Assembly CSharp Completed!"); } 再对mono加载时做一定的修改可以看这里`},{header:"tips",slug:"tips",content:"在 vs中查看Modules中对应的dll文件的Syboml是否加载进来，就可以看到是否可以调式"}]},{path:"/GameEngine/Unity/manual/normal/model_setting.html",title:"模型设置",pathLocale:"/",contents:[{header:"模型设置",slug:"模型设置",content:`模型导入Model设置：Read/Write Enabled - 关闭
这个开关是控制我们在运行游戏是去改变模型的mesh数据同步到GPU内存中，并是否保存在GUP内存中，或者去读取mesh中的数据。在大多数情况下设置为false，除了以下情况设置为true： 使用了StaticBatchingUtility.Combine() 合并mesh的时候
使用Mesh去烘焙成NavMesh
使用了Mesh Collider并且transform拥有负数的大小（如：scale（-1,1,1））
使用了Mesh Collider并且对transform做了裁剪和扭曲
使用了Mesh Collider并且 Mesh Collider 的 Cooking 设置不是默认值 原理：
如果勾选了这个选项，那么这个FBX是会在内存中存在一个拷贝，硬盘上存在一个么。要是不勾选的话，是不是只有硬盘中有一份，内存中没有了。这个解释有待考证
需要打开：Optimize Game Object
少一些节点，会在加载速度有所提升。在动画机update上也会有所减少消耗
参考：
https://zhuanlan.zhihu.com/p/27378492`}]},{path:"/GameEngine/Unity/manual/normal/mono.html",title:"Mono",pathLocale:"/",contents:[{header:"Mono",slug:"mono",content:"Github:https://github.com/BanMing/mono"},{header:"编译",slug:"编译",content:`不使用cygwin，直接使用vs2017以上的版本
https://www.mono-project.com/docs/compiling-mono/windows/no-cygwin/
注意：需要使用vs打开一下，并且更新一下Build target。
msbuild msvc\\mono.sln /p:Platform=x64 /p:Configuration=Release /p:MONO_TARGET_GC=sgen 编译32位-bdwgc
msbuild msvc\\mono.sln /p:Platform=Win32 /p:Configuration=Release /p:MONO_TARGET_GC=bdwgc 编译64位-bdwgc
msbuild msvc\\mono.sln /p:Platform=x64 /p:Configuration=Release /p:MONO_TARGET_GC=bdwgc`},{header:"修改读取dll",slug:"修改读取dll",content:`/** * mono_image_open_from_data_with_name: */
MonoImage *
mono_image_open_from_data_with_name (char *data, guint32 data_len, gboolean need_copy, MonoImageOpenStatus *status, gboolean refonly, const char *name)
{ if (strstr (name, "Sample.dll") != NULL) { guint32 offset = (guint32)strlen (name); memcpy (data, data + offset, data_len - offset); } return mono_image_open_from_data_internal (data, data_len, need_copy, status, refonly, FALSE, name);
}`}]},{path:"/GameEngine/Unity/manual/normal/sound_setting.html",title:"音效设置",pathLocale:"/",contents:[{header:"音效设置",slug:"音效设置",content:""},{header:"设置界面",slug:"设置界面",content:`这里使用一个2.4mb背景音乐做参数测试 Force To Mono : 强制把多声道文件设置为单声道，使用此选项可降低内存的的占用。（音质会受影响，打开后大小为0.6mb） Load In Background: 后台加载，这里做了个测试： 以流的方式加载，打开选项，内存：202kb
以流的方式加载，关闭选项，内存：192kb 是不是意味着打开后台加载，会造成内存的多占用。 Ambisonic:3d环绕音响 Load Type : 记载方式（测试在开启Force To Mono） Streaming: 流的方式加载，内存占用少（200kb），Streaming CPU占用大，适用于大于200kb的文件。 Decompress On Load: 加载时就解压，内存占用极大（6.5mb），CPU占用极小 Compress In Memory：在内存中解压，内存占用大（0.6mb），DSP CPU占用大，加载速度极快 Preload Audio Data：在场景加载时就加载音效 这里有个问题：是打开了这个，是否是在加载任何场景都会加载该音效？还是只加载场景中用到的打了这个音效的资源，但是如果加载场景，场景会自动加载场景中所有资源，难道是提前一些？
测试打开，不会再任何场景加载时加载打开的音效 Compression Format: 压缩方式 PCM:无损
Vorbis:压缩为ogg，压缩最小，一般用这个。
ADPCM:稍微压缩，是pcm压缩率的3.5倍。`},{header:"加载速度对比",slug:"加载速度对比",content:`Load in Background
格式设置
速度倍数 开
Compressed + Vorbis
1倍 开
其他格式 + Vorbis
1倍 开
所有格 + PCM
5倍 关
Compressed + Vorbis
1倍 关
其他格式 + Vorbis
1倍 关
所有格 + PCM
9倍`},{header:"内存占用对比",slug:"内存占用对比",content:"2.png"},{header:"参考测试数据",slug:"参考测试数据",content:"3.png"},{header:"测试数据：12个背景音乐同事播放",slug:"测试数据-12个背景音乐同事播放",content:"4.png"},{header:"总结",slug:"总结",content:`格式：mp3，在苹果设备上有优化，这里格式使用wav也可以，反而会更好些，因为unity在打包时，都会重新设置格式。包括图片也是。
Load In Background 可以用在背景音乐
Compression Format 使用Vorbis就可以，Quality选项调整到50%
频繁使用的音效：Decompress On Load
都可以选择上Force To Mono
在手机上出现了声音延迟的情况，在查阅逻辑无误后，可修改AudioSetting中的DSP Buffer Size。这个是来控制传输音效数据到cpu的一个桶，如果出现延迟就是这个桶的值太大。如果过小的话，就会出现cpu负担。有点像drawcall。`}]},{path:"/GameEngine/Unity/manual/optimize/DynamicGraphics.html",title:"Dynamic Graphics",pathLocale:"/",contents:[{header:"Dynamic Graphics",slug:"dynamic-graphics",content:""}]},{path:"/GameEngine/Unity/manual/optimize/MemoryManagement.html",title:"Masterful Memory Management",pathLocale:"/",contents:[{header:"Masterful Memory Management",slug:"masterful-memory-management",content:""},{header:"Overview of the Mono platform",slug:"overview-of-the-mono-platform",content:"C#为托管语言，也就是托管代码，意思是他是运行在通用语言运行（CLR）环境中的，而不是编译他到指定的操作系统中去运行。"},{header:"Native and managed memory domains",slug:"native-and-managed-memory-domains",content:`Unity 有三个内存分区： The managed domain: 托管分区，也就是Mono使用到的那部分，这里会使用垃圾收集（GC）来自动管理
The native domain: 原生分区，也就是内置的一些系统，如声音，贴图，物理这些，是由c++使用的。
The external libraries：外部库，如图形：DirectX 和 OpenGL。 托管区域还有一个就是原生区和托管区之间的交互，在交互时，需要一定的内存空间来处理，这可能会对我们的游戏造成相当大的性能影响。`},{header:"The statck",slug:"the-statck",content:`栈是内存中一个特殊空间，分配给小的，短生命周期的数据，这些数据会自动回收当他们离开他们所在的范围时。这些数据都存在栈的数据结构中，读取和存储的方式就是后进后出。
栈包含了我们声明的任何局部变量，并在调用函数时处理函数的加载和卸载。这些函数调用通过所谓的调用栈进行扩展和收缩。当调用栈完成当前函数时，它将跳回到调用栈上的前一点，并从他停止的地方继续。
前一个内存分配的开始总是已知的，没有理由执行任何清理操作，因为任何新的分配可以简单地覆盖旧的数据。因此，栈是相对快速和有效的。
栈一般很小，通常是MB。造成栈溢出一般都是分配空间超过栈的空间： 异常大的调用栈，如无限循环
有一个超级大的数字，越界 尽管栈的规模相对较小，但很少引起栈溢出。`},{header:"The heap",slug:"the-heap",content:`堆表示所有剩余的内存空间，它用于绝大多数内存分配。当我们的需要让一个内存分配更加的持久，我们就需要分配到堆中，还有就是数据类型过大，也是需要分配到堆中。堆和栈在物理上都是在RAM中的。
在本地代码（如C++）的编写中，我们需要手动对堆内存做管理，申请了堆内存，就一定需要手动释放该内存，不然会造成内存过大或者内存泄露。
在托管代码中，对于堆内存是通过GC来自动管理。Mono在unity程序启动时，会想操作系统申请一块堆内存空间来给我们写的C#代码使用，也叫做托管堆。堆内存开始会很小，小于1MB。会随着我们在脚本中的使用增加。`},{header:"Garbage collection",slug:"garbage-collection",content:`GC可以让我们安全使用托管内存，让一些我们不再使用的对象回收。比如我们在销毁GameObject后，GC会标记那块内存空间，且并不会立即清空该内存空间，会在内存需要时才会清空。
当申请新的内存时，如果托管内存是足够的，直接分配。反之，就会先触发GC去扫描当前在内存的所有对象，找到那些没有在使用了，并对其清空。
Mono中的GC在Unity中使用的是追踪类型，策略是标记和扫描（Mark-and-Sweep）。这个算法大致的流程如下： 每分配一个对象时给他一个额外字节，来存储一个标准位，这个标志位代表这该对象是否没标记。这个 标志 开始设置为false，表示尚未标记。当 GC开始时，这个标志会标记为true来表示程序仍然可以访问该对象。
遍历所有对象，通过标记来判断当前对象的空间是否应该被销毁。把所有未标记的对象都清空他们的空间。
如果GC后空间足够给新的对象分配，就把空间给新对象。反之，则需要向操作系统申请新的托管堆内存`},{header:"Memory fragmentation",slug:"memory-fragmentation",content:`所有的对象在清空内存空间时，这个清空顺序肯跟我们在申请时的顺序不同且每个对象使用的空间也不同，所以就会产生内存碎片化的问题。因为内存是连续性的，就会出现一小格空的，然后一大格被占用。这样出现小空格很难分配给新的对象。 我们可以简单使用四个步骤来解释这一问题： 开始有一个空的堆内存空间
分配4格对象A,B,C,D，每个对象占用64-bytes的大小
过一段时间A和C释放128-bytes的空间
这时，我们尝试分配一个新的128-bytes大小的空间。因为A和C释放的空间并不连续，所以我们需要新申请一个空间，不能达到复用的效果。 这样的话我们就需要等到下一个申请64-bytes大小的空间或者小于时，才能对A或C的空间复用。这就会出现两个问题： 这造成内存复用率不高。每次都需要GC后发现没有空间适合，就需要新的申请堆内存。
这会在分配新空间时，花费更多时间去找到适合的内存。 所以申请新的空间，最坏的结果会让CPU多工作很多步，如下： 判断当前堆内存是否有一个连续且大小合适的空间给新的对象
如果没有，遍历所有直接和间接的引用，将它们连接的所有内容标记为可访问
再次遍历这些引用，标记未标记的对象以进行释放
遍历所有标记的对象，检查释放其中一些对象是否会为新对象创建足够的连续空间
如果不能，就需要向操作系统申请新的堆内存块
然后分配新的空间给新对象 这对于玩家直接的影响就是游戏会卡顿，比如说一些粒子系统，角色进入一个新的场景。`},{header:"Threaded garbage collection",slug:"threaded-garbage-collection",content:`GC一般会执行再两个线程上： 主线程
最终调用线程
这过程都不是立即释放内存空间，可能会等几秒`},{header:"Code compilation",slug:"code-compilation",content:`我们在写了C#代码后，它会被自动的编译到Unity编辑器下。C#并没有直接编译到机器码，不像C++一样使用静态编译器转化为机器码。
我们的代码被转化为Common Intermediate Language(CIL)，它是机器码之上的抽象。属于是一种中间语言，它和Java的字节码相似，CPU并不能直接运行这个代码。
在运行是，中间代码运行在Mono的虚拟机上，虚拟机可以使同样的代码运行在不同的平台上。
在通用语言运行环境中（CLR），中间语言（CIL）是需要编译成本地代码，从而使平台的CPU能够运行编写的指令，这里由两种方式： Ahead-Of-Time（AOT）：提前编译，构建时编译或者软件初始化时编译。所以会再运行时快一些。
Just-In-Time（JIT）：运行时在调用前，在一个独立线程中编译。所以会花一些时间编译，但是一旦编译过后的模块，后续再次调用就不需要再编译。 JIT编译必须快速，所以无法像静态的AOT编译器一样使用很多优化的方式。Mono有些平台只支持AOT而有些平台只支持JIT，可以查看这个文档：https://docs.unity3d.com/Manual/ScriptingRestrictions.html`},{header:"Building a project using IL2CPP",slug:"building-a-project-using-il2cpp",content:`IL2CPP是一个脚本后台，用于把Mono的CIL转化为对应平台的C++代码。这可以提高运行效率。IL2CPP提供了自带的AOT编译器和一个虚拟机，同时还可以自定义一些子系统，如GC和编译过程。
Unity选择使用IL2CPP的原因：https://blog.unity.com/technology/the-future-of-scripting-in-unity
Unity中的IL2CPP具体可以查看文档：https://docs.unity3d.com/Manual/IL2CPP.html`},{header:"How to profile memory issues",slug:"how-to-profile-memory-issues",content:""},{header:"Implement various memory-related performance enhancements",slug:"implement-various-memory-related-performance-enhancements",content:""},{header:"Minimizing garbage collection",slug:"minimizing-garbage-collection",content:""},{header:"Profiling memory consumption",slug:"profiling-memory-consumption",content:`使用Profiler.GetRuntimeMenorySize()可以获得本地代码分配的内存。
使用Profiler.GetMonoHeapSize()和Profiler.GetMonoUsedSize()获取托管堆中内存大小和托管代码已经使用的代码。`},{header:"Profiling memory efficiency",slug:"profiling-memory-efficiency",content:"我们衡量内存管理是否是良好时，就去观察GC的行为。GC的运行的次数越多，就会产生更多浪费和性能更加糟糕。"},{header:"Garbage collection tactics",slug:"garbage-collection-tactics",content:`一个最小化垃圾回收问题的策略是在我们确信玩家不会注意到的时候手动调用GC来隐藏垃圾回收。可以使用System.GC.Collect()。
手动调用这个方法最好的时机，是场景切换，游戏暂停，或者是玩家不经意间。我们也可以使用Profiler.GetMonoUsedSize()和Profiler.GetMonoHeapSize()这两个方法来判断内存的使用程度，来手动调用GC。
我们也可以让在销毁后需要立即清空内存的对象继承于IDiposable，我们可以强制控制这个对象的内存清空。在Unity引擎中也有很多继承该接口的类型：NetworkConnection，UnityWebRequest，UploadHandler...`},{header:"Manual JIT compilation",slug:"manual-jit-compilation",content:`如果JIT编译会导致运行时性能损失，实际上可以通过反射在任何时候强制对方法进行JIT编译。例如：
var method = typeof(MyComponent).GetMethod("MethodName");
if(method != null)
{ method.MethodHandle.GetFunctionPointer(); Debug.Log("JIT compilation complete!");
} 但是反射的使用同样是很消耗性能，所以这种方式能不用就不用。除非我们已经确定说当前性能的问题就是出现在编译上。`},{header:"Using value types and reference types properly",slug:"using-value-types-and-reference-types-properly",content:`一般而言，引用类型是分配在堆上，值类型是分配在栈上。但是当一个值类型在一个引用类型内部时，比如一个数组或者一个类，这也暗示着这个类型数据过大对于栈来说，或者需要更长存在时间，所以这种情况下久会被分配到堆内中，与它拥有的引用类型绑定在一起。
在栈里，旧数据是被新数据覆盖的。并没有新创建数据，所以栈里并不需要GC。
以下有几个典型的例子：
public class TestComponent
{ void TestFunction() { int data = 5; // allocated on the statck DoSomething(data); }// integer is dealloacted from the stack here
} public class TestComponent : MonoBehaviour
{ int _data = 5; // allocated on the heap, deallocated when the component is destroyed void TestFunction() { DoSomething(data); }
} public class TestData
{ public int data = 5;
} public class TestComponent
{ void TestFunction() { TestData dataObj = new TestData(); // allocated on the heap DoSomething(data); }// dataObj is not immediately deallocated here // but it will become a candidate during the next GC sweep
} public class TestComponent
{ private TestData _testDataObj; void TestFunction() { TestData dataObj = new TestData(); // allocated on the heap DoSomething(data); } void DoSomething(TestData dataObj) { _testDataObj = dataObj;// a new reference created! // The referenced object will now be marked during Mark-and-Sweep }
} public class TestClass
{ private int[] _intArray = new int[1000];// Reference type, full of Value types void StoreANumber(int num) { _intArray[0] = num; // copy a Value } }`},{header:"Pass by value and by reference",slug:"pass-by-value-and-by-reference",content:"传递引用只是复制了一个指向值，传递值是需要复制所有值。"},{header:"Structs are value types",slug:"structs-are-value-types",content:"当一个数据结构比较大时，同时它传递超过5个函数时，我们需要考虑使用ref关键字来减少复制。"},{header:"Arrays are reference types",slug:"arrays-are-reference-types",content:`当我们创建一个引用类型的数据数组时，每个数据真实的值都在堆上，数组中存的只是一个地址。
当我们创建一个值类型的数据数组时，我们只是把一个值类型的列表打包放在堆上。`},{header:"Using strings responsibly",slug:"using-strings-responsibly",content:`字符串是引用类型，但是特殊的是它是不能被修改的，当它被分配后。因为字符串就是字符的数组，这也暗示着他需要一个连续的内存。所以我们在改变一个字符串的值时，是在堆中新申请一个空间，然后把这空间替换到字符串上去。所以老的字符串空间就没有被引用到了，这里就会等待GC扫描到它，然后再清理。下面有一个堆字符串特殊性的例子简介：
void TestFunction()
{ string testString = "Hello"; DoSomething(testString); Debug.Log(testString);
} void DoSomething(string localString)
{ localString = "World";
} 这里按照引用类型来说，这里输出的是World，但是实际上这里最终输出的是Hello。这就是字符串特殊之处，因为字符串是不可修改的，当我们修改它时，需要新分配一个含有World的字符串。这个值就会替换到localString的值。Hello的字符串的引用数变成了1。testString就不会改变。所以最终的输出是Hello。
StringBuilder 是在最开始就是申请一个长的数组，这样来处理字符串就可以不需要新区申请字符串，但是如果字符串过长，超过最开始申请的数组，也是需要新申请的。`},{header:"Boxing",slug:"boxing",content:"关于装箱，值得注意的是，把值类型的变量用作引用类型，装箱仅仅是创建了一个外壳来存放这个值类型，这个外壳可以认为是引用类型。这个行为会造成堆内存分配的，所以我们需要尽量避免。"},{header:"The importance of data layout",slug:"the-importance-of-data-layout",content:`在取数据时，减少查命中失败是一个很好的优化方式，这意味着一系列的数据都在连续的内存中，这样我们在取时就会很快。这同样对GC也很有效果，因为在检测数据时，是需要遍历所有数据的，所以这样在遍历时就更快。本质上来说，我们希望大块的引用类型的数据和大块的值类型的数据分开。就算只有一个引用类型在值类型中，那么这个值类型的所有参数都需要被验证。比如说一个数据结构：
public struct MyStruct
{ int myInt; float myFloat; bool myBool; string myString;
}
MyStruct [] arraryOfStructs = new MyStruct[1000]; 这里我们就需要额外去检测3000次，也就是那3个基础类型。如果我们换成这样写：
int[] myInts = new int[1000];
float[] myFloats = new float[1000];
bool[] myBoolss = new bool[1000];
string[] myStrings = new string[1000]; 这样的GC就会快于上一种，这里只需要扫描字符串。`},{header:"Arrays from the Unity API",slug:"arrays-from-the-unity-api",content:`在unity的API中有的方法也会在堆中分配内存，比如：
GetComponents<T>(); // (T[])
Mesh.vertices; // (Vector3[])
Camera.allCameras; // (Camera[]) 这些方法我们需要避免调用，最多调用一次即可。`},{header:"Using InstanceIDs for dictionary keys",slug:"using-instanceids-for-dictionary-keys",content:"我们可以使用Object.GetInstanceID()这个方法来区分对象，这种方式在使用Mono时会比IL2CPP的消耗的大一些。因为Mono调用一些线程不安全的方法，同时Mono编译器不会优化循环。"},{header:"foreach loops",slug:"foreach-loops",content:"在Unity 2018.1 的版本前使用foreach会造成大量的堆内存分配，在之后的版本就修复。这个问题的核心还是在于GetEnumerator这个方法的实现。现在还是会有堆内存的分配，不过还好，都是复用的Enumerator对于消耗来说是比较小的。全部替换为for循环也是不太好的。"},{header:"Coroutines",slug:"coroutines",content:"在开启一个协成时，会分配小部分内存去启动这个协成。如果内存和GC是一个严重问题对于项目，我们就需要减少使用短周期的协成和调用StartCoroutine很多次。"},{header:"Closures",slug:"closures",content:`关于闭包和匿名函数的区别如下例子：
System.Func<int,int> anon = (x) => {return x;};
int result = anon(5); 以上这个例子只是单纯的匿名函数，并不是闭包，这个跟正常的本地函数是一样的。
int i = 1;
System.Func<int,int> anon = (x) => {return x + i;};
int result = anon(5); 以上这个例子就是闭包了，因为在匿名函数中使用了本地变量。编译器会申明一个自定义的类来引用环境以便于可以调用i这个数据，在运行中时，在堆中创建一个对象，这个对象会传递给匿名方法。使用完了也会销毁，所以这里就会造成GC。所以我们一般不使用闭包，使用委托对象来代替。`},{header:"The .NET library functions",slug:"the-net-library-functions",content:"有两个方法我们应该避免使用LINQ和regular expressions，他们的消耗都挺高的。"},{header:"Object and Perfab pooling",slug:"object-and-perfab-pooling",content:`可以有三种类型： C#对象
GameObject
Components`}]},{path:"/GameEngine/Unity/manual/optimize/ProfileAnalysis.html",title:"Final thoughts on profiling and analysis",pathLocale:"/",contents:[{header:"Final thoughts on profiling and analysis",slug:"final-thoughts-on-profiling-and-analysis",content:""},{header:"Understanding the tool",slug:"understanding-the-tool",content:"并不是峰值就是问题点，因为Unity记录的数据只是300帧内的，是一个相对的数据。这个峰值只是在提示我们出现了问题。"},{header:"Reducing noise",slug:"reducing-noise",content:"数据越多我们更加难得去找到问题，所以我们需要减少数量去记录。与此同时，我们也可以使用排除法，就是一步一步的关闭一些系统，来做profile，然后做对比。"},{header:"Focusing on the issue",slug:"focusing-on-the-issue",content:"专注是一种不被无关紧要的任务和漫无目的的追逐分心的技能"}]},{path:"/GameEngine/Unity/manual/optimize/References.html",title:"References",pathLocale:"/",contents:[{header:"References",slug:"references",content:`https://resources.unity.com/optimizing-your-game-with-unity
https://learn.unity.com/project/optimizing-for-performance-2019-3
https://blog.unity.com/technology/optimize-your-mobile-game-performance-tips-on-profiling-memory-and-code-architecture
https://unity.com/how-to/best-practices-performance-optimization-unity
https://unity.com/how-to/advanced/optimize-lighting-mobile-games
https://blog.unity.com/technology/optimize-your-mobile-game-performance-tips-on-profiling-memory-and-code-architecture
手游性能原理篇 - 游戏狗的文章 - 知乎
https://zhuanlan.zhihu.com/p/543466481`}]},{path:"/GameEngine/Unity/manual/optimize/optimizing_ugui.html",title:"UGUI 优化",pathLocale:"/",contents:[{header:"UGUI 优化",slug:"ugui-优化",content:"https://blog.unity.com/technology/optimize-your-mobile-game-performance-get-expert-tips-on-physics-ui-and-audio-settings"}]},{path:"/GameEngine/Unity/manual/optimize/scripting.html",title:"Scritping Strategies",pathLocale:"/",contents:[{header:"Scritping Strategies",slug:"scritping-strategies",content:""},{header:"Obtaining components using the fastest mehod",slug:"obtaining-components-using-the-fastest-mehod",content:`最好的方式获得组件：
GetComponent<T>()`},{header:"Removing empty callback definitions",slug:"removing-empty-callback-definitions",content:`移除MonoBehaviour中空的生命周期函数：
void Start();
void Update();
void OnGUI();
void LateUpdate();
void FixedUpdate(); 可以使用正则表达式查找：
void\\s*Update\\s*?\\(s*?\\)\\s*?\\n*?\\{\\n*?\\s*?\\}`},{header:"Caching component referemces",slug:"caching-component-referemces",content:"使用少量的内存换取CPU的开销。"},{header:"Shaing calculation output",slug:"shaing-calculation-output",content:"存放一些可能会公用的计算结果，这样我们就不需要重复计算，如AI中的寻路。"},{header:"Update,coroutines,and InvokeRepeating",slug:"update-coroutines-and-invokerepeating",content:`我们在计算一些数据的次数比使用到这些数据的次数多的时候，就需要对update做一定的优化。
比如：
void Update()
{ ProcessAI();
} 我们可能不需要每一帧去调用这个方法，所以可以使用隔几秒调用。
float _delayTime = 0.3f;
float _curTime;
void Update()
{ _curTime += Time.deltaTime; if(_curTime > _delayTime) { _curTime = 0; ProcessAI(); }
} 这种做法，就会出现空的Update回调。我们可以使用到另外两种做法： Corotines
InvokeRepeating 有一个性能测试对比空的Update,Coroutines,InvokeRepeating： 1000个空的Update的耗时1.1毫秒
1000个协成使用的WaitForEndOfFrame的耗时是2.9毫秒
1000个InvokeRepeating的耗时是2.6毫秒 协成还有很多问题： 内存开销会大一些
运行会受到GameObject的激活`},{header:"Faster GameObject null reference checks",slug:"faster-gameobject-null-reference-checks",content:`一些不必要的GameObject判空会造成性能的消耗。因为GameObject和Monobehaviours这两个属于是两个特殊的对象，他们在内存中有两种表示形式：一个存在于管理我们编写的C#代码的统一系统所管理的内存中（托管代码），而另一个则单独的操作于不同的内存空间（本地代码）。数据可以在这两个空间之间移动，但是每一次移动会造成额外的CPU消耗和内存的分配。
我们可以改使用：
if (gameObject != null){ // do stuff with gameObject
} if (!System.Object.ReferenceEquals(gameObject,null)){ // do stuff with gameObject
} 这个也可以应该到其他的Unity Objects，这个的影响其实不太大。`},{header:"Avoid retrieving string properties from GameObjects",slug:"avoid-retrieving-string-properties-from-gameobjects",content:`不要使用tag和name来判断一个游戏物体这会造成多余的内存分配。我们可以通过组件来区分游戏物体。
如果一定要是使用tag我们可以使用CompareTag这个方法会好一些。`},{header:"Using appropriate data structures",slug:"using-appropriate-data-structures",content:`字典与列表的区别： 字典在取和插入时，可以很快。遍历可能就不是那么快，取决于内存分配
列表恰恰相反`},{header:"Avoiding re-parenting transforms at runtime",slug:"avoiding-re-parenting-transforms-at-runtime",content:`每个Transform都会有一个层级结构，使用一个列表来存储子物体。若果当前Transform的这个列表长度达到上限了，我们就需要新申请空间。所以说我们可以在游戏物体实例化时就对这个游戏物体的父物体做指定。
GameObject.Instantiate(....,parent); 同样我们也可以早早的定义好没有子物体的游戏物体的Transform.hierarchyCapacity`},{header:"Considering caching transform changes",slug:"considering-caching-transform-changes",content:`有两种优化这里： 能直接修改local本地的数据就修改本地的数据，这样省去了矩阵的转换，世界坐标到本地坐标
缓存本地transform的变化，在FixedUpdate中修改。因为在修改transform属性时，会通知其他的组件，这样就会一直通知。`},{header:"Avoiding Find() and SendMessage() at runtime",slug:"avoiding-find-and-sendmessage-at-runtime",content:`消耗非常之大，我们可以使用一下方案来解决： Assign references to preexisting objets：在组件中直接引用其他对象，并在编辑器下对其赋值
Static classes：构造方法是在第一次调用该类时调用
Singleton components：file access,downloads,data parsing, and messaging.
A global messaging system`},{header:"Disabling unused scripts and objects",slug:"disabling-unused-scripts-and-objects",content:"场景足够大时，物体多就会导致性能拖拉，我们可以把远处或者不必要的物体或脚本关闭。"},{header:"Disabling objects by visibility",slug:"disabling-objects-by-visibility",content:`可以使用两个回调来知道我们的游戏物体是否被相机看到：
void OnBecameVisible() {gameObject.SetActive(true);}
void OnBecameInvisible() {gameObject.SetActive(false);} 但是触发这个回调必须要有Render相关的组件才行，如：Skinned Mesh Renderer,Mesh Renderer 等。`},{header:"Disabling objects by distance",slug:"disabling-objects-by-distance",content:"距离远的物体可以关闭"},{header:"Using distance-squared over distance",slug:"using-distance-squared-over-distance",content:`使用开方消耗极大，我们使用sqrMagnitude来代替，例如：
float distanceSqrd = (transform.position - other.transform.position).sqrMagnitude;
if(distanceSqrd < (targetDistance * targetDistance))
{ // do studff
}`},{header:"Minimizing deserialization behavior",slug:"minimizing-deserialization-behavior",content:`Unity的序列化系统主要是场景，预制件，ScriptableObjects和各种资源类型。它们是以文本文件的形式存在磁盘上的，使用一种标记语言的格式存储的（Yet Another Markup Language - YAML），可以反序列化回对象。
其实反序列化这个过程对性能有一个较大的开销，过程也是相对比较慢。比如说一个预制件拥有很深的层级，预制件有很多空的GameObject，并且每一个GameObject至少有一个Transform的组件。这种情况最多出现在UI的预制件中。
加载一个大预制件时，可能会造成CPU的峰值，同时也增加了加载时间。更重要的是，它会引起帧率下降。`},{header:"Reducing serialized object size",slug:"reducing-serialized-object-size",content:"我们的目标应该是使序列化的对象尽可能小，或者将他们分割成更小的数据块，后面使用时，可以把他们组合起来。"},{header:"Loading serialized objects asynchronously",slug:"loading-serialized-objects-asynchronously",content:"这对于游戏开始就需要使用到的物体，不太适用于异步加载。"},{header:"Keeping previously loaded serialized objects in memory",slug:"keeping-previously-loaded-serialized-objects-in-memory",content:""},{header:"Moving common data into ScriptableObjects",slug:"moving-common-data-into-scriptableobjects",content:"直接使用这个可以节省反序列化后的赋值。"},{header:"Loading scenes additively and async hronously",slug:"loading-scenes-additively-and-async-hronously",content:""},{header:"Creating a custom Update() layer",slug:"creating-a-custom-update-layer",content:"使用一个Update方法代替多个Update方法，编写一个OnUpdate的接口，然后把所有继承该接口的对象，都放在唯一的一个Update中去调用。"}]},{path:"/GameEngine/Unity/manual/reader/commandbuffer.html",title:"Command Buffers",pathLocale:"/",contents:[{header:"Command Buffers",slug:"command-buffers",content:`这是一个可以自己定义设置额外渲染命令的API，我们可以在渲染前完成一些操作，感觉有点像局部后处理，可以用到： 模糊折射
延迟灯光
延迟贴花 这个文章非常详细：
https://blog.unity.com/technology/extending-unity-5-rendering-pipeline-command-buffers
其中还有实例代码：https://blog-api.unity.com/sites/default/files/2015/02/RenderingCommandBuffers50b22.zip。
文档：
https://docs.unity3d.com/2021.3/Documentation/Manual/GraphicsCommandBuffers.html
https://docs.unity3d.com/2021.3/Documentation/ScriptReference/Rendering.CommandBuffer.html`}]},{path:"/GameEngine/Unity/manual/tools/encryption.html",title:"加密",pathLocale:"/",contents:[{header:"加密",slug:"加密",content:""},{header:"Mono",slug:"mono",content:`https://titanwolf.org/Network/Articles/Article?AID=1191a414-b11f-4cf5-b48b-d0ff0289ed1b
https://blog.csdn.net/weixin_39186306/article/details/104691632`},{header:"IL2Cpp",slug:"il2cpp",content:"https://blog.csdn.net/ZhangDi2017/article/details/93502914"}]},{path:"/GameEngine/Unity/manual/tools/remote_debug.html",title:"远程调试",pathLocale:"/",contents:[{header:"远程调试",slug:"远程调试",content:`参数配置需要这两个：
UnityEditor.BuildOptions： BuildOptions.Development | BuildOptions.AllowDebugging 查看调试端口，可以在缓存目录看Player.log文件`},{header:"参考",slug:"参考",content:`https://docs.unity3d.com/ScriptReference/BuildOptions.html
https://docs.unity3d.com/Manual/EditorCommandLineArguments.html
https://docs.unity3d.com/Manual/UnityCloudBuildDevelopmentBuilds.html`}]},{path:"/404.html",title:"",pathLocale:"/",contents:[{header:"",slug:"",content:"404 Not Found"}]},{path:"/AI/",title:"AI",pathLocale:"/",contents:[]},{path:"/Animation/",title:"Animation",pathLocale:"/",contents:[]},{path:"/Basic/",title:"Basic",pathLocale:"/",contents:[]},{path:"/Career/",title:"Career",pathLocale:"/",contents:[]},{path:"/Playing/",title:"Playing",pathLocale:"/",contents:[]},{path:"/Tools/",title:"Tools",pathLocale:"/",contents:[]},{path:"/Web/",title:"Web",pathLocale:"/",contents:[]},{path:"/Animation/CharacterAnimation/",title:"Character Animation",pathLocale:"/",contents:[]},{path:"/Basic/math/",title:"Math",pathLocale:"/",contents:[]},{path:"/GameEngine/Godot/",title:"Godot",pathLocale:"/",contents:[]},{path:"/GameEngine/",title:"Game Engine",pathLocale:"/",contents:[]},{path:"/GameEngine/Unreal/",title:"Unreal",pathLocale:"/",contents:[]},{path:"/Career/interview/",title:"Interview",pathLocale:"/",contents:[]},{path:"/Gameplay/",title:"Gameplay",pathLocale:"/",contents:[]},{path:"/Gameplay/ECS/",title:"ECS",pathLocale:"/",contents:[]},{path:"/Gameplay/network/",title:"Network",pathLocale:"/",contents:[]},{path:"/Graphic/DirectX/",title:"Direct X",pathLocale:"/",contents:[]},{path:"/Graphic/basic/",title:"Basic",pathLocale:"/",contents:[]},{path:"/Graphic/bgfx/",title:"Bgfx",pathLocale:"/",contents:[]},{path:"/Web/Project/",title:"Project",pathLocale:"/",contents:[]},{path:"/Basic/language/Golang/",title:"Golang",pathLocale:"/",contents:[]},{path:"/Basic/language/Java/",title:"Java",pathLocale:"/",contents:[]},{path:"/GameEngine/Unity/manual/",title:"Manual",pathLocale:"/",contents:[]},{path:"/GameEngine/Unity/",title:"Unity",pathLocale:"/",contents:[]},{path:"/GameEngine/Unity/somecode/",title:"Somecode",pathLocale:"/",contents:[]},{path:"/GameEngine/Unreal/animation/",title:"Animation",pathLocale:"/",contents:[]},{path:"/GameEngine/Unreal/course/",title:"Course",pathLocale:"/",contents:[]},{path:"/GameEngine/Unreal/manual/",title:"Manual",pathLocale:"/",contents:[]},{path:"/GameEngine/Unreal/online/",title:"Online",pathLocale:"/",contents:[]},{path:"/GameEngine/Unreal/optimize/",title:"Optimize",pathLocale:"/",contents:[]},{path:"/Gameplay/AI/Movement/",title:"Movement",pathLocale:"/",contents:[]},{path:"/Gameplay/AI/%E6%B8%B8%E6%88%8FAI%E8%AF%BE%E7%A8%8B/",title:"游戏 AI课程",pathLocale:"/",contents:[]},{path:"/Graphic/basic/geometry/",title:"Geometry",pathLocale:"/",contents:[]},{path:"/Graphic/basic/math/",title:"Math",pathLocale:"/",contents:[]},{path:"/Graphic/basic/shading/",title:"Shading",pathLocale:"/",contents:[]},{path:"/Graphic/basic/textureformat/",title:"Textureformat",pathLocale:"/",contents:[]},{path:"/GameEngine/Unity/manual/animation/",title:"Animation",pathLocale:"/",contents:[]},{path:"/GameEngine/Unity/manual/editor/",title:"Editor",pathLocale:"/",contents:[]},{path:"/GameEngine/Unity/manual/normal/",title:"Normal",pathLocale:"/",contents:[]},{path:"/GameEngine/Unity/manual/optimize/",title:"Optimize",pathLocale:"/",contents:[]},{path:"/GameEngine/Unity/manual/reader/",title:"Reader",pathLocale:"/",contents:[]},{path:"/GameEngine/Unity/manual/tools/",title:"Tools",pathLocale:"/",contents:[]},{path:"/category/",title:"Category",pathLocale:"/",contents:[]},{path:"/tag/",title:"Tag",pathLocale:"/",contents:[]},{path:"/tag/animation/",title:"Tag: Animation",pathLocale:"/",contents:[]},{path:"/tag/software-engineering/",title:"Tag: Software Engineering",pathLocale:"/",contents:[]},{path:"/tag/career/",title:"Tag: Career",pathLocale:"/",contents:[]},{path:"/tag/graphic/",title:"Tag: Graphic",pathLocale:"/",contents:[]},{path:"/tag/linux/",title:"Tag: Linux",pathLocale:"/",contents:[]},{path:"/tag/ai/",title:"Tag: AI",pathLocale:"/",contents:[]},{path:"/tag/tools/",title:"Tag: Tools",pathLocale:"/",contents:[]},{path:"/tag/c__/",title:"Tag: C++",pathLocale:"/",contents:[]},{path:"/tag/windows/",title:"Tag: Windows",pathLocale:"/",contents:[]},{path:"/tag/web/",title:"Tag: Web",pathLocale:"/",contents:[]},{path:"/tag/c_/",title:"Tag: C#",pathLocale:"/",contents:[]},{path:"/tag/d3d/",title:"Tag: D3D",pathLocale:"/",contents:[]},{path:"/tag/physics/",title:"Tag: Physics",pathLocale:"/",contents:[]},{path:"/tag/math/",title:"Tag: Math",pathLocale:"/",contents:[]},{path:"/tag/opengl/",title:"Tag: OpenGL",pathLocale:"/",contents:[]},{path:"/tag/asset-file/",title:"Tag: Asset File",pathLocale:"/",contents:[]},{path:"/tag/os/",title:"Tag: OS",pathLocale:"/",contents:[]},{path:"/tag/network/",title:"Tag: Network",pathLocale:"/",contents:[]},{path:"/tag/memory/",title:"Tag: Memory",pathLocale:"/",contents:[]},{path:"/tag/concurrency/",title:"Tag: Concurrency",pathLocale:"/",contents:[]},{path:"/tag/godot/",title:"Tag: Godot",pathLocale:"/",contents:[]},{path:"/tag/unreal-engine/",title:"Tag: Unreal Engine",pathLocale:"/",contents:[]},{path:"/tag/interview/",title:"Tag: Interview",pathLocale:"/",contents:[]},{path:"/tag/game-ai/",title:"Tag: Game AI",pathLocale:"/",contents:[]},{path:"/tag/gameplay/",title:"Tag: Gameplay",pathLocale:"/",contents:[]},{path:"/tag/project/",title:"Tag: Project",pathLocale:"/",contents:[]},{path:"/tag/optimization/",title:"Tag: Optimization",pathLocale:"/",contents:[]},{path:"/tag/golang/",title:"Tag: Golang",pathLocale:"/",contents:[]},{path:"/tag/java/",title:"Tag: Java",pathLocale:"/",contents:[]},{path:"/tag/unity/",title:"Tag: Unity",pathLocale:"/",contents:[]},{path:"/article/",title:"Articles",pathLocale:"/",contents:[]},{path:"/star/",title:"Star",pathLocale:"/",contents:[]},{path:"/timeline/",title:"Timeline",pathLocale:"/",contents:[]},{path:"/recent-updated/",title:"Recent Updated",pathLocale:"/",contents:[]}],q="update-vuepress-plugin-full-text-search2-search-index";var S=f(O),W=C(()=>{const e=new Map;for(const t of S.value)e.set(t.path,t);return e});import.meta.webpackHot&&(__VUE_HMR_RUNTIME__[q]=e=>{S.value=e});function H(e){const t=f([]);let s=null;return x(e,()=>{s&&clearTimeout(s),s=setTimeout(i,100)}),t;function i(){const c=e.value.toLowerCase().trim();if(!c){t.value=[];return}const o=new Map,a=new Set;for(const n of S.value)for(const r of z(n,c)){a.add(r.parentPageTitle);let l=o.get(r.parentPageTitle);l||(l=[],o.set(r.parentPageTitle,l)),l.push(r)}const d=[...a].sort((n,r)=>{const l=o.get(n);return o.get(r).length-l.length});t.value=[...o].flatMap(([,n])=>n).sort((n,r)=>n.parentPagePriority-r.parentPagePriority||d.indexOf(n.parentPageTitle)-d.indexOf(r.parentPageTitle)||n.priority-r.priority)}}function*z(e,t){const s=T(e.title,t);if(s){yield{path:e.path,parentPageTitle:A(e),title:e.title,display:s,page:e,content:null,parentPagePriority:1,priority:1};return}for(const i of e.contents){const c=T(i.header,t);if(c){yield{path:e.path+(i.slug?`#${i.slug}`:""),parentPageTitle:A(e),title:e.title,display:c,page:e,content:null,parentPagePriority:10,priority:2};continue}const o=T(i.content,t);o&&(yield{path:e.path+(i.slug?`#${i.slug}`:""),parentPageTitle:A(e),title:e.title,display:[{type:"header",str:`${i.header}
`},...o],page:e,content:null,parentPagePriority:10,priority:10})}}function A(e){const t=e.path.split("/");let s="/";return t[1]&&(s=`/${t[1]}/`),(W.value.get(s)||e).title}function T(e,t){const s=[];let i=0;const c=e.toLowerCase().replace(/\s/gu," ");let o=0,a=c.indexOf(t,o);if(a<0)return null;for(;a>=0;){const n=a+t.length;if(d(e.slice(o,a),"normal"),d(e.slice(a,n),"highlight"),o=n,a=c.indexOf(t,o),i>100)break}return d(e.slice(o),"normal"),s.filter(n=>n.str);function d(n,r){let l=n;r==="normal"&&l.length>100&&i===0&&(l=`… ${l.slice(-10)}`);let p=!1;if(i+l.length>100){if(s.some(g=>g.type==="ellipsis"))return;l=l.slice(0,Math.max(100-i,1)),p=!0}s.push({type:r,str:l}),i+=l.length,p&&(s.push({type:"ellipsis",str:" …"}),i+=2)}}var j={};const V=j,$=R({name:"SearchBox",props:{locales:{type:Object,required:!1,default:()=>V}},setup(e){const{locales:t}=M(e),s=f(""),i=f(!1),c=f(-1),o=H(s),a=C(()=>s.value&&i.value&&o.value.length),d=L(),n=F(),r=C(()=>t.value[n.value]??{});function l(){if(!a.value)return;let h=c.value-1;h<0&&(h=o.value.length-1),g(h)}function p(){if(!a.value)return;let h=c.value+1;h>=o.value.length&&(h=0),g(h)}function g(h){c.value=h}function P(){c.value=-1}function D(h){if(!a.value)return;const k=o.value[h];k&&d.push(k.path)}return{query:s,focused:i,focusIndex:c,suggestions:o,activeSuggestion:a,onUp:l,onDown:p,focus:g,unfocus:P,go:D,locale:r}}}),Y={class:"search-box",role:"search"},K=["placeholder"],Q=["onMousedown","onMouseenter"],X=["href"],J={key:0,class:"parent-page-title"},Z={class:"suggestion-row"},ee={class:"page-title"},te={class:"suggestion-content"};function ae(e,t,s,i,c,o){return u(),m("div",Y,[N(y("input",{ref:"input","onUpdate:modelValue":t[0]||(t[0]=a=>e.query=a),"aria-label":"Search",class:b({focused:e.focused}),placeholder:e.locale.placeholder??"Search",autocomplete:"off",spellcheck:"false",onFocus:t[1]||(t[1]=()=>e.focused=!0),onBlur:t[2]||(t[2]=()=>e.focused=!1),onKeyup:[t[3]||(t[3]=w(a=>e.go(e.focusIndex),["enter"])),t[4]||(t[4]=w((...a)=>e.onUp&&e.onUp(...a),["up"])),t[5]||(t[5]=w((...a)=>e.onDown&&e.onDown(...a),["down"]))]},null,42,K),[[_,e.query]]),e.activeSuggestion?(u(),m("ul",{key:0,class:"suggestions",onMouseleave:t[7]||(t[7]=(...a)=>e.unfocus&&e.unfocus(...a))},[(u(!0),m(G,null,I(e.suggestions,(a,d)=>(u(),m("li",{key:d,class:b(["suggestion",{focused:d===e.focusIndex}]),onMousedown:n=>e.go(d),onMouseenter:n=>e.focus(d)},[y("a",{href:a.path,onClick:t[6]||(t[6]=U(()=>{},["prevent"]))},[a.parentPageTitle&&(!e.suggestions[d-1]||e.suggestions[d-1].parentPageTitle!==a.parentPageTitle)?(u(),m("div",J,v(a.parentPageTitle),1)):E("v-if",!0),y("div",Z,[y("div",ee,v(a.title||a.path),1),y("div",te,[(u(!0),m(G,null,I(a.display,(n,r)=>(u(),m("span",{key:r,class:b(n.type)},v(n.str),3))),128))])])],8,X)],42,Q))),128))],32)):E("v-if",!0)])}const oe=B($,[["render",ae],["__scopeId","data-v-11a6bb44"],["__file","SearchBox.vue"]]);export{oe as default};
